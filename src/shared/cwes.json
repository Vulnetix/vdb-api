[
    {
        "cwe": "1004",
        "name": "Sensitive Cookie Without 'HttpOnly' Flag",
        "description": "The product uses a cookie to store sensitive information, but the cookie is not marked with the HttpOnly flag.",
        "detail": "**Extended Description:**\nThe HttpOnly flag directs compatible browsers to prevent client-side script from accessing cookies. Including the HttpOnly flag in the Set-Cookie HTTP response header helps mitigate the risk associated with Cross-Site Scripting (XSS) where an attacker's script code might attempt to read the contents of a cookie and exfiltrate information obtained. When set, browsers that support the flag will not reveal the contents of the cookie to a third party via client-side script executed via XSS.\n\n**Background Details:**\n[\"An HTTP cookie is a small piece of data attributed to a specific website and stored on the user's computer by the user's web browser. This data can be leveraged for a variety of purposes including saving information entered into form fields, recording user activity, and for authentication purposes. Cookies used to save or record information generated by the user are accessed and modified by script code embedded in a web page. While cookies used for authentication are created by the website's server and sent to the user to be attached to future requests. These authentication cookies are often not meant to be accessed by the web page sent to the user, and are instead just supposed to be attached to future requests to verify authentication details.\"]\n\n**Consequence Note:** If the HttpOnly flag is not set, then sensitive information stored in the cookie may be exposed to unintended parties.\n\n**Consequence Note:** If the cookie in question is an authentication cookie, then not setting the HttpOnly flag may allow an adversary to steal authentication data (e.g., a session ID) and assume the identity of the user.\n",
        "parent": [
            "732"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Leverage the HttpOnly flag when setting a sensitive cookie in a response.\n\n**Effectiveness:** While this mitigation is effective for protecting cookies from a browser's own scripting engine, third-party components or plugins may have their own engines that allow access to cookies. Attackers might also be able to use XMLHTTPResponse to read the headers directly and obtain the cookie.\n",
        "languages": []
    },
    {
        "cwe": "1007",
        "name": "Insufficient Visual Distinction of Homoglyphs Presented to User",
        "description": "The product displays information or identifiers to a user, but the display mechanism does not make it easy for the user to distinguish between visually similar or identical glyphs (homoglyphs), which may cause the user to misinterpret a glyph and perform an unintended, insecure action.",
        "detail": "**Extended Description:**\n\n\nSome glyphs, pictures, or icons can be semantically distinct to a program, while appearing very similar or identical to a human user. These are referred to as homoglyphs. For example, the lowercase \"l\" (ell) and uppercase \"I\" (eye) have different character codes, but these characters can be displayed in exactly the same way to a user, depending on the font. This can also occur between different character sets. For example, the Latin capital letter \"A\" and the Greek capital letter \"Α\" (Alpha) are treated as distinct by programs, but may be displayed in exactly the same way to a user. Accent marks may also cause letters to appear very similar, such as the Latin capital letter grave mark \"À\" and its equivalent \"Á\" with the acute accent.\n\n\nAdversaries can exploit this visual similarity for attacks such as phishing, e.g. by providing a link to an attacker-controlled hostname that looks like a hostname that the victim trusts. In a different use of homoglyphs, an adversary may create a back door username that is visually similar to the username of a regular user, which then makes it more difficult for a system administrator to detect the malicious username while reviewing logs.\n\n\n**Alternate Terms:** Homograph Attack\n\n**Mode of Introduction:** This weakness may occur when characters from various character sets are allowed to be interchanged within a URL, username, email address, etc. without any notification to the user or underlying system being used.\n\n**Consequence Note:** An attacker may ultimately redirect a user to a malicious website, by deceiving the user into believing the URL they are accessing is a trusted domain. However, the attack can also be used to forge log entries by using homoglyphs in usernames. Homoglyph manipulations are often the first step towards executing advanced attacks such as stealing a user's credentials, Cross-Site Scripting (XSS), or log forgery. If an attacker redirects a user to a malicious site, the attacker can mimic a trusted domain to steal account credentials and perform actions on behalf of the user, without the user's knowledge. Similarly, an attacker could create a username for a website that contains homoglyph characters, making it difficult for an admin to review logs and determine which users performed which actions.\n",
        "parent": [
            "451"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** If utilizing user accounts, attempt to submit a username that contains homoglyphs. Similarly, check to see if links containing homoglyphs can be sent via email, web browsers, or other mechanisms.\n\n**Mitigation:** \n\nUse a browser that displays Punycode for IDNs in the URL and status bars, or which color code various scripts in URLs.\n\n\nDue to the prominence of homoglyph attacks, several browsers now help safeguard against this attack via the use of Punycode. For example, Mozilla Firefox and Google Chrome will display IDNs as Punycode if top-level domains do not restrict which characters can be used in domain names or if labels mix scripts for different languages.\n\n\n**Mitigation:** \n\nUse an email client that has strict filters and prevents messages that mix character sets to end up in a user's inbox.\n\n\nCertain email clients such as Google's GMail prevent the use of non-Latin characters in email addresses or in links contained within emails. This helps prevent homoglyph attacks by flagging these emails and redirecting them to a user's spam folder.\n\n",
        "languages": []
    },
    {
        "cwe": "102",
        "name": "Struts: Duplicate Validation Forms",
        "description": "The product uses multiple validation forms with the same name, which might cause the Struts Validator to validate a form that the programmer does not expect.",
        "detail": "**Extended Description:**\nIf two validation forms have the same name, the Struts Validator arbitrarily chooses one of the forms to use for input validation and discards the other. This decision might not correspond to the programmer's expectations, possibly leading to resultant weaknesses. Moreover, it indicates that the validation logic is not up-to-date, and can indicate that other, more subtle validation errors are present.\n",
        "parent": [
            "1173",
            "20",
            "694"
        ],
        "children": [],
        "related": [
            "675"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** The DTD or schema validation will not catch the duplicate occurrence of the same form name. To find the issue in the implementation, manual checks or automated static analysis could be applied to the xml configuration files.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1021",
        "name": "Improper Restriction of Rendered UI Layers or Frames",
        "description": "The web application does not restrict or incorrectly restricts frame objects or UI layers that belong to another application or domain, which can lead to user confusion about which interface the user is interacting with.",
        "detail": "**Extended Description:**\nA web application is expected to place restrictions on whether it is allowed to be rendered within frames, iframes, objects, embed or applet elements. Without the restrictions, users can be tricked into interacting with the application when they were not intending to.\n\n**Alternate Terms:** Clickjacking, UI Redress Attack, Tapjacking\n\n**Consequence Note:** An attacker can trick a user into performing actions that are masked and hidden from the user's view. The impact varies widely, depending on the functionality of the underlying application. For example, in a social media application, clickjacking could be used to trik the user into changing privacy settings.\n",
        "parent": [
            "441",
            "451",
            "610"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nThe use of X-Frame-Options allows developers of web content to restrict the usage of their application within the form of overlays, frames, or iFrames. The developer can indicate from which domains can frame the content.\n\n\nThe concept of X-Frame-Options is well documented, but implementation of this protection mechanism is in development to cover gaps. There is a need for allowing frames from multiple domains.\n\n\n**Mitigation:** \n\nA developer can use a \"frame-breaker\" script in each page that should not be framed. This is very helpful for legacy browsers that do not support X-Frame-Options security feature previously mentioned.\n\n\nIt is also important to note that this tactic has been circumvented or bypassed. Improper usage of frames can persist in the web application through nested frames. The \"frame-breaking\" script does not intuitively account for multiple nested frames that can be presented to the user.\n\n\n**Mitigation:** This defense-in-depth technique can be used to prevent the improper usage of frames in web applications. It prioritizes the valid sources of data to be loaded into the application through the usage of declarative policies. Based on which implementation of Content Security Policy is in use, the developer should use the \"frame-ancestors\" directive or the \"frame-src\" directive to mitigate this weakness. Both directives allow for the placement of restrictions when it comes to allowing embedded content.\n",
        "languages": []
    },
    {
        "cwe": "1022",
        "name": "Use of Web Link to Untrusted Target with window.opener Access",
        "description": "The web application produces links to untrusted external sites outside of its sphere of control, but it does not properly prevent the external site from modifying  security-critical properties of the window.opener object, such as the location property.",
        "detail": "**Extended Description:**\nWhen a user clicks a link to an external site (\"target\"), the target=\"_blank\" attribute causes the target site's contents to be opened in a new window or tab, which runs in the same process as the original page. The window.opener object records information about the original page that offered the link. If an attacker can run script on the target page, then they could read or modify certain properties of the window.opener object, including the location property - even if the original and target site are not the same origin. An attacker can modify the location property to automatically redirect the user to a malicious site, e.g. as part of a phishing attack. Since this redirect happens in the original window/tab - which is not necessarily visible, since the browser is focusing the display on the new target page - the user might not notice any suspicious redirection.\n\n**Alternate Terms:** tabnabbing\n\n**Mode of Introduction:** This weakness is introduced during the design of an application when the architect does not specify that a linked external document should not be able to alter the location of the calling page.\n\n**Mode of Introduction:** This weakness is introduced during the coding of an application when the developer does not include the noopener and/or noreferrer value for the rel attribute.\n\n**Consequence Note:** The user may be redirected to an untrusted page that contains undesired content or malicious script code.\n",
        "parent": [
            "266"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Specify in the design that any linked external document must not be granted access to the location object of the calling page.\n\n**Mitigation:** \n\nWhen creating a link to an external document using the <a> tag with a defined target, for example \"_blank\" or a named frame, provide the rel attribute with a value \"noopener noreferrer\".\n\n\nIf opening the external document in a new window via javascript, then reset the opener by setting it equal to null.\n\n\n**Mitigation:** \n\nDo not use \"_blank\" targets. However, this can affect the usability of the application.\n\n",
        "languages": [
            "JavaScript"
        ]
    },
    {
        "cwe": "1023",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "478"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1024",
        "name": "Comparison of Incompatible Types",
        "description": "The product performs a comparison between two entities, but the entities are of different, incompatible types that cannot be guaranteed to provide correct results when they are directly compared.",
        "detail": "**Extended Description:**\nIn languages that are strictly typed but support casting/conversion, such as C or C++, the programmer might assume that casting one entity to the same type as another entity will ensure that the comparison will be performed correctly, but this cannot be guaranteed. In languages that are not strictly typed, such as PHP or JavaScript, there may be implicit casting/conversion to a type that the programmer is unaware of, causing unexpected results; for example, the string \"123\" might be converted to a number type. See examples.\n",
        "parent": [
            "697"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.\n",
        "languages": [
            "JavaScript",
            "PHP"
        ]
    },
    {
        "cwe": "1025",
        "name": "Comparison Using Wrong Factors",
        "description": "The code performs a comparison between two entities, but the comparison examines the wrong factors or characteristics of the entities, which can lead to incorrect results and resultant weaknesses.",
        "detail": "**Extended Description:**\nThis can lead to incorrect results and resultant weaknesses. For example, the code might inadvertently compare references to objects, instead of the relevant contents of those objects, causing two \"equal\" objects to be considered unequal.\n",
        "parent": [
            "697"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Thoroughly test the comparison scheme before deploying code into production. Perform positive testing as well as negative testing.\n",
        "languages": []
    },
    {
        "cwe": "103",
        "name": "Struts: Incomplete validate() Method Definition",
        "description": "The product has a validator form that either does not define a validate() method, or defines a validate() method but does not call super.validate().",
        "detail": "**Extended Description:**\nIf the code does not call super.validate(), the Validation Framework cannot check the contents of the form against a validation form. In other words, the validation framework will be disabled for the given form.\n\n**Background Details:**\n[\"The Struts Validator uses a form's validate() method to check the contents of the form properties against the constraints specified in the associated validation form. That means the following classes have a validate() method that is part of the validation framework: ValidatorForm, ValidatorActionForm, DynaValidatorForm, and DynaValidatorActionForm. If the code creates a class that extends one of these classes, and if that class implements custom validation logic by overriding the validate() method, the code must call super.validate() in the validate() implementation.\"]\n\n**Consequence Note:** Disabling the validation framework for a form exposes the product to numerous types of attacks. Unchecked input is the root cause of vulnerabilities like cross-site scripting, process control, and SQL injection.\n\n**Consequence Note:** Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.\n",
        "parent": [
            "20",
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Implement the validate() method and call super.validate() within that method.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1037",
        "name": "Processor Optimization Removal or Modification of Security-critical Code",
        "description": "The developer builds a security-critical protection mechanism into the software, but the processor optimizes the execution of the program such that the mechanism is removed or modified.",
        "detail": "**Mode of Introduction:** Optimizations built into the design of the processor can have unintended consequences during the execution of an application.\n\n**Consequence Note:** A successful exploitation of this weakness will change the order of an application's execution and will likely be used to bypass specific protection mechanisms. This bypass can be exploited further to potentially read data that should otherwise be unaccessible.\n",
        "parent": [
            "1038"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** In theory this weakness can be detected through the use of white box testing techniques where specifically crafted test cases are used in conjunction with debuggers to verify the order of statements being executed.\n",
        "languages": []
    },
    {
        "cwe": "1038",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1037",
            "733"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1039",
        "name": "Inadequate Detection or Handling of Adversarial Input Perturbations in Automated Recognition Mechanism",
        "description": "The product uses an automated mechanism such as machine learning to recognize complex data inputs (e.g. image or audio) as a particular concept or category, but it does not properly detect or handle inputs that have been modified or constructed in a way that causes the mechanism to detect a different, incorrect concept.",
        "detail": "**Extended Description:**\n\n\nWhen techniques such as machine learning are used to automatically classify input streams, and those classifications are used for security-critical decisions, then any mistake in classification can introduce a vulnerability that allows attackers to cause the product to make the wrong security decision or disrupt service of the automated mechanism. If the mechanism is not developed or \"trained\" with enough input data or has not adequately undergone test and evaluation, then attackers may be able to craft malicious inputs that intentionally trigger the incorrect classification.\n\n\nTargeted technologies include, but are not necessarily limited to:\n\n\n  - automated speech recognition\n\n  - automated image recognition\n\n  - automated cyber defense\n\n  - Chatbot, LLMs, generative AI\n\nFor example, an attacker might modify road signs or road surface markings to trick autonomous vehicles into misreading the sign/marking and performing a dangerous action. Another example includes an attacker that crafts highly specific and complex prompts to \"jailbreak\" a chatbot to bypass safety or privacy mechanisms, better known as prompt injection attacks.\n\n**Mode of Introduction:** This issue can be introduced into the automated algorithm itself due to inadequate training data used as well as lack of validation, verification, testing, and evaluation of the algorithm. These factors can affect the overall robustness of the algorithm when introduced into operational settings.\n\n**Mode of Introduction:** The developer might not apply external validation of inputs into the algorithm.\n\n**Consequence Note:** When the automated recognition is used in a protection mechanism, an attacker may be able to craft inputs that are misinterpreted in a way that grants excess privileges.\n\n**Consequence Note:** There could be disruption to the service of the automated recognition system, which could cause further downstream failures of the software.\n\n**Consequence Note:** This weakness could lead to breaches of data privacy through exposing features of the training data, e.g., by using membership inference attacks or prompt injection attacks.\n\n**Consequence Note:** The consequences depend on how the application applies or integrates the affected algorithm.\n",
        "parent": [
            "693",
            "697"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Use indicators from model performance deviations such as sudden drops in accuracy or unexpected outputs to verify the model.\n\n**Detection:** Use indicators from input data collection mechanisms to verify that inputs are statistically within the distribution of the training and test data.\n\n**Detection:** Use multiple models or model ensembling techniques to check for consistency of predictions/inferences.\n\n**Mitigation:** Algorithmic modifications such as model pruning or compression can help mitigate this weakness. Model pruning ensures that only weights that are most relevant to the task are used in the inference of incoming data and has shown resilience to adversarial perturbed data.\n\n**Mitigation:** Consider implementing adversarial training, a method that introduces adversarial examples into the training data to promote robustness of algorithm at inference time.\n\n**Mitigation:** Consider implementing model hardening to fortify the internal structure of the algorithm, including techniques such as regularization and optimization to desensitize algorithms to minor input perturbations and/or changes.\n\n**Mitigation:** Consider implementing multiple models or using model ensembling techniques to improve robustness of individual model weaknesses against adversarial input perturbations.\n\n**Mitigation:** Incorporate uncertainty estimations into the algorithm that trigger human intervention or secondary/fallback software when reached. This could be when inference predictions and confidence scores are abnormally high/low comparative to expected model performance.\n\n**Mitigation:** Reactive defenses such as input sanitization, defensive distillation, and input transformations can all be implemented before input data reaches the algorithm for inference.\n\n**Mitigation:** Consider reducing the output granularity of the inference/prediction such that attackers cannot gain additional information due to leakage in order to craft adversarially perturbed data.\n",
        "languages": []
    },
    {
        "cwe": "104",
        "name": "Struts: Form Bean Does Not Extend Validation Class",
        "description": "If a form bean does not extend an ActionForm subclass of the Validator framework, it can expose the application to other weaknesses related to insufficient input validation.",
        "detail": "**Background Details:**\n['In order to use the Struts Validator, a form must extend one of the following: ValidatorForm, ValidatorActionForm, DynaValidatorActionForm, and DynaValidatorForm. One of these classes must be extended because the Struts Validator ties in to the application by implementing the validate() method in these classes. Forms derived from the ActionForm and DynaActionForm classes cannot use the Struts Validator.']\n\n**Consequence Note:** Bypassing the validation framework for a form exposes the application to numerous types of attacks. Unchecked input is an important component of vulnerabilities like cross-site scripting, process control, and SQL injection.\n\n**Consequence Note:** Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.\n",
        "parent": [
            "20",
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Ensure that all forms extend one of the Validation Classes.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1045",
        "name": "Parent Class with a Virtual Destructor and a Child Class without a Virtual Destructor",
        "description": "A parent class has a virtual destructor method, but the parent has a child class that does not have a virtual destructor.",
        "detail": "**Extended Description:**\n\n\nThis issue can prevent the product from running reliably, since the child might not perform essential destruction operations. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability, such as a memory leak (CWE-401).\n\n",
        "parent": [
            "1076"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1046",
        "name": "Creation of Immutable Text Using String Concatenation",
        "description": "The product creates an immutable text string using string concatenation operations.",
        "detail": "**Extended Description:**\n\n\nWhen building a string via a looping feature (e.g., a FOR or WHILE loop), the use of += to append to the existing string will result in the creation of a new object with each iteration. This programming pattern can be inefficient in comparison with use of text buffer data elements. This issue can make the product perform more slowly. If the relevant code is reachable by an attacker, then this could be influenced to create performance problem.\n\n",
        "parent": [
            "1176"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1049",
        "name": "Excessive Data Query Operations in a Large Data Table",
        "description": "The product performs a data query with a large number of joins\n\t\t\t\t\tand sub-queries on a large data table.",
        "detail": "**Extended Description:**\n\n\nThis issue can make the product perform more slowly. If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.\n\n\nWhile the interpretation of \"large data table\" and \"large number of joins or sub-queries\" may vary for each product or developer, CISQ recommends a default of 1 million rows for a \"large\" data table, a default minimum of 5 joins, and a default minimum of 3 sub-queries.\n\n",
        "parent": [
            "1176"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "105",
        "name": "Struts: Form Field Without Validator",
        "description": "The product has a form field that is not validated by a corresponding validation form, which can introduce other weaknesses related to insufficient input validation.",
        "detail": "**Extended Description:**\nOmitting validation for even a single input field may give attackers the leeway they need to compromise the product. Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.\n\n**Mode of Introduction:** Some products use the same ActionForm for more than one purpose. In situations like this, some fields may go unused under some action mappings.\n\n**Consequence Note:** If unused fields are not validated, shared business logic in an action may allow attackers to bypass the validation checks that are performed for other uses of the form.\n",
        "parent": [
            "1173",
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Validate all form fields. If a field is unused, it is still important to constrain it so that it is empty or undefined.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1050",
        "name": "Excessive Platform Resource Consumption within a Loop",
        "description": "The product has a loop body or loop condition that contains a control element that directly or\n\t\t\t\t\tindirectly consumes platform resources, e.g. messaging, sessions, locks, or file\n\t\t\t\t\tdescriptors.",
        "detail": "**Extended Description:**\n\n\nThis issue can make the product perform more slowly. If an attacker can influence the number of iterations in the loop, then this performance problem might allow a denial of service by consuming more platform resources than intended.\n\n",
        "parent": [
            "405"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1052",
        "name": "Excessive Use of Hard-Coded Literals in Initialization",
        "description": "The product initializes a data element using a hard-coded\n\t\t\t\t\tliteral that is not a simple integer or static constant element.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to modify or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "1419"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1058",
        "name": "Invokable Control Element in Multi-Thread Context with non-Final Static Storable or Member Element",
        "description": "The code contains a function or method that\n\t\t operates in a multi-threaded environment but owns an unsafe non-final\n\t\t                     static storable or member data element.",
        "detail": "**Extended Description:**\n\n\nThis issue can prevent the product from running reliably. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.\n\n",
        "parent": [
            "662"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "106",
        "name": "Struts: Plug-in Framework not in Use",
        "description": "When an application does not use an input validation framework such as the Struts Validator, there is a greater risk of introducing weaknesses related to insufficient input validation.",
        "detail": "**Extended Description:**\n\n\nUnchecked input is the leading cause of vulnerabilities in J2EE applications. Unchecked input leads to cross-site scripting, process control, and SQL injection vulnerabilities, among others.\n\n\nAlthough J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.\n\n",
        "parent": [
            "1173",
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use an input validation framework such as Struts.\n\n**Mitigation:** Use an input validation framework such as Struts.\n\n**Mitigation:** \n\nUse the Struts Validator to validate all program input before it is processed by the application. Ensure that there are no holes in the configuration of the Struts Validator. Example uses of the validator include checking to ensure that:\n\n\n  - Phone number fields contain only valid characters in phone numbers\n\n  - Boolean values are only \"T\" or \"F\"\n\n  - Free-form strings are of a reasonable length and composition\n\n\n\n**Mitigation:** \n\nUse the Struts Validator to validate all program input before it is processed by the application. Ensure that there are no holes in the configuration of the Struts Validator. Example uses of the validator include checking to ensure that:\n\n\n  - Phone number fields contain only valid characters in phone numbers\n\n  - Boolean values are only \"T\" or \"F\"\n\n  - Free-form strings are of a reasonable length and composition\n\n\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1061",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1100",
            "766"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1067",
        "name": "Excessive Execution of Sequential Searches of Data Resource",
        "description": "The product contains a data query against an SQL table or view\n\t\t\t\t\tthat is configured in a way that does not utilize an index and may cause\n\t\t\t\t\tsequential searches to be performed.",
        "detail": "**Extended Description:**\n\n\nThis issue can make the product perform more slowly. If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.\n\n",
        "parent": [
            "1176"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "107",
        "name": "Struts: Unused Validation Form",
        "description": "An unused validation form indicates that validation logic is not up-to-date.",
        "detail": "**Extended Description:**\nIt is easy for developers to forget to update validation logic when they remove or rename action form mappings. One indication that validation logic is not being properly maintained is the presence of an unused validation form.\n",
        "parent": [
            "1164",
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Remove the unused Validation Form from the validation.xml file.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1071",
        "name": "Empty Code Block",
        "description": "The source code contains a block that does not contain any code, i.e., the block is empty.",
        "detail": "**Extended Description:**\n\n\nEmpty code blocks can occur in the bodies of conditionals, function or method definitions, exception handlers, etc. While an empty code block might be intentional, it might also indicate incomplete implementation, accidental code deletion, unexpected macro expansion, etc. For some programming languages and constructs, an empty block might be allowed by the syntax, but the lack of any behavior within the block might violate a convention or API in such a way that it is an error.\n\n",
        "parent": [
            "1164"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1075",
        "name": "Unconditional Control Flow Transfer outside of Switch Block",
        "description": "The product performs unconditional control transfer (such as a\n\t\t\t\t\t\"goto\") in code outside of a branching structure such as a switch\n\t\t\t\t\tblock.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "1120"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1076",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1045",
            "1087",
            "1098",
            "1108",
            "586"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1077",
        "name": "Floating Point Comparison with Incorrect Operator",
        "description": "The code performs a comparison such as an\n        equality test between two float (floating point) values, but\n        it uses comparison operators that do not account for the\n        possibility of loss of precision.",
        "detail": "**Extended Description:**\n\n\nNumeric calculation using floating point values can generate imprecise results because of rounding errors. As a result, two different calculations might generate numbers that are mathematically equal, but have slightly different bit representations that do not translate to the same mathematically-equal values. As a result, an equality test or other comparison might produce unexpected results.\n\n\nThis issue can prevent the product from running reliably. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.\n\n",
        "parent": [
            "697"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1078",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1116",
            "547"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1079",
        "name": "Parent Class without Virtual Destructor Method",
        "description": "A parent class contains one or more child classes, but the parent class does not have a virtual destructor method.",
        "detail": "**Extended Description:**\n\n\nThis issue can prevent the product from running reliably due to undefined or unexpected behaviors. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.\n\n",
        "parent": [
            "1076"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "108",
        "name": "Struts: Unvalidated Action Form",
        "description": "Every Action Form must have a corresponding validation form.",
        "detail": "**Extended Description:**\nIf a Struts Action Form Mapping specifies a form, it must have a validation form defined under the Struts Validator.\n\n**Consequence Note:** If an action form mapping does not have a validation form defined, it may be vulnerable to a number of attacks that rely on unchecked input. Unchecked input is the root cause of some of today's worst and most common software security problems. Cross-site scripting, SQL injection, and process control vulnerabilities all stem from incomplete or absent input validation.\n\n**Consequence Note:** Although J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.\n",
        "parent": [
            "1173",
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nMap every Action Form to a corresponding validation form.\n\n\nAn action or a form may perform validation in other ways, but the Struts Validator provides an excellent way to verify that all input receives at least a basic level of validation. Without this approach, it is difficult, and often impossible, to establish with a high level of confidence that all input is validated.\n\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1087",
        "name": "Class with Virtual Method without a Virtual Destructor",
        "description": "A class contains a virtual method, but the method does not have an associated virtual destructor.",
        "detail": "**Extended Description:**\n\n\nThis issue can prevent the product from running reliably, e.g. due to undefined behavior. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.\n\n",
        "parent": [
            "1076"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1088",
        "name": "Synchronous Access of Remote Resource without Timeout",
        "description": "The code has a synchronous call to a remote resource, but there is no timeout for the call, or the timeout is set to infinite.",
        "detail": "**Extended Description:**\n\n\nThis issue can prevent the product from running reliably, since an outage for the remote resource can cause the product to hang. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.\n\n",
        "parent": [
            "821"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1089",
        "name": "Large Data Table with Excessive Number of Indices",
        "description": "The product uses a large data table that contains an excessively large number of\n\t\t\t\t\tindices.",
        "detail": "**Extended Description:**\n\n\nThis issue can make the product perform more slowly. If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.\n\n\nWhile the interpretation of \"large data table\" and \"excessively large number of indices\" may vary for each product or developer, CISQ recommends a default threshold of 1000000 rows for a \"large\" table and a default threshold of 3 indices.\n\n",
        "parent": [
            "405"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "109",
        "name": "Struts: Validator Turned Off",
        "description": "Automatic filtering via a Struts bean has been turned off, which disables the Struts Validator and custom validation logic. This exposes the application to other weaknesses related to insufficient input validation.",
        "detail": null,
        "parent": [
            "1173",
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Ensure that an action form mapping enables validation. Set the validate field to true.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1091",
        "name": "Use of Object without Invoking Destructor Method",
        "description": "The product contains a method that accesses an object but does not later invoke\n\t\t\t\t\tthe element's associated finalize/destructor method.",
        "detail": "**Extended Description:**\n\n\nThis issue can make the product perform more slowly by retaining memory and/or other resources longer than necessary. If the relevant code is reachable by an attacker, then this performance problem might introduce a vulnerability.\n\n",
        "parent": [
            "1076",
            "772"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1093",
        "name": "Excessively Complex Data Representation",
        "description": "The product uses an unnecessarily complex internal representation for its data structures or interrelationships between those structures.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to understand or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "710"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1096",
        "name": "Singleton Class Instance Creation without Proper Locking or Synchronization",
        "description": "The product implements a Singleton design pattern but does not use appropriate locking or other synchronization mechanism to ensure that the singleton class is only instantiated once.",
        "detail": "**Extended Description:**\n\n\nThis issue can prevent the product from running reliably, e.g. by making the instantiation process non-thread-safe and introducing deadlock (CWE-833) or livelock conditions. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.\n\n",
        "parent": [
            "662",
            "820"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1098",
        "name": "Data Element containing Pointer Item without Proper Copy Control Element",
        "description": "The code contains a data element with a pointer that does not have an associated copy or constructor method.",
        "detail": "**Extended Description:**\n\n\nThis issue can prevent the product from running reliably. If the relevant code is reachable by an attacker, then this reliability problem might introduce a vulnerability.\n\n",
        "parent": [
            "1076"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "11",
        "name": "ASP.NET Misconfiguration: Creating Debug Binary",
        "description": "Debugging messages help attackers learn about the system and plan a form of attack.",
        "detail": "**Extended Description:**\nASP .NET applications can be configured to produce debug binaries. These binaries give detailed debugging messages and should not be used in production environments. Debug binaries are meant to be used in a development or testing environment and can pose a security risk if they are deployed to production.\n\n**Background Details:**\n['The debug attribute of the <compilation> tag defines whether compiled binaries should include debugging information. The use of debug binaries causes an application to provide as much information about itself as possible to the user.']\n\n**Consequence Note:** Attackers can leverage the additional information they gain from debugging output to mount attacks targeted on the framework, database, or other resources used by the application.\n",
        "parent": [
            "489"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid releasing debug binaries into the production environment. Change the debug mode to false when the application is deployed into production.\n",
        "languages": [
            "ASP.NET"
        ]
    },
    {
        "cwe": "110",
        "name": "Struts: Validator Without Form Field",
        "description": "Validation fields that do not appear in forms they are associated with indicate that the validation logic is out of date.",
        "detail": "**Extended Description:**\n\n\nIt is easy for developers to forget to update validation logic when they make changes to an ActionForm class. One indication that validation logic is not being properly maintained is inconsistencies between the action form and the validation form.\n\n\nAlthough J2EE applications are not generally susceptible to memory corruption attacks, if a J2EE application interfaces with native code that does not perform array bounds checking, an attacker may be able to use an input validation mistake in the J2EE application to launch a buffer overflow attack.\n\n\n**Consequence Note:** It is critically important that validation logic be maintained and kept in sync with the rest of the application. Unchecked input is the root cause of some of today's worst and most common software security problems. Cross-site scripting, SQL injection, and process control vulnerabilities all stem from incomplete or absent input validation.\n",
        "parent": [
            "1164",
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** To find the issue in the implementation, manual checks or automated static analysis could be applied to the XML configuration files.\n\n**Detection:** To find the issue in the implementation, manual checks or automated static analysis could be applied to the XML configuration files.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1100",
        "name": "Insufficient Isolation of System-Dependent Functions",
        "description": "The product or code does not isolate system-dependent\n\t\t\t\t\tfunctionality into separate standalone modules.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to maintain and/or port the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "1061"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1102",
        "name": "Reliance on Machine-Dependent Data Representation",
        "description": "The code uses a data representation that relies on low-level\n\t\t\t\t\tdata representation or constructs that may vary across different processors,\n\t\t\t\t\tphysical machines, OSes, or other physical components.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to maintain and/or port the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "758"
        ],
        "children": [],
        "related": [
            "1105"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1104",
        "name": "Use of Unmaintained Third Party Components",
        "description": "The product relies on third-party components that are not\n\t\t\t\t\tactively supported or maintained by the original developer or a trusted proxy\n\t\t\t\t\tfor the original developer.",
        "detail": "**Extended Description:**\n\n\nReliance on components that are no longer maintained can make it difficult or impossible to fix significant bugs, vulnerabilities, or quality issues. In effect, unmaintained code can become obsolete.\n\n\nThis issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "1357"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1105",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "1102"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1108",
        "name": "Excessive Reliance on Global Variables",
        "description": "The code is structured in a way that relies too much on using\n\t\t\t\t\tor setting global variables throughout various points in the code, instead of\n\t\t\t\t\tpreserving the associated information in a narrower, more local\n\t\t\t\t\tcontext.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "1076"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "111",
        "name": "Direct Use of Unsafe JNI",
        "description": "When a Java application uses the Java Native Interface (JNI) to call code written in another programming language, it can expose the application to weaknesses in that code, even if those weaknesses cannot occur in Java.",
        "detail": "**Extended Description:**\nMany safety features that programmers may take for granted do not apply for native code, so you must carefully review all such code for potential problems. The languages used to implement native code may be more susceptible to buffer overflows and other attacks. Native code is unprotected by the security features enforced by the runtime environment, such as strong typing and array bounds checking.\n",
        "parent": [
            "20",
            "695"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Implement error handling around the JNI call.\n\n**Mitigation:** Do not use JNI calls if you don't trust the native library.\n\n**Mitigation:** Be reluctant to use JNI calls. A Java API equivalent may exist.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "1116",
        "name": "Inaccurate Comments",
        "description": "The source code contains comments that do not accurately\n\t\t\t\t\tdescribe or explain aspects of the portion of the code with which the comment is\n\t\t\t\t\tassociated.",
        "detail": "**Extended Description:**\n\n\nWhen a comment does not accurately reflect the associated code elements, this can introduce confusion to a reviewer (due to inconsistencies) or make it more difficult and less efficient to validate that the code is implementing the intended behavior correctly.\n\n\nThis issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "1078"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Verify that each comment accurately reflects what is intended to happen during execution of the code.\n",
        "languages": []
    },
    {
        "cwe": "112",
        "name": "Missing XML Validation",
        "description": "The product accepts XML from an untrusted source but does not validate the XML against the proper schema.",
        "detail": "**Extended Description:**\nMost successful attacks begin with a violation of the programmer's assumptions. By accepting an XML document without validating it against a DTD or XML schema, the programmer leaves a door open for attackers to provide unexpected, unreasonable, or malicious input.\n",
        "parent": [
            "1286",
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nAlways validate XML input against a known XML Schema or DTD.\n\n\nIt is not possible for an XML parser to validate all aspects of a document's content because a parser cannot understand the complete semantics of the data. However, a parser can do a complete and thorough job of checking the document's structure and therefore guarantee to the code that processes the document that the content is well-formed.\n\n",
        "languages": []
    },
    {
        "cwe": "1120",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1123"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1123",
        "name": "Excessive Use of Self-Modifying Code",
        "description": "The product uses too much self-modifying\n\t\t\t\t\tcode.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to understand or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "1120"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1126",
        "name": "Declaration of Variable with Unnecessarily Wide Scope",
        "description": "The source code declares a variable in one scope, but the\n\t\t\t\t\tvariable is only used within a narrower scope.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to understand and/or maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "710"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1127",
        "name": "Compilation with Insufficient Warnings or Errors",
        "description": "The code is compiled without sufficient warnings enabled, which\n\t\t\t\t\tmay prevent the detection of subtle bugs or quality\n\t\t\t\t\tissues.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n",
        "parent": [
            "710"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "113",
        "name": "Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Request/Response Splitting')",
        "description": "The product receives data from an HTTP agent/component (e.g., web server, proxy, browser, etc.), but it does not neutralize or incorrectly neutralizes CR and LF characters before the data is included in outgoing HTTP headers.",
        "detail": "**Extended Description:**\n\n\n HTTP agents or components may include a web server, load balancer, reverse proxy, web caching proxy, application firewall, web browser, etc. Regardless of the role, they are expected to maintain coherent, consistent HTTP communication state across all components. However, including unexpected data in an HTTP header allows an attacker to specify the entirety of the HTTP message that is rendered by the client HTTP agent (e.g., web browser) or back-end HTTP agent (e.g., web server), whether the message is part of a request or a response. \n\n\nWhen an HTTP request contains unexpected CR and LF characters, the server may respond with an output stream that is interpreted as \"splitting\" the stream into two different HTTP messages instead of one. CR is carriage return, also given by %0d or \\r, and LF is line feed, also given by %0a or \\n.\n\n\nIn addition to CR and LF characters, other valid/RFC compliant special characters and unique character encodings can be utilized, such as HT (horizontal tab, also given by %09 or \\t) and SP (space, also given as + sign or %20).\n\n\nThese types of unvalidated and unexpected data in HTTP message headers allow an attacker to control the second \"split\" message to mount attacks such as server-side request forgery, cross-site scripting, and cache poisoning attacks.\n\n\nHTTP response splitting weaknesses may be present when:\n\n\n  1. Data enters a web application through an untrusted source, most frequently an HTTP request.\n\n  1. The data is included in an HTTP response header sent to a web user without neutralizing malicious characters that can be interpreted as separator characters for headers.\n\n\n\n**Alternate Terms:** HTTP Request Splitting, HTTP Response Splitting\n\n**Consequence Note:** CR and LF characters in an HTTP header may give attackers control of the remaining headers and body of the message that the application intends to send/receive, as well as allowing them to create additional messages entirely under their control.\n",
        "parent": [
            "20",
            "436",
            "93"
        ],
        "children": [],
        "related": [
            "79"
        ],
        "scopes": [
            "Access Control",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Construct HTTP headers very carefully, avoiding the use of non-validated input data.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. If an input does not strictly conform to specifications, reject it or transform it into something that conforms.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "114",
        "name": "Process Control",
        "description": "Executing commands or loading libraries from an untrusted source or in an untrusted environment can cause an application to execute malicious commands (and payloads) on behalf of an attacker.",
        "detail": "**Extended Description:**\nProcess control vulnerabilities take two forms: \n\n  - An attacker can change the command that the program executes: the attacker explicitly controls what the command is.\n\n  - An attacker can change the environment in which the command executes: the attacker implicitly controls what the command means.\n\nProcess control vulnerabilities of the first type occur when either data enters the application from an untrusted source and the data is used as part of a string representing a command that is executed by the application. By executing the command, the application gives an attacker a privilege or capability that the attacker would not otherwise have.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "20",
            "73"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Libraries that are loaded should be well understood and come from a trusted source. The application can execute code contained in the native libraries, which often contain calls that are susceptible to other security problems, such as buffer overflows or command injection. All native libraries should be validated to determine if the application requires the use of the library. It is very difficult to determine what these native libraries actually do, and the potential for malicious code is high. In addition, the potential for an inadvertent mistake in these native libraries is also high, as many are written in C or C++ and may be susceptible to buffer overflow or race condition problems. To help prevent buffer overflow attacks, validate all input to native calls for content and length. If the native library does not come from a trusted source, review the source code of the library. The library should be built from the reviewed source before using it.\n",
        "languages": []
    },
    {
        "cwe": "115",
        "name": "Misinterpretation of Input",
        "description": "The product misinterprets an input, whether from an attacker or another product, in a security-relevant fashion.",
        "detail": null,
        "parent": [
            "436"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n",
        "languages": []
    },
    {
        "cwe": "116",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "117"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1164",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1071"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "117",
        "name": "Improper Output Neutralization for Logs",
        "description": "The product constructs a log message from external input, but it does not neutralize or incorrectly neutralizes special elements when the message is written to a log file.",
        "detail": "**Alternate Terms:** Log forging\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Background Details:**\n['Applications typically use log files to store a history of events or transactions for later review, statistics gathering, or debugging. Depending on the nature of the application, the task of reviewing log files may be performed manually on an as-needed basis or automated with a tool that automatically culls logs for important events or trending information.']\n\n**Consequence Note:** Interpretation of the log files may be hindered or misdirected if an attacker can supply data to the application that is subsequently logged verbatim. In the most benign case, an attacker may be able to insert false entries into the log file by providing the application with input that includes appropriate characters. Forged or otherwise corrupted log files can be used to cover an attacker's tracks, possibly by skewing statistics, or even to implicate another party in the commission of a malicious act. If the log file is processed automatically, the attacker can render the file unusable by corrupting the format of the file or injecting unexpected characters. An attacker may inject code or other commands into the log file and take advantage of a vulnerability in the log processing utility.\n",
        "parent": [
            "116",
            "20"
        ],
        "children": [],
        "related": [
            "93"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "1173",
        "name": "Improper Use of Validation Framework",
        "description": "The product does not use, or incorrectly uses, an input validation framework that is provided by the source language or an independent library.",
        "detail": "**Extended Description:**\nMany modern coding languages provide developers with input validation frameworks to make the task of input validation easier and less error-prone. These frameworks will automatically check all input against specified criteria and direct execution to error handlers when invalid input is received. The improper use (i.e., an incorrect implementation or missing altogether) of these frameworks is not directly exploitable, but can lead to an exploitable condition if proper input validation is not performed later in the product. Not using provided input validation frameworks can also hurt the maintainability of code as future developers may not recognize the downstream input validation being used in the place of the validation framework.\n\n**Mode of Introduction:** This weakness may occur when software designers choose to not leverage input validation frameworks provided by the source language.\n\n**Mode of Introduction:** This weakness may occur when developers do not correctly use a provided input validation framework.\n\n**Consequence Note:** Unchecked input leads to cross-site scripting, process control, and SQL injection vulnerabilities, among others.\n",
        "parent": [
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nSome instances of improper input validation can be detected using automated static analysis.\n\n\nA static analysis tool might allow the user to specify which application-specific methods or functions perform input validation; the tool might also have built-in knowledge of validation frameworks such as Struts. The tool may then suppress or de-prioritize any associated warnings. This allows the analyst to focus on areas of the software in which input validation does not appear to be present.\n\n\nExcept in the cases described in the previous paragraph, automated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or require any code changes.\n\n\n**Mitigation:** Properly use provided input validation frameworks.\n",
        "languages": []
    },
    {
        "cwe": "1174",
        "name": "ASP.NET Misconfiguration: Improper Model Validation",
        "description": "The ASP.NET application does not use, or incorrectly uses, the model validation framework.",
        "detail": "**Consequence Note:** Unchecked input leads to cross-site scripting, process control, and SQL injection vulnerabilities, among others.\n",
        "parent": [
            "1173"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": [
            "ASP.NET"
        ]
    },
    {
        "cwe": "1176",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1046",
            "1049",
            "1067"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1177",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "242",
            "676"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "118",
        "name": "Incorrect Access of Indexable Resource ('Range Error')",
        "description": "The product does not restrict or incorrectly restricts operations within the boundaries of a resource that is accessed using an index or pointer, such as memory or files.",
        "detail": null,
        "parent": [
            "664"
        ],
        "children": [
            "119"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1188",
        "name": "Initialization of a Resource with an Insecure Default",
        "description": "The product initializes or sets a resource with a default that is intended to be changed by the administrator, but the default is not secure.",
        "detail": "**Extended Description:**\n\n\nDevelopers often choose default values that leave the product as open and easy to use as possible out-of-the-box, under the assumption that the administrator can (or should) change the default value. However, this ease-of-use comes at a cost when the default is insecure and the administrator does not change it.\n\n",
        "parent": [
            "1419",
            "665"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1189",
        "name": "Improper Isolation of Shared Resources on System-on-a-Chip (SoC)",
        "description": "The System-On-a-Chip (SoC) does not properly isolate shared resources between trusted and untrusted agents.",
        "detail": "**Extended Description:**\n\n\nA System-On-a-Chip (SoC) has a lot of functionality, but it may have a limited number of pins or pads. A pin can only perform one function at a time. However, it can be configured to perform multiple different functions. This technique is called pin multiplexing. Similarly, several resources on the chip may be shared to multiplex and support different features or functions. When such resources are shared between trusted and untrusted agents, untrusted agents may be able to access the assets intended to be accessed only by the trusted agents.\n\n\n**Consequence Note:** If resources being used by a trusted user are shared with an untrusted user, the untrusted user may be able to modify the functionality of the shared resource of the trusted user.\n\n**Consequence Note:** The functionality of the shared resource may be intentionally degraded.\n",
        "parent": [
            "653",
            "668"
        ],
        "children": [
            "1303"
        ],
        "related": [
            "1331"
        ],
        "scopes": [
            "Access Control",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nPre-silicon / post-silicon: Test access to shared systems resources (memory ranges, control registers, etc.) from untrusted software to verify that the assets are not incorrectly exposed to untrusted agents. Note that access to shared resources can be dynamically allowed or revoked based on system flows. Security testing should cover such dynamic shared resource allocation and access control modification flows.\n\n\n**Mitigation:** \n\nWhen sharing resources, avoid mixing agents of varying trust levels.\n\n\nUntrusted agents should not share resources with trusted agents.\n\n",
        "languages": []
    },
    {
        "cwe": "119",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "120",
            "125",
            "130",
            "786",
            "787",
            "788",
            "805",
            "822",
            "823",
            "824",
            "825"
        ],
        "related": [
            "128",
            "131",
            "843"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1190",
        "name": "DMA Device Enabled Too Early in Boot Phase",
        "description": "The product enables a Direct Memory Access (DMA) capable device before the security configuration settings are established, which allows an attacker to extract data from or gain privileges on the product.",
        "detail": "**Extended Description:**\n\n\nDMA is included in a number of devices because it allows data transfer between the computer and the connected device, using direct hardware access to read or write directly to main memory without any OS interaction. An attacker could exploit this to access secrets. Several virtualization-based mitigations have been introduced to thwart DMA attacks. These are usually configured/setup during boot time. However, certain IPs that are powered up before boot is complete (known as early boot IPs) may be DMA capable. Such IPs, if not trusted, could launch DMA attacks and gain access to assets that should otherwise be protected.\n\n\n**Consequence Note:** DMA devices have direct write access to main memory and due to time of attack will be able to bypass OS or Bootloader access control.\n",
        "parent": [
            "696"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Utilize an IOMMU to orchestrate IO access from the start of the boot process.\n",
        "languages": []
    },
    {
        "cwe": "1191",
        "name": "On-Chip Debug and Test Interface With Improper Access Control",
        "description": "The chip does not implement or does not correctly perform access control to check whether users are authorized to access internal registers and test modes through the physical debug/test interface.",
        "detail": "**Extended Description:**\n\n\nA device's internal information may be accessed through a scan chain of interconnected internal registers, usually through a JTAG interface. The JTAG interface provides access to these registers in a serial fashion in the form of a scan chain for the purposes of debugging programs running on a device. Since almost all information contained within a device may be accessed over this interface, device manufacturers typically insert some form of authentication and authorization to prevent unintended use of this sensitive information. This mechanism is implemented in addition to on-chip protections that are already present.\n\n\nIf authorization, authentication, or some other form of access control is not implemented or not implemented correctly, a user may be able to bypass on-chip protection mechanisms through the debug interface.\n\n\nSometimes, designers choose not to expose the debug pins on the motherboard. Instead, they choose to hide these pins in the intermediate layers of the board. This is primarily done to work around the lack of debug authorization inside the chip. In such a scenario (without debug authorization), when the debug interface is exposed, chip internals are accessible to an attacker.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [
            "1263",
            "1299"
        ],
        "scopes": [
            "Access Control",
            "Authorization",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nAuthentication and authorization of debug and test interfaces should be part of the architecture and design review process. Withholding of private register documentation from the debug and test interface public specification (\"Security by obscurity\") should not be considered as sufficient security.\n\n\n**Detection:** \n\nDynamic tests should be done in the pre-silicon and post-silicon stages to verify that the debug and test interfaces are not open by default.\n\n\n**Detection:** Tests that fuzz Debug and Test Interfaces should ensure that no access without appropriate authentication and authorization is possible.\n\n**Mitigation:** If feasible, the manufacturer should disable the JTAG interface or implement authentication and authorization for the JTAG interface. If authentication logic is added, it should be resistant to timing attacks. Security-sensitive data stored in registers, such as keys, etc. should be cleared when entering debug mode.\n",
        "languages": []
    },
    {
        "cwe": "1192",
        "name": "Improper Identifier for IP Block used in System-On-Chip (SOC)",
        "description": "The System-on-Chip (SoC) does not have unique, immutable identifiers for each of its components.",
        "detail": "**Extended Description:**\n\n\nA System-on-Chip (SoC) comprises several components (IP) with varied trust requirements. It is required that each IP is identified uniquely and should distinguish itself from other entities in the SoC without any ambiguity. The unique secured identity is required for various purposes. Most of the time the identity is used to route a transaction or perform certain actions, including resetting, retrieving a sensitive information, and acting upon or on behalf of something else.\n\n\nThere are several variants of this weakness:\n\n\n  - A \"missing\" identifier is when the SoC does not define any mechanism to uniquely identify the IP.\n\n  - An \"insufficient\" identifier might provide some defenses - for example, against the most common attacks - but it does not protect against everything that is intended.\n\n  - A \"misconfigured\" mechanism occurs when a mechanism is available but not implemented correctly.\n\n  - An \"ignored\" identifier occurs when the SoC/IP has not applied any policies or does not act upon the identifier securely.\n\n\n",
        "parent": [
            "657"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** \n\n Every identity generated in the SoC should be unique and immutable in hardware. The actions that an IP is trusted or not trusted should be clearly defined, implemented, configured, and tested. If the definition is implemented via a policy, then the policy should be immutable or protected with clear authentication and authorization. \n\n",
        "languages": []
    },
    {
        "cwe": "1193",
        "name": "Power-On of Untrusted Execution Core Before Enabling Fabric Access Control",
        "description": "The product enables components that contain untrusted firmware before memory and fabric access controls have been enabled.",
        "detail": "**Extended Description:**\n\n\n After initial reset, System-on-Chip (SoC) fabric access controls and other security features need to be programmed by trusted firmware as part of the boot sequence. If untrusted IPs or peripheral microcontrollers are enabled first, then the untrusted component can master transactions on the hardware bus and target memory or other assets to compromise the SoC boot firmware.\n\n\n**Consequence Note:** An untrusted component can master transactions on the HW bus and target memory or other assets to compromise the SoC boot firmware.\n",
        "parent": [
            "696"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** \n\nThe boot sequence should enable fabric access controls and memory protections before enabling third-party hardware IPs and peripheral microcontrollers that use untrusted firmware.\n\n",
        "languages": []
    },
    {
        "cwe": "12",
        "name": "ASP.NET Misconfiguration: Missing Custom Error Page",
        "description": "An ASP .NET application must enable custom error pages in order to prevent attackers from mining information from the framework's built-in responses.",
        "detail": "**Background Details:**\n['The mode attribute of the <customErrors> tag defines whether custom or default error pages are used.']\n\n**Consequence Note:** Default error pages gives detailed information about the error that occurred, and should not be used in production environments. Attackers can leverage the additional information provided by a default error page to mount attacks targeted on the framework, database, or other resources used by the application.\n",
        "parent": [
            "756"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Handle exceptions appropriately in source code. ASP .NET applications should be configured to use custom error pages instead of the framework default page.\n\n**Mitigation:** Do not attempt to process an error or attempt to mask it.\n\n**Mitigation:** Verify return values are correct and do not supply sensitive information about the system.\n",
        "languages": [
            "ASP.NET"
        ]
    },
    {
        "cwe": "120",
        "name": "Buffer Copy without Checking Size of Input ('Classic Buffer Overflow')",
        "description": "The product copies an input buffer to an output buffer without verifying that the size of the input buffer is less than the size of the output buffer, leading to a buffer overflow.",
        "detail": "**Extended Description:**\nA buffer overflow condition exists when a product attempts to put more data in a buffer than it can hold, or when it attempts to put data in a memory area outside of the boundaries of a buffer. The simplest type of error, and the most common cause of buffer overflows, is the \"classic\" case in which the product copies the buffer without restricting how much is copied. Other variants exist, but the existence of a classic overflow strongly suggests that the programmer is not considering even the most basic of security protections.\n\n**Alternate Terms:** Classic Buffer Overflow, Unbounded Transfer\n\n**Consequence Note:** Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of the product's implicit security policy. This can often be used to subvert any other security service.\n\n**Consequence Note:** Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the product into an infinite loop.\n",
        "parent": [
            "119",
            "20",
            "787"
        ],
        "children": [],
        "related": [
            "123",
            "170"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.\n\n\nAutomated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges.\n\n\n**Detection:** This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Detection:** Manual analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. This becomes difficult for weaknesses that must be considered for all inputs, since the attack surface can be too large.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** \n\nUse a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, many languages that perform their own memory management, such as Java and Perl, are not subject to buffer overflows. Other languages, such as Ada and C#, typically provide overflow protection, but the protection can be disabled by the programmer.\n\n\nBe wary that a language's interface to native code may still be subject to overflows, even if the language itself is theoretically safe.\n\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nExamples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57], and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer versions of overflow-prone string-handling functions.\n\n\n**Effectiveness:** This is not a complete solution, since many buffer overflows are not related to strings.\n\n**Mitigation:** \n\nUse automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking. \n\n\n D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail. \n\n\n**Effectiveness:** \n\n This is not necessarily a complete solution, since these mechanisms only detect certain types of overflows. In addition, the result is still a denial of service, since the typical response is to exit the application. \n\n\n**Mitigation:** \n\nConsider adhering to the following rules when allocating and managing an application's memory:\n\n\n  - Double check that your buffer is as large as you specify.\n\n  - When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string.\n\n  - Check buffer boundaries if accessing the buffer in a loop and make sure there is no danger of writing past the allocated space.\n\n  - If necessary, truncate all input strings to a reasonable length before passing them to the copy and concatenation functions.\n\n\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nRun or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code. \n\n\n Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking. \n\n\n For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335]. \n\n\n**Effectiveness:** These techniques do not provide a complete solution. For instance, exploits frequently use a bug that discloses memory addresses in order to maximize reliability of code execution [REF-1337]. It has also been shown that a side-channel attack can bypass ASLR [REF-1333]\n\n**Mitigation:** \n\n Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment. \n\n\n For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336]. \n\n\n**Effectiveness:** This is not a complete solution, since buffer overflows could be used to overwrite nearby variables to modify the software's state in dangerous ways. In addition, it cannot be used in cases in which self-modifying code is required. Finally, an attack could still cause a denial of service, since the typical response is to exit the application.\n\n**Mitigation:** Most mitigating technologies at the compiler or OS level to date address only a subset of buffer overflow problems and rarely provide complete protection against even that subset. It is good practice to implement strategies to increase the workload of an attacker, such as leaving the attacker to guess an unknown value that changes every program execution.\n\n**Mitigation:** Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.\n\n**Effectiveness:** This approach is still susceptible to calculation errors, including issues such as off-by-one errors (CWE-193) and incorrectly calculating buffer lengths (CWE-131).\n\n**Mitigation:** When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** \n\nRun the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n\n\nOS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Effectiveness:** The effectiveness of this mitigation depends on the prevention capabilities of the specific sandbox or jail being used and might only help to reduce the scope of an attack, such as restricting the attacker to certain system calls or limiting the portion of the file system that can be accessed.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1204",
        "name": "Generation of Weak Initialization Vector (IV)",
        "description": "The product uses a cryptographic primitive that uses an Initialization\n\t\t\tVector (IV), but the product does not generate IVs that are\n\t\t\tsufficiently unpredictable or unique according to the expected\n\t\t\tcryptographic requirements for that primitive.\n\t\t\t",
        "detail": "**Extended Description:**\nBy design, some cryptographic primitives (such as block ciphers) require that IVs must have certain properties for the uniqueness and/or unpredictability of an IV. Primitives may vary in how important these properties are. If these properties are not maintained, e.g. by a bug in the code, then the cryptography may be weakened or broken by attacking the IVs themselves.\n\n**Consequence Note:** If the IV is not properly initialized, data that is encrypted can be compromised and information about the data can be leaked. See [REF-1179].\n",
        "parent": [
            "330"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** \n\nDifferent cipher modes have different requirements for their IVs. When choosing and implementing a mode, it is important to understand those requirements in order to keep security guarantees intact. Generally, it is safest to generate a random IV, since it will be both unpredictable and have a very low chance of being non-unique. IVs do not have to be kept secret, so if generating duplicate IVs is a concern, a list of already-used IVs can be kept and checked against. \n\n\n NIST offers recommendations on generation of IVs for modes of which they have approved. These include options for when random IVs are not practical. For CBC, CFB, and OFB, see [REF-1175]; for GCM, see [REF-1178]. \n\n",
        "languages": []
    },
    {
        "cwe": "1209",
        "name": "Failure to Disable Reserved Bits",
        "description": "The reserved bits in a hardware design are not disabled prior to production. Typically, reserved bits are used for future capabilities and should not support any functional logic in the design.   However, designers might covertly use these bits to debug or further develop new capabilities in production hardware. Adversaries with access to these bits will write to them in hopes of compromising hardware state.",
        "detail": "**Extended Description:**\n\n\nReserved bits are labeled as such so they can be allocated for a later purpose. They are not to do anything in the current design. However, designers might want to use these bits to debug or control/configure a future capability to help minimize time to market (TTM). If the logic being controlled by these bits is still enabled in production, an adversary could use the logic to induce unwanted/unsupported behavior in the hardware.\n\n\n**Mode of Introduction:** The Designer and Implementer have to make a conscious choice to do this\n\n**Mode of Introduction:** The Designer and Implementer have to make a conscious choice to do this\n\n**Mode of Introduction:** If documentation labels anything \"for future use\", \"reserved\", or the like, such labeling could indicate to an attacker a potential attack point\n\n**Consequence Note:** This type of weakness all depends on the capabilities of the logic being controlled or configured by the reserved bits.\n",
        "parent": [
            "710"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** \n\nInclude a feature to disable reserved bits.\n\n\n**Mitigation:** \n\nAny writes to these reserve bits are blocked (e.g., ignored, access-protected, etc.), or an exception can be asserted.\n\n",
        "languages": []
    },
    {
        "cwe": "121",
        "name": "Stack-based Buffer Overflow",
        "description": "A stack-based buffer overflow condition is a condition where the buffer being overwritten is allocated on the stack (i.e., is a local variable or, rarely, a parameter to a function).",
        "detail": "**Alternate Terms:** Stack Overflow\n\n**Background Details:**\n['There are generally several security-critical data on an execution stack that can lead to arbitrary code execution. The most prominent is the stored return address, the memory address at which execution should continue once the current function is finished executing. The attacker can overwrite this value with some memory address to which the attacker also has write access, into which they place arbitrary code to be run with the full privileges of the vulnerable program. Alternately, the attacker can supply the address of an important call, for instance the POSIX system() call, leaving arguments to the call on the stack. This is often called a return into libc exploit, since the attacker generally forces the program to jump at return time into an interesting routine in the C standard library (libc). Other important data commonly on the stack include the stack pointer and frame pointer, two values that indicate offsets for computing memory addresses. Modifying those values can often be leveraged into a \"write-what-where\" condition.']\n\n**Consequence Note:** Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.\n\n**Consequence Note:** Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy.\n\n**Consequence Note:** When the consequence is arbitrary code execution, this can often be used to subvert any other security service.\n",
        "parent": [
            "787",
            "788"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nUse automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking. \n\n\n D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail. \n\n\n**Effectiveness:** \n\n This is not necessarily a complete solution, since these mechanisms only detect certain types of overflows. In addition, the result is still a denial of service, since the typical response is to exit the application. \n\n\n**Mitigation:** Use an abstraction library to abstract away risky APIs. Not a complete solution.\n\n**Mitigation:** Implement and perform bounds checking on input.\n\n**Mitigation:** Do not use dangerous functions such as gets. Use safer, equivalent functions which check for boundary errors.\n\n**Mitigation:** \n\nRun or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code. \n\n\n Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking. \n\n\n For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335]. \n\n\n**Effectiveness:** These techniques do not provide a complete solution. For instance, exploits frequently use a bug that discloses memory addresses in order to maximize reliability of code execution [REF-1337]. It has also been shown that a side-channel attack can bypass ASLR [REF-1333]\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "122",
        "name": "Heap-based Buffer Overflow",
        "description": "A heap overflow condition is a buffer overflow, where the buffer that can be overwritten is allocated in the heap portion of memory, generally meaning that the buffer was allocated using a routine such as malloc().",
        "detail": "**Consequence Note:** Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.\n\n**Consequence Note:** Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy. Besides important user data, heap-based overflows can be used to overwrite function pointers that may be living in memory, pointing it to the attacker's code. Even in applications that do not explicitly use function pointers, the run-time will usually leave many in memory. For example, object methods in C++ are generally implemented using function pointers. Even in C programs, there is often a global offset table used by the underlying runtime.\n\n**Consequence Note:** When the consequence is arbitrary code execution, this can often be used to subvert any other security service.\n",
        "parent": [
            "787",
            "788"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Mitigation:** Pre-design: Use a language or compiler that performs automatic bounds checking.\n\n**Mitigation:** Use an abstraction library to abstract away risky APIs. Not a complete solution.\n\n**Mitigation:** \n\nUse automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking. \n\n\n D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail. \n\n\n**Effectiveness:** \n\n This is not necessarily a complete solution, since these mechanisms only detect certain types of overflows. In addition, the result is still a denial of service, since the typical response is to exit the application. \n\n\n**Mitigation:** \n\nRun or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code. \n\n\n Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking. \n\n\n For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335]. \n\n\n**Effectiveness:** These techniques do not provide a complete solution. For instance, exploits frequently use a bug that discloses memory addresses in order to maximize reliability of code execution [REF-1337]. It has also been shown that a side-channel attack can bypass ASLR [REF-1333]\n\n**Mitigation:** Implement and perform bounds checking on input.\n\n**Mitigation:** Do not use dangerous functions such as gets. Look for their safe equivalent, which checks for the boundary.\n\n**Mitigation:** Use OS-level preventative functionality. This is not a complete solution, but it provides some defense in depth.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1220",
        "name": "Insufficient Granularity of Access Control",
        "description": "The product implements access controls via a policy or other feature with the intention to disable or restrict accesses (reads and/or writes) to assets in a system from untrusted agents. However, implemented access controls lack required granularity, which renders the control policy too broad because it allows accesses from unauthorized agents to the security-sensitive assets.",
        "detail": "**Extended Description:**\n\n\nIntegrated circuits and hardware engines can expose accesses to assets (device configuration, keys, etc.) to trusted firmware or a software module (commonly set by BIOS/bootloader). This access is typically access-controlled. Upon a power reset, the hardware or system usually starts with default values in registers, and the trusted firmware (Boot firmware) configures the necessary access-control protection.\n\n\nA common weakness that can exist in such protection schemes is that access controls or policies are not granular enough. This condition allows agents beyond trusted agents to access assets and could lead to a loss of functionality or the ability to set up the device securely. This further results in security risks from leaked, sensitive, key material to modification of device configuration.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during hardware implementation and identified later during Testing or System Configuration phases.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\n  - Access-control-policy protections must be reviewed for design inconsistency and common weaknesses.\n\n  - Access-control-policy definition and programming flow must be tested in pre-silicon, post-silicon testing.\n\n\n",
        "languages": []
    },
    {
        "cwe": "1221",
        "name": "Incorrect Register Defaults or Module Parameters",
        "description": "Hardware description language code incorrectly defines register defaults or hardware Intellectual Property (IP) parameters to insecure values.",
        "detail": "**Extended Description:**\n\n\nIntegrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to defined default values that are hard coded in the hardware description language (HDL) code of the hardware unit. Hardware descriptive languages also support definition of parameter variables, which can be defined in code during instantiation of the hardware IP module. Such parameters are generally used to configure a specific instance of a hardware IP in the design.\n\n\nThe system security settings of a hardware design can be affected by incorrectly defined default values or IP parameters. The hardware IP would be in an insecure state at power reset, and this can be exposed or exploited by untrusted software running on the system. Both register defaults and parameters are hardcoded values, which cannot be changed using software or firmware patches but must be changed in hardware silicon. Thus, such security issues are considerably more difficult to address later in the lifecycle. Hardware designs can have a large number of such parameters and register defaults settings, and it is important to have design tool support to check these settings in an automated way and be able to identify which settings are security sensitive.\n\n\n**Mode of Introduction:** Such issues could be introduced during implementation of hardware design, since IP parameters and defaults are defined in HDL code and identified later during Testing or System Configuration phases.\n\n**Consequence Note:** Degradation of system functionality, or loss of access control enforcement can occur.\n",
        "parent": [
            "1419"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** During hardware design, all the system parameters and register defaults must be reviewed to identify security sensitive settings.\n\n**Mitigation:** The default values of these security sensitive settings need to be defined as part of the design review phase.\n\n**Mitigation:** Testing phase should use automated tools to test that values are configured per design specifications.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1222",
        "name": "Insufficient Granularity of Address Regions Protected by Register Locks",
        "description": "The product defines a large address region protected from modification by the same register lock control bit. This results in a conflict between the functional requirement that some addresses need to be writable by software during operation and the security requirement that the system configuration lock bit must be set during the boot process.",
        "detail": "**Extended Description:**\n\n\nIntegrated circuits and hardware IPs can expose the device configuration controls that need to be programmed after device power reset by a trusted firmware or software module (commonly set by BIOS/bootloader) and then locked from any further modification. In hardware design, this is commonly implemented using a programmable lock bit which enables/disables writing to a protected set of registers or address regions. When the programmable lock bit is set, the relevant address region can be implemented as a hardcoded value in hardware logic that cannot be changed later.\n\n\nA problem can arise wherein the protected region definition is not granular enough. After the programmable lock bit has been set, then this new functionality cannot be implemented without change to the hardware design.\n\n\n**Mode of Introduction:** Such issues are introduced during hardware architecture and design since software controls and configuration are defined during these phases and identified later during Testing or System Configuration phases.\n\n**Consequence Note:** System security configuration cannot be defined in a way that does not conflict with functional requirements of device.\n",
        "parent": [
            "1220"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** \n\nThe defining of protected locked registers should be reviewed or tested early in the design phase with software teams to ensure software flows are not blocked by the security locks.\n\n\nAs an alternative to using register lock control bits and fixed access control regions, the hardware design could use programmable security access control configuration so that device trusted firmware can configure and change the protected regions based on software usage and security models.\n\n",
        "languages": []
    },
    {
        "cwe": "1223",
        "name": "Race Condition for Write-Once Attributes",
        "description": "A write-once register in hardware design is programmable by an untrusted software component earlier than the trusted software component, resulting in a race condition issue.",
        "detail": "**Extended Description:**\n\n\nIntegrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to defined default values that are hard coded in the hardware description language (HDL) code of the hardware unit. A common security protection method used to protect register settings from modification by software is to make them write-once. This means the hardware implementation only allows writing to such registers once, and they become read-only after having been written once by software. This is useful to allow initial boot software to configure systems settings to secure values while blocking runtime software from modifying such hardware settings.\n\n\nImplementation issues in hardware design of such controls can expose such registers to a race condition security flaw. For example, consider a hardware design that has two different software/firmware modules executing in parallel. One module is trusted (module A) and another is untrusted (module B). In this design it could be possible for Module B to send write cycles to the write-once register before Module A. Since the field is write-once the programmed value from Module A will be ignored and the pre-empted value programmed by Module B will be used by hardware.\n\n\n**Mode of Introduction:** This weakness can appear in designs that use register write-once attributes with two or more software/firmware modules with varying levels of trust executing in parallel.\n\n**Consequence Note:** System configuration cannot be programmed in a secure way.\n",
        "parent": [
            "362"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** During hardware design all register write-once or sticky fields must be evaluated for proper configuration.\n\n**Mitigation:** The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1224",
        "name": "Improper Restriction of Write-Once Bit Fields",
        "description": "The hardware design control register \"sticky bits\" or write-once bit fields are improperly implemented, such that they can be reprogrammed by software.",
        "detail": "**Extended Description:**\n\n\nIntegrated circuits and hardware IP software programmable controls and settings are commonly stored in register circuits. These register contents have to be initialized at hardware reset to define default values that are hard coded in the hardware description language (HDL) code of the hardware unit. A common security protection method used to protect register settings from modification by software is to make the settings write-once or \"sticky.\" This allows writing to such registers only once, whereupon they become read-only. This is useful to allow initial boot software to configure systems settings to secure values while blocking runtime software from modifying such hardware settings.\n\n\nFailure to implement write-once restrictions in hardware design can expose such registers to being re-programmed by software and written multiple times. For example, write-once fields could be implemented to only be write-protected if they have been set to value \"1\", wherein they would work as \"write-1-once\" and not \"write-once\".\n\n\n**Mode of Introduction:** Such issues could be introduced during implementation of hardware design, since IP parameters and defaults are defined in HDL code and identified later during Testing or System Configuration phases.\n\n**Consequence Note:** System configuration cannot be programmed in a secure way.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** During hardware design all register write-once or sticky fields must be evaluated for proper configuration.\n\n**Mitigation:** The testing phase should use automated tools to test that values are not reprogrammable and that write-once fields lock on writing zeros.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1229",
        "name": "Creation of Emergent Resource",
        "description": "The product manages resources or behaves in a way that indirectly creates a new, distinct resource that can be used by attackers in violation of the intended policy.",
        "detail": "**Extended Description:**\n\n\nA product is only expected to behave in a way that was specifically intended by the developer. Resource allocation and management is expected to be performed explicitly by the associated code. However, in systems with complex behavior, the product might indirectly produce new kinds of resources that were never intended in the original design. For example, a covert channel is a resource that was never explicitly intended by the developer, but it is useful to attackers. \"Parasitic computing,\" while not necessarily malicious in nature, effectively tricks a product into performing unintended computations on behalf of another party.\n\n",
        "parent": [
            "664"
        ],
        "children": [
            "514"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "123",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "120",
            "364"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1230",
        "name": "Exposure of Sensitive Information Through Metadata",
        "description": "The product prevents direct access to a resource containing sensitive information, but it does not sufficiently limit access to metadata that is derived from the original, sensitive information.",
        "detail": "**Extended Description:**\n\n\nDevelopers might correctly prevent unauthorized access to a database or other resource containing sensitive information, but they might not consider that portions of the original information might also be recorded in metadata, search indices, statistical reports, or other resources. If these resources are not also restricted, then attackers might be able to extract some or all of the original information, or otherwise infer some details. For example, an attacker could specify search terms that are known to be unique to a particular person, or view metadata such as activity or creation dates in order to identify usage patterns.\n\n",
        "parent": [
            "285"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1231",
        "name": "Improper Prevention of Lock Bit Modification",
        "description": "The product uses a trusted lock bit for restricting access to registers, address regions, or other resources, but the product does not prevent the value of the lock bit from being modified after it has been set.",
        "detail": "**Extended Description:**\n\n\nIn integrated circuits and hardware intellectual property (IP) cores, device configuration controls are commonly programmed after a device power reset by a trusted firmware or software module (e.g., BIOS/bootloader) and then locked from any further modification.\n\n\nThis behavior is commonly implemented using a trusted lock bit. When set, the lock bit disables writes to a protected set of registers or address regions. Design or coding errors in the implementation of the lock bit protection feature may allow the lock bit to be modified or cleared by software after it has been set. Attackers might be able to unlock the system and features that the bit is intended to protect.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.\n\n**Consequence Note:** Registers protected by lock bit can be modified even when lock is set.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Set the lock bit. Power cycle the device. Attempt to clear the lock bit. If the information is changed, implement a design fix. Retest. Also, attempt to indirectly clear the lock bit or bypass it.\n\n**Mitigation:** \n\n  - Security lock bit protections must be reviewed for design inconsistency and common weaknesses.\n\n  - Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.\n\n\n",
        "languages": []
    },
    {
        "cwe": "1232",
        "name": "Improper Lock Behavior After Power State Transition",
        "description": "Register lock bit protection disables changes to system configuration once the bit is set. Some of the protected registers or lock bits become programmable after power state transitions (e.g., Entry and wake from low power sleep modes) causing the system configuration to be changeable.",
        "detail": "**Extended Description:**\n\n\nDevices may allow device configuration controls which need to be programmed after device power reset via a trusted firmware or software module (commonly set by BIOS/bootloader) and then locked from any further modification. This action is commonly implemented using a programmable lock bit, which, when set, disables writes to a protected set of registers or address regions.\n\n\nAfter a power state transition, the lock bit is set to unlocked. Some common weaknesses that can exist in such a protection scheme are that the lock gets cleared, the values of the protected registers get reset, or the lock become programmable.\n\n",
        "parent": [
            "667"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** \n\n  - Security Lock bit protections should be reviewed for behavior across supported power state transitions.\n\n  - Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing including testing across power transitions.\n\n\n",
        "languages": []
    },
    {
        "cwe": "1233",
        "name": "Security-Sensitive Hardware Controls with Missing Lock Bit Protection",
        "description": "The product uses a register lock bit protection mechanism, but it does not ensure that the lock bit prevents modification of system registers or controls that perform changes to important hardware system configuration.",
        "detail": "**Extended Description:**\n\n\nIntegrated circuits and hardware intellectual properties (IPs) might provide device configuration controls that need to be programmed after device power reset by a trusted firmware or software module, commonly set by BIOS/bootloader. After reset, there can be an expectation that the controls cannot be used to perform any further modification. This behavior is commonly implemented using a trusted lock bit, which can be set to disable writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration).\n\n\nHowever, if the lock bit does not effectively write-protect all system registers or controls that could modify the protected system configuration, then an adversary may be able to use software to access the registers/controls and modify the protected hardware configuration.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.\n\n**Consequence Note:** System Configuration protected by the lock bit can be modified even when the lock is set.\n",
        "parent": [
            "284",
            "667"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Set the lock bit. Attempt to modify the information protected by the lock bit. If the information is changed, implement a design fix. Retest. Also, attempt to indirectly clear the lock bit or bypass it.\n\n**Mitigation:** \n\n  - Security lock bit protections must be reviewed for design inconsistency and common weaknesses.\n\n  - Security lock programming flow and lock properties must be tested in pre-silicon and post-silicon testing.\n\n\n",
        "languages": []
    },
    {
        "cwe": "1234",
        "name": "Hardware Internal or Debug Modes Allow Override of Locks",
        "description": "System configuration protection may be bypassed during debug mode.",
        "detail": "**Extended Description:**\n\n\nDevice configuration controls are commonly programmed after a device power reset by a trusted firmware or software module (e.g., BIOS/bootloader) and then locked from any further modification. This is commonly implemented using a trusted lock bit, which when set, disables writes to a protected set of registers or address regions. The lock protection is intended to prevent modification of certain system configuration (e.g., memory/memory protection unit configuration). If debug features supported by hardware or internal modes/system states are supported in the hardware design, modification of the lock protection may be allowed allowing access and modification of configuration information.\n\n\n**Consequence Note:** Bypass of lock bit allows access and modification of system configuration even when the lock bit is set.\n",
        "parent": [
            "667"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** \n\n  - Security Lock bit protections should be reviewed for any bypass/override modes supported.\n\n  - Any supported override modes either should be removed or protected using authenticated debug modes.\n\n  - Security lock programming flow and lock properties should be tested in pre-silicon and post-silicon testing.\n\n\n",
        "languages": []
    },
    {
        "cwe": "1235",
        "name": "Incorrect Use of Autoboxing and Unboxing for Performance Critical Operations",
        "description": "The code uses boxed primitives, which may introduce inefficiencies into performance-critical operations.",
        "detail": "**Extended Description:**\n\n\nLanguages such as Java and C# support automatic conversion through their respective compilers from primitive types into objects of the corresponding wrapper classes, and vice versa. For example, a compiler might convert an int to Integer (called autoboxing) or an Integer to int (called unboxing). This eliminates forcing the programmer to perform these conversions manually, which makes the code cleaner.\n\n\nHowever, this feature comes at a cost of performance and can lead to resource exhaustion and impact availability when used with generic collections. Therefore, they should not be used for scientific computing or other performance critical operations. They are only suited to support \"impedance mismatch\" between reference types and primitives.\n\n\n**Mode of Introduction:** The programmer may use boxed primitives when not strictly necessary.\n\n**Consequence Note:** Incorrect autoboxing/unboxing would result in reduced performance, which sometimes can lead to resource consumption issues.\n",
        "parent": [
            "400"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Use of boxed primitives should be limited to certain situations such as when calling methods with typed parameters. Examine the use of boxed primitives prior to use. Use SparseArrays or ArrayMap instead of HashMap to avoid performance overhead.\n",
        "languages": [
            "C#",
            "Java"
        ]
    },
    {
        "cwe": "1236",
        "name": "Improper Neutralization of Formula Elements in a CSV File",
        "description": "The product saves user-provided information into a Comma-Separated Value (CSV) file, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as a command when the file is opened by a spreadsheet product.",
        "detail": "**Extended Description:**\nUser-provided data is often saved to traditional databases. This data can be exported to a CSV file, which allows users to read the data using spreadsheet software such as Excel, Numbers, or Calc. This software interprets entries beginning with '=' as formulas, which are then executed by the spreadsheet software. The software's formula language often allows methods to access hyperlinks or the local command line, and frequently allows enough characters to invoke an entire script. Attackers can populate data fields which, when saved to a CSV file, may attempt information exfiltration or other malicious activity when automatically executed by the spreadsheet software.\n\n**Alternate Terms:** CSV Injection, Formula Injection, Excel Macro Injection\n\n**Mode of Introduction:** The weakness is in the implementation of a software's CSV export feature, in particular how it formats formula entries as the output gets flattened into a text file.\n\n**Consequence Note:** Current versions of Excel warn users of untrusted content.\n",
        "parent": [
            "74"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** When generating CSV output, ensure that formula-sensitive metacharacters are effectively escaped or removed from all data before storage in the resultant CSV. Risky characters include '=' (equal), '+' (plus), '-' (minus), and '@' (at).\n\n**Effectiveness:** Unfortunately, there is no perfect solution, since different spreadsheet products act differently.\n\n**Mitigation:** If a field starts with a formula character, prepend it with a ' (single apostrophe), which prevents Excel from executing the formula.\n\n**Effectiveness:** It is not clear how effective this mitigation is with other spreadsheet software.\n\n**Mitigation:** Certain implementations of spreadsheet software might disallow formulas from executing if the file is untrusted, or if the file is not authored by the current user.\n\n**Effectiveness:** This mitigation has limited effectiveness because it often depends on end users opening spreadsheet software safely.\n",
        "languages": []
    },
    {
        "cwe": "1239",
        "name": "Improper Zeroization of Hardware Register",
        "description": "The hardware product does not properly clear sensitive information from built-in registers when the user of the hardware block changes.",
        "detail": "**Extended Description:**\nHardware logic operates on data stored in registers local to the hardware block. Most hardware IPs, including cryptographic accelerators, rely on registers to buffer I/O, store intermediate values, and interface with software. The result of this is that sensitive information, such as passwords or encryption keys, can exist in locations not transparent to the user of the hardware logic. When a different entity obtains access to the IP due to a change in operating mode or conditions, the new entity can extract information belonging to the previous user if no mechanisms are in place to clear register contents. It is important to clear information stored in the hardware if a physical attack on the product is detected, or if the user of the hardware block changes. The process of clearing register contents in a hardware IP is referred to as zeroization in standards for cryptographic hardware modules such as FIPS-140-2 [REF-267].\n\n**Mode of Introduction:** Lack of hardware mechanisms to zeroize or clear registers in the design or specification.\n\n**Mode of Introduction:** Mechanisms to zeroize and clear registers are in the design but implemented incorrectly.\n\n**Mode of Introduction:** Hardware-provided zeroization mechanisms are not used appropriately by the IP user (ex. firmware), or data remanence issues are not taken into account.\n\n**Consequence Note:** The consequences will depend on the information disclosed due to the vulnerability.\n",
        "parent": [
            "226"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Every register potentially containing sensitive information must have a policy specifying how and when information is cleared, in addition to clarifying if it is the responsibility of the hardware logic or IP user to initiate the zeroization procedure at the appropriate time.\n\n**Effectiveness:** Unfortunately, data disclosure can occur even after information has been overwritten/zeroized from the digital perspective. Physical characteristics of the memory can reveal the history of previously written data. For example, if the same value is written repeatedly to a memory location, the corresponding memory cells can become physically altered to a degree that even if the original data is erased it can still be recovered through physical characterization of the memory cells [REF-1055].\n",
        "languages": []
    },
    {
        "cwe": "124",
        "name": "Buffer Underwrite ('Buffer Underflow')",
        "description": "The product writes to a buffer using an index or pointer that references a memory location prior to the beginning of the buffer.",
        "detail": "**Extended Description:**\nThis typically occurs when a pointer or its index is decremented to a position before the buffer, when pointer arithmetic results in a position before the beginning of the valid memory location, or when a negative index is used.\n\n**Alternate Terms:** buffer underrun\n\n**Consequence Note:** Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash.\n\n**Consequence Note:** If the corrupted memory can be effectively controlled, it may be possible to execute arbitrary code. If the corrupted memory is data rather than instructions, the system will continue to function with improper changes, possibly in violation of an implicit or explicit policy. The consequences would only be limited by how the affected data is used, such as an adjacent memory location that is used to specify whether the user has special privileges.\n\n**Consequence Note:** When the consequence is arbitrary code execution, this can often be used to subvert any other security service.\n",
        "parent": [
            "786",
            "787"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Choose a language that is not susceptible to these issues.\n\n**Mitigation:** All calculated values that are used as index or for pointer arithmetic should be validated to ensure that they are within an expected range.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1240",
        "name": "Use of a Cryptographic Primitive with a Risky Implementation",
        "description": "To fulfill the need for a cryptographic primitive, the product implements a cryptographic algorithm using a non-standard, unproven, or disallowed/non-compliant cryptographic implementation.",
        "detail": "**Extended Description:**\n\n\nCryptographic protocols and systems depend on cryptographic primitives (and associated algorithms) as their basic building blocks. Some common examples of primitives are digital signatures, one-way hash functions, ciphers, and public key cryptography; however, the notion of \"primitive\" can vary depending on point of view. See \"Terminology Notes\" for further explanation of some concepts.\n\n\nCryptographic primitives are defined to accomplish one very specific task in a precisely defined and mathematically reliable fashion. For example, suppose that for a specific cryptographic primitive (such as an encryption routine), the consensus is that the primitive can only be broken after trying out N different inputs (where the larger the value of N, the stronger the cryptography). For an encryption scheme like AES-256, one would expect N to be so large as to be infeasible to execute in a reasonable amount of time.\n\n\nIf a vulnerability is ever found that shows that one can break a cryptographic primitive in significantly less than the expected number of attempts, then that primitive is considered weakened (or sometimes in extreme cases, colloquially it is \"broken\"). As a result, anything using this cryptographic primitive would now be considered insecure or risky. Thus, even breaking or weakening a seemingly small cryptographic primitive has the potential to render the whole system vulnerable, due to its reliance on the primitive. A historical example can be found in TLS when using DES. One would colloquially call DES the cryptographic primitive for transport encryption in this version of TLS. In the past, DES was considered strong, because no weaknesses were found in it; importantly, DES has a key length of 56 bits. Trying N=2^56 keys was considered impractical for most actors. Unfortunately, attacking a system with 56-bit keys is now practical via brute force, which makes defeating DES encryption practical. It is now practical for an adversary to read any information sent under this version of TLS and use this information to attack the system. As a result, it can be claimed that this use of TLS is weak, and that any system depending on TLS with DES could potentially render the entire system vulnerable to attack.\n\n\nCryptographic primitives and associated algorithms are only considered safe after extensive research and review from experienced cryptographers from academia, industry, and government entities looking for any possible flaws. Furthermore, cryptographic primitives and associated algorithms are frequently reevaluated for safety when new mathematical and attack techniques are discovered. As a result and over time, even well-known cryptographic primitives can lose their compliance status with the discovery of novel attacks that might either defeat the algorithm or reduce its robustness significantly.\n\n\nIf ad-hoc cryptographic primitives are implemented, it is almost certain that the implementation will be vulnerable to attacks that are well understood by cryptographers, resulting in the exposure of sensitive information and other consequences.\n\n\nThis weakness is even more difficult to manage for hardware-implemented deployment of cryptographic algorithms. First, because hardware is not patchable as easily as software, any flaw discovered after release and production typically cannot be fixed without a recall of the product. Secondly, the hardware product is often expected to work for years, during which time computation power available to the attacker only increases. Therefore, for hardware implementations of cryptographic primitives, it is absolutely essential that only strong, proven cryptographic primitives are used.\n\n\n**Mode of Introduction:** This weakness is primarily introduced during the architecture and design phase as risky primitives are included.\n\n**Mode of Introduction:** Even in cases where the Architectural phase properly specifies a cryptographically secure design, the design may be changed during implementation due to unforeseen constraints.\n\n**Consequence Note:** Incorrect usage of crypto primitives could render the supposedly encrypted data as unencrypted plaintext in the worst case.\n",
        "parent": [
            "327"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Review requirements, documentation, and product design to ensure that primitives are consistent with the strongest-available recommendations from trusted parties. If the product appears to be using custom or proprietary implementations that have not had sufficient public review and approval, then this is a significant concern.\n\n**Detection:** Analyze the product to ensure that implementations for each primitive do not contain any known vulnerabilities and are not using any known-weak algorithms, including MD4, MD5, SHA1, DES, etc.\n\n**Detection:** For hardware, during the implementation (pre-Silicon / post-Silicon) phase, dynamic tests should be done to ensure that outputs from cryptographic routines are indeed working properly, such as test vectors provided by NIST [REF-1236].\n\n**Detection:** It needs to be determined if the output of a cryptographic primitive is lacking entropy, which is one clear sign that something went wrong with the crypto implementation. There exist many methods of measuring the entropy of a bytestream, from sophisticated ones (like calculating Shannon's entropy of a sequence of characters) to crude ones (by compressing it and comparing the size of the original bytestream vs. the compressed - a truly random byte stream should not be compressible and hence the uncompressed and compressed bytestreams should be nearly identical in size).\n\n**Mitigation:** Require compliance with the strongest-available recommendations from trusted parties, and require that compliance must be kept up-to-date, since recommendations evolve over time. For example, US government systems require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].\n\n**Mitigation:** Ensure that the architecture/design uses the strongest-available primitives and algorithms from trusted parties. For example, US government systems require FIPS 140-3 certification, which supersedes FIPS 140-2 [REF-1192] [REF-1226].\n\n**Mitigation:** Do not develop custom or private cryptographic algorithms. They will likely be exposed to attacks that are well-understood by cryptographers. As with all cryptographic mechanisms, the source code should be available for analysis. If the algorithm may be compromised when attackers find out how it works, then it is especially weak.\n\n**Mitigation:** Try not to use cryptographic algorithms in novel ways or with new modes of operation even when you \"know\" it is secure. For example, using SHA-2 chaining to create a 1-time pad for encryption might sound like a good idea, but one should not do this.\n\n**Mitigation:** Ensure that the design can replace one cryptographic primitive or algorithm with another in the next generation (\"cryptographic agility\"). Where possible, use wrappers to make the interfaces uniform. This will make it easier to upgrade to stronger algorithms. This is especially important for hardware, which can be more difficult to upgrade quickly than software; design the hardware at a replaceable block level.\n\n**Mitigation:** Do not use outdated or non-compliant cryptography algorithms. Some older algorithms, once thought to require a billion years of computing time, can now be broken in days or hours. This includes MD4, MD5, SHA1, DES, and other algorithms that were once regarded as strong [REF-267].\n\n**Mitigation:** Do not use a linear-feedback shift register (LFSR) or other legacy methods as a substitute for an accepted and standard Random Number Generator.\n\n**Mitigation:** Do not use a checksum as a substitute for a cryptographically generated hash.\n\n**Mitigation:** Use a vetted cryptographic library or framework. Industry-standard implementations will save development time and are more likely to avoid errors that can occur during implementation of cryptographic algorithms. However, the library/framework could be used incorrectly during implementation.\n\n**Mitigation:** When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for the prevention of common attacks.\n\n**Mitigation:** Do not store keys in areas accessible to untrusted agents. Carefully manage and protect the cryptographic keys (see CWE-320). If the keys can be guessed or stolen, then the strength of the cryptography algorithm is irrelevant.\n",
        "languages": []
    },
    {
        "cwe": "1241",
        "name": "Use of Predictable Algorithm in Random Number Generator",
        "description": "The device uses an algorithm that is predictable and generates a pseudo-random number.",
        "detail": "**Extended Description:**\n\n\nPseudo-random number generator algorithms are predictable because their registers have a finite number of possible states, which eventually lead to repeating patterns. As a result, pseudo-random number generators (PRNGs) can compromise their randomness or expose their internal state to various attacks, such as reverse engineering or tampering. It is highly recommended to use hardware-based true random number generators (TRNGs) to ensure the security of encryption schemes. TRNGs generate unpredictable, unbiased, and independent random numbers because they employ physical phenomena, e.g., electrical noise, as sources to generate random numbers.\n\n\n**Mode of Introduction:** In many cases, the design originally defines a cryptographically secure random number generator, but is then changed during implementation due to unforeseen constraints.\n",
        "parent": [
            "330"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** A true random number generator should be specified for cryptographic algorithms.\n\n**Mitigation:** A true random number generator should be implemented for cryptographic algorithms.\n",
        "languages": []
    },
    {
        "cwe": "1242",
        "name": "Inclusion of Undocumented Features or Chicken Bits",
        "description": "The device includes chicken bits or undocumented features that can create entry points for unauthorized actors.",
        "detail": "**Extended Description:**\n\n\nA common design practice is to use undocumented bits on a device that can be used to disable certain functional security features. These bits are commonly referred to as \"chicken bits\". They can facilitate quick identification and isolation of faulty components, features that negatively affect performance, or features that do not provide the required controllability for debug and test. Another way to achieve this is through implementation of undocumented features. An attacker might exploit these interfaces for unauthorized access.\n\n",
        "parent": [
            "912"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nThe implementation of chicken bits in a released product is highly discouraged. If implemented at all, ensure that they are disabled in production devices. All interfaces to a device should be documented.\n\n",
        "languages": []
    },
    {
        "cwe": "1243",
        "name": "Sensitive Non-Volatile Information Not Protected During Debug",
        "description": "Access to security-sensitive information stored in fuses is not limited during debug.",
        "detail": "**Extended Description:**\n\n\nSeveral security-sensitive values are programmed into fuses to be used during early-boot flows or later at runtime. Examples of these security-sensitive values include root keys, encryption keys, manufacturing-specific information, chip-manufacturer-specific information, and original-equipment-manufacturer (OEM) data. After the chip is powered on, these values are sensed from fuses and stored in temporary locations such as registers and local memories. These locations are typically access-control protected from untrusted agents capable of accessing them. Even to trusted agents, only read-access is provided. However, these locations are not blocked during debug operations, allowing a user to access this sensitive information.\n\n",
        "parent": [
            "1263"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** \n\nDisable access to security-sensitive information stored in fuses directly and also reflected from temporary storage locations when in debug mode.\n\n",
        "languages": []
    },
    {
        "cwe": "1244",
        "name": "Internal Asset Exposed to Unsafe Debug Access Level or State",
        "description": "The product uses physical debug or test\n        interfaces with support for multiple access levels, but it\n        assigns the wrong debug access level to an internal asset,\n        providing unintended access to the asset from untrusted debug\n        agents.",
        "detail": "**Extended Description:**\n\n\nDebug authorization can have multiple levels of access, defined such that different system internal assets are accessible based on the current authorized debug level. Other than debugger authentication (e.g., using passwords or challenges), the authorization can also be based on the system state or boot stage. For example, full system debug access might only be allowed early in boot after a system reset to ensure that previous session data is not accessible to the authenticated debugger.\n\n\nIf this protection mechanism does not ensure that internal assets have the correct debug access level during each boot stage or change in system state, an attacker could obtain sensitive information from the internal asset using a debugger.\n\n",
        "parent": [
            "863"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Authorization",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Check 2 devices for their passcode to authenticate access to JTAG/debugging ports. If the passcodes are missing or the same, update the design to fix and retest. Check communications over JTAG/debugging ports for encryption. If the communications are not encrypted, fix the design and retest.\n\n**Mitigation:** \n\nFor security-sensitive assets accessible over debug/test interfaces, only allow trusted agents.\n\n\n**Mitigation:** Apply blinding [REF-1219] or masking techniques in strategic areas.\n\n**Mitigation:** Add shielding or tamper-resistant protections to the device, which increases the difficulty and cost for accessing debug/test interfaces.\n",
        "languages": []
    },
    {
        "cwe": "1245",
        "name": "Improper Finite State Machines (FSMs) in Hardware Logic",
        "description": "Faulty finite state machines (FSMs) in the hardware logic allow an attacker to put the system in an undefined state, to cause a denial of service (DoS) or gain privileges on the victim's system.",
        "detail": "**Extended Description:**\n\n\nThe functionality and security of the system heavily depend on the implementation of FSMs. FSMs can be used to indicate the current security state of the system. Lots of secure data operations and data transfers rely on the state reported by the FSM. Faulty FSM designs that do not account for all states, either through undefined states (left as don't cares) or through incorrect implementation, might lead an attacker to drive the system into an unstable state from which the system cannot recover without a reset, thus causing a DoS. Depending on what the FSM is used for, an attacker might also gain additional privileges to launch further attacks and compromise the security guarantees.\n\n",
        "parent": [
            "684"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability"
        ],
        "mitigation": "**Mitigation:** Define all possible states and handle all unused states through default statements. Ensure that system defaults to a secure state.\n",
        "languages": []
    },
    {
        "cwe": "1246",
        "name": "Improper Write Handling in Limited-write Non-Volatile Memories",
        "description": "The product does not implement or incorrectly implements wear leveling operations in limited-write non-volatile memories.",
        "detail": "**Extended Description:**\n\n\nNon-volatile memories such as NAND Flash, EEPROM, etc. have individually erasable segments, each of which can be put through a limited number of program/erase or write cycles. For example, the device can only endure a limited number of writes, after which the device becomes unreliable. In order to wear out the cells in a uniform manner, non-volatile memory and storage products based on the above-mentioned technologies implement a technique called wear leveling. Once a set threshold is reached, wear leveling maps writes of a logical block to a different physical block. This prevents a single physical block from prematurely failing due to a high concentration of writes. If wear leveling is improperly implemented, attackers may be able to programmatically cause the storage to become unreliable within a much shorter time than would normally be expected.\n\n",
        "parent": [
            "400"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Include secure wear leveling algorithms and ensure they may not be bypassed.\n",
        "languages": []
    },
    {
        "cwe": "1247",
        "name": "Improper Protection Against Voltage and Clock Glitches",
        "description": "The device does not contain or contains incorrectly implemented circuitry or sensors to detect and mitigate voltage and clock glitches and protect sensitive information or software contained on the device.",
        "detail": "**Extended Description:**\n\n\nA device might support features such as secure boot which are supplemented with hardware and firmware support. This involves establishing a chain of trust, starting with an immutable root of trust by checking the signature of the next stage (culminating with the OS and runtime software) against a golden value before transferring control. The intermediate stages typically set up the system in a secure state by configuring several access control settings. Similarly, security logic for exercising a debug or testing interface may be implemented in hardware, firmware, or both. A device needs to guard against fault attacks such as voltage glitches and clock glitches that an attacker may employ in an attempt to compromise the system.\n\n",
        "parent": [
            "1384"
        ],
        "children": [],
        "related": [
            "1332"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nPut the processor in an infinite loop, which is then followed by instructions that should not ever be executed, since the loop is not expected to exit. After the loop, toggle an I/O bit (for oscilloscope monitoring purposes), print a console message, and reenter the loop. Note that to ensure that the loop exit is actually captured, many NOP instructions should be coded after the loop branch instruction and before the I/O bit toggle and the print statement.\n\n\nMargining the clock consists of varying the clock frequency until an anomaly occurs. This could be a continuous frequency change or it could be a single cycle. The single cycle method is described here. For every 1000th clock pulse, the clock cycle is shortened by 10 percent. If no effect is observed, the width is shortened by 20%. This process is continued in 10% increments up to and including 50%. Note that the cycle time may be increased as well, down to seconds per cycle.\n\n\nSeparately, the voltage is margined. Note that the voltage could be increased or decreased. Increasing the voltage has limits, as the circuitry may not be able to withstand a drastically increased voltage. This process starts with a 5% reduction of the DC supply to the CPU chip for 5 millisecond repeated at 1KHz. If this has no effect, the process is repeated, but a 10% reduction is used. This process is repeated at 10% increments down to a 50% reduction. If no effects are observed at 5 millisecond, the whole process is repeated using a 10 millisecond pulse. If no effects are observed, the process is repeated in 10 millisecond increments out to 100 millisecond pulses.\n\n\nWhile these are suggested starting points for testing circuitry for weaknesses, the limits may need to be pushed further at the risk of device damage. See [REF-1217] for descriptions of Smart Card attacks against a clock (section 14.6.2) and using a voltage glitch (section 15.5.3).\n\n\n**Detection:** During the implementation phase where actual hardware is available, specialized hardware tools and apparatus such as ChipWhisperer may be used to check if the platform is indeed susceptible to voltage and clock glitching attacks.\n\n**Detection:** Review if the protections against glitching merely transfer the attack target. For example, suppose a critical authentication routine that an attacker would want to bypass is given the protection of modifying certain artifacts from within that specific routine (so that if the routine is bypassed, one can examine the artifacts and figure out that an attack must have happened). However, if the attacker has the ability to bypass the critical authentication routine, they might also have the ability to bypass the other protection routine that checks the artifacts. Basically, depending on these kind of protections is akin to resorting to \"Security by Obscurity\".\n\n**Detection:** Many SoCs come equipped with a built-in Dynamic Voltage and Frequency Scaling (DVFS) that can control the voltage and clocks via software alone. However, there have been demonstrated attacks (like Plundervolt and CLKSCREW) that target this DVFS [REF-1081] [REF-1082]. During the design and implementation phases, one needs to check if the interface to this power management feature is available from unprivileged SW (CWE-1256), which would make the attack very easy.\n\n**Mitigation:** \n\nAt the circuit-level, using Tunable Replica Circuits (TRCs) or special flip-flops such as Razor flip-flops helps mitigate glitch attacks. Working at the SoC or platform base, level sensors may be implemented to detect glitches. Implementing redundancy in security-sensitive code (e.g., where checks are performed)also can help with mitigation of glitch attacks.\n\n",
        "languages": []
    },
    {
        "cwe": "1248",
        "name": "Semiconductor Defects in Hardware Logic with Security-Sensitive Implications",
        "description": "The security-sensitive hardware module contains semiconductor defects.",
        "detail": "**Extended Description:**\n\n\nA semiconductor device can fail for various reasons. While some are manufacturing and packaging defects, the rest are due to prolonged use or usage under extreme conditions. Some mechanisms that lead to semiconductor defects include encapsulation failure, die-attach failure, wire-bond failure, bulk-silicon defects, oxide-layer faults, aluminum-metal faults (including electromigration, corrosion of aluminum, etc.), and thermal/electrical stress. These defects manifest as faults on chip-internal signals or registers, have the effect of inputs, outputs, or intermediate signals being always 0 or always 1, and do not switch as expected. If such faults occur in security-sensitive hardware modules, the security objectives of the hardware module may be compromised.\n\n\n**Mode of Introduction:** May be introduced due to issues in the manufacturing environment or improper handling of components, for example.\n\n**Mode of Introduction:** May be introduced by improper handling or usage outside of rated operating environments (temperature, humidity, etc.)\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability"
        ],
        "mitigation": "**Mitigation:** \n\nWhile semiconductor-manufacturing companies implement several mechanisms to continuously improve the semiconductor manufacturing process to ensure reduction of defects, some defects can only be fixed after manufacturing. Post-manufacturing testing of silicon die is critical. Fault models such as stuck-at-0 or stuck-at-1 must be used to develop post-manufacturing test cases and achieve good coverage. Once the silicon packaging is done, extensive post-silicon testing must be performed to ensure that hardware logic implementing security functionalities is defect-free.\n\n\n**Mitigation:** \n\nOperating the hardware outside device specification, such as at extremely high temperatures, voltage, etc., accelerates semiconductor degradation and results in defects. When these defects manifest as faults in security-critical, hardware modules, it results in compromise of security guarantees. Thus, operating the device within the specification is important.\n\n",
        "languages": []
    },
    {
        "cwe": "1249",
        "name": "Application-Level Admin Tool with Inconsistent View of Underlying Operating System",
        "description": "The product provides an application for administrators to manage parts of the underlying operating system, but the application does not accurately identify all of the relevant entities or resources that exist in the OS; that is, the application's model of the OS's state is inconsistent with the OS's actual state.",
        "detail": "**Extended Description:**\n\n\nMany products provide web-based applications or other interfaces for managing the underlying operating system. This is common with cloud, network access devices, home networking, and other systems. When the management tool does not accurately represent what is in the OS - such as user accounts - then the administrator might not see suspicious activities that would be noticed otherwise.\n\n\nFor example, numerous systems utilize a web front-end for administrative control. They also offer the ability to add, alter, and drop users with various privileges as it relates to the functionality of the system. A potential architectural weakness may exist where the user information reflected in the web interface does not mirror the users in the underlying operating system. Many web UI or REST APIs use the underlying operating system for authentication; the system's logic may also track an additional set of user capabilities within configuration files and datasets for authorization capabilities. When there is a discrepancy between the user information in the UI or REST API's interface system and the underlying operating system's user listing, this may introduce a weakness into the system. For example, if an attacker compromises the OS and adds a new user account - a \"ghost\" account - then the attacker could escape detection if the management tool does not list the newly-added account.\n\n\nThis discrepancy could be exploited in several ways:\n\n\n  - A rogue admin could insert a new account into a system that will persist if they are terminated or wish to take action on a system that cannot be directly associated with them.\n\n  - An attacker can leverage a separate command injection attack available through the web interface to insert a ghost account with shell privileges such as ssh.\n\n  - An attacker can leverage existing web interface APIs, manipulated in such a way that a new user is inserted into the operating system, and the user web account is either partially created or not at all.\n\n  - An attacker could create an admin account which is viewable by an administrator, use this account to create the ghost account, delete logs and delete the first created admin account.\n\nMany of these attacker scenarios can be realized by leveraging separate vulnerabilities related to XSS, command injection, authentication bypass, or logic flaws on the various systems. \n\n**Alternate Terms:** Ghost in the Shell\n\n**Mode of Introduction:** The design might assume that the underlying OS does not change.\n\n**Mode of Introduction:** Assumptions about the underlying OS might be hard-coded into the application or otherwise in external data stores in a way that is not updated when the OS's state changes.\n",
        "parent": [
            "1250"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Accountability"
        ],
        "mitigation": "**Mitigation:** \n\nEnsure that the admin tool refreshes its model of the underlying OS on a regular basis, and note any inconsistencies with configuration files or other data sources that are expected to have the same data.\n\n",
        "languages": []
    },
    {
        "cwe": "125",
        "name": "Out-of-bounds Read",
        "description": "The product reads data past the end, or before the beginning, of the intended buffer.",
        "detail": "**Alternate Terms:** OOB read\n\n**Consequence Note:** An attacker could get secret values such as cryptographic keys, PII, memory addresses, or other information that could be used in additional attacks.\n\n**Consequence Note:** Out-of-bounds memory could contain memory addresses or other information that can be used to bypass ASLR and other protection mechanisms in order to improve the reliability of exploiting a separate weakness for code execution.\n\n**Consequence Note:** An attacker could cause a segmentation fault or crash by causing memory to be read outside of the bounds of the buffer. This is especially likely when the code reads a variable amount of data and assumes that a sentinel exists to stop the read operation, such as a NUL in a string.\n\n**Consequence Note:** The read operation could produce other undefined or unexpected results.\n",
        "parent": [
            "119"
        ],
        "children": [],
        "related": [
            "822",
            "823",
            "824",
            "825"
        ],
        "scopes": [
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nTo reduce the likelihood of introducing an out-of-bounds read, ensure that you validate and ensure correct calculations for any length argument, buffer size calculation, or offset. Be especially careful of relying on a sentinel (i.e. special character such as NUL) in untrusted inputs.\n\n\n**Mitigation:** Use a language that provides appropriate memory abstractions.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1250",
        "name": "Improper Preservation of Consistency Between Independent Representations of Shared State",
        "description": "The product has or supports multiple distributed components or sub-systems that are each required to keep their own local copy of shared data - such as state or cache - but the product does not ensure that all local copies remain consistent with each other.",
        "detail": "**Extended Description:**\n\n\nIn highly distributed environments, or on systems with distinct physical components that operate independently, there is often a need for each component to store and update its own local copy of key data such as state or cache, so that all components have the same \"view\" of the overall system and operate in a coordinated fashion. For example, users of a social media service or a massively multiplayer online game might be using their own personal computers while also interacting with different physical hosts in a globally distributed service, but all participants must be able to have the same \"view\" of the world. Alternately, a processor's Memory Management Unit (MMU) might have \"shadow\" MMUs to distribute its workload, and all shadow MMUs are expected to have the same accessible ranges of memory.\n\n\nIn such environments, it becomes critical for the product to ensure that this \"shared state\" is consistently modified across all distributed systems. If state is not consistently maintained across all systems, then critical transactions might take place out of order, or some users might not get the same data as other users. When this inconsistency affects correctness of operations, it can introduce vulnerabilities in mechanisms that depend on consistent state.\n\n",
        "parent": [
            "664"
        ],
        "children": [
            "1249",
            "1251"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1251",
        "name": "Mirrored Regions with Different Values",
        "description": "The product's architecture mirrors regions without ensuring that their contents always stay in sync.",
        "detail": "**Extended Description:**\n\n\nHaving mirrored regions with different values might result in the exposure of sensitive information or possibly system compromise.\n\n\nIn the interest of increased performance, one might need to duplicate a resource. A cache memory is a common example of this concept, which keeps a \"local\" copy of a data element in the high speed cache memory. Unfortunately, this speed improvement comes with a downside, since the product needs to ensure that the local copy always mirrors the original copy truthfully. If they get out of sync, the computational result is no longer true.\n\n\nDuring hardware design, memory is not the only item which gets mirrored. There are many other entities that get mirrored, as well: registers, memory regions, and, in some cases, even whole computational units. For example, within a multi-core processor, if all memory accesses for each and every core goes through a single Memory-Management Unit (MMU) then the MMU will become a performance bottleneck. In such cases, duplicating local MMUs that will serve only a subset of the cores rather than all of them may resolve the performance issue. These local copies are also called \"shadow copies\" or \"mirrored copies.\"\n\n\nIf the original resource never changed, local duplicate copies getting out of sync would never be an issue. However, the values of the original copy will sometimes change. When the original copy changes, the mirrored copies must also change, and change fast.\n\n\nThis situation of shadow-copy-possibly-out-of-sync-with-original-copy might occur as a result of multiple scenarios, including the following: \n\n\n  - After the values in the original copy change, due to some reason the original copy does not send the \"update\" request to its shadow copies.\n\n  - After the values in the original copy change, the original copy dutifully sends the \"update\" request to its shadow copies, but due to some reason the shadow copy does not \"execute\" this update request.\n\n  - After the values in the original copy change, the original copy sends the \"update\" request to its shadow copies, and the shadow copy executes this update request faithfully. However, during the small time period when the original copy has \"new\" values and the shadow copy is still holding the \"old\" values, an attacker can exploit the old values. Then it becomes a race condition between the attacker and the update process of who can reach the target, shadow copy first, and, if the attacker reaches first, the attacker wins.\n\n  - The attacker might send a \"spoofed\" update request to the target shadow copy, pretending that this update request is coming from the original copy. This spoofed request might cause the targeted shadow copy to update its values to some attacker-friendly values, while the original copies remain unchanged by the attacker.\n\n  - Suppose a situation where the original copy has a system of reverting back to its original value if it does not hear back from all the shadow copies that such copies have successfully completed the update request. In such a case, an attack might occur as follows: (1) the original copy might send an update request; (2) the shadow copy updates it; (3) the shadow copy sends back the successful completion message; (4) through a separate issue, the attacker is able to intercept the shadow copy's completion message. In this case, the original copy thinks that the update did not succeed, hence it reverts to its original value. Now there is a situation where the original copy has the \"old\" value, and the shadow copy has the \"new\" value.\n\n\n",
        "parent": [
            "1250"
        ],
        "children": [],
        "related": [
            "1312"
        ],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** \n\nWhenever there are multiple, physically different copies of the same value that might change and the process to update them is not instantaneous and atomic, it is impossible to assert that the original and shadow copies will always be in sync - there will always be a time period when they are out of sync. To mitigate the consequential risk, the recommendations essentially are:\n\n\n  - Make this out-of-sync time period as small as possible, and\n\n  - Make the update process as robust as possible.\n\n\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1252",
        "name": "CPU Hardware Not Configured to Support Exclusivity of Write and Execute Operations",
        "description": "The CPU is not configured to provide hardware support for exclusivity of write and execute operations on memory. This allows an attacker to execute data from all of memory.",
        "detail": "**Extended Description:**\n\n\nCPUs provide a special bit that supports exclusivity of write and execute operations. This bit is used to segregate areas of memory to either mark them as code (instructions, which can be executed) or data (which should not be executed). In this way, if a user can write to a region of memory, the user cannot execute from that region and vice versa. This exclusivity provided by special hardware bit is leveraged by the operating system to protect executable space. While this bit is available in most modern processors by default, in some CPUs the exclusivity is implemented via a memory-protection unit (MPU) and memory-management unit (MMU) in which memory regions can be carved out with exact read, write, and execute permissions. However, if the CPU does not have an MMU/MPU, then there is no write exclusivity. Without configuring exclusivity of operations via segregated areas of memory, an attacker may be able to inject malicious code onto memory and later execute it.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nImplement a dedicated bit that can be leveraged by the Operating System to mark data areas as non-executable. If such a bit is not available in the CPU, implement MMU/MPU (memory management unit / memory protection unit).\n\n\n**Mitigation:** \n\nIf MMU/MPU are not available, then the firewalls need to be implemented in the SoC interconnect to mimic the write-exclusivity operation.\n\n",
        "languages": []
    },
    {
        "cwe": "1253",
        "name": "Incorrect Selection of Fuse Values",
        "description": "The logic level used to set a system to a secure state relies on a fuse being unblown. An attacker can set the system to an insecure state merely by blowing the fuse.",
        "detail": "**Extended Description:**\n\n\nFuses are often used to store secret data, including security configuration data. When not blown, a fuse is considered to store a logic 0, and, when blown, it indicates a logic 1. Fuses are generally considered to be one-directional, i.e., once blown to logic 1, it cannot be reset to logic 0. However, if the logic used to determine system-security state (by leveraging the values sensed from the fuses) uses negative logic, an attacker might blow the fuse and drive the system to an insecure state.\n\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Logic should be designed in a way that blown fuses do not put the product into an insecure state that can be leveraged by an attacker.\n",
        "languages": []
    },
    {
        "cwe": "1254",
        "name": "Incorrect Comparison Logic Granularity",
        "description": "The product's comparison logic is performed over a series of steps rather than across the entire string in one operation. If there is a comparison logic failure on one of these steps, the operation may be vulnerable to a timing attack that can result in the interception of the process for nefarious purposes.",
        "detail": "**Extended Description:**\n\n\nComparison logic is used to compare a variety of objects including passwords, Message Authentication Codes (MACs), and responses to verification challenges. When comparison logic is implemented at a finer granularity (e.g., byte-by-byte comparison) and breaks in the case of a comparison failure, an attacker can exploit this implementation to identify when exactly the failure occurred. With multiple attempts, the attacker may be able to guesses the correct password/response to challenge and elevate their privileges.\n\n",
        "parent": [
            "208",
            "697"
        ],
        "children": [],
        "related": [
            "1261"
        ],
        "scopes": [
            "Authorization",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** \n\nThe hardware designer should ensure that comparison logic is implemented so as to compare in one operation instead in smaller chunks.\n\n",
        "languages": []
    },
    {
        "cwe": "1255",
        "name": "Comparison Logic is Vulnerable to Power Side-Channel Attacks",
        "description": "A device's real time power consumption may be monitored during security token evaluation and the information gleaned may be used to determine the value of the reference token.",
        "detail": "**Extended Description:**\n\n\nThe power consumed by a device may be instrumented and monitored in real time. If the algorithm for evaluating security tokens is not sufficiently robust, the power consumption may vary by token entry comparison against the reference value. Further, if retries are unlimited, the power difference between a \"good\" entry and a \"bad\" entry may be observed and used to determine whether each entry itself is correct thereby allowing unauthorized parties to calculate the reference value.\n\n\n**Mode of Introduction:** The design of the algorithm itself may intrinsically allow the power side channel attack to be effective\n\n**Mode of Introduction:** This weakness may be introduced during implementation despite a robust design that otherwise prevents exploitation\n\n**Consequence Note:** As compromising a security token may result in complete system control, the impacts are relatively universal.\n",
        "parent": [
            "1300"
        ],
        "children": [],
        "related": [
            "1259"
        ],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** The design phase must consider each check of a security token against a standard and the amount of power consumed during the check of a good token versus a bad token. The alternative is an all at once check where a retry counter is incremented PRIOR to the check.\n\n**Mitigation:** Another potential mitigation is to parallelize shifting of secret data (see example 2 below). Note that the wider the bus the more effective the result.\n\n**Mitigation:** An additional potential mitigation is to add random data to each crypto operation then subtract it out afterwards. This is highly effective but costly in performance, area, and power consumption. It also requires a random number generator.\n\n**Mitigation:** If the architecture is unable to prevent the attack, using filtering components may reduce the ability to implement an attack, however, consideration must be given to the physical removal of the filter elements.\n\n**Mitigation:** During integration, avoid use of a single secret for an extended period (e.g. frequent key updates). This limits the amount of data compromised but at the cost of complexity of use.\n",
        "languages": []
    },
    {
        "cwe": "1256",
        "name": "Improper Restriction of Software Interfaces to Hardware Features",
        "description": "The product provides software-controllable\n\t\t\tdevice functionality for capabilities such as power and\n\t\t\tclock management, but it does not properly limit\n\t\t\tfunctionality that can lead to modification of\n\t\t\thardware memory or register bits, or the ability to\n\t\t\tobserve physical side channels.",
        "detail": "**Extended Description:**\n\n\nIt is frequently assumed that physical attacks such as fault injection and side-channel analysis require an attacker to have physical access to the target device. This assumption may be false if the device has improperly secured power management features, or similar features. For mobile devices, minimizing power consumption is critical, but these devices run a wide variety of applications with different performance requirements. Software-controllable mechanisms to dynamically scale device voltage and frequency and monitor power consumption are common features in today's chipsets, but they also enable attackers to mount fault injection and side-channel attacks without having physical access to the device.\n\n\nFault injection attacks involve strategic manipulation of bits in a device to achieve a desired effect such as skipping an authentication step, elevating privileges, or altering the output of a cryptographic operation. Manipulation of the device clock and voltage supply is a well-known technique to inject faults and is cheap to implement with physical device access. Poorly protected power management features allow these attacks to be performed from software. Other features, such as the ability to write repeatedly to DRAM at a rapid rate from unprivileged software, can result in bit flips in other memory locations (Rowhammer, [REF-1083]).\n\n\nSide channel analysis requires gathering measurement traces of physical quantities such as power consumption. Modern processors often include power metering capabilities in the hardware itself (e.g., Intel RAPL) which if not adequately protected enable attackers to gather measurements necessary for performing side-channel attacks from software.\n\n\n**Mode of Introduction:** An architect may initiate introduction of this weakness via exacting requirements for software accessible power/clock management requirements\n\n**Mode of Introduction:** An implementer may introduce this weakness by assuming there are no consequences to unbounded power and clock management for secure components from untrusted ones.\n",
        "parent": [
            "285"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Perform a security evaluation of system-level architecture and design with software-aided physical attacks in scope.\n\n**Detection:** \n\nUse custom software to change registers that control clock settings or power settings to try to bypass security locks, or repeatedly write DRAM to try to change adjacent locations. This can be effective in extracting or changing data. The drawback is that it cannot be run before manufacturing, and it may require specialized software.\n\n\n**Mitigation:** \n\nEnsure proper access control mechanisms protect software-controllable features altering physical operating conditions such as clock frequency and voltage.\n\n",
        "languages": []
    },
    {
        "cwe": "1257",
        "name": "Improper Access Control Applied to Mirrored or Aliased Memory Regions",
        "description": "Aliased or mirrored memory regions in hardware designs may have inconsistent read/write permissions enforced by the hardware. A possible result is that an untrusted agent is blocked from accessing a memory region but is not blocked from accessing the corresponding aliased memory region.\n\t\t\t",
        "detail": "**Extended Description:**\n\n\nHardware product designs often need to implement memory protection features that enable privileged software to define isolated memory regions and access control (read/write) policies. Isolated memory regions can be defined on different memory spaces in a design (e.g. system physical address, virtual address, memory mapped IO).\n\n\nEach memory cell should be mapped and assigned a system address that the core software can use to read/write to that memory. It is possible to map the same memory cell to multiple system addresses such that read/write to any of the aliased system addresses would be decoded to the same memory cell.\n\n\nThis is commonly done in hardware designs for redundancy and simplifying address decoding logic. If one of the memory regions is corrupted or faulty, then that hardware can switch to using the data in the mirrored memory region. Memory aliases can also be created in the system address map if the address decoder unit ignores higher order address bits when mapping a smaller address region into the full system address.\n\n\nA common security weakness that can exist in such memory mapping is that aliased memory regions could have different read/write access protections enforced by the hardware such that an untrusted agent is blocked from accessing a memory address but is not blocked from accessing the corresponding aliased memory address. Such inconsistency can then be used to bypass the access protection of the primary memory block and read or modify the protected memory.\n\n\nAn untrusted agent could also possibly create memory aliases in the system address map for malicious purposes if it is able to change the mapping of an address region or modify memory region sizes.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [
            "119"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** The checks should be applied for consistency access rights between primary memory regions and any mirrored or aliased memory regions. If different memory protection units (MPU) are protecting the aliased regions, their protected range definitions and policies should be synchronized.\n\n**Mitigation:** The controls that allow enabling memory aliases or changing the size of mapped memory regions should only be programmable by trusted software components.\n",
        "languages": []
    },
    {
        "cwe": "1258",
        "name": "Exposure of Sensitive System Information Due to Uncleared Debug Information",
        "description": "The hardware does not fully clear security-sensitive values, such as keys and intermediate values in cryptographic operations, when debug mode is entered.",
        "detail": "**Extended Description:**\n\n\nSecurity sensitive values, keys, intermediate steps of cryptographic operations, etc. are stored in temporary registers in the hardware. If these values are not cleared when debug mode is entered they may be accessed by a debugger allowing sensitive information to be accessible by untrusted parties.\n\n",
        "parent": [
            "200",
            "212"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** \n\nWhenever debug mode is enabled, all registers containing sensitive assets must be cleared.\n\n",
        "languages": []
    },
    {
        "cwe": "1259",
        "name": "Improper Restriction of Security Token Assignment",
        "description": "The System-On-A-Chip (SoC) implements a Security Token mechanism to differentiate what actions are allowed or disallowed when a transaction originates from an entity. However, the Security Tokens are improperly protected.",
        "detail": "**Extended Description:**\nSystems-On-A-Chip (Integrated circuits and hardware engines) implement Security Tokens to differentiate and identify which actions originated from which agent. These actions may be one of the directives: 'read', 'write', 'program', 'reset', 'fetch', 'compute', etc. Security Tokens are assigned to every agent in the System that is capable of generating an action or receiving an action from another agent. Multiple Security Tokens may be assigned to an agent and may be unique based on the agent's trust level or allowed privileges. Since the Security Tokens are integral for the maintenance of security in an SoC, they need to be protected properly. A common weakness afflicting Security Tokens is improperly restricting the assignment to trusted components. Consequently, an improperly protected Security Token may be able to be programmed by a malicious agent (i.e., the Security Token is mutable) to spoof the action as if it originated from a trusted agent.\n",
        "parent": [
            "1294",
            "284"
        ],
        "children": [],
        "related": [
            "1255"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\n  - Security Token assignment review checks for design inconsistency and common weaknesses.\n\n  - Security-Token definition and programming flow is tested in both pre-silicon and post-silicon testing.\n\n\n",
        "languages": []
    },
    {
        "cwe": "126",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "170"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1260",
        "name": "Improper Handling of Overlap Between Protected Memory Ranges",
        "description": "The product allows address regions to overlap, which can result in the bypassing of intended memory protection.",
        "detail": "**Extended Description:**\n\n\nIsolated memory regions and access control (read/write) policies are used by hardware to protect privileged software. Software components are often allowed to change or remap memory region definitions in order to enable flexible and dynamically changeable memory management by system software.\n\n\nIf a software component running at lower privilege can program a memory address region to overlap with other memory regions used by software running at higher privilege, privilege escalation may be available to attackers. The memory protection unit (MPU) logic can incorrectly handle such an address overlap and allow the lower-privilege software to read or write into the protected memory region, resulting in privilege escalation attack. An address overlap weakness can also be used to launch a denial of service attack on the higher-privilege software memory regions.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design or implementation and identified later during the Testing phase.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [
            "119"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Create a high privilege memory block of any arbitrary size. Attempt to create a lower privilege memory block with an overlap of the high privilege memory block. If the creation attempt works, fix the hardware. Repeat the test.\n\n**Mitigation:** \n\nEnsure that memory regions are isolated as intended and that access control (read/write) policies are used by hardware to protect privileged software.\n\n\n**Mitigation:** \n\nFor all of the programmable memory protection regions, the memory protection unit (MPU) design can define a priority scheme.\n\n\nFor example: if three memory regions can be programmed (Region_0, Region_1, and Region_2), the design can enforce a priority scheme, such that, if a system address is within multiple regions, then the region with the lowest ID takes priority and the access-control policy of that region will be applied. In some MPU designs, the priority scheme can also be programmed by trusted software.\n\n\nHardware logic or trusted firmware can also check for region definitions and block programming of memory regions with overlapping addresses. \n\n\nThe memory-access-control-check filter can also be designed to apply a policy filter to all of the overlapping ranges, i.e., if an address is within Region_0 and Region_1, then access to this address is only granted if both Region_0 and Region_1 policies allow the access.\n\n",
        "languages": []
    },
    {
        "cwe": "1261",
        "name": "Improper Handling of Single Event Upsets",
        "description": "The hardware logic does not effectively handle when single-event upsets (SEUs) occur.",
        "detail": "**Extended Description:**\n\n\nTechnology trends such as CMOS-transistor down-sizing, use of new materials, and system-on-chip architectures continue to increase the sensitivity of systems to soft errors. These errors are random, and their causes might be internal (e.g., interconnect coupling) or external (e.g., cosmic radiation). These soft errors are not permanent in nature and cause temporary bit flips known as single-event upsets (SEUs). SEUs are induced errors in circuits caused when charged particles lose energy by ionizing the medium through which they pass, leaving behind a wake of electron-hole pairs that cause temporary failures. If these failures occur in security-sensitive modules in a chip, it might compromise the security guarantees of the chip. For instance, these temporary failures could be bit flips that change the privilege of a regular user to root.\n\n",
        "parent": [
            "1384"
        ],
        "children": [],
        "related": [
            "1254"
        ],
        "scopes": [
            "Access Control",
            "Availability"
        ],
        "mitigation": "**Mitigation:** \n\nImplement triple-modular redundancy around security-sensitive modules.\n\n\n**Mitigation:** \n\nSEUs mostly affect SRAMs. For SRAMs storing security-critical data, implement Error-Correcting-Codes (ECC) and Address Interleaving.\n\n",
        "languages": []
    },
    {
        "cwe": "1262",
        "name": "Improper Access Control for Register Interface",
        "description": "The product uses memory-mapped I/O registers that act as an interface to hardware functionality from software, but there is improper access control to those registers.",
        "detail": "**Extended Description:**\n\n\nSoftware commonly accesses peripherals in a System-on-Chip (SoC) or other device through a memory-mapped register interface. Malicious software could tamper with any security-critical hardware data that is accessible directly or indirectly through the register interface, which could lead to a loss of confidentiality and integrity.\n\n\n**Mode of Introduction:** This weakness may be exploited if the register interface design does not adequately protect hardware assets from software.\n\n**Mode of Introduction:** Mis-implementation of access control policies may inadvertently allow access to hardware assets through the register interface.\n\n**Consequence Note:** Confidentiality of hardware assets may be violated if the protected information can be read out by software through the register interface. Registers storing security state, settings, other security-critical data may be corruptible by software without correctly implemented protections.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** This is applicable in the Architecture phase before implementation started. Make sure access policy is specified for the entire memory map. Manual analysis may not ensure the implementation is correct.\n\n**Detection:** Registers controlling hardware should have access control implemented. This access control may be checked manually for correct implementation. Items to check consist of how are trusted parties set, how are trusted parties verified, how are accesses verified, etc. Effectiveness of a manual analysis will vary depending upon how complicated the interface is constructed.\n\n**Detection:** Functional simulation is applicable during the Implementation Phase. Testcases must be created and executed for memory mapped registers to verify adherence to the access control policy. This method can be effective, since functional verification needs to be performed on the design, and verification for this weakness will be included. There can be difficulty covering the entire memory space during the test.\n\n**Detection:** Formal verification is applicable during the Implementation phase. Assertions need to be created in order to capture illegal register access scenarios and prove that they cannot occur. Formal methods are exhaustive and can be very effective, but creating the cases for large designs may be complex and difficult.\n\n**Detection:** Information flow tracking can be applicable during the Implementation phase. Security sensitive data (assets) - for example, as stored in registers - is automatically tracked over time through the design to verify the data doesn't reach illegal destinations that violate the access policies for the memory map. This method can be very effective when used together with simulation and emulation, since detecting violations doesn't rely on specific scenarios or data values. This method does rely on simulation and emulation, so testcases must exist in order to use this method.\n\n**Detection:** Manual documentation review of the system memory map, register specification, and permissions associated with accessing security-relevant functionality exposed via memory-mapped registers.\n\n**Detection:** Perform penetration testing (either manual or semi-automated with fuzzing) to verify that access control mechanisms such as the memory protection units or on-chip bus firewall settings adequately protect critical hardware registers from software access.\n\n**Mitigation:** Design proper policies for hardware register access from software.\n\n**Mitigation:** Ensure that access control policies for register access are implemented in accordance with the specified design.\n",
        "languages": []
    },
    {
        "cwe": "1263",
        "name": "Improper Physical Access Control",
        "description": "The product is designed with access restricted to certain information, but it does not sufficiently protect against an unauthorized actor with physical access to these areas.",
        "detail": "**Extended Description:**\nSections of a product intended to have restricted access may be inadvertently or intentionally rendered accessible when the implemented physical protections are insufficient. The specific requirements around how robust the design of the physical protection mechanism needs to be depends on the type of product being protected. Selecting the correct physical protection mechanism and properly enforcing it through implementation and manufacturing are critical to the overall physical security of the product.\n\n**Mode of Introduction:** This weakness can arise if design decisions are made that do not align with the intended physical protection of the product\n\n**Mode of Introduction:** While the architecture and design phase of the product may have accurately met the intended robustness for product physical protections, this phase may introduce the weakness through errors in physically manufacturing the product.\n",
        "parent": [
            "284"
        ],
        "children": [
            "1243"
        ],
        "related": [
            "1191"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Specific protection requirements depend strongly on contextual factors including the level of acceptable risk associated with compromise to the product's protection mechanism. Designers could incorporate anti-tampering measures that protect against or detect when the product has been tampered with.\n\n**Mitigation:** The testing phase of the lifecycle should establish a method for determining whether the protection mechanism is sufficient to prevent unauthorized access.\n\n**Mitigation:** Ensure that all protection mechanisms are fully activated at the time of manufacturing and distribution.\n",
        "languages": []
    },
    {
        "cwe": "1264",
        "name": "Hardware Logic with Insecure De-Synchronization between Control and Data Channels",
        "description": "The hardware logic for error handling and security checks can incorrectly forward data before the security check is complete.",
        "detail": "**Extended Description:**\n\n\nMany high-performance on-chip bus protocols and processor data-paths employ separate channels for control and data to increase parallelism and maximize throughput. Bugs in the hardware logic that handle errors and security checks can make it possible for data to be forwarded before the completion of the security checks. If the data can propagate to a location in the hardware observable to an attacker, loss of data confidentiality can occur. 'Meltdown' is a concrete example of how de-synchronization between data and permissions checking logic can violate confidentiality requirements. Data loaded from a page marked as privileged was returned to the cpu regardless of current privilege level for performance reasons. The assumption was that the cpu could later remove all traces of this data during the handling of the illegal memory access exception, but this assumption was proven false as traces of the secret data were not removed from the microarchitectural state.\n\n\n**Mode of Introduction:** The weakness can be introduced in the data transfer or bus protocol itself or in the implementation.\n",
        "parent": [
            "821"
        ],
        "children": [],
        "related": [
            "1037"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** \n\nThoroughly verify the data routing logic to ensure that any error handling or security checks effectively block illegal dataflows.\n\n",
        "languages": []
    },
    {
        "cwe": "1265",
        "name": "Unintended Reentrant Invocation of Non-reentrant Code Via Nested Calls",
        "description": "During execution of non-reentrant code, the product performs a call that unintentionally produces a nested invocation of the non-reentrant code.",
        "detail": "**Extended Description:**\nIn a complex product, a single function call may lead to many different possible code paths, some of which may involve deeply nested calls. It may be difficult to foresee all possible code paths that could emanate from a given function call. In some systems, an external actor can manipulate inputs to the system and thereby achieve a wide range of possible control flows. This is frequently a concern in products that execute scripts from untrusted sources. Examples of such products are web browsers and PDF readers. A weakness is present when one of the possible code paths resulting from a function call alters program state that the original caller assumes to be unchanged during the call.\n\n**Consequence Note:** Exploitation of this weakness can leave the application in an unexpected state and cause variables to be reassigned before the first invocation has completed. This may eventually result in memory corruption or unexpected code execution.\n",
        "parent": [
            "691"
        ],
        "children": [],
        "related": [
            "416",
            "663"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** When architecting a system that will execute untrusted code in response to events, consider executing the untrusted event handlers asynchronously (asynchronous message passing) as opposed to executing them synchronously at the time each event fires. The untrusted code should execute at the start of the next iteration of the thread's message loop. In this way, calls into non-reentrant code are strictly serialized, so that each operation completes fully before the next operation begins. Special attention must be paid to all places where type coercion may result in script execution. Performing all needed coercions at the very beginning of an operation can help reduce the chance of operations executing at unexpected junctures.\n\n**Mitigation:** Make sure the code (e.g., function or class) in question is reentrant by not leveraging non-local data, not modifying its own code, and not calling other non-reentrant code.\n",
        "languages": []
    },
    {
        "cwe": "1266",
        "name": "Improper Scrubbing of Sensitive Data from Decommissioned Device",
        "description": "The product does not properly provide a capability for the product administrator to remove sensitive data at the time the product is decommissioned.  A scrubbing capability could be missing, insufficient, or incorrect.",
        "detail": "**Extended Description:**\n\n\nWhen a product is decommissioned - i.e., taken out of service - best practices or regulatory requirements may require the administrator to remove or overwrite sensitive data first, i.e. \"scrubbing.\" Improper scrubbing of sensitive data from a decommissioned device leaves that data vulnerable to acquisition by a malicious actor. Sensitive data may include, but is not limited to, device/manufacturer proprietary information, user/device credentials, network configurations, and other forms of sensitive data.\n\n",
        "parent": [
            "404"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** \n\nFunctionality to completely scrub data from a product at the conclusion of its lifecycle should be part of the design phase. Trying to add this function on top of an existing architecture could lead to incomplete removal of sensitive information/data.\n\n\n**Mitigation:** \n\nThe manufacturer should describe the location(s) where sensitive data is stored and the policies and procedures for its removal. This information may be conveyed, for example, in an Administrators Guide or a Statement of Volatility.\n\n\n**Mitigation:** \n\nIf the capability to wipe sensitive data isn't built-in, the manufacturer may need to provide a utility to scrub sensitive data from storage if that data is located in a place which is non-accessible by the administrator. One example of this could be when sensitive data is stored on an EEPROM for which there is no user/admin interface provided by the system.\n\n",
        "languages": []
    },
    {
        "cwe": "1267",
        "name": "Policy Uses Obsolete Encoding",
        "description": "The product uses an obsolete encoding mechanism to implement access controls.",
        "detail": "**Extended Description:**\n\n\nWithin a System-On-a-Chip (SoC), various circuits and hardware engines generate transactions for the purpose of accessing (read/write) assets or performing various actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (identifying the originator of the transaction) and a destination identity (routing the transaction to the respective entity). Sometimes the transactions are qualified with a Security Token. This Security Token helps the destination agent decide on the set of allowed actions (e.g., access to an asset for reads and writes). A policy encoder is used to map the bus transactions to Security Tokens that in turn are used as access-controls/protection mechanisms. A common weakness involves using an encoding which is no longer trusted, i.e., an obsolete encoding.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nSecurity Token Decoders should be reviewed for design inconsistency and common weaknesses.\n\n\nAccess and programming flows should be tested in both pre-silicon and post-silicon testing.\n\n",
        "languages": []
    },
    {
        "cwe": "1268",
        "name": "Policy Privileges are not Assigned Consistently Between Control and Data Agents",
        "description": "The product's hardware-enforced access control for a particular resource improperly accounts for privilege discrepancies between control and write policies.\n\t\t\t   ",
        "detail": "**Extended Description:**\n\n\nIntegrated circuits and hardware engines may provide access to resources (device-configuration, encryption keys, etc.) belonging to trusted firmware or software modules (commonly set by a BIOS or a bootloader). These accesses are typically controlled and limited by the hardware. Hardware design access control is sometimes implemented using a policy. A policy defines which entity or agent may or may not be allowed to perform an action. When a system implements multiple levels of policies, a control policy may allow direct access to a resource as well as changes to the policies themselves.\n\n\nResources that include agents in their control policy but not in their write policy could unintentionally allow an untrusted agent to insert itself in the write policy register. Inclusion in the write policy register could allow a malicious or misbehaving agent write access to resources. This action could result in security compromises including leaked information, leaked encryption keys, or modification of device configuration.\n\n\n**Mode of Introduction:** This weakness may be introduced during the design of a device when the architect does not comprehensively specify all of the policies required by an agent.\n\n**Mode of Introduction:** This weakness may be introduced during implementation if device policy restrictions do not sufficiently constrain less-privileged clients.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Access-control-policy definition and programming flow must be sufficiently tested in pre-silicon and post-silicon testing.\n",
        "languages": []
    },
    {
        "cwe": "1269",
        "name": "Product Released in Non-Release Configuration",
        "description": "The product released to market is released in pre-production or manufacturing configuration.",
        "detail": "**Extended Description:**\n\n\nProducts in the pre-production or manufacturing stages are configured to have many debug hooks and debug capabilities, including but not limited to:\n\n\n  - Ability to override/bypass various cryptographic checks (including authentication, authorization, and integrity)\n\n  - Ability to read/write/modify/dump internal state (including registers and memory)\n\n  - Ability to change system configurations\n\n  - Ability to run hidden or private commands that are not allowed during production (as they expose IP).\n\nThe above is by no means an exhaustive list, but it alludes to the greater capability and the greater state of vulnerability of a product during it's preproduction or manufacturing state.\n\nComplexity increases when multiple parties are involved in executing the tests before the final production version. For example, a chipmaker might fabricate a chip and run its own preproduction tests, following which the chip would be delivered to the Original Equipment Manufacturer (OEM), who would now run a second set of different preproduction tests on the same chip. Only after both of these sets of activities are complete, can the overall manufacturing phase be called \"complete\" and have the \"Manufacturing Complete\" fuse blown. However, if the OEM forgets to blow the Manufacturing Complete fuse, then the system remains in the manufacturing stage, rendering the system both exposed and vulnerable.\n\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).\n\n**Mitigation:** Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).\n\n**Mitigation:** Ensure that there exists a marker for denoting the Manufacturing Complete stage and that the Manufacturing Complete marker gets updated at the Manufacturing Complete stage (i.e., the Manufacturing Complete fuse gets blown).\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "127",
        "name": "Buffer Under-read",
        "description": "The product reads from a buffer using buffer access mechanisms such as indexes or pointers that reference memory locations prior to the targeted buffer.",
        "detail": "**Extended Description:**\nThis typically occurs when the pointer or its index is decremented to a position before the buffer, when pointer arithmetic results in a position before the beginning of the valid memory location, or when a negative index is used. This may result in exposure of sensitive information or possibly a crash.\n\n**Consequence Note:** By reading out-of-bounds memory, an attacker might be able to get secret values, such as memory addresses, which can be bypass protection mechanisms such as ASLR in order to improve the reliability and likelihood of exploiting a separate weakness to achieve code execution instead of just denial of service.\n",
        "parent": [
            "125",
            "786"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1270",
        "name": "Generation of Incorrect Security Tokens",
        "description": "The product implements a Security Token mechanism to differentiate what actions are allowed or disallowed when a transaction originates from an entity. However, the Security Tokens generated in the system are incorrect.",
        "detail": "**Extended Description:**\n\n\nSystems-On-a-Chip (SoC) (Integrated circuits and hardware engines) implement Security Tokens to differentiate and identify actions originated from various agents. These actions could be \"read\", \"write\", \"program\", \"reset\", \"fetch\", \"compute\", etc. Security Tokens are generated and assigned to every agent on the SoC that is either capable of generating an action or receiving an action from another agent. Every agent could be assigned a unique, Security Token based on its trust level or privileges. Incorrectly generated Security Tokens could result in the same token used for multiple agents or multiple tokens being used for the same agent. This condition could result in a Denial-of-Service (DoS) or the execution of an action that in turn could result in privilege escalation or unintended access.\n\n",
        "parent": [
            "1294",
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\n  - Generation of Security Tokens should be reviewed for design inconsistency and common weaknesses.\n\n  - Security-Token definition and programming flow should be tested in pre-silicon and post-silicon testing.\n\n\n",
        "languages": []
    },
    {
        "cwe": "1271",
        "name": "Uninitialized Value on Reset for Registers Holding Security Settings",
        "description": "Security-critical logic is not set to a known value on reset.",
        "detail": "**Extended Description:**\n\n\nWhen the device is first brought out of reset, the state of registers will be indeterminate if they have not been initialized by the logic. Before the registers are initialized, there will be a window during which the device is in an insecure state and may be vulnerable to attack.\n\n",
        "parent": [
            "909"
        ],
        "children": [],
        "related": [
            "1304"
        ],
        "scopes": [
            "Access Control",
            "Authentication",
            "Authorization"
        ],
        "mitigation": "**Mitigation:** Design checks should be performed to identify any uninitialized flip-flops used for security-critical functions.\n\n**Mitigation:** All registers holding security-critical information should be set to a specific value on reset.\n",
        "languages": []
    },
    {
        "cwe": "1272",
        "name": "Sensitive Information Uncleared Before Debug/Power State Transition",
        "description": "The product performs a power or debug state transition, but it does not clear sensitive information that should no longer be accessible due to changes to information access restrictions.",
        "detail": "**Extended Description:**\n\n\nA device or system frequently employs many power and sleep states during its normal operation (e.g., normal power, additional power, low power, hibernate, deep sleep, etc.). A device also may be operating within a debug condition. State transitions can happen from one power or debug state to another. If there is information available in the previous state which should not be available in the next state and is not properly removed before the transition into the next state, sensitive information may leak from the system.\n\n\n**Consequence Note:** Sensitive information may be used to unlock additional capabilities of the device and take advantage of hidden functionalities which could be used to compromise device security.\n",
        "parent": [
            "226"
        ],
        "children": [],
        "related": [
            "200"
        ],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Write a known pattern into each sensitive location. Enter the power/debug state in question. Read data back from the sensitive locations. If the reads are successful, and the data is the same as the pattern that was originally written, the test fails and the device needs to be fixed. Note that this test can likely be automated.\n\n**Mitigation:** During state transitions, information not needed in the next state should be removed before the transition to the next state.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1273",
        "name": "Device Unlock Credential Sharing",
        "description": "The credentials necessary for unlocking a device are shared across multiple parties and may expose sensitive information.",
        "detail": "**Extended Description:**\n\n\n\"Unlocking a device\" often means activating certain unadvertised debug and manufacturer-specific capabilities of a device using sensitive credentials. Unlocking a device might be necessary for the purpose of troubleshooting device problems. For example, suppose a device contains the ability to dump the content of the full system memory by disabling the memory-protection mechanisms. Since this is a highly security-sensitive capability, this capability is \"locked\" in the production part. Unless the device gets unlocked by supplying the proper credentials, the debug capabilities are not available. For cases where the chip designer, chip manufacturer (fabricator), and manufacturing and assembly testers are all employed by the same company, the risk of compromise of the credentials is greatly reduced. However, the risk is greater when the chip designer is employed by one company, the chip manufacturer is employed by another company (a foundry), and the assemblers and testers are employed by yet a third company. Since these different companies will need to perform various tests on the device to verify correct device function, they all need to share the unlock key. Unfortunately, the level of secrecy and policy might be quite different at each company, greatly increasing the risk of sensitive credentials being compromised.\n\n\n**Consequence Note:** Once unlock credentials are compromised, an attacker can use the credentials to unlock the device and gain unauthorized access to the hidden functionalities protected by those credentials.\n",
        "parent": [
            "200"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Ensure the unlock credentials are shared with the minimum number of parties and with utmost secrecy. To limit the risk associated with compromised credentials, where possible, the credentials should be part-specific.\n\n**Mitigation:** Ensure the unlock credentials are shared with the minimum number of parties and with utmost secrecy. To limit the risk associated with compromised credentials, where possible, the credentials should be part-specific.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1274",
        "name": "Improper Access Control for Volatile Memory Containing Boot Code",
        "description": "The product conducts a secure-boot process that transfers bootloader code from Non-Volatile Memory (NVM) into Volatile Memory (VM), but it does not have sufficient access control or other protections for the Volatile Memory.",
        "detail": "**Extended Description:**\n\n\nAdversaries could bypass the secure-boot process and execute their own untrusted, malicious boot code.\n\n\nAs a part of a secure-boot process, the read-only-memory (ROM) code for a System-on-Chip (SoC) or other system fetches bootloader code from Non-Volatile Memory (NVM) and stores the code in Volatile Memory (VM), such as dynamic, random-access memory (DRAM) or static, random-access memory (SRAM). The NVM is usually external to the SoC, while the VM is internal to the SoC. As the code is transferred from NVM to VM, it is authenticated by the SoC's ROM code.\n\n\nIf the volatile-memory-region protections or access controls are insufficient to prevent modifications from an adversary or untrusted agent, the secure boot may be bypassed or replaced with the execution of an adversary's code.\n\n\n**Mode of Introduction:** This weakness can be introduced during hardware architecture or design but can be identified later during testing.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Integrity"
        ],
        "mitigation": "**Detection:** Ensure the volatile memory is lockable or has locks. Ensure the volatile memory is locked for writes from untrusted agents or adversaries. Try modifying the volatile memory from an untrusted agent, and ensure these writes are dropped.\n\n**Detection:** \n\nAnalyze the device using the following steps:\n\n\n  1. Identify all fabric master agents that are active during system Boot Flow when initial code is loaded from Non-volatile storage to volatile memory.\n\n  1. Identify the volatile memory regions that are used for storing loaded system executable program.\n\n  1. During system boot, test programming the identified memory regions in step 2 from all the masters identified in step 1.\n\nOnly trusted masters should be allowed to write to the memory regions. For example, pluggable device peripherals should not have write access to program load memory regions.\n\n**Mitigation:** Ensure that the design of volatile-memory protections is enough to prevent modification from an adversary or untrusted code.\n\n**Mitigation:** Test the volatile-memory protections to ensure they are safe from modification or untrusted code.\n",
        "languages": []
    },
    {
        "cwe": "1275",
        "name": "Sensitive Cookie with Improper SameSite Attribute",
        "description": "The SameSite attribute for sensitive cookies is not set, or an insecure value is used.",
        "detail": "**Extended Description:**\nThe SameSite attribute controls how cookies are sent for cross-domain requests. This attribute may have three values: 'Lax', 'Strict', or 'None'. If the 'None' value is used, a website may create a cross-domain POST HTTP request to another website, and the browser automatically adds cookies to this request. This may lead to Cross-Site-Request-Forgery (CSRF) attacks if there are no additional protections in place (such as Anti-CSRF tokens).\n\n**Mode of Introduction:** This weakness occurs during implementation when the coder does not properly set the SameSite attribute.\n\n**Consequence Note:** If the website does not impose additional defense against CSRF attacks, failing to use the 'Lax' or 'Strict' values could increase the risk of exposure to CSRF attacks. The likelihood of the integrity breach is Low because a successful attack does not only depend on an insecure SameSite attribute. In order to perform a CSRF attack there are many conditions that must be met, such as the lack of CSRF tokens, no confirmations for sensitive actions on the website, a \"simple\" \"Content-Type\" header in the HTTP request and many more.\n",
        "parent": [
            "923"
        ],
        "children": [],
        "related": [
            "352"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Set the SameSite attribute of a sensitive cookie to 'Lax' or 'Strict'. This instructs the browser to apply this cookie only to same-domain requests, which provides a good Defense in Depth against CSRF attacks. When the 'Lax' value is in use, cookies are also sent for top-level cross-domain navigation via HTTP GET, HEAD, OPTIONS, and TRACE methods, but not for other HTTP methods that are more like to cause side-effects of state mutation.\n\n**Effectiveness:** While this mitigation is effective for protecting cookies from a browser's own scripting engine, third-party components or plugins may have their own engines that allow access to cookies. Attackers might also be able to use XMLHTTPResponse to read the headers directly and obtain the cookie.\n",
        "languages": []
    },
    {
        "cwe": "1276",
        "name": "Hardware Child Block Incorrectly Connected to Parent System",
        "description": "Signals between a hardware IP and the parent system design are incorrectly connected causing security risks.",
        "detail": "**Extended Description:**\n\n\nIndividual hardware IP must communicate with the parent system in order for the product to function correctly and as intended. If implemented incorrectly, while not causing any apparent functional issues, may cause security issues. For example, if the IP should only be reset by a system-wide hard reset, but instead the reset input is connected to a software-triggered debug mode reset (which is also asserted during a hard reset), integrity of data inside the IP can be violated.\n\n\n**Mode of Introduction:** This weakness is introduced when integrating IP into a parent design.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** System-level verification may be used to ensure that components are correctly connected and that design security requirements are not violated due to interactions between various IP blocks.\n",
        "languages": []
    },
    {
        "cwe": "1277",
        "name": "Firmware Not Updateable",
        "description": "The product does not provide its\n\t\t\tusers with the ability to update or patch its\n\t\t\tfirmware to address any vulnerabilities or\n\t\t\tweaknesses that may be present.",
        "detail": "**Extended Description:**\nWithout the ability to patch or update firmware, consumers will be left vulnerable to exploitation of any known vulnerabilities, or any vulnerabilities that are discovered in the future. This can expose consumers to permanent risk throughout the entire lifetime of the device, which could be years or decades. Some external protective measures and mitigations might be employed to aid in preventing or reducing the risk of malicious attack, but the root weakness cannot be corrected.\n\n**Mode of Introduction:** Requirements development might not consider the importance of updates over the lifetime of the product, or might not choose the ability due to concerns such as expense or speed to market.\n\n**Mode of Introduction:** Lack of planning during architecture development and design, or external pressures such as speed to market, could ignore the capability to update.\n\n**Mode of Introduction:** The weakness can appear through oversight during implementation.\n\n**Consequence Note:** If an attacker can identify an exploitable vulnerability in one device that has no means of patching, the attack may be used against an entire class of devices.\n",
        "parent": [
            "1329"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Authentication",
            "Authorization",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Create a new installable boot image of the current build with a minor version number change. Use the standard installation method to update the boot image. Verify that the minor version number has changed. Create a fake image. Verify that the boot updater will not install the fake image and generates an \"invalid image\" error message or equivalent.\n\n**Detection:** Check the consumer or maintainer documentation, the architecture/design documentation, or the original requirements to ensure that the documentation includes details for how to update the firmware.\n\n**Detection:** Determine if there is a lack of a capability to update read-only memory (ROM) structure. This could manifest as a difference between the latest firmware version and the current version within the device.\n\n**Mitigation:** Specify requirements to include the ability to update the firmware. Include integrity checks and authentication to ensure that untrusted firmware cannot be installed.\n\n**Mitigation:** Design the device to allow for updating the firmware. Ensure that the design specifies how to distribute the updates and ensure their integrity and authentication.\n\n**Mitigation:** Implement the necessary functionality to allow the firmware to be updated.\n",
        "languages": []
    },
    {
        "cwe": "1278",
        "name": "Missing Protection Against Hardware Reverse Engineering Using Integrated Circuit (IC) Imaging Techniques",
        "description": "Information stored in hardware may be recovered by an attacker with the capability to capture and analyze images of the integrated circuit using techniques such as scanning electron microscopy.",
        "detail": "**Extended Description:**\n\n\nThe physical structure of a device, viewed at high enough magnification, can reveal the information stored inside. Typical steps in IC reverse engineering involve removing the chip packaging (decapsulation) then using various imaging techniques ranging from high resolution x-ray microscopy to invasive techniques involving removing IC layers and imaging each layer using a scanning electron microscope.\n\n\nThe goal of such activities is to recover secret keys, unique device identifiers, and proprietary code and circuit designs embedded in hardware that the attacker has been unsuccessful at accessing through other means. These secrets may be stored in non-volatile memory or in the circuit netlist. Memory technologies such as masked ROM allow easier to extraction of secrets than One-time Programmable (OTP) memory.\n\n\n**Consequence Note:** A common goal of malicious actors who reverse engineer ICs is to produce and sell counterfeit versions of the IC.\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** The cost of secret extraction via IC reverse engineering should outweigh the potential value of the secrets being extracted. Threat model and value of secrets should be used to choose the technology used to safeguard those secrets. Examples include IC camouflaging and obfuscation, tamper-proof packaging, active shielding, and physical tampering detection information erasure.\n",
        "languages": []
    },
    {
        "cwe": "1279",
        "name": "Cryptographic Operations are run Before Supporting Units are Ready",
        "description": "Performing cryptographic operations without ensuring that the supporting inputs are ready to supply valid data may compromise the cryptographic result.",
        "detail": "**Extended Description:**\nMany cryptographic hardware units depend upon other hardware units to supply information to them to produce a securely encrypted result. For example, a cryptographic unit that depends on an external random-number-generator (RNG) unit for entropy must wait until the RNG unit is producing random numbers. If a cryptographic unit retrieves a private encryption key from a fuse unit, the fuse unit must be up and running before a key may be supplied.\n\n**Mode of Introduction:** The decision to continue using a cryptographic unit even though the input units to it are not producing valid data will compromise the encrypted result.\n",
        "parent": [
            "665",
            "696"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Best practices should be used to design cryptographic systems.\n\n**Mitigation:** Continuously ensuring that cryptographic inputs are supplying valid information is necessary to ensure that the encrypted output is secure.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "128",
        "name": "Wrap-around Error",
        "description": "Wrap around errors occur whenever a value is incremented past the maximum value for its type and therefore \"wraps around\" to a very small, negative, or undefined value.",
        "detail": "**Background Details:**\n['Due to how addition is performed by computers, if a primitive is incremented past the maximum value possible for its storage space, the system will not recognize this, and therefore increment each bit as if it still had extra space. Because of how negative numbers are represented in binary, primitives interpreted as signed may \"wrap\" to very large negative values.']\n\n**Consequence Note:** This weakness will generally lead to undefined behavior and therefore crashes. In the case of overflows involving loop index variables, the likelihood of infinite loops is also high.\n\n**Consequence Note:** If the value in question is important to data (as opposed to flow), simple data corruption has occurred. Also, if the wrap around results in other conditions such as buffer overflows, further memory corruption may occur.\n\n**Consequence Note:** This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [
            "119",
            "190"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Requirements specification: The choice could be made to use a language that is not susceptible to these issues.\n\n**Mitigation:** Provide clear upper and lower bounds on the scale of any protocols designed.\n\n**Mitigation:** Perform validation on all incremented variables to ensure that they remain within reasonable bounds.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1280",
        "name": "Access Control Check Implemented After Asset is Accessed",
        "description": "A product's hardware-based access control check occurs after the asset has been accessed.",
        "detail": "**Extended Description:**\n\n\nThe product implements a hardware-based access control check. The asset should be accessible only after the check is successful. If, however, this operation is not atomic and the asset is accessed before the check is complete, the security of the system may be compromised.\n\n",
        "parent": [
            "284",
            "696"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Implement the access control check first. Access should only be given to asset if agent is authorized.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1281",
        "name": "Sequence of Processor Instructions Leads to Unexpected Behavior",
        "description": "Specific combinations of processor instructions lead to undesirable behavior such as locking the processor until a hard reset performed.",
        "detail": "**Extended Description:**\n\n\nIf the instruction set architecture (ISA) and processor logic are not designed carefully and tested thoroughly, certain combinations of instructions may lead to locking the processor or other unexpected and undesirable behavior. Upon encountering unimplemented instruction opcodes or illegal instruction operands, the processor should throw an exception and carry on without negatively impacting security. However, specific combinations of legal and illegal instructions may cause unexpected behavior with security implications such as allowing unprivileged programs to completely lock the CPU. \n\n\n**Mode of Introduction:** Unexpected behavior from certain instruction combinations can arise from bugs in the ISA\n\n**Mode of Introduction:** Unexpected behavior from certain instruction combinations can arise because of implementation details such as speculative execution, caching etc.\n",
        "parent": [
            "691"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Implement a rigorous testing strategy that incorporates randomization to explore instruction sequences that are unlikely to appear in normal workloads in order to identify halt and catch fire instruction sequences.\n\n**Mitigation:** Patch operating system to avoid running Halt and Catch Fire type sequences or to mitigate the damage caused by unexpected behavior. See [REF-1108].\n",
        "languages": []
    },
    {
        "cwe": "1282",
        "name": "Assumed-Immutable Data is Stored in Writable Memory",
        "description": "Immutable data, such as a first-stage bootloader, device identifiers, and \"write-once\" configuration settings are stored in writable memory that can be re-programmed or updated in the field.",
        "detail": "**Extended Description:**\n\n\nSecurity services such as secure boot, authentication of code and data, and device attestation all require assets such as the first stage bootloader, public keys, golden hash digests, etc. which are implicitly trusted. Storing these assets in read-only memory (ROM), fuses, or one-time programmable (OTP) memory provides strong integrity guarantees and provides a root of trust for securing the rest of the system. Security is lost if assets assumed to be immutable can be modified.\n\n\n**Mode of Introduction:** Keys, code, configuration settings, and other data should be programmed in write-once or read-only memory instead of writable memory.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [
            "471"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** All immutable code or data should be programmed into ROM or write-once memory.\n",
        "languages": []
    },
    {
        "cwe": "1283",
        "name": "Mutable Attestation or Measurement Reporting Data",
        "description": "The register contents used for attestation or measurement reporting data to verify boot flow are modifiable by an adversary.",
        "detail": "**Extended Description:**\n\n\nA System-on-Chip (SoC) implements secure boot or verified boot. During this boot flow, the SoC often measures the code that it authenticates. The measurement is usually done by calculating the one-way hash of the code binary and extending it to the previous hash. The hashing algorithm should be a Secure One-Way hash function. The final hash, i.e., the value obtained after the completion of the boot flow, serves as the measurement data used in reporting or in attestation. The calculated hash is often stored in registers that can later be read by the party of interest to determine tampering of the boot flow. A common weakness is that the contents in these registers are modifiable by an adversary, thus spoofing the measurement.\n\n\n**Mode of Introduction:** Such issues can be introduced during hardware architecture or design and can be identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** If the access-controls which protecting the reporting registers are misconfigured during implementation, this weakness can arise.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** \n\nMeasurement data should be stored in registers that are read-only or otherwise have access controls that prevent modification by an untrusted agent.\n\n",
        "languages": []
    },
    {
        "cwe": "1284",
        "name": "Improper Validation of Specified Quantity in Input",
        "description": "The product receives input that is expected to specify a quantity (such as size or length), but it does not validate or incorrectly validates that the quantity has the required properties.",
        "detail": "**Extended Description:**\n\n\nSpecified quantities include size, length, frequency, price, rate, number of operations, time, and others. Code may rely on specified quantities to allocate resources, perform calculations, control iteration, etc. When the quantity is not properly validated, then attackers can specify malicious quantities to cause excessive resource allocation, trigger unexpected failures, enable buffer overflows, etc.\n\n\n**Consequence Note:** Since quantities are used so often to affect resource allocation or process financial data, they are often present in many places in the code.\n",
        "parent": [
            "20"
        ],
        "children": [
            "606"
        ],
        "related": [
            "789"
        ],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n",
        "languages": []
    },
    {
        "cwe": "1285",
        "name": "Improper Validation of Specified Index, Position, or Offset in Input",
        "description": "The product receives input that is expected to specify an index, position, or offset into an indexable resource such as a buffer or file, but it does not validate or incorrectly validates that the specified index/position/offset has the required properties.",
        "detail": "**Extended Description:**\n\n\nOften, indexable resources such as memory buffers or files can be accessed using a specific position, index, or offset, such as an index for an array or a position for a file. When untrusted input is not properly validated before it is used as an index, attackers could access (or attempt to access) unauthorized portions of these resources. This could be used to cause buffer overflows, excessive resource allocation, or trigger unexpected failures. \n\n",
        "parent": [
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n",
        "languages": []
    },
    {
        "cwe": "1286",
        "name": "Improper Validation of Syntactic Correctness of Input",
        "description": "The product receives input that is expected to be well-formed - i.e., to comply with a certain syntax - but it does not validate or incorrectly validates that the input complies with the syntax.",
        "detail": "**Extended Description:**\n\n\nOften, complex inputs are expected to follow a particular syntax, which is either assumed by the input itself, or declared within metadata such as headers. The syntax could be for data exchange formats, markup languages, or even programming languages. When untrusted input is not properly validated for the expected syntax, attackers could cause parsing failures, trigger unexpected errors, or expose latent vulnerabilities that might not be directly exploitable if the input had conformed to the syntax.\n\n",
        "parent": [
            "20"
        ],
        "children": [
            "112"
        ],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n",
        "languages": []
    },
    {
        "cwe": "1287",
        "name": "Improper Validation of Specified Type of Input",
        "description": "The product receives input that is expected to be of a certain type, but it does not validate or incorrectly validates that the input is actually of the expected type.",
        "detail": "**Extended Description:**\n\n\nWhen input does not comply with the expected type, attackers could trigger unexpected errors, cause incorrect actions to take place, or exploit latent vulnerabilities that would not be possible if the input conformed with the expected type.\n\n\nThis weakness can appear in type-unsafe programming languages, or in programming languages that support casting or conversion of an input to another type.\n\n",
        "parent": [
            "20"
        ],
        "children": [],
        "related": [
            "843"
        ],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n",
        "languages": []
    },
    {
        "cwe": "1288",
        "name": "Improper Validation of Consistency within Input",
        "description": "The product receives a complex input with multiple elements or fields that must be consistent with each other, but it does not validate or incorrectly validates that the input is actually consistent.",
        "detail": "**Extended Description:**\n\n\nSome input data can be structured with multiple elements or fields that must be consistent with each other, e.g. a number-of-items field that is followed by the expected number of elements. When such complex inputs are inconsistent, attackers could trigger unexpected errors, cause incorrect actions to take place, or exploit latent vulnerabilities.\n\n",
        "parent": [
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n",
        "languages": []
    },
    {
        "cwe": "1289",
        "name": "Improper Validation of Unsafe Equivalence in Input",
        "description": "The product receives an input value that is used as a resource identifier or other type of reference, but it does not validate or incorrectly validates that the input is equivalent to a potentially-unsafe value.",
        "detail": "**Extended Description:**\n\n\nAttackers can sometimes bypass input validation schemes by finding inputs that appear to be safe, but will be dangerous when processed at a lower layer or by a downstream component. For example, a simple XSS protection mechanism might try to validate that an input has no \"<script>\" tags using case-sensitive matching, but since HTML is case-insensitive when processed by web browsers, an attacker could inject \"<ScrIpT>\" and trigger XSS.\n\n",
        "parent": [
            "20"
        ],
        "children": [],
        "related": [
            "178",
            "41"
        ],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n",
        "languages": []
    },
    {
        "cwe": "129",
        "name": "Improper Validation of Array Index",
        "description": "The product uses untrusted input when calculating or using an array index, but the product does not validate or incorrectly validates the index to ensure the index references a valid position within the array.",
        "detail": "**Alternate Terms:** out-of-bounds array index, index-out-of-range, array index underflow\n\n**Consequence Note:** Use of an index that is outside the bounds of an array will very likely result in the corruption of relevant memory and perhaps instructions, leading to a crash, if the values are outside of the valid memory area.\n\n**Consequence Note:** If the memory corrupted is data, rather than instructions, the system will continue to function with improper values.\n\n**Consequence Note:** Use of an index that is outside the bounds of an array can also trigger out-of-bounds read or write operations, or operations on the wrong objects; i.e., \"buffer overflows\" are not always the result. This may result in the exposure or modification of sensitive data.\n\n**Consequence Note:** If the memory accessible by the attacker can be effectively controlled, it may be possible to execute arbitrary code, as with a standard buffer overflow and possibly without the use of large inputs if a precise index can be controlled.\n\n**Consequence Note:** A single fault could allow either an overflow (CWE-788) or underflow (CWE-786) of the array index. What happens next will depend on the type of operation being performed out of bounds, but can expose sensitive information, cause a system crash, or possibly lead to arbitrary code execution.\n",
        "parent": [
            "1285",
            "20"
        ],
        "children": [],
        "related": [
            "119",
            "789",
            "823"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.\n\n\nAutomated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report array index errors that originate from command line arguments in a program that is not expected to run with setuid or other special privileges.\n\n\n**Detection:** This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Detection:** Black box methods might not get the needed code coverage within limited time constraints, and a dynamic test might not produce any noticeable side effects even if it is successful.\n\n**Mitigation:** Use an input validation framework such as Struts or the OWASP ESAPI Validation API. Note that using a framework does not automatically address all input validation problems; be mindful of weaknesses that could arise from misusing the framework itself (CWE-1173).\n\n**Mitigation:** \n\nFor any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n\nEven though client-side checks provide minimal benefits with respect to server-side security, they are still useful. First, they can support intrusion detection. If the server receives input that should have been rejected by the client, then it may be an indication of an attack. Second, client-side error-checking can provide helpful feedback to the user about the expectations for valid input. Third, there may be a reduction in server-side processing time for accidental input errors, although this is typically a small savings.\n\n\n**Mitigation:** \n\nUse a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, Ada allows the programmer to constrain the values of a variable and languages such as Java and Ruby will allow the programmer to handle exceptions when an out-of-bounds index is accessed.\n\n\n**Mitigation:** \n\nRun or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code. \n\n\n Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking. \n\n\n For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335]. \n\n\n**Effectiveness:** These techniques do not provide a complete solution. For instance, exploits frequently use a bug that discloses memory addresses in order to maximize reliability of code execution [REF-1337]. It has also been shown that a side-channel attack can bypass ASLR [REF-1333]\n\n**Mitigation:** \n\n Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment. \n\n\n For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336]. \n\n\n**Effectiveness:** This is not a complete solution, since buffer overflows could be used to overwrite nearby variables to modify the software's state in dangerous ways. In addition, it cannot be used in cases in which self-modifying code is required. Finally, an attack could still cause a denial of service, since the typical response is to exit the application.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen accessing a user-controlled array index, use a stringent range of values that are within the target array. Make sure that you do not allow negative values to be used. That is, verify the minimum as well as the maximum of the range of acceptable values.\n\n\n**Mitigation:** Be especially careful to validate all input when invoking code that crosses language boundaries, such as from an interpreted language to native code. This could create an unexpected interaction between the language boundaries. Ensure that you are not violating any of the expectations of the language with which you are interfacing. For example, even though Java may not be susceptible to buffer overflows, providing a large argument in a call to native code might trigger an overflow.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** \n\nRun the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n\n\nOS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Effectiveness:** The effectiveness of this mitigation depends on the prevention capabilities of the specific sandbox or jail being used and might only help to reduce the scope of an attack, such as restricting the attacker to certain system calls or limiting the portion of the file system that can be accessed.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1290",
        "name": "Incorrect Decoding of Security Identifiers ",
        "description": "The product implements a decoding mechanism to decode certain bus-transaction signals to security identifiers. If the decoding is implemented incorrectly, then untrusted agents can now gain unauthorized access to the asset.",
        "detail": "**Extended Description:**\n\n\nIn a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity). Sometimes the transactions are qualified with a security identifier. The security identifier helps the destination agent decide on the set of allowed actions (e.g., access an asset for read and writes). A decoder decodes the bus transactions to map security identifiers into necessary access-controls/protections.\n\n\nA common weakness that can exist in this scenario is incorrect decoding because an untrusted agent's security identifier is decoded into a trusted agent's security identifier. Thus, an untrusted agent previously without access to an asset can now gain access to the asset.\n\n",
        "parent": [
            "1294",
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Security identifier decoders must be reviewed for design consistency and common weaknesses.\n\n**Mitigation:** Access and programming flows must be tested in pre-silicon and post-silicon testing in order to check for this weakness.\n",
        "languages": []
    },
    {
        "cwe": "1291",
        "name": "Public Key Re-Use for Signing both Debug and Production Code",
        "description": "The same public key is used for signing both debug and production code.",
        "detail": "**Extended Description:**\n\n\nA common usage of public-key cryptography is to verify the integrity and authenticity of another entity (for example a firmware binary). If a company wants to ensure that its firmware runs only on its own hardware, before the firmware runs, an encrypted hash of the firmware image will be decrypted with the public key and then verified against the now-computed hash of the firmware image. This means that the public key forms the root of trust, which necessitates that the public key itself must be protected and used properly.\n\n\nDuring the development phase, debug firmware enables many hardware debug hooks, debug modes, and debug messages for testing. Those debug facilities provide significant, additional views about the firmware's capability and, in some cases, additional capability into the chip or SoC. If compromised, these capabilities could be exploited by an attacker to take full control of the system.\n\n\nOnce the product exits the manufacturing stage and enters production, it is good practice to use a different public key. Debug firmware images are known to leak. With the debug key being reused as the production key, the debug image will also work on the production image. Thus, it will open all the internal, debug capabilities to the attacker.\n\n\nIf a different public key is used for the production image, even if the attacker gains access to the debug firmware image, they will not be able to run it on a production machine. Thus, damage will be limited to the intellectual property leakage resulting from the debug image.\n\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [
            "321"
        ],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** \n\nCompare the debug key with the production key to make sure that they are not the same.\n\n\n**Detection:** \n\nCompare the debug key with the production key to make sure that they are not the same.\n\n\n**Mitigation:** Use different keys for Production and Debug\n",
        "languages": []
    },
    {
        "cwe": "1292",
        "name": "Incorrect Conversion of Security Identifiers",
        "description": "The product implements a conversion mechanism to map certain bus-transaction signals to security identifiers. However, if the conversion is incorrectly implemented, untrusted agents can gain unauthorized access to the asset.",
        "detail": "**Extended Description:**\n\n\nIn a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute, etc.). Among various types of message information, a typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity). Sometimes the transactions are qualified with a security identifier. This security identifier helps the destination agent decide on the set of allowed actions (e.g., access an asset for read and writes).\n\n\nA typical bus connects several leader and follower agents. Some follower agents implement bus protocols differently from leader agents. A protocol conversion happens at a bridge to seamlessly connect different protocols on the bus. One example is a system that implements a leader with the Advanced High-performance Bus (AHB) protocol and a follower with the Open-Core Protocol (OCP). A bridge AHB-to-OCP is needed to translate the transaction from one form to the other.\n\n\nA common weakness that can exist in this scenario is that this conversion between protocols is implemented incorrectly, whereupon an untrusted agent may gain unauthorized access to an asset.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design, then identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during hardware implementation, then identified later during Testing or System Configuration phases.\n",
        "parent": [
            "1294",
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Security identifier decoders must be reviewed for design inconsistency and common weaknesses.\n\n**Mitigation:** Access and programming flows must be tested in pre-silicon and post-silicon testing.\n",
        "languages": []
    },
    {
        "cwe": "1293",
        "name": "Missing Source Correlation of Multiple Independent Data",
        "description": "The product relies on one source of data, preventing the ability to detect if an adversary has compromised a data source.",
        "detail": "**Extended Description:**\n\n\nTo operate successfully, a product sometimes has to implicitly trust the integrity of an information source. When information is implicitly signed, one can ensure that the data was not tampered in transit. This does not ensure that the information source was not compromised when responding to a request. By requesting information from multiple sources, one can check if all of the data is the same. If they are not, the system should report the information sources that respond with a different or minority value as potentially compromised. If there are not enough answers to provide a majority or plurality of responses, the system should report all of the sources as potentially compromised. As the seriousness of the impact of incorrect integrity increases, so should the number of independent information sources that would need to be queried.\n\n\n**Mode of Introduction:** This flaw could be introduced during the design of the application or misconfiguration at run time by only specifying a single point of validation.\n\n**Mode of Introduction:** Such issues could be introduced during hardware implementation, then identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** This weakness could be introduced by intentionally failing all but one of the devices used to retrieve the data or by failing the devices that validate the data.\n\n**Consequence Note:** An attacker that may be able to execute a single Person-in-the-Middle attack can subvert a check of an external oracle (e.g. the ACME protocol check for a file on a website), and thus inject an arbitrary reply to the single perspective request to the external oracle.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [
            "654"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Design system to use a Practical Byzantine fault method, to request information from multiple sources to verify the data and report on potentially compromised information sources.\n\n**Mitigation:** Failure to use a Practical Byzantine fault method when requesting data. Lack of place to report potentially compromised information sources. Relying on non-independent information sources for integrity checking. Failure to report information sources that respond in the minority to incident response procedures.\n",
        "languages": []
    },
    {
        "cwe": "1294",
        "name": "Insecure Security Identifier Mechanism",
        "description": "The System-on-Chip (SoC) implements a Security Identifier mechanism to differentiate what actions are allowed or disallowed when a transaction originates from an entity. However, the Security Identifiers are not correctly implemented.",
        "detail": "**Extended Description:**\n\n\nSystems-On-Chip (Integrated circuits and hardware engines) implement Security Identifiers to differentiate/identify actions originated from various agents. These actions could be 'read', 'write', 'program', 'reset', 'fetch', 'compute', etc. Security identifiers are generated and assigned to every agent in the System (SoC) that is either capable of generating an action or receiving an action from another agent. Every agent could be assigned a unique, Security Identifier based on its trust level or privileges.\n\n\nA broad class of flaws can exist in the Security Identifier process, including but not limited to missing security identifiers, improper conversion of security identifiers, incorrect generation of security identifiers, etc.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design, then identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during hardware implementation, then identified later during Testing or System Configuration phases.\n",
        "parent": [
            "284"
        ],
        "children": [
            "1259",
            "1270",
            "1290",
            "1292",
            "1302"
        ],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Security Identifier Decoders must be reviewed for design inconsistency and common weaknesses.\n\n**Mitigation:** Access and programming flows must be tested in pre-silicon and post-silicon testing.\n",
        "languages": []
    },
    {
        "cwe": "1295",
        "name": "Debug Messages Revealing Unnecessary Information",
        "description": "The product fails to adequately prevent the revealing of unnecessary and potentially sensitive system information within debugging messages.",
        "detail": "**Extended Description:**\n\n\nDebug messages are messages that help troubleshoot an issue by revealing the internal state of the system. For example, debug data in design can be exposed through internal memory array dumps or boot logs through interfaces like UART via TAP commands, scan chain, etc. Thus, the more information contained in a debug message, the easier it is to debug. However, there is also the risk of revealing information that could help an attacker either decipher a vulnerability, and/or gain a better understanding of the system. Thus, this extra information could lower the \"security by obscurity\" factor. While \"security by obscurity\" alone is insufficient, it can help as a part of \"Defense-in-depth\". \n\n",
        "parent": [
            "200"
        ],
        "children": [],
        "related": [
            "209"
        ],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Ensure that a debug message does not reveal any unnecessary information during the debug process for the intended response.\n",
        "languages": []
    },
    {
        "cwe": "1296",
        "name": "Incorrect Chaining or Granularity of Debug Components",
        "description": "The product's debug components contain incorrect chaining or granularity of debug components.",
        "detail": "**Extended Description:**\n\n\nFor debugging and troubleshooting a chip, several hardware design elements are often implemented, including:\n\n\n  - Various Test Access Ports (TAPs) allow boundary scan commands to be executed.\n\n  - For scanning the internal components of a chip, there are scan cells that allow the chip to be used as a \"stimulus and response\" mechanism.\n\n  - Chipmakers might create custom methods to observe the internal components of their chips by placing various tracing hubs within their chip and creating hierarchical or interconnected structures among those hubs.\n\nLogic errors during design or synthesis could misconfigure the interconnection of the debug components, which could allow unintended access permissions.\n\n**Consequence Note:** Depending on the access to debug component(s) erroneously granted, an attacker could use the debug component to gain additional understanding about the system to further an attack and/or execute other commands. This could compromise any security property, including the ones listed above.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Appropriate Post-Si tests should be carried out at various authorization levels to ensure that debug components are properly chained and accessible only to users with appropriate credentials.\n\n**Detection:** Appropriate Post-Si tests should be carried out at various authorization levels to ensure that debug components are properly chained and accessible only to users with appropriate credentials.\n\n**Mitigation:** Ensure that debug components are properly chained and their granularity is maintained at different authentication levels.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1297",
        "name": "Unprotected Confidential Information on Device is Accessible by OSAT Vendors",
        "description": "The product does not adequately protect confidential information on the device from being accessed by Outsourced Semiconductor Assembly and Test (OSAT) vendors.",
        "detail": "**Extended Description:**\n\n\nIn contrast to complete vertical integration of architecting, designing, manufacturing, assembling, and testing chips all within a single organization, an organization can choose to simply architect and design a chip before outsourcing the rest of the process to OSAT entities (e.g., external foundries and test houses). In the latter example, the device enters an OSAT facility in a much more vulnerable pre-production stage where many debug and test modes are accessible. Therefore, the chipmaker must place a certain level of trust with the OSAT. To counter this, the chipmaker often requires the OSAT partner to enter into restrictive non-disclosure agreements (NDAs). Nonetheless, OSAT vendors likely have many customers, which increases the risk of accidental sharing of information. There may also be a security vulnerability in the information technology (IT) system of the OSAT facility. Alternatively, a malicious insider at the OSAT facility may carry out an insider attack. Considering these factors, it behooves the chipmaker to minimize any confidential information in the device that may be accessible to the OSAT vendor.\n\n\nLogic errors during design or synthesis could misconfigure the interconnection of the debug components, which could provide improper authorization to sensitive information.\n\n\n**Consequence Note:** The impact depends on the confidential information itself and who is inadvertently granted access. For example, if the confidential information is a key that can unlock all the parts of a generation, the impact could be severe.\n",
        "parent": [
            "285"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Accountability",
            "Authentication",
            "Authorization",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Appropriate Post-Si tests should be carried out to ensure that residual confidential information is not left on parts leaving one facility for another facility.\n\n**Detection:** Appropriate Post-Si tests should be carried out to ensure that residual confidential information is not left on parts leaving one facility for another facility.\n\n**Mitigation:** \n\n  - Ensure that when an OSAT vendor is allowed to access test interfaces necessary for preproduction and returned parts, the vendor only pulls the minimal information necessary. Also, architect the product in such a way that, when an \"unlock device\" request comes, it only unlocks that specific part and not all the parts for that product line.\n\n  - Ensure that the product's non-volatile memory (NVM) is scrubbed of all confidential information and secrets before handing it over to an OSAT.\n\n  - Arrange to secure all communication between an OSAT facility and the chipmaker.\n\n\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1298",
        "name": "Hardware Logic Contains Race Conditions",
        "description": "A race condition in the hardware logic results in undermining security guarantees of the system.",
        "detail": "**Extended Description:**\n\n\nA race condition in logic circuits typically occurs when a logic gate gets inputs from signals that have traversed different paths while originating from the same source. Such inputs to the gate can change at slightly different times in response to a change in the source signal. This results in a timing error or a glitch (temporary or permanent) that causes the output to change to an unwanted state before settling back to the desired state. If such timing errors occur in access control logic or finite state machines that are implemented in security sensitive flows, an attacker might exploit them to circumvent existing protections.\n\n",
        "parent": [
            "362"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Adopting design practices that encourage designers to recognize and eliminate race conditions, such as Karnaugh maps, could result in the decrease in occurrences of race conditions.\n\n**Mitigation:** Logic redundancy can be implemented along security critical paths to prevent race conditions. To avoid metastability, it is a good practice in general to default to a secure state in which access is not given to untrusted agents.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1299",
        "name": "Missing Protection Mechanism for Alternate Hardware Interface",
        "description": "The lack of protections on alternate paths to access\n                control-protected assets (such as unprotected shadow registers\n                and other external facing unguarded interfaces) allows an\n                attacker to bypass existing protections to the asset that are\n\t\tonly performed against the primary path.",
        "detail": "**Extended Description:**\n\n\nAn asset inside a chip might have access-control protections through one interface. However, if all paths to the asset are not protected, an attacker might compromise the asset through alternate paths. These alternate paths could be through shadow or mirror registers inside the IP core, or could be paths from other external-facing interfaces to the IP core or SoC.\n\n\nConsider an SoC with various interfaces such as UART, SMBUS, PCIe, USB, etc. If access control is implemented for SoC internal registers only over the PCIe interface, then an attacker could still modify the SoC internal registers through alternate paths by coming through interfaces such as UART, SMBUS, USB, etc. \n\n\nAlternatively, attackers might be able to bypass existing protections by exploiting unprotected, shadow registers. Shadow registers and mirror registers typically refer to registers that can be accessed from multiple addresses. Writing to or reading from the aliased/mirrored address has the same effect as writing to the address of the main register. They are typically implemented within an IP core or SoC to temporarily hold certain data. These data will later be updated to the main register, and both registers will be in synch. If the shadow registers are not access-protected, attackers could simply initiate transactions to the shadow registers and compromise system security. \n\n",
        "parent": [
            "288",
            "420"
        ],
        "children": [],
        "related": [
            "1191",
            "1314"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Protect assets from accesses against all potential interfaces and alternate paths.\n\n**Mitigation:** Protect assets from accesses against all potential interfaces and alternate paths.\n\n**Mitigation:** Protect assets from accesses against all potential interfaces and alternate paths.\n",
        "languages": []
    },
    {
        "cwe": "13",
        "name": "ASP.NET Misconfiguration: Password in Configuration File",
        "description": "Storing a plaintext password in a configuration file allows anyone who can read the file access to the password-protected resource making them an easy target for attackers.",
        "detail": null,
        "parent": [
            "260"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Credentials stored in configuration files should be encrypted, Use standard APIs and industry accepted algorithms to encrypt the credentials stored in configuration files.\n",
        "languages": []
    },
    {
        "cwe": "130",
        "name": "Improper Handling of Length Parameter Inconsistency",
        "description": "The product parses a formatted message or structure, but it does not handle or incorrectly handles a length field that is inconsistent with the actual length of the associated data.",
        "detail": "**Extended Description:**\nIf an attacker can manipulate the length parameter associated with an input such that it is inconsistent with the actual length of the input, this can be leveraged to cause the target application to behave in unexpected, and possibly, malicious ways. One of the possible motives for doing so is to pass in arbitrarily large input to the application. Another possible motivation is the modification of application state by including invalid data for subsequent properties of the application. Such weaknesses commonly lead to attacks such as buffer overflows and execution of arbitrary code.\n\n**Alternate Terms:** length manipulation, length tampering\n",
        "parent": [
            "119",
            "240"
        ],
        "children": [],
        "related": [
            "805"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** When processing structured incoming data containing a size field followed by raw data, ensure that you identify and resolve any inconsistencies between the size field and the actual size of the data.\n\n**Mitigation:** Do not let the user control the size of the buffer.\n\n**Mitigation:** Validate that the length of the user-supplied data is consistent with the buffer size.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1300",
        "name": "Improper Protection of Physical Side Channels",
        "description": "The device does not contain sufficient protection\n\tmechanisms to prevent physical side channels from exposing\n\tsensitive information due to patterns in physically observable\n\tphenomena such as variations in power consumption,\n\telectromagnetic emissions (EME), or acoustic emissions.",
        "detail": "**Extended Description:**\n\n\nAn adversary could monitor and measure physical phenomena to detect patterns and make inferences, even if it is not possible to extract the information in the digital domain.\n\n\nPhysical side channels have been well-studied for decades in the context of breaking implementations of cryptographic algorithms or other attacks against security features. These side channels may be easily observed by an adversary with physical access to the device, or using a tool that is in close proximity. If the adversary can monitor hardware operation and correlate its data processing with power, EME, and acoustic measurements, the adversary might be able to recover of secret keys and data.\n\n",
        "parent": [
            "203"
        ],
        "children": [
            "1255"
        ],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Perform a set of leakage detection tests such as the procedure outlined in the Test Vector Leakage Assessment (TVLA) test requirements for AES [REF-1230]. TVLA is the basis for the ISO standard 17825 [REF-1229]. A separate methodology is provided by [REF-1228]. Note that sole reliance on this method might not yield expected results [REF-1239] [REF-1240].\n\n**Detection:** \n\nPost-silicon, perform full side-channel attacks (penetration testing) covering as many known leakage models as possible against test code.\n\n\n**Detection:** \n\nPre-silicon - while the aforementioned TVLA methods can be performed post-silicon, models of device power consumption or other physical emanations can be built from information present at various stages of the hardware design process before fabrication. TVLA or known side-channel attacks can be applied to these simulated traces and countermeasures applied before tape-out. Academic research in this field includes [REF-1231] [REF-1232] [REF-1233].\n\n\n**Mitigation:** Apply blinding or masking techniques to implementations of cryptographic algorithms.\n\n**Mitigation:** Add shielding or tamper-resistant protections to the device to increase the difficulty of obtaining measurements of the side-channel.\n",
        "languages": []
    },
    {
        "cwe": "1301",
        "name": "Insufficient or Incomplete Data Removal within Hardware Component",
        "description": "The product's data removal process does not completely delete all data and potentially sensitive information within hardware components.",
        "detail": "**Extended Description:**\n\n\nPhysical properties of hardware devices, such as remanence of magnetic media, residual charge of ROMs/RAMs, or screen burn-in may still retain sensitive data after a data removal process has taken place and power is removed.\n\n\nRecovering data after erasure or overwriting is possible due to a phenomenon called data remanence. For example, if the same value is written repeatedly to a memory location, the corresponding memory cells can become physically altered to a degree such that even after the original data is erased that data can still be recovered through physical characterization of the memory cells.\n\n",
        "parent": [
            "226"
        ],
        "children": [
            "1330"
        ],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Apply blinding or masking techniques to implementations of cryptographic algorithms.\n\n**Mitigation:** Alter the method of erasure, add protection of media, or destroy the media to protect the data.\n",
        "languages": []
    },
    {
        "cwe": "1302",
        "name": "Missing Source Identifier in Entity Transactions on a System-On-Chip (SOC)",
        "description": "The product implements a security identifier mechanism to differentiate what actions are allowed or disallowed when a transaction originates from an entity. A transaction is sent without a security identifier.",
        "detail": "**Extended Description:**\n\n\nIn a System-On-Chip (SoC), various integrated circuits and hardware engines generate transactions such as to access (reads/writes) assets or perform certain actions (e.g., reset, fetch, compute). A typical transaction is comprised of source identity (to identify the originator of the transaction) and a destination identity (to route the transaction to the respective entity) in addition to much more information in the message. Sometimes the transactions are qualified with a Security Identifier. This Security Identifier helps the destination agent decide on the set of allowed or disallowed actions.\n\n\nA weakness that can exist in such transaction schemes is that the source agent does not consistently include the necessary Security Identifier with the transaction. If the Security Identifier is missing, the destination agent might drop the message (resulting in an inadvertent Denial-of-Service (DoS)) or take inappropriate action by default in its attempt to execute the transaction, resulting in privilege escalation or provision of unintended access.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.\n",
        "parent": [
            "1294"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Transaction details must be reviewed for design inconsistency and common weaknesses.\n\n**Mitigation:** Security identifier definition and programming flow must be tested in pre-silicon and post-silicon testing.\n",
        "languages": []
    },
    {
        "cwe": "1303",
        "name": "Non-Transparent Sharing of Microarchitectural Resources",
        "description": "Hardware structures shared across execution contexts (e.g., caches and branch predictors) can violate the expected architecture isolation between contexts.",
        "detail": "**Extended Description:**\n\n\nModern processors use techniques such as out-of-order execution, speculation, prefetching, data forwarding, and caching to increase performance. Details about the implementation of these techniques are hidden from the programmer's view. This is problematic when the hardware implementation of these techniques results in resources being shared across supposedly isolated contexts. Contention for shared resources between different contexts opens covert channels that allow malicious programs executing in one context to recover information from another context.\n\n\nSome examples of shared micro-architectural resources that have been used to leak information between contexts are caches, branch prediction logic, and load or store buffers. Speculative and out-of-order execution provides an attacker with increased control over which data is leaked through the covert channel.\n\n\nIf the extent of resource sharing between contexts in the design microarchitecture is undocumented, it is extremely difficult to ensure system assets are protected against disclosure.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.\n\n**Consequence Note:** Microarchitectural side-channels have been used to leak specific information such as cryptographic keys, and Address Space Layout Randomization (ALSR) offsets as well as arbitrary memory.\n",
        "parent": [
            "1189",
            "203"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Microarchitectural covert channels can be addressed using a mixture of hardware and software mitigation techniques. These include partitioned caches, new barrier and flush instructions, and disabling high resolution performance counters and timers.\n\n**Mitigation:** Microarchitectural covert channels can be addressed using a mixture of hardware and software mitigation techniques. These include partitioned caches, new barrier and flush instructions, and disabling high resolution performance counters and timers.\n",
        "languages": []
    },
    {
        "cwe": "1304",
        "name": "Improperly Preserved Integrity of Hardware Configuration State During a Power Save/Restore Operation",
        "description": "The product performs a power save/restore\n            operation, but it does not ensure that the integrity of\n            the configuration state is maintained and/or verified between\n\t    the beginning and ending of the operation.",
        "detail": "**Extended Description:**\n\n\nBefore powering down, the Intellectual Property (IP) saves current state (S) to persistent storage such as flash or always-on memory in order to optimize the restore operation. During this process, an attacker with access to the persistent storage may alter (S) to a configuration that could potentially modify privileges, disable protections, and/or cause damage to the hardware. If the IP does not validate the configuration state stored in persistent memory, upon regaining power or becoming operational again, the IP could be compromised through the activation of an unwanted/harmful configuration. \n\n\n**Mode of Introduction:** Weakness introduced via missing internal integrity guarantees during power save/restore\n\n**Mode of Introduction:** Weakness introduced via missing external integrity verification during power save/restore\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [
            "1271",
            "345"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inside the IP, incorporate integrity checking on the configuration state via a cryptographic hash. The hash can be protected inside the IP such as by storing it in internal registers which never lose power. Before powering down, the IP performs a hash of the configuration and saves it in these persistent registers. Upon restore, the IP performs a hash of the saved configuration and compares it with the saved hash. If they do not match, then the IP should not trust the configuration.\n\n**Mitigation:** Outside the IP, incorporate integrity checking of the configuration state via a trusted agent. Before powering down, the trusted agent performs a hash of the configuration and saves the hash in persistent storage. Upon restore, the IP requests the trusted agent validate its current configuration. If the configuration hash is invalid, then the IP should not trust the configuration.\n\n**Mitigation:** Outside the IP, incorporate a protected environment that prevents undetected modification of the configuration state by untrusted agents. Before powering down, a trusted agent saves the IP's configuration state in this protected location that only it is privileged to. Upon restore, the trusted agent loads the saved state into the IP.\n",
        "languages": []
    },
    {
        "cwe": "131",
        "name": "Incorrect Calculation of Buffer Size",
        "description": "The product does not correctly calculate the size to be used when allocating a buffer, which could lead to a buffer overflow.",
        "detail": "**Consequence Note:** If the incorrect calculation is used in the context of memory allocation, then the software may create a buffer that is smaller or larger than expected. If the allocated buffer is smaller than expected, this could lead to an out-of-bounds read or write (CWE-119), possibly causing a crash, allowing arbitrary code execution, or exposing sensitive data.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [
            "119"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.\n\n\nAutomated static analysis generally does not account for environmental considerations when reporting potential errors in buffer calculations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges.\n\n\n**Detection:** This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Detection:** Manual analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. This becomes difficult for weaknesses that must be considered for all inputs, since the attack surface can be too large.\n\n**Detection:** \n\nThis weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.\n\n\nSpecifically, manual static analysis is useful for evaluating the correctness of allocation calculations. This can be useful for detecting overflow conditions (CWE-190) or similar weaknesses that might have serious security impacts on the program.\n\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource Code Quality Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** When allocating a buffer for the purpose of transforming, converting, or encoding an input, allocate enough memory to handle the largest possible encoding. For example, in a routine that converts \"&\" characters to \"&amp;\" for HTML entity encoding, the output buffer needs to be at least 5 times as large as the input buffer.\n\n**Mitigation:** \n\nUnderstand the programming language's underlying representation and how it interacts with numeric calculation (CWE-681). Pay close attention to byte size discrepancies, precision, signed/unsigned distinctions, truncation, conversion and casting between types, \"not-a-number\" calculations, and how the language handles numbers that are too large or too small for its underlying representation. [REF-7]\n\n\nAlso be careful to account for 32-bit, 64-bit, and other potential differences that may affect the numeric representation.\n\n\n**Mitigation:** Perform input validation on any numeric input by ensuring that it is within the expected range. Enforce that the input meets both the minimum and maximum requirements for the expected range.\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** When processing structured incoming data containing a size field followed by raw data, identify and resolve any inconsistencies between the size field and the actual size of the data (CWE-130).\n\n**Mitigation:** When allocating memory that uses sentinels to mark the end of a data structure - such as NUL bytes in strings - make sure you also include the sentinel in your calculation of the total amount of memory that must be allocated.\n\n**Mitigation:** Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.\n\n**Effectiveness:** This approach is still susceptible to calculation errors, including issues such as off-by-one errors (CWE-193) and incorrectly calculating buffer lengths (CWE-131). Additionally, this only addresses potential overflow issues. Resource consumption / exhaustion issues are still possible.\n\n**Mitigation:** Use sizeof() on the appropriate data type to avoid CWE-467.\n\n**Mitigation:** Use the appropriate type for the desired action. For example, in C/C++, only use unsigned types for values that could never be negative, such as height, width, or other numbers related to quantity. This will simplify validation and will reduce surprises related to unexpected casting.\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nUse libraries or frameworks that make it easier to handle numbers without unexpected consequences, or buffer allocation routines that automatically track buffer size.\n\n\nExamples include safe integer handling packages such as SafeInt (C++) or IntegerLib (C or C++). [REF-106]\n\n\n**Mitigation:** \n\nUse automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking. \n\n\n D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail. \n\n\n**Effectiveness:** \n\n This is not necessarily a complete solution, since these mechanisms only detect certain types of overflows. In addition, the result is still a denial of service, since the typical response is to exit the application. \n\n\n**Mitigation:** \n\nRun or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code. \n\n\n Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking. \n\n\n For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335]. \n\n\n**Effectiveness:** These techniques do not provide a complete solution. For instance, exploits frequently use a bug that discloses memory addresses in order to maximize reliability of code execution [REF-1337]. It has also been shown that a side-channel attack can bypass ASLR [REF-1333]\n\n**Mitigation:** \n\n Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment. \n\n\n For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336]. \n\n\n**Effectiveness:** This is not a complete solution, since buffer overflows could be used to overwrite nearby variables to modify the software's state in dangerous ways. In addition, it cannot be used in cases in which self-modifying code is required. Finally, an attack could still cause a denial of service, since the typical response is to exit the application.\n\n**Mitigation:** Examine compiler warnings closely and eliminate problems with potential security implications, such as signed / unsigned mismatch in memory operations, or use of uninitialized variables. Even if the weakness is rarely exploitable, a single failure may lead to the compromise of the entire system.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** \n\nRun the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n\n\nOS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Effectiveness:** The effectiveness of this mitigation depends on the prevention capabilities of the specific sandbox or jail being used and might only help to reduce the scope of an attack, such as restricting the attacker to certain system calls or limiting the portion of the file system that can be accessed.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1310",
        "name": "Missing Ability to Patch ROM Code",
        "description": "Missing an ability to patch ROM code may leave a System or System-on-Chip (SoC) in a vulnerable state.",
        "detail": "**Extended Description:**\n\n\nA System or System-on-Chip (SoC) that implements a boot process utilizing security mechanisms such as Root-of-Trust (RoT) typically starts by executing code from a Read-only-Memory (ROM) component. The code in ROM is immutable, hence any security vulnerabilities discovered in the ROM code can never be fixed for the systems that are already in use.\n\n\nA common weakness is that the ROM does not have the ability to patch if security vulnerabilities are uncovered after the system gets shipped. This leaves the system in a vulnerable state where an adversary can compromise the SoC.\n\n\n**Mode of Introduction:** This issue could be introduced during hardware architecture and design and can be identified later during Testing.\n\n**Mode of Introduction:** This issue could be introduced during implementation and can be identified later during Testing.\n\n**Mode of Introduction:** This issue could be introduced during integration and can be identified later during Testing.\n\n**Mode of Introduction:** This issue could be introduced during manufacturing and can be identified later during Testing.\n\n**Consequence Note:** When the system is unable to be patched, it can be left in a vulnerable state.\n",
        "parent": [
            "1329"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Secure patch support to allow ROM code to be patched on the next boot.\n\n**Effectiveness:** Some parts of the hardware initialization or signature verification done to authenticate patches will always be \"not patchable.\"\n\n**Mitigation:** Support patches that can be programmed in-field or during manufacturing through hardware fuses. This feature can be used for limited patching of devices after shipping, or for the next batch of silicon devices manufactured, without changing the full device ROM.\n\n**Effectiveness:** Patches that use hardware fuses will have limitations in terms of size and the number of patches that can be supported. Note that some parts of the hardware initialization or signature verification done to authenticate patches will always be \"not patchable.\"\n",
        "languages": []
    },
    {
        "cwe": "1311",
        "name": "Improper Translation of Security Attributes by Fabric Bridge",
        "description": "The bridge incorrectly translates security attributes from either trusted to untrusted or from untrusted to trusted when converting from one fabric protocol to another.",
        "detail": "**Extended Description:**\n\n\nA bridge allows IP blocks supporting different fabric protocols to be integrated into the system. Fabric end-points or interfaces usually have dedicated signals to transport security attributes. For example, HPROT signals in AHB, AxPROT signals in AXI, and MReqInfo and SRespInfo signals in OCP.\n\n\nThe values on these signals are used to indicate the security attributes of the transaction. These include the immutable hardware identity of the controller initiating the transaction, privilege level, and type of transaction (e.g., read/write, cacheable/non-cacheable, posted/non-posted).\n\n\nA weakness can arise if the bridge IP block, which translates the signals from the protocol used in the IP block endpoint to the protocol used by the central bus, does not properly translate the security attributes. As a result, the identity of the initiator could be translated from untrusted to trusted or vice-versa. This could result in access-control bypass, privilege escalation, or denial of service.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** The translation must map signals in such a way that untrusted agents cannot map to trusted agents or vice-versa.\n\n**Mitigation:** Ensure that the translation maps signals in such a way that untrusted agents cannot map to trusted agents or vice-versa.\n",
        "languages": [
            "VHDL",
            "Verilog"
        ]
    },
    {
        "cwe": "1312",
        "name": "Missing Protection for Mirrored Regions in On-Chip Fabric Firewall",
        "description": "The firewall in an on-chip fabric protects the main addressed region, but it does not protect any mirrored memory or memory-mapped-IO (MMIO) regions.",
        "detail": "**Extended Description:**\n\n\nFew fabrics mirror memory and address ranges, where mirrored regions contain copies of the original data. This redundancy is used to achieve fault tolerance. Whatever protections the fabric firewall implements for the original region should also apply to the mirrored regions. If not, an attacker could bypass existing read/write protections by reading from/writing to the mirrored regions to leak or corrupt the original data.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [
            "1251"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Using an external debugger, send write transactions to mirrored regions to test if original, write-protected regions are modified. Similarly, send read transactions to mirrored regions to test if the original, read-protected signals can be read.\n\n**Mitigation:** The fabric firewall should apply the same protections as the original region to the mirrored regions.\n\n**Mitigation:** The fabric firewall should apply the same protections as the original region to the mirrored regions.\n",
        "languages": []
    },
    {
        "cwe": "1313",
        "name": "Hardware Allows Activation of Test or Debug Logic at Runtime",
        "description": "During runtime, the hardware allows for test or debug logic (feature) to be activated, which allows for changing the state of the hardware. This feature can alter the intended behavior of the system and allow for alteration and leakage of sensitive data by an adversary.",
        "detail": "**Extended Description:**\n\n\nAn adversary can take advantage of test or debug logic that is made accessible through the hardware during normal operation to modify the intended behavior of the system. For example, an accessible Test/debug mode may allow read/write access to any system data. Using error injection (a common test/debug feature) during a transmit/receive operation on a bus, data may be modified to produce an unintended message. Similarly, confidentiality could be compromised by such features allowing access to secrets.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during integration and identified later during Testing or System configuration phases.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.\n\n**Mitigation:** Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.\n\n**Mitigation:** Insert restrictions on when the hardware's test or debug features can be activated. For example, during normal operating modes, the hardware's privileged modes that allow access to such features cannot be activated. Configuring the hardware to only enter a test or debug mode within a window of opportunity such as during boot or configuration stage. The result is disablement of such test/debug features and associated modes during normal runtime operations.\n",
        "languages": []
    },
    {
        "cwe": "1314",
        "name": "Missing Write Protection for Parametric Data Values",
        "description": "The device does not write-protect the parametric data values for sensors that scale the sensor value, allowing untrusted software to manipulate the apparent result and potentially damage hardware or cause operational failure.",
        "detail": "**Extended Description:**\n\n\nVarious sensors are used by hardware to detect any devices operating outside of the design limits. The threshold limit values are set by hardware fuses or trusted software such as the BIOS. These limits may be related to thermal, power, voltage, current, and frequency. Hardware mechanisms may be used to protect against alteration of the threshold limit values by untrusted software.\n\n\nThe limit values are generally programmed in standard units for the type of value being read. However, the hardware-sensor blocks may report the settings in different units depending upon sensor design and operation. The raw sensor output value is converted to the desired units using a scale conversion based on the parametric data programmed into the sensor. The final converted value is then compared with the previously programmed limits.\n\n\nWhile the limit values are usually protected, the sensor parametric data values may not be. By changing the parametric data, safe operational limits may be bypassed.\n\n\n**Mode of Introduction:** The lack of a requirement to protect parametric values may contribute to this weakness.\n\n**Mode of Introduction:** The lack of parametric value protection may be a cause of this weakness.\n\n**Consequence Note:** Sensor value manipulation, particularly thermal or power, may allow physical damage to occur or disabling of the device by a false fault shutdown causing a Denial-Of-Service.\n",
        "parent": [
            "862"
        ],
        "children": [],
        "related": [
            "1299"
        ],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Access controls for sensor blocks should ensure that only trusted software is allowed to change threshold limits and sensor parametric data.\n",
        "languages": []
    },
    {
        "cwe": "1315",
        "name": "Improper Setting of Bus Controlling Capability in Fabric End-point",
        "description": "The bus controller enables bits in the fabric end-point to allow responder devices to control transactions on the fabric.",
        "detail": "**Extended Description:**\n\n\nTo support reusability, certain fabric interfaces and end points provide a configurable register bit that allows IP blocks connected to the controller to access other peripherals connected to the fabric. This allows the end point to be used with devices that function as a controller or responder. If this bit is set by default in hardware, or if firmware incorrectly sets it later, a device intended to be a responder on a fabric is now capable of controlling transactions to other devices and might compromise system security.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.\n\n**Mitigation:** For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.\n\n**Mitigation:** For responder devices, the register bit in the fabric end-point that enables the bus controlling capability must be set to 0 by default. This bit should not be set during secure-boot flows. Also, writes to this register must be access-protected to prevent malicious modifications to obtain bus-controlling capability.\n",
        "languages": []
    },
    {
        "cwe": "1316",
        "name": "Fabric-Address Map Allows Programming of Unwarranted Overlaps of Protected and Unprotected Ranges",
        "description": "The address map of the on-chip fabric has protected and unprotected regions overlapping, allowing an attacker to bypass access control to the overlapping portion of the protected region.",
        "detail": "**Extended Description:**\n\n\nVarious ranges can be defined in the system-address map, either in the memory or in Memory-Mapped-IO (MMIO) space. These ranges are usually defined using special range registers that contain information, such as base address and size. Address decoding is the process of determining for which range the incoming transaction is destined. To ensure isolation, ranges containing secret data are access-control protected.\n\n\nOccasionally, these ranges could overlap. The overlap could either be intentional (e.g. due to a limited number of range registers or limited choice in choosing size of the range) or unintentional (e.g. introduced by errors). Some hardware designs allow dynamic remapping of address ranges assigned to peripheral MMIO ranges. In such designs, intentional address overlaps can be created through misconfiguration by malicious software. When protected and unprotected ranges overlap, an attacker could send a transaction and potentially compromise the protections in place, violating the principle of least privilege. \n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Authorization",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Review address map in specification to see if there are any overlapping ranges.\n\n**Detection:** Negative testing of access control on overlapped ranges.\n\n**Mitigation:** When architecting the address map of the chip, ensure that protected and unprotected ranges are isolated and do not overlap. When designing, ensure that ranges hardcoded in Register-Transfer Level (RTL) do not overlap.\n\n**Mitigation:** Ranges configured by firmware should not overlap. If overlaps are mandatory because of constraints such as a limited number of registers, then ensure that no assets are present in the overlapped portion.\n\n**Mitigation:** Validate mitigation actions with robust testing.\n",
        "languages": []
    },
    {
        "cwe": "1317",
        "name": "Improper Access Control in Fabric Bridge",
        "description": "The product uses a fabric bridge for transactions between two Intellectual Property (IP) blocks, but the bridge does not properly perform the expected privilege, identity, or other access control checks between those IP blocks.",
        "detail": "**Extended Description:**\n\n\nIn hardware designs, different IP blocks are connected through interconnect-bus fabrics (e.g. AHB and OCP). Within a System on Chip (SoC), the IP block subsystems could be using different bus protocols. In such a case, the IP blocks are then linked to the central bus (and to other IP blocks) through a fabric bridge. Bridges are used as bus-interconnect-routing modules that link different protocols or separate, different segments of the overall SoC interconnect.\n\n\nFor overall system security, it is important that the access-control privileges associated with any fabric transaction are consistently maintained and applied, even when they are routed or translated by a fabric bridge. A bridge that is connected to a fabric without security features forwards transactions to the slave without checking the privilege level of the master and results in a weakness in SoC access-control security. The same weakness occurs if a bridge does not check the hardware identity of the transaction received from the slave interface of the bridge.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** RTL simulation to ensure that bridge-access controls are implemented properly.\n\n**Detection:** Formal verification of bridge RTL to ensure that access control cannot be bypassed.\n\n**Mitigation:** Ensure that the design includes provisions for access-control checks in the bridge for both upstream and downstream transactions.\n\n**Mitigation:** Implement access-control checks in the bridge for both upstream and downstream transactions.\n",
        "languages": []
    },
    {
        "cwe": "1318",
        "name": "Missing Support for Security Features in On-chip Fabrics or Buses",
        "description": " On-chip fabrics or buses either do not support or are not configured to support privilege separation or other security features, such as access control. ",
        "detail": "**Extended Description:**\n\n\nCertain on-chip fabrics and buses, especially simple and low-power buses, do not support security features. Apart from data transfer and addressing ports, some fabrics and buses do not have any interfaces to transfer privilege, immutable identity, or any other security attribute coming from the bus master. Similarly, they do not have dedicated signals to transport security-sensitive data from slave to master, such as completions for certain types of transactions. Few other on-chip fabrics and buses support security features and define specific interfaces/signals for transporting security attributes from master to slave or vice-versa. However, including these signals is not mandatory and could be left unconfigured when generating the register-transfer-level (RTL) description for the fabric. Such fabrics or buses should not be used to transport any security attribute coming from the bus master. In general, peripherals with security assets should not be connected to such buses before the transaction from the bus master reaches the bus, unless some form of access control is performed at a fabric bridge or another intermediate module.\n\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Review the fabric specification and ensure that it contains signals to transfer security-sensitive signals.\n\n**Detection:** Lack of security features can also be confirmed through manual RTL review of the fabric RTL.\n\n**Mitigation:** If fabric does not support security features, implement security checks in a bridge or any component that is between the master and the fabric. Alternatively, connect all fabric slaves that do not have any security assets under one such fabric and connect peripherals with security assets to a different fabric that supports security features.\n",
        "languages": []
    },
    {
        "cwe": "1319",
        "name": "Improper Protection against Electromagnetic Fault Injection (EM-FI)",
        "description": "The device is susceptible to electromagnetic fault injection attacks, causing device internal information to be compromised or security mechanisms to be bypassed.",
        "detail": "**Extended Description:**\n\n\nElectromagnetic fault injection may allow an attacker to locally and dynamically modify the signals (both internal and external) of an integrated circuit. EM-FI attacks consist of producing a local, transient magnetic field near the device, inducing current in the device wires. A typical EMFI setup is made up of a pulse injection circuit that generates a high current transient in an EMI coil, producing an abrupt magnetic pulse which couples to the target producing faults in the device, which can lead to:\n\n\n  - Bypassing security mechanisms such as secure JTAG or Secure Boot\n\n  - Leaking device information\n\n  - Modifying program flow\n\n  - Perturbing secure hardware modules (e.g. random number generators)\n\n\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\n  - 1. Redundancy - By replicating critical operations and comparing the two outputs can help indicate whether a fault has been injected.\n\n  - 2. Error detection and correction codes - Gay, Mael, et al. proposed a new scheme that not only detects faults injected by a malicious adversary but also automatically corrects single nibble/byte errors introduced by low-multiplicity faults.\n\n  - 3. Fail by default coding - When checking conditions (switch or if) check all possible cases and fail by default because the default case in a switch (or the else part of a cascaded if-else-if construct) is used for dealing with the last possible (and valid) value without checking. This is prone to fault injection because this alternative is easily selected as a result of potential data manipulation [REF-1141].\n\n  - 4. Random Behavior - adding random delays before critical operations, so that timing is not predictable.\n\n  - 5. Program Flow Integrity Protection - The program flow can be secured by integrating run-time checking aiming at detecting control flow inconsistencies. One such example is tagging the source code to indicate the points not to be bypassed [REF-1147].\n\n  - 6. Sensors - Usage of sensors can detect variations in voltage and current.\n\n  - 7. Shields - physical barriers to protect the chips from malicious manipulation.\n\n\n",
        "languages": []
    },
    {
        "cwe": "1320",
        "name": "Improper Protection for Outbound Error Messages and Alert Signals",
        "description": "Untrusted agents can disable alerts about signal conditions exceeding limits or the response mechanism that handles such alerts.\n\t\t\t",
        "detail": "**Extended Description:**\n\n\nHardware sensors are used to detect whether a device is operating within design limits. The threshold values for these limits are set by hardware fuses or trusted software such as a BIOS. Modification of these limits may be protected by hardware mechanisms.\n\n\nWhen device sensors detect out of bound conditions, alert signals may be generated for remedial action, which may take the form of device shutdown or throttling.\n\n\nWarning signals that are not properly secured may be disabled or used to generate spurious alerts, causing degraded performance or denial-of-service (DoS). These alerts may be masked by untrusted software. Examples of these alerts involve thermal and power sensor alerts.\n\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Alert signals generated by critical events should be protected from access by untrusted agents. Only hardware or trusted firmware modules should be able to alter the alert configuration.\n",
        "languages": []
    },
    {
        "cwe": "1321",
        "name": "Improperly Controlled Modification of Object Prototype Attributes ('Prototype Pollution')",
        "description": "The product receives input from an upstream component that specifies attributes that are to be initialized or updated in an object, but it does not properly control modifications of attributes of the object prototype.",
        "detail": "**Extended Description:**\n\n\nBy adding or modifying attributes of an object prototype, it is possible to create attributes that exist on every object, or replace critical attributes with malicious ones. This can be problematic if the product depends on existence or non-existence of certain attributes, or uses pre-defined attributes of object prototype (such as hasOwnProperty, toString or valueOf).\n\n\nThis weakness is usually exploited by using a special attribute of objects called proto, constructor or prototype. Such attributes give access to the object prototype. This weakness is often found in code that assigns object attributes based on user input, or merges or clones objects recursively.\n\n\n**Consequence Note:** An attacker can inject attributes that are used in other components.\n\n**Consequence Note:** An attacker can override existing attributes with ones that have incompatible type, which may lead to a crash.\n",
        "parent": [
            "913",
            "915"
        ],
        "children": [],
        "related": [
            "471"
        ],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** By freezing the object prototype first (for example, Object.freeze(Object.prototype)), modification of the prototype becomes impossible.\n\n**Effectiveness:** While this can mitigate this weakness completely, other methods are recommended when possible, especially in components used by upstream software (\"libraries\").\n\n**Mitigation:** By blocking modifications of attributes that resolve to object prototype, such as proto or prototype, this weakness can be mitigated.\n\n**Mitigation:** When handling untrusted objects, validating using a schema can be used.\n\n**Mitigation:** By using an object without prototypes (via Object.create(null) ), adding object prototype attributes by accessing the prototype via the special attributes becomes impossible, mitigating this weakness.\n\n**Mitigation:** Map can be used instead of objects in most cases. If Map methods are used instead of object attributes, it is not possible to access the object prototype or modify it.\n",
        "languages": [
            "JavaScript"
        ]
    },
    {
        "cwe": "1322",
        "name": "Use of Blocking Code in Single-threaded, Non-blocking Context",
        "description": "The product uses a non-blocking model that relies on a single threaded process\n\t\t\tfor features such as scalability, but it contains code that can block when it is invoked.",
        "detail": "**Extended Description:**\n\n\nWhen an attacker can directly invoke the blocking code, or the blocking code can be affected by environmental conditions that can be influenced by an attacker, then this can lead to a denial of service by causing unexpected hang or freeze of the code. Examples of blocking code might be an expensive computation or calling blocking library calls, such as those that perform exclusive file operations or require a successful network operation.\n\n\nDue to limitations in multi-thread models, single-threaded models are used to overcome the resource constraints that are caused by using many threads. In such a model, all code should generally be non-blocking. If blocking code is called, then the event loop will effectively be stopped, which can be undesirable or dangerous. Such models are used in Python asyncio, Vert.x, and Node.js, or other custom event loop code.\n\n\n**Consequence Note:** An unexpected call to blocking code can trigger an infinite loop, or a large loop that causes the software to pause and wait indefinitely.\n",
        "parent": [
            "834"
        ],
        "children": [],
        "related": [
            "835"
        ],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Generally speaking, blocking calls should be replaced with non-blocking alternatives that can be used asynchronously. Expensive computations should be passed off to worker threads, although the correct approach depends on the framework being used.\n\n**Mitigation:** For expensive computations, consider breaking them up into multiple smaller computations. Refer to the documentation of the framework being used for guidance.\n",
        "languages": []
    },
    {
        "cwe": "1323",
        "name": "Improper Management of Sensitive Trace Data",
        "description": "Trace data collected from several sources on the\n                System-on-Chip (SoC) is stored in unprotected locations or\n                transported to untrusted agents.",
        "detail": "**Extended Description:**\n\n\nTo facilitate verification of complex System-on-Chip (SoC) designs, SoC integrators add specific IP blocks that trace the SoC's internal signals in real-time. This infrastructure enables observability of the SoC's internal behavior, validation of its functional design, and detection of hardware and software bugs. Such tracing IP blocks collect traces from several sources on the SoC including the CPU, crypto coprocessors, and on-chip fabrics. Traces collected from these sources are then aggregated inside trace IP block and forwarded to trace sinks, such as debug-trace ports that facilitate debugging by external hardware and software debuggers.\n\n\nSince these traces are collected from several security-sensitive sources, they must be protected against untrusted debuggers. If they are stored in unprotected memory, an untrusted software debugger can access these traces and extract secret information. Additionally, if security-sensitive traces are not tagged as secure, an untrusted hardware debugger might access them to extract confidential information.\n\n\n**Consequence Note:** An adversary can read secret values if they are captured in debug traces and stored unsafely.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Tag traces to indicate owner and debugging privilege level (designer, OEM, or end user) needed to access that trace.\n",
        "languages": []
    },
    {
        "cwe": "1325",
        "name": "Improperly Controlled Sequential Memory Allocation",
        "description": "The product manages a group of objects or resources and performs a separate memory allocation for each object, but it does not properly limit the total amount of memory that is consumed by all of the combined objects.",
        "detail": "**Extended Description:**\n\n\nWhile the product might limit the amount of memory that is allocated in a single operation for a single object (such as a malloc of an array), if an attacker can cause multiple objects to be allocated in separate operations, then this might cause higher total memory consumption than the developer intended, leading to a denial of service.\n\n\n**Alternate Terms:** Stack Exhaustion\n\n**Consequence Note:** Not controlling memory allocation can result in a request for too much system memory, possibly leading to a crash of the application due to out-of-memory conditions, or the consumption of a large amount of memory on the system.\n",
        "parent": [
            "770"
        ],
        "children": [],
        "related": [
            "476",
            "789"
        ],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Ensure multiple allocations of the same kind of object are properly tracked - possibly across multiple sessions, requests, or messages. Define an appropriate strategy for handling requests that exceed the limit, and consider supporting a configuration option so that the administrator can extend the amount of memory to be used if necessary.\n\n**Mitigation:** Run the program using system-provided resource limits for memory. This might still cause the program to crash or exit, but the impact to the rest of the system will be minimized.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1326",
        "name": "Missing Immutable Root of Trust in Hardware",
        "description": "A missing immutable root of trust in the hardware results in the ability to bypass secure boot or execute untrusted or adversarial boot code.",
        "detail": "**Extended Description:**\n\n\nA System-on-Chip (SoC) implements secure boot by verifying or authenticating signed boot code. The signing of the code is achieved by an entity that the SoC trusts. Before executing the boot code, the SoC verifies that the code or the public key with which the code has been signed has not been tampered with. The other data upon which the SoC depends are system-hardware settings in fuses such as whether \"Secure Boot is enabled\". These data play a crucial role in establishing a Root of Trust (RoT) to execute secure-boot flows.\n\n\nOne of the many ways RoT is achieved is by storing the code and data in memory or fuses. This memory should be immutable, i.e., once the RoT is programmed/provisioned in memory, that memory should be locked and prevented from further programming or writes. If the memory contents (i.e., RoT) are mutable, then an adversary can modify the RoT to execute their choice of code, resulting in a compromised secure boot.\n\n\nNote that, for components like ROM, secure patching/update features should be supported to allow authenticated and authorized updates in the field. \n\n\n**Mode of Introduction:** Such issues could be introduced during policy definition, hardware architecture, design, manufacturing, and/or provisioning. They can be identified later during testing or system configuration phases.\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Authentication",
            "Authorization"
        ],
        "mitigation": "**Detection:** Automated testing can verify that RoT components are immutable.\n\n**Detection:** Root of trust elements and memory should be part of architecture and design reviews.\n\n**Mitigation:** When architecting the system, the RoT should be designated for storage in a memory that does not allow further programming/writes.\n\n**Mitigation:** During implementation and test, the RoT memory location should be demonstrated to not allow further programming/writes.\n",
        "languages": []
    },
    {
        "cwe": "1327",
        "name": "Binding to an Unrestricted IP Address",
        "description": "The product assigns the address 0.0.0.0 for a database server, a cloud service/instance, or any computing resource that communicates remotely.",
        "detail": "**Extended Description:**\n\n\nWhen a server binds to the address 0.0.0.0, it allows connections from every IP address on the local machine, effectively exposing the server to every possible network. This might be much broader access than intended by the developer or administrator, who might only be expecting the server to be reachable from a single interface/network.\n\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Assign IP addresses that are not 0.0.0.0.\n\n**Mitigation:** Unwanted connections to the configured server may be denied through a firewall or other packet filtering measures.\n",
        "languages": []
    },
    {
        "cwe": "1328",
        "name": "Security Version Number Mutable to Older Versions",
        "description": "Security-version number in hardware is mutable, resulting in the ability to downgrade (roll-back) the boot firmware to vulnerable code versions.",
        "detail": "**Extended Description:**\n\n\nA System-on-Chip (SoC) implements secure boot or verified boot. It might support a security version number, which prevents downgrading the current firmware to a vulnerable version. Once downgraded to a previous version, an adversary can launch exploits on the SoC and thus compromise the security of the SoC. These downgrade attacks are also referred to as roll-back attacks.\n\n\nThe security version number must be stored securely and persistently across power-on resets. A common weakness is that the security version number is modifiable by an adversary, allowing roll-back or downgrade attacks or, under certain circumstances, preventing upgrades (i.e. Denial-of-Service on upgrades). In both cases, the SoC is in a vulnerable state.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design, and can be identified later during testing or system configuration phases.\n\n**Consequence Note:** Impact includes roll-back or downgrade to a vulnerable version of the firmware or DoS (prevent upgrades).\n",
        "parent": [
            "285"
        ],
        "children": [],
        "related": [
            "757"
        ],
        "scopes": [
            "Authentication",
            "Authorization",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Mutability of stored security version numbers and programming with older firmware images should be part of automated testing.\n\n**Detection:** Anti-roll-back features should be reviewed as part of Architecture or Design review.\n\n**Mitigation:** When architecting the system, security version data should be designated for storage in registers that are either read-only or have access controls that prevent modification by an untrusted agent.\n\n**Mitigation:** During implementation and test, security version data should be demonstrated to be read-only and access controls should be validated.\n",
        "languages": []
    },
    {
        "cwe": "1329",
        "name": "Reliance on Component That is Not Updateable",
        "description": "The product contains a component that cannot be updated or patched in order to remove vulnerabilities or significant bugs.",
        "detail": "**Extended Description:**\n\n\n If the component is discovered to contain a vulnerability or critical bug, but the issue cannot be fixed using an update or patch, then the product's owner will not be able to protect against the issue. The only option might be replacement of the product, which could be too financially or operationally expensive for the product owner. As a result, the inability to patch or update can leave the product open to attacker exploitation or critical operation failures. This weakness can be especially difficult to manage when using ROM, firmware, or similar components that traditionally have had limited or no update capabilities. \n\n\n In industries such as healthcare, \"legacy\" devices can be operated for decades. As a US task force report [REF-1197] notes, \"the inability to update or replace equipment has both large and small health care delivery organizations struggle with numerous unsupported legacy systems that cannot easily be replaced (hardware, software, and operating systems) with large numbers of vulnerabilities and few modern countermeasures.\" \n\n\n While hardware can be prone to this weakness, software systems can also be affected, such as when a third-party driver or library is no longer actively maintained or supported but is still critical for the required functionality.\n\n\n**Mode of Introduction:** Requirements development might not consider the importance of updates over the lifetime of the product or might intentionally exclude this capability due to concerns such as expense or speed to market.\n\n**Mode of Introduction:** Lack of planning during architecture development and design, or external pressures such as speed to market, could ignore the capability to update.\n\n**Mode of Introduction:** Designers might omit capabilities for updating a component due to time pressures to release the product or assumptions about the stability of the component.\n\n**Mode of Introduction:** The weakness can appear through oversight during implementation.\n\n**Consequence Note:** If an attacker can identify an exploitable vulnerability in one product that has no means of patching, the attack may be used against all affected versions of that product.\n",
        "parent": [
            "1357",
            "664"
        ],
        "children": [
            "1277",
            "1310"
        ],
        "related": [],
        "scopes": [
            "Access Control",
            "Authentication",
            "Authorization",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Check the consumer or maintainer documentation, the architecture/design documentation, or the original requirements to ensure that the documentation includes details for how to update the firmware.\n\n**Mitigation:** Specify requirements that each component should be updateable, including ROM, firmware, etc.\n\n**Mitigation:** Design the product to allow for updating of its components. Include the external infrastructure that might be necessary to support updates, such as distribution servers.\n\n**Mitigation:** With hardware, support patches that can be programmed in-field or during manufacturing through hardware fuses. This feature can be used for limited patching of devices after shipping, or for the next batch of silicon devices manufactured, without changing the full device ROM.\n\n**Effectiveness:** Some parts of the hardware initialization or signature verification done to authenticate patches will always be \"not patchable.\" Hardware-fuse-based patches will also have limitations in terms of size and the number of patches that can be supported.\n\n**Mitigation:** Implement the necessary functionality to allow each component to be updated.\n",
        "languages": []
    },
    {
        "cwe": "1330",
        "name": "Remanent Data Readable after Memory Erase",
        "description": "Confidential information stored in memory circuits is readable or recoverable after being cleared or erased.",
        "detail": "**Extended Description:**\n\n\nData remanence occurs when stored, memory content is not fully lost after a memory-clear or -erase operation. Confidential memory contents can still be readable through data remanence in the hardware.\n\n\nData remanence can occur because of performance optimization or memory organization during 'clear' or 'erase' operations, like a design that allows the memory-organization metadata (e.g., file pointers) to be erased without erasing the actual memory content. To protect against this weakness, memory devices will often support different commands for optimized memory erase and explicit secure erase.\n\n\nData remanence can also happen because of the physical properties of memory circuits in use. For example, static, random-access-memory (SRAM) and dynamic, random-access-memory (DRAM) data retention is based on the charge retained in the memory cell, which depends on factors such as power supply, refresh rates, and temperature.\n\n\nOther than explicit erase commands, self-encrypting, secure-memory devices can also support secure erase through cryptographic erase commands. In such designs, only the decryption keys for encrypted data stored on the device are erased. That is, the stored data are always remnant in the media after a cryptographic erase. However, only the encrypted data can be extracted. Thus, protection against data recovery in such designs relies on the strength of the encryption algorithm.\n\n\n**Consequence Note:** Confidential data are readable to untrusted agent.\n",
        "parent": [
            "1301"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** \n\n  - Testing of memory-device contents after clearing or erase commands.\n\n  - Dynamic analysis of memory contents during device operation to detect specific, confidential assets.\n\n  - Architecture and design analysis of memory clear and erase operations.\n\n\n\n**Detection:** \n\n  - Testing of memory-device contents after clearing or erase commands.\n\n  - Dynamic analysis of memory contents during device operation to detect specific, confidential assets.\n\n  - Architecture and design analysis of memory clear and erase operations.\n\n\n\n**Mitigation:** \n\n  - Support for secure-erase commands that apply multiple cycles of overwriting memory with known patterns and of erasing actual content.\n\n  - Support for cryptographic erase in self-encrypting, memory devices.\n\n  - External, physical tools to erase memory such as ultraviolet-rays-based erase of Electrically erasable, programmable, read-only memory (EEPROM).\n\n  - Physical destruction of media device. This is done for repurposed or scrapped devices that are no longer in use.\n\n\n",
        "languages": []
    },
    {
        "cwe": "1331",
        "name": "Improper Isolation of Shared Resources in Network On Chip (NoC)",
        "description": "The Network On Chip (NoC) does not isolate or incorrectly isolates its on-chip-fabric and internal resources such that they are shared between trusted and untrusted agents, creating timing channels.",
        "detail": "**Extended Description:**\n\n\nTypically, network on chips (NoC) have many internal resources that are shared between packets from different trust domains. These resources include internal buffers, crossbars and switches, individual ports, and channels. The sharing of resources causes contention and introduces interference between differently trusted domains, which poses a security threat via a timing channel, allowing attackers to infer data that belongs to a trusted agent. This may also result in introducing network interference, resulting in degraded throughput and latency.\n\n\n**Background Details:**\n['\\n\\n\"Network-on-chip\" (NoC) is a commonly-used term used for hardware interconnect fabrics used by multicore Systems-on-Chip (SoC). Communication between modules on the chip uses packet-based methods, with improved efficiency and scalability compared to bus architectures [REF-1241].\\n']\n\n**Consequence Note:** Attackers may infer data that belongs to a trusted agent. The methods used to perform this attack may result in noticeably increased resource consumption.\n",
        "parent": [
            "653",
            "668"
        ],
        "children": [],
        "related": [
            "1189"
        ],
        "scopes": [
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Providing marker flags to send through the interfaces coupled with examination of which users are able to read or manipulate the flags will help verify that the proper isolation has been achieved and is effective.\n\n**Mitigation:** Implement priority-based arbitration inside the NoC and have dedicated buffers or virtual channels for routing secret data from trusted agents.\n",
        "languages": []
    },
    {
        "cwe": "1332",
        "name": "Improper Handling of Faults that Lead to Instruction Skips",
        "description": "The device is missing or incorrectly implements circuitry or sensors that detect and mitigate the skipping of security-critical CPU instructions when they occur.",
        "detail": "**Extended Description:**\n\n\nThe operating conditions of hardware may change in ways that cause unexpected behavior to occur, including the skipping of security-critical CPU instructions. Generally, this can occur due to electrical disturbances or when the device operates outside of its expected conditions.\n\n\nIn practice, application code may contain conditional branches that are security-sensitive (e.g., accepting or rejecting a user-provided password). These conditional branches are typically implemented by a single conditional branch instruction in the program binary which, if skipped, may lead to effectively flipping the branch condition - i.e., causing the wrong security-sensitive branch to be taken. This affects processes such as firmware authentication, password verification, and other security-sensitive decision points.\n\n\nAttackers can use fault injection techniques to alter the operating conditions of hardware so that security-critical instructions are skipped more frequently or more reliably than they would in a \"natural\" setting.\n\n\n**Mode of Introduction:** Failure to design appropriate countermeasures to common fault injection techniques can manifest this weakness.\n\n**Mode of Introduction:** This weakness can arise if the hardware design incorrectly implements countermeasures to prevent fault injection.\n\n**Consequence Note:** Depending on the context, instruction skipping can have a broad range of consequences related to the generic bypassing of security critical code.\n",
        "parent": [
            "1384"
        ],
        "children": [],
        "related": [
            "1247"
        ],
        "scopes": [
            "Authentication",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** This weakness can be found using automated static analysis once a developer has indicated which code paths are critical to protect.\n\n**Detection:** This weakness can be found using automated dynamic analysis. Both emulation of a CPU with instruction skips, as well as RTL simulation of a CPU IP, can indicate parts of the code that are sensitive to faults due to instruction skips.\n\n**Detection:** This weakness can be found using manual (static) analysis. The analyst has security objectives that are matched against the high-level code. This method is less precise than emulation, especially if the analysis is done at the higher level language rather than at assembly level.\n\n**Mitigation:** Design strategies for ensuring safe failure if inputs, such as Vcc, are modified out of acceptable ranges.\n\n**Mitigation:** Design strategies for ensuring safe behavior if instructions attempt to be skipped.\n\n**Mitigation:** Identify mission critical secrets that should be wiped if faulting is detected, and design a mechanism to do the deletion.\n\n**Mitigation:** Add redundancy by performing an operation multiple times, either in space or time, and perform majority voting. Additionally, make conditional instruction timing unpredictable.\n\n**Mitigation:** Use redundant operations or canaries to detect and respond to faults.\n\n**Mitigation:** Ensure that fault mitigations are strong enough in practice. For example, a low power detection mechanism that takes 50 clock cycles to trigger at lower voltages may be an insufficient security mechanism if the instruction counter has already progressed with no other CPU activity occurring.\n",
        "languages": []
    },
    {
        "cwe": "1333",
        "name": "Inefficient Regular Expression Complexity",
        "description": "The product uses a regular expression with an inefficient, possibly exponential worst-case computational complexity that consumes excessive CPU cycles.",
        "detail": "**Extended Description:**\nSome regular expression engines have a feature called \"backtracking\". If the token cannot match, the engine \"backtracks\" to a position that may result in a different token that can match.\n Backtracking becomes a weakness if all of these conditions are met:\n\n\n  - The number of possible backtracking attempts are exponential relative to the length of the input.\n\n  - The input can fail to match the regular expression.\n\n  - The input can be long enough.\n\n Attackers can create crafted inputs that intentionally cause the regular expression to use excessive backtracking in a way that causes the CPU consumption to spike. \n\n**Alternate Terms:** ReDoS, Regular Expression Denial of Service, Catastrophic backtracking\n\n**Mode of Introduction:** A RegEx can be easy to create and read using unbounded matching characters, but the programmer might not consider the risk of excessive backtracking.\n",
        "parent": [
            "407"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Use regular expressions that do not support backtracking, e.g. by removing nested quantifiers.\n\n**Effectiveness:** This is one of the few effective solutions when using user-provided regular expressions.\n\n**Mitigation:** Set backtracking limits in the configuration of the regular expression implementation, such as PHP's pcre.backtrack_limit. Also consider limits on execution time for the process.\n\n**Mitigation:** Do not use regular expressions with untrusted input. If regular expressions must be used, avoid using backtracking in the expression.\n\n**Mitigation:** Limit the length of the input that the regular expression will process.\n",
        "languages": []
    },
    {
        "cwe": "1334",
        "name": "Unauthorized Error Injection Can Degrade Hardware Redundancy",
        "description": "An unauthorized agent can inject errors into a redundant block to deprive the system of redundancy or put the system in a degraded operating mode.",
        "detail": "**Extended Description:**\n\n\nTo ensure the performance and functional reliability of certain components, hardware designers can implement hardware blocks for redundancy in the case that others fail. This redundant block can be prevented from performing as intended if the design allows unauthorized agents to inject errors into it. In this way, a path with injected errors may become unavailable to serve as a redundant channel. This may put the system into a degraded mode of operation which could be exploited by a subsequent attack.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture and design and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during implementation and identified later during Testing or System Configuration phases.\n\n**Mode of Introduction:** Such issues could be introduced during integration and identified later during Testing or System Configuration phases.\n",
        "parent": [
            "284"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Ensure the design does not allow error injection in modes intended for normal run-time operation. Provide access controls on interfaces for injecting errors.\n\n**Mitigation:** Disallow error injection in modes which are expected to be used for normal run-time operation. Provide access controls on interfaces for injecting errors.\n\n**Mitigation:** Add an access control layer atop any unprotected interfaces for injecting errors.\n",
        "languages": []
    },
    {
        "cwe": "1335",
        "name": "Incorrect Bitwise Shift of Integer",
        "description": "An integer value is specified to be shifted by a negative amount or an amount greater than or equal to the number of bits contained in the value causing an unexpected or indeterminate result.",
        "detail": "**Extended Description:**\n\n\nSpecifying a value to be shifted by a negative amount is undefined in various languages. Various computer architectures implement this action in different ways. The compilers and interpreters when generating code to accomplish a shift generally do not do a check for this issue.\n\n\nSpecifying an over-shift, a shift greater than or equal to the number of bits contained in a value to be shifted, produces a result which varies by architecture and compiler. In some languages, this action is specifically listed as producing an undefined result.\n\n\n**Mode of Introduction:** Adding shifts without properly verifying the size and sign of the shift amount.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Implicitly or explicitly add checks and mitigation for negative or over-shift values.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java",
            "JavaScript"
        ]
    },
    {
        "cwe": "1336",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "917"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1338",
        "name": "Improper Protections Against Hardware Overheating",
        "description": "A hardware device is missing or has inadequate protection features to prevent overheating.",
        "detail": "**Extended Description:**\n\n\nHardware, electrical circuits, and semiconductor silicon have thermal side effects, such that some of the energy consumed by the device gets dissipated as heat and increases the temperature of the device. For example, in semiconductors, higher-operating frequency of silicon results in higher power dissipation and heat. The leakage current in CMOS circuits increases with temperature, and this creates positive feedback that can result in thermal runaway and damage the device permanently.\n\n\nAny device lacking protections such as thermal sensors, adequate platform cooling, or thermal insulation is susceptible to attacks by malicious software that might deliberately operate the device in modes that result in overheating. This can be used as an effective denial of service (DoS) or permanent denial of service (PDoS) attack.\n\n\nDepending on the type of hardware device and its expected usage, such thermal overheating can also cause safety hazards and reliability issues. Note that battery failures can also cause device overheating but the mitigations and examples included in this submission cannot reliably protect against a battery failure. \n\n\nThere can be similar weaknesses with lack of protection from attacks based on overvoltage or overcurrent conditions. However, thermal heat is generated by hardware operation and the device should implement protection from overheating.\n\n\n**Mode of Introduction:** Such issues could be introduced during hardware architecture, design or implementation.\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** Dynamic tests should be performed to stress-test temperature controls.\n\n**Detection:** Power management controls should be part of Architecture and Design reviews.\n\n**Mitigation:** Temperature maximum and minimum limits should be enforced using thermal sensors both in silicon and at the platform level.\n\n**Mitigation:** The platform should support cooling solutions such as fans that can be modulated based on device-operation needs to maintain a stable temperature.\n",
        "languages": []
    },
    {
        "cwe": "1339",
        "name": "Insufficient Precision or Accuracy of a Real Number",
        "description": "The product processes a real number with an implementation in which the number's representation does not preserve required accuracy and precision in its fractional part, causing an incorrect result.",
        "detail": "**Extended Description:**\n\n\nWhen a security decision or calculation requires highly precise, accurate numbers such as financial calculations or prices, then small variations in the number could be exploited by an attacker. \n\n\nThere are multiple ways to store the fractional part of a real number in a computer. In all of these cases, there is a limit to the accuracy of recording a fraction. If the fraction can be represented in a fixed number of digits (binary or decimal), there might not be enough digits assigned to represent the number. In other cases the number cannot be represented in a fixed number of digits due to repeating in decimal or binary notation (e.g. 0.333333...) or due to a transcendental number such as Π or √2. Rounding of numbers can lead to situations where the computer results do not adequately match the result of sufficiently accurate math. \n\n\n**Mode of Introduction:** This weakness is introduced when the developer picks a method to represent a real number. The weakness may only be visible with very specific numeric inputs.\n\n**Background Details:**\n[\"There are three major ways to store real numbers in computers. Each method is described along with the limitations of how they store their numbers. \\n\\n  - Fixed: Some implementations use a fixed number of binary bits to represent both the integer and the fraction. In the demonstrative example about Muller's Recurrence, the fraction 108.0 - ((815.0 - 1500.0 / z) / y) cannot be represented in 8 binary digits. The numeric accuracy within languages such as PL/1, COBOL and Ada is expressed in decimal digits rather than binary digits. In SQL and most databases, the length of the integer and the fraction are specified by the programmer in decimal. In the language C, fixed reals are implemented according to ISO/IEC TR18037\\n\\n  - Floating: The number is stored in a version of scientific notation with a fixed length for the base and the significand. This allows flexibility for more accuracy when the integer portion is smaller. When dealing with large integers, the fractional accuracy is less. Languages such as PL/1, COBOL and Ada set the accuracy by decimal digit representation rather than using binary digits. Python also implements decimal floating-point numbers using the IEEE 754-2008 encoding method.\\n\\n  - Ratio: The number is stored as the ratio of two integers. These integers also have their limits. These integers can be stored in a fixed number of bits or in a vector of digits. While the vector of digits method provides for very large integers, they cannot truly represent a repeating or transcendental number as those numbers do not ever have a fixed length.\\n\\n\"]\n\n**Consequence Note:** This weakness will generally lead to undefined results and therefore crashes. In some implementations the program will halt if the weakness causes an overflow during a calculation.\n\n**Consequence Note:** The results of the math are not as expected. This could cause issues where a value would not be properly calculated and provide an incorrect answer.\n\n**Consequence Note:** This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a product's implicit security policy.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [
            "119",
            "190",
            "834"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** The developer or maintainer can move to a more accurate representation of real numbers. In extreme cases, the programmer can move to representations such as ratios of BigInts which can represent real numbers to extremely fine precision. The programmer can also use the concept of an Unum real. The memory and CPU tradeoffs of this change must be examined. Since floating point reals are used in many products and many locations, they are implemented in hardware and most format changes will cause the calculations to be moved into software resulting in slower products.\n",
        "languages": []
    },
    {
        "cwe": "134",
        "name": "Use of Externally-Controlled Format String",
        "description": "The product uses a function that accepts a format string as an argument, but the format string originates from an external source.",
        "detail": "**Mode of Introduction:** The programmer rarely intends for a format string to be externally-controlled at all. This weakness is frequently introduced in code that constructs log messages, where a constant format string is omitted.\n\n**Mode of Introduction:** In cases such as localization and internationalization, the language-specific message repositories could be an avenue for exploitation, but the format string issue would be resultant, since attacker control of those repositories would also allow modification of message length, format, and content.\n\n**Consequence Note:** Format string problems allow for information disclosure which can severely simplify exploitation of the program.\n\n**Consequence Note:** Format string problems can result in the execution of arbitrary code, buffer overflows, denial of service, or incorrect data representation.\n",
        "parent": [
            "20",
            "668"
        ],
        "children": [],
        "related": [
            "123"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** This weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.\n\n**Detection:** Since format strings often occur in rarely-occurring erroneous conditions (e.g. for error message logging), they can be difficult to detect using black box methods. It is highly likely that many latent issues exist in executables that do not have associated source code (or equivalent source.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode simple extractor - strings, ELF readers, etc.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWarning Flags\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** Choose a language that is not subject to this flaw.\n\n**Mitigation:** Ensure that all format string functions are passed a static string which cannot be controlled by the user, and that the proper number of arguments are always sent to that function as well. If at all possible, use functions that do not support the %n operator in format strings. [REF-116] [REF-117]\n\n**Mitigation:** Run compilers and linkers with high warning levels, since they may detect incorrect usage.\n",
        "languages": [
            "C",
            "C++",
            "Perl"
        ]
    },
    {
        "cwe": "1341",
        "name": "Multiple Releases of Same Resource or Handle",
        "description": "The product attempts to close or release a resource or handle more than once, without any successful open between the close operations.",
        "detail": "**Extended Description:**\n\n\nCode typically requires \"opening\" handles or references to resources such as memory, files, devices, socket connections, services, etc. When the code is finished with using the resource, it is typically expected to \"close\" or \"release\" the resource, which indicates to the environment (such as the OS) that the resource can be re-assigned or reused by unrelated processes or actors - or in some cases, within the same process. API functions or other abstractions are often used to perform this release, such as free() or delete() within C/C++, or file-handle close() operations that are used in many languages.\n\n\nUnfortunately, the implementation or design of such APIs might expect the developer to be responsible for ensuring that such APIs are only called once per release of the resource. If the developer attempts to release the same resource/handle more than once, then the API's expectations are not met, resulting in undefined and/or insecure behavior. This could lead to consequences such as memory corruption, data corruption, execution path corruption, or other consequences.\n\n\nNote that while the implementation for most (if not all) resource reservation allocations involve a unique identifier/pointer/symbolic reference, then if this identifier is reused, checking the identifier for resource closure may result in a false state of openness and closing of the wrong resource. For this reason, reuse of identifiers is discouraged.\n\n",
        "parent": [
            "675"
        ],
        "children": [],
        "related": [
            "672"
        ],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Detection:** For commonly-used APIs and resource types, automated tools often have signatures that can spot this issue.\n\n**Detection:** Some compiler instrumentation tools such as AddressSanitizer (ASan) can indirectly detect some instances of this weakness.\n\n**Mitigation:** Change the code's logic so that the resource is only closed once. This might require simplifying or refactoring. This fix can be simple to do in small code blocks, but more difficult when multiple closes are buried within complex conditionals.\n\n**Mitigation:** It can be effective to implement a flag that is (1) set when the resource is opened, (2) cleared when it is closed, and (3) checked before closing. This approach can be useful when there are disparate cases in which closes must be performed. However, flag-tracking can increase code complexity and requires diligent compliance by the programmer.\n\n**Mitigation:** When closing a resource, set the resource's associated variable to NULL or equivalent value for the given language. Some APIs will ignore this null value without causing errors. For other APIs, this can lead to application crashes or exceptions, which may still be preferable to corrupting an unintended resource such as memory or data.\n",
        "languages": [
            "C",
            "C++",
            "Java",
            "Rust"
        ]
    },
    {
        "cwe": "1342",
        "name": "Information Exposure through Microarchitectural State after Transient Execution",
        "description": "The processor does not properly clear microarchitectural state after incorrect microcode assists or speculative execution, resulting in transient execution.",
        "detail": "**Extended Description:**\n\n\nIn many processor architectures an exception, mis-speculation, or microcode assist results in a flush operation to clear results that are no longer required. This action prevents these results from influencing architectural state that is intended to be visible from software. However, traces of this transient execution may remain in microarchitectural buffers, resulting in a change in microarchitectural state that can expose sensitive information to an attacker using side-channel analysis. For example, Load Value Injection (LVI) [REF-1202] can exploit direct injection of erroneous values into intermediate load and store buffers.\n\n\nSeveral conditions may need to be fulfilled for a successful attack:\n\n\n  1. incorrect transient execution that results in remanence of sensitive information;\n\n  1. attacker has the ability to provoke microarchitectural exceptions;\n\n  1. operations and structures in victim code that can be exploited must be identified.\n\n\n",
        "parent": [
            "226"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Hardware ensures that no illegal data flows from faulting micro-ops exists at the microarchitectural level.\n\n**Effectiveness:** Being implemented in silicon it is expected to fully address the known weaknesses with limited performance impact.\n\n**Mitigation:** Include instructions that explicitly remove traces of unneeded computations from software interactions with microarchitectural elements e.g. lfence, sfence, mfence, clflush.\n\n**Effectiveness:** This effectively forces the processor to complete each memory access before moving on to the next operation. This may have a large performance impact.\n",
        "languages": []
    },
    {
        "cwe": "135",
        "name": "Incorrect Calculation of Multi-Byte String Length",
        "description": "The product does not correctly calculate the length of strings that can contain wide or multi-byte characters.",
        "detail": "**Mode of Introduction:** \n\nThere are several ways in which improper string length checking may result in an exploitable condition. All of these, however, involve the introduction of buffer overflow conditions in order to reach an exploitable state.\n\n\nThe first of these issues takes place when the output of a wide or multi-byte character string, string-length function is used as a size for the allocation of memory. While this will result in an output of the number of characters in the string, note that the characters are most likely not a single byte, as they are with standard character strings. So, using the size returned as the size sent to new or malloc and copying the string to this newly allocated memory will result in a buffer overflow.\n\n\nAnother common way these strings are misused involves the mixing of standard string and wide or multi-byte string functions on a single string. Invariably, this mismatched information will result in the creation of a possibly exploitable buffer overflow condition.\n\n\n**Consequence Note:** This weakness may lead to a buffer overflow. Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy. This can often be used to subvert any other security service.\n\n**Consequence Note:** Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.\n\n**Consequence Note:** In the case of an out-of-bounds read, the attacker may have access to sensitive information. If the sensitive information contains system details, such as the current buffer's position in memory, this knowledge can be used to craft further attacks, possibly with more severe consequences.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Always verify the length of the string unit character.\n\n**Mitigation:** Use length computing functions (e.g. strlen, wcslen, etc.) appropriately with their equivalent type (e.g.: byte, wchar_t, etc.)\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "1351",
        "name": "Improper Handling of Hardware Behavior in Exceptionally Cold Environments",
        "description": "A hardware device, or the firmware running on it, is\n                missing or has incorrect protection features to maintain\n                goals of security primitives when the device is cooled below\n                standard operating temperatures.",
        "detail": "**Extended Description:**\n\n\nThe hardware designer may improperly anticipate hardware behavior when exposed to exceptionally cold conditions. As a result they may introduce a weakness by not accounting for the modified behavior of critical components when in extreme environments.\n\n\nAn example of a change in behavior is that power loss won't clear/reset any volatile state when cooled below standard operating temperatures. This may result in a weakness when the starting state of the volatile memory is being relied upon for a security decision. For example, a Physical Unclonable Function (PUF) may be supplied as a security primitive to improve confidentiality, authenticity, and integrity guarantees. However, when the PUF is paired with DRAM, SRAM, or another temperature sensitive entropy source, the system designer may introduce weakness by failing to account for the chosen entropy source's behavior at exceptionally low temperatures. In the case of DRAM and SRAM, when power is cycled at low temperatures, the device will not contain the bitwise biasing caused by inconsistencies in manufacturing and will instead contain the data from previous boot. Should the PUF primitive be used in a cryptographic construction which does not account for full adversary control of PUF seed data, weakness would arise.\n\n\nThis weakness does not cover \"Cold Boot Attacks\" wherein RAM or other external storage is super cooled and read externally by an attacker.\n\n\n**Consequence Note:** Consequences of this weakness are highly contextual.\n",
        "parent": [
            "1384"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Authentication",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** The system should account for security primitive behavior when cooled outside standard temperatures.\n",
        "languages": []
    },
    {
        "cwe": "1357",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1104"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "138",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "140"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1384",
        "name": "Improper Handling of Physical or Environmental Conditions",
        "description": "The product does not properly handle unexpected physical or environmental conditions that occur naturally or are artificially induced.",
        "detail": "**Extended Description:**\n\n\nHardware products are typically only guaranteed to behave correctly within certain physical limits or environmental conditions. Such products cannot necessarily control the physical or external conditions to which they are subjected. However, the inability to handle such conditions can undermine a product's security. For example, an unexpected physical or environmental condition may cause the flipping of a bit that is used for an authentication decision. This unexpected condition could occur naturally or be induced artificially by an adversary.\n\n\nPhysical or environmental conditions of concern are:\n\n\n  -  **Atmospheric characteristics: ** extreme temperature ranges, etc.\n\n  -  **Interference: ** electromagnetic interference (EMI), radio frequency interference (RFI), etc.\n\n  -  **Assorted light sources: ** white light, ultra-violet light (UV), lasers, infrared (IR), etc.\n\n  -  **Power variances: ** under-voltages, over-voltages, under-current, over-current, etc.\n\n  -  **Clock variances: ** glitching, overclocking, clock stretching, etc.\n\n  -  **Component aging and degradation** \n\n  -  **Materials manipulation: ** focused ion beams (FIB), etc.\n\n  -  **Exposure to radiation: ** x-rays, cosmic radiation, etc.\n\n\n\n**Mode of Introduction:** The product's design might not consider checking and handling extreme conditions.\n\n**Mode of Introduction:** For hardware manufacturing, sub-par components might be chosen that are not able to handle the expected environmental conditions.\n\n**Consequence Note:** Consequences of this weakness are highly dependent on the role of affected components within the larger product.\n",
        "parent": [
            "703"
        ],
        "children": [
            "1247",
            "1261",
            "1332",
            "1351"
        ],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** In requirements, be specific about expectations for how the product will perform when it exceeds physical and environmental boundary conditions, e.g., by shutting down.\n\n**Mitigation:** Where possible, include independent components that can detect excess environmental conditions and have the capability to shut down the product.\n\n**Mitigation:** Where possible, use shielding or other materials that can increase the adversary's workload and reduce the likelihood of being able to successfully trigger a security-related failure.\n",
        "languages": []
    },
    {
        "cwe": "1385",
        "name": "Missing Origin Validation in WebSockets",
        "description": "The product uses a WebSocket, but it does not properly verify that the source of data or communication is valid.",
        "detail": "**Extended Description:**\n\n\nWebSockets provide a bi-directional low latency communication (near real-time) between a client and a server. WebSockets are different than HTTP in that the connections are long-lived, as the channel will remain open until the client or the server is ready to send the message, whereas in HTTP, once the response occurs (which typically happens immediately), the transaction completes. \n\n\nA WebSocket can leverage the existing HTTP protocol over ports 80 and 443, but it is not limited to HTTP. WebSockets can make cross-origin requests that are not restricted by browser-based protection mechanisms such as the Same Origin Policy (SOP) or Cross-Origin Resource Sharing (CORS). Without explicit origin validation, this makes CSRF attacks more powerful.\n\n\n**Alternate Terms:** Cross-Site WebSocket hijacking (CSWSH)\n\n**Consequence Note:** The consequences will vary depending on the nature of the functionality that is vulnerable to CSRF. An attacker could effectively perform any operations as the victim. If the victim is an administrator or privileged user, the consequences may include obtaining complete control over the web application - deleting or stealing data, uninstalling the product, or using it to launch other attacks against all of the product's users. Because the attacker has the identity of the victim, the scope of the CSRF is limited only by the victim's privileges.\n",
        "parent": [
            "346"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Enable CORS-like access restrictions by verifying the 'Origin' header during the WebSocket handshake.\n\n**Mitigation:** Use a randomized CSRF token to verify requests.\n\n**Mitigation:** Use TLS to securely communicate using 'wss' (WebSocket Secure) instead of 'ws'.\n\n**Mitigation:** Require user authentication prior to the WebSocket connection being established. For example, the WS library in Node has a 'verifyClient' function.\n\n**Mitigation:** Leverage rate limiting to prevent against DoS. Use of the leaky bucket algorithm can help with this.\n\n**Mitigation:** Use a library that provides restriction of the payload size. For example, WS library for Node includes 'maxPayloadoption' that can be set.\n\n**Mitigation:** Treat data/input as untrusted in both directions and apply the same data/input sanitization as XSS, SQLi, etc.\n",
        "languages": []
    },
    {
        "cwe": "1386",
        "name": "Insecure Operation on Windows Junction / Mount Point",
        "description": "The product opens a file or directory, but it does not properly prevent the name from being associated with a junction or mount point to a destination that is outside of the intended control sphere.",
        "detail": "**Extended Description:**\n\n\nDepending on the intended action being performed, this could allow an attacker to cause the product to read, write, delete, or otherwise operate on unauthorized files.\n\n\nIn Windows, NTFS5 allows for file system objects called reparse points. Applications can create a hard link from one directory to another directory, called a junction point. They can also create a mapping from a directory to a drive letter, called a mount point. If a file is used by a privileged program, but it can be replaced with a hard link to a sensitive file (e.g., AUTOEXEC.BAT), an attacker could excalate privileges. When the process opens the file, the attacker can assume the privileges of that process, tricking the privileged process to read, modify, or delete the sensitive file, preventing the program from accurately processing data. Note that one can also point to registries and semaphores.\n\n\n**Mode of Introduction:** The developer might not consider that when a program in Windows operates with different permissions than the executing user, the use of links, mount points, and junctions might cause the program to access files or directories that are outside of the intended storage location.\n\n**Consequence Note:** Read arbitrary files by replacing a user-controlled folder with a mount point and additional hard links.\n\n**Consequence Note:** Modify an arbitrary file by replacing the rollback files in installer directories, as they can have the installer execute those rollbacks.\n\n**Consequence Note:** Even if there is no control of contents, an arbitrary file delete or overwrite (when running as SYSTEM or admin) can be used for a permanent system denial-of-service, e.g. by deleting a startup configuration file that prevents the service from starting.\n",
        "parent": [
            "59"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** When designing software that will have different rights than the executer, the software should check that files that it is interacting with are not improper hard links or mount points. One way to do this in Windows is to use the functionality embedded in the following command: \"dir /al /s /b\" or, in PowerShell, use LinkType as a filter. In addition, some software uses authentication via signing to ensure that the file is the correct one to use. Make checks atomic with the file action, otherwise a TOCTOU weakness (CWE-367) can be introduced.\n",
        "languages": []
    },
    {
        "cwe": "1389",
        "name": "Incorrect Parsing of Numbers with Different Radices",
        "description": "The product parses numeric input assuming base 10 (decimal) values, but it does not account for inputs that use a different base number (radix).",
        "detail": "**Extended Description:**\n\n\nFrequently, a numeric input that begins with \"0\" is treated as octal, or \"0x\" causes it to be treated as hexadecimal, e.g. by the inet_addr() function. For example, \"023\" (octal) is 35 decimal, or \"0x31\" is 49 decimal. Other bases may be used as well. If the developer assumes decimal-only inputs, the code could produce incorrect numbers when the inputs are parsed using a different base. This can result in unexpected and/or dangerous behavior. For example, a \"0127.0.0.1\" IP address is parsed as octal due to the leading \"0\", whose numeric value would be the same as 87.0.0.1 (decimal), where the developer likely expected to use 127.0.0.1.\n\n\nThe consequences vary depending on the surrounding code in which this weakness occurs, but they can include bypassing network-based access control using unexpected IP addresses or netmasks, or causing apparently-symbolic identifiers to be processed as if they are numbers. In web applications, this can enable bypassing of SSRF restrictions.\n\n\n**Mode of Introduction:** Input validation used may assume decimal bases during conditional checks, when it may not always be the case.\n\n**Mode of Introduction:** The application may rely on a service that supports different numerical bases.\n\n**Consequence Note:** An attacker may use an unexpected numerical base to access private application resources.\n\n**Consequence Note:** An attacker may use an unexpected numerical base to bypass or manipulate access control mechanisms.\n",
        "parent": [
            "704"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** If only decimal-based values are expected in the application, conditional checks should be created in a way that prevent octal or hexadecimal strings from being checked. This can be achieved by converting any numerical string to an explicit base-10 integer prior to the conditional check, to prevent octal or hex values from ever being checked against the condition.\n\n**Mitigation:** If various numerical bases do need to be supported, check for leading values indicating the non-decimal base you wish to support (such as 0x for hex) and convert the numeric strings to integers of the respective base. Reject any other alternative-base string that is not intentionally supported by the application.\n\n**Mitigation:** If regular expressions are used to validate IP addresses, ensure that they are bounded using ^ and $ to prevent base-prepended IP addresses from being matched.\n",
        "languages": []
    },
    {
        "cwe": "1390",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "262",
            "263",
            "289",
            "290",
            "294",
            "301",
            "303",
            "305",
            "307",
            "603",
            "620",
            "640",
            "804"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1391",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1392",
            "521",
            "798"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "1392",
        "name": "Use of Default Credentials",
        "description": "The product uses default credentials (such as passwords or cryptographic keys) for potentially critical functionality.",
        "detail": "**Extended Description:**\nIt is common practice for products to be designed to use default keys, passwords, or other mechanisms for authentication. The rationale is to simplify the manufacturing process or the system administrator's task of installation and deployment into an enterprise. However, if admins do not change the defaults, it is easier for attackers to bypass authentication quickly across multiple organizations.\n",
        "parent": [
            "1391"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Authentication"
        ],
        "mitigation": "**Mitigation:** Prohibit use of default, hard-coded, or other values that do not vary for each installation of the product - especially for separate organizations.\n\n**Mitigation:** Force the administrator to change the credential upon installation.\n\n**Mitigation:** The product administrator could change the defaults upon installation or during operation.\n",
        "languages": []
    },
    {
        "cwe": "1393",
        "name": "Use of Default Password",
        "description": "The product uses default passwords for potentially critical functionality.",
        "detail": "**Extended Description:**\nIt is common practice for products to be designed to use default passwords for authentication. The rationale is to simplify the manufacturing process or the system administrator's task of installation and deployment into an enterprise. However, if admins do not change the defaults, then it makes it easier for attackers to quickly bypass authentication across multiple organizations. There are many lists of default passwords and default-password scanning tools that are easily available from the World Wide Web.\n",
        "parent": [
            "1392"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Authentication"
        ],
        "mitigation": "**Mitigation:** Prohibit use of default, hard-coded, or other values that do not vary for each installation of the product - especially for separate organizations.\n\n**Mitigation:** Ensure that product documentation clearly emphasizes the presence of default passwords and provides steps for the administrator to change them.\n\n**Mitigation:** Force the administrator to change the credential upon installation.\n\n**Mitigation:** The product administrator could change the defaults upon installation or during operation.\n",
        "languages": []
    },
    {
        "cwe": "1394",
        "name": "Use of Default Cryptographic Key",
        "description": "The product uses a default cryptographic key for potentially critical functionality.",
        "detail": "**Extended Description:**\nIt is common practice for products to be designed to use default keys. The rationale is to simplify the manufacturing process or the system administrator's task of installation and deployment into an enterprise. However, if admins do not change the defaults, it is easier for attackers to bypass authentication quickly across multiple organizations.\n",
        "parent": [
            "1392"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Authentication"
        ],
        "mitigation": "**Mitigation:** Prohibit use of default, hard-coded, or other values that do not vary for each installation of the product - especially for separate organizations.\n\n**Mitigation:** Force the administrator to change the credential upon installation.\n\n**Mitigation:** The product administrator could change the defaults upon installation or during operation.\n",
        "languages": []
    },
    {
        "cwe": "1395",
        "name": "Dependency on Vulnerable Third-Party Component",
        "description": "The product has a dependency on a third-party component that contains one or more known vulnerabilities.",
        "detail": "**Extended Description:**\n\n\nMany products are large enough or complex enough that part of their functionality uses libraries, modules, or other intellectual property developed by third parties who are not the product creator. For example, even an entire operating system might be from a third-party supplier in some hardware products. Whether open or closed source, these components may contain publicly known vulnerabilities that could be exploited by adversaries to compromise the product.\n\n\n**Mode of Introduction:** The product architect or designer might choose a component that is already known to contain vulnerabilities or has a high likelihood of containing vulnerabilities in the future.\n\n**Mode of Introduction:** For reasons of compatibility or stability, developers might choose a third-party component, such as a library, that is already known to contain vulnerabilities.\n\n**Mode of Introduction:** Since all products contain vulnerabilities, over time, a third-party component will be discovered to have a vulnerability.\n\n**Consequence Note:** The consequences vary widely, depending on the vulnerabilities that exist in the component; how those vulnerabilities can be \"reached\" by adversaries, as the exploitation paths and attack surface will vary depending on how the component is used; and the criticality of the privilege levels and features for which the product relies on the component.\n",
        "parent": [
            "657"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** For software, use Software Composition Analysis (SCA) tools, which automatically analyze products to identify third-party dependencies. Often, SCA tools can be used to link with known vulnerabilities in the dependencies that they detect. There are commercial and open-source alternatives, such as OWASP Dependency-Check [REF-1312]. Many languages or frameworks have package managers with similar capabilities, such as npm audit for JavaScript, pip-audit for Python, govulncheck for Go, and many others. Dynamic methods can detect loading of third-party components.\n\n**Mitigation:** In some industries such as healthcare [REF-1320] [REF-1322] or technologies such as the cloud [REF-1321], it might be unclear about who is responsible for applying patches for third-party vulnerabilities: the vendor, the operator/customer, or a separate service. Clarifying roles and responsibilities can be important to minimize confusion or unnecessary delay when third-party vulnerabilities are disclosed.\n\n**Mitigation:** Require a Bill of Materials for all components and sub-components of the product. For software, require a Software Bill of Materials (SBOM) [REF-1247] [REF-1311].\n\n**Mitigation:** Maintain a Bill of Materials for all components and sub-components of the product. For software, maintain a Software Bill of Materials (SBOM). According to [REF-1247], \"An SBOM is a formal, machine-readable inventory of software components and dependencies, information about those components, and their hierarchical relationships.\"\n\n**Mitigation:** Actively monitor when a third-party component vendor announces vulnerability patches; fix the third-party component as soon as possible; and make it easy for operators/customers to obtain and apply the patch.\n\n**Mitigation:** Continuously monitor changes in each of the product's components, especially when the changes indicate new vulnerabilities, end-of-life (EOL) plans, etc.\n",
        "languages": []
    },
    {
        "cwe": "14",
        "name": "Compiler Removal of Code to Clear Buffers",
        "description": "Sensitive memory is cleared according to the source code, but compiler optimizations leave the memory untouched when it is not read from again, aka \"dead store removal.\"",
        "detail": "**Extended Description:**\n\n\nThis compiler optimization error occurs when:\n\n\n  1. Secret data are stored in memory.\n\n  1. The secret data are scrubbed from memory by overwriting its contents.\n\n  1. The source code is compiled using an optimizing compiler, which identifies and removes the function that overwrites the contents as a dead store because the memory is not used subsequently.\n\n\n\n**Consequence Note:** This weakness will allow data that has not been cleared from memory to be read. If this data contains sensitive password information, then an attacker can read the password and use the information to bypass protection mechanisms.\n",
        "parent": [
            "733"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** This specific weakness is impossible to detect using black box methods. While an analyst could examine memory to see that it has not been scrubbed, an analysis of the executable would not be successful. This is because the compiler has already removed the relevant code. Only the source code shows whether the programmer intended to clear the memory or not, so this weakness is indistinguishable from others.\n\n**Detection:** This weakness is only detectable using white box methods (see black box detection factor). Careful analysis is required to determine if the code is likely to be removed by the compiler.\n\n**Mitigation:** Store the sensitive data in a \"volatile\" memory location if available.\n\n**Mitigation:** If possible, configure your compiler so that it does not remove dead stores.\n\n**Mitigation:** Where possible, encrypt sensitive data that are used by a software system.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "140",
        "name": "Improper Neutralization of Delimiters",
        "description": "The product does not neutralize or incorrectly neutralizes delimiters.",
        "detail": null,
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "141",
        "name": "Improper Neutralization of Parameter/Argument Delimiters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as parameter or argument delimiters when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.\n",
        "parent": [
            "140"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that parameter/argument delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "1419",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1052",
            "1188"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "142",
        "name": "Improper Neutralization of Value Delimiters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as value delimiters when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.\n",
        "parent": [
            "140"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that value delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "1420",
        "name": "Exposure of Sensitive Information during Transient Execution",
        "description": "A processor event or prediction may allow incorrect operations (or correct operations with incorrect data) to execute transiently, potentially exposing data over a covert channel.",
        "detail": "**Extended Description:**\n\n\nWhen operations execute but do not commit to the processor's architectural state, this is commonly referred to as transient execution. This behavior can occur when the processor mis-predicts an outcome (such as a branch target), or when a processor event (such as an exception or microcode assist, etc.) is handled after younger operations have already executed. Operations that execute transiently may exhibit observable discrepancies (CWE-203) in covert channels [REF-1400] such as data caches. Observable discrepancies of this kind can be detected and analyzed using timing or power analysis techniques, which may allow an attacker to infer information about the operations that executed transiently. For example, the attacker may be able to infer confidential data that was accessed or used by those operations.\n\n\nTransient execution weaknesses may be exploited using one of two methods. In the first method, the attacker generates a code sequence that exposes data through a covert channel when it is executed transiently (the attacker must also be able to trigger transient execution). Some transient execution weaknesses can only expose data that is accessible within the attacker's processor context. For example, an attacker executing code in a software sandbox may be able to use a transient execution weakness to expose data within the same address space, but outside of the attacker's sandbox. Other transient execution weaknesses can expose data that is architecturally inaccessible, that is, data protected by hardware-enforced boundaries such as page tables or privilege rings. These weaknesses are the subject of CWE-1421.\n\n\nIn the second exploitation method, the attacker first identifies a code sequence in a victim program that, when executed transiently, can expose data that is architecturally accessible within the victim's processor context. For instance, the attacker may search the victim program for code sequences that resemble a bounds-check bypass sequence (see Demonstrative Example 1). If the attacker can trigger a mis-prediction of the conditional branch and influence the index of the out-of-bounds array access, then the attacker may be able to infer the value of out-of-bounds data by monitoring observable discrepancies in a covert channel.\n\n\n**Mode of Introduction:** This weakness can be introduced when a computing unit (such as a CPU, GPU, accelerator, or any other processor) uses out-of-order execution, speculation, or any other microarchitectural feature that can allow microarchitectural operations to execute without committing to architectural state.\n\n**Mode of Introduction:** This weakness can be introduced when sandboxes or managed runtimes are not properly isolated by using hardware-enforced boundaries. Developers of sandbox or managed runtime software should exercise caution when relying on software techniques (such as bounds checking) to prevent code in one sandbox from accessing confidential data in another sandbox. For example, an attacker sandbox may be able to trigger a processor event or mis-prediction in a manner that allows it to transiently read a victim sandbox's private data.\n",
        "parent": [
            "669"
        ],
        "children": [
            "1421",
            "1422",
            "1423"
        ],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can be detected in hardware by manually inspecting processor specifications. Features that exhibit this weakness may include microarchitectural predictors, access control checks that occur out-of-order, or any other features that can allow operations to execute without committing to architectural state. Academic researchers have demonstrated that new hardware weaknesses can be discovered by exhaustively analyzing a processor's machine clear (or nuke) conditions ([REF-1427]).\n\n\n**Detection:** \n\nAcademic researchers have demonstrated that this weakness can be detected in hardware using software fuzzing tools that treat the underlying hardware as a black box ([REF-1428]).\n\n\n**Detection:** \n\nAcademic researchers have demonstrated that this weakness can be detected in software using software fuzzing tools ([REF-1429]).\n\n\n**Detection:** \n\nA variety of automated static analysis tools can identify potentially exploitable code sequences in software. These tools may perform the analysis on source code, on binary code, or on an intermediate code representation (for example, during compilation).\n\n\n**Detection:** \n\nSoftware vendors can release tools that detect presence of known weaknesses on a processor. For example, some of these tools can attempt to transiently execute a vulnerable code sequence and detect whether code successfully leaks data in a manner consistent with the weakness under test. Alternatively, some hardware vendors provide enumeration for the presence of a weakness (or lack of a weakness). These enumeration bits can be checked and reported by system software. For example, Linux supports these checks for many commodity processors:\n\n\n$ cat /proc/cpuinfo | grep bugs | head -n 1\n\n\nbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit srbds mmio_stale_data retbleed\n\n\n**Mitigation:** The hardware designer can attempt to prevent transient execution from causing observable discrepancies in specific covert channels.\n\n**Effectiveness:** \n\nThis technique has many pitfalls. For example, InvisiSpec was an early attempt to mitigate this weakness by blocking \"micro-architectural covert and side channels through the multiprocessor data cache hierarchy due to speculative loads\" [REF-1417]. Commodity processors and SoCs have many covert and side channels that exist outside of the data cache hierarchy. Even when some of these channels are blocked, others (such as execution ports [REF-1418]) may allow an attacker to infer confidential data. Mitigation strategies that attempt to prevent transient execution from causing observable discrepancies also have other pitfalls, for example, see [REF-1419].\n\n\n**Mitigation:** \n\nProcessor designers may expose instructions or other architectural features that allow software to mitigate the effects of transient execution, but without disabling predictors. These features may also help to limit opportunities for data exposure.\n\n\n**Effectiveness:** \n\nInstructions or features that constrain transient execution or suppress its side effects may impact performance.\n\n\n**Mitigation:** \n\nProcessor designers may expose registers (for example, control registers or model-specific registers) that allow privileged and/or user software to disable specific predictors or other hardware features that can cause confidential data to be exposed during transient execution.\n\n\n**Effectiveness:** \n\nDisabling specific predictors or other hardware features may result in significant performance overhead.\n\n\n**Mitigation:** \n\nProcessor designers, system software vendors, or other agents may choose to restrict the ability of unprivileged software to access to high-resolution timers that are commonly used to monitor covert channels.\n\n\n**Effectiveness:** \n\nSpecific software algorithms can be used by an attacker to compensate for a lack of a high-resolution time source [REF-1420].\n\n\n**Mitigation:** \n\nIsolate sandboxes or managed runtimes in separate address spaces (separate processes). For examples, see [REF-1421].\n\n\n**Mitigation:** \n\nInclude serialization instructions (for example, LFENCE) that prevent processor events or mis-predictions prior to the serialization instruction from causing transient execution after the serialization instruction. For some weaknesses, a serialization instruction can also prevent a processor event or a mis-prediction from occurring after the serialization instruction (for example, CVE-2018-3639 can allow a processor to predict that a load will not depend on an older store; a serialization instruction between the store and the load may allow the store to update memory and prevent the prediction from happening at all).\n\n\n**Effectiveness:** \n\nWhen used to comprehensively mitigate a transient execution weakness (for example, by inserting an LFENCE after every instruction in a program), serialization instructions can introduce significant performance overhead. On the other hand, when used to mitigate only a relatively small number of high-risk code sequences, serialization instructions may have a low or negligible impact on performance.\n\n\n**Mitigation:** \n\nUse control-flow integrity (CFI) techniques to constrain the behavior of instructions that redirect the instruction pointer, such as indirect branch instructions.\n\n\n**Effectiveness:** \n\nSome CFI techniques may not be able to constrain transient execution, even though they are effective at constraining architectural execution. Or they may be able to provide some additional protection against a transient execution weakness, but without comprehensively mitigating the weakness. For example, Clang-CFI provides strong architectural CFI properties and can make some transient execution weaknesses more difficult to exploit [REF-1398].\n\n\n**Mitigation:** \n\nIf the weakness is exposed by a single instruction (or a small set of instructions), then the compiler (or JIT, etc.) can be configured to prevent the affected instruction(s) from being generated, and instead generate an alternate sequence of instructions that is not affected by the weakness. One prominent example of this mitigation is retpoline ([REF-1414]).\n\n\n**Effectiveness:** \n\nThis technique may only be effective for software that is compiled with this mitigation. For some transient execution weaknesses, this technique may not be sufficient to protect software that is compiled without the affected instruction(s). For example, see CWE-1421.\n\n\n**Mitigation:** \n\nUse software techniques that can mitigate the consequences of transient execution. For example, address masking can be used in some circumstances to prevent out-of-bounds transient reads.\n\n\n**Effectiveness:** \n\nAddress masking and related software mitigation techniques have been used to harden specific code sequences that could potentially be exploited via transient execution. For example, the Linux kernel makes limited use of manually inserted address masks to mitigate bounds-check bypass [REF-1390]. Compiler-based techniques have also been used to automatically harden software [REF-1425].\n\n\n**Mitigation:** \n\nUse software techniques (including the use of serialization instructions) that are intended to reduce the number of instructions that can be executed transiently after a processor event or misprediction.\n\n\n**Effectiveness:** \n\nSome transient execution weaknesses can be exploited even if a single instruction is executed transiently after a processor event or mis-prediction. This mitigation strategy has many other pitfalls that prevent it from eliminating this weakness entirely. For example, see [REF-1389].\n\n\n**Mitigation:** \n\nIf a hardware feature can allow incorrect operations (or correct operations with incorrect data) to execute transiently, the hardware designer may opt to disclose this behavior in architecture documentation. This documentation can inform users about potential consequences and effective mitigations.\n\n",
        "languages": []
    },
    {
        "cwe": "1421",
        "name": "Exposure of Sensitive Information in Shared Microarchitectural Structures during Transient Execution",
        "description": "\n\t\t\tA processor event may allow transient operations to access\n\t\t\tarchitecturally restricted data (for example, in another address\n\t\t\tspace) in a shared microarchitectural structure (for example, a CPU\n\t\t\tcache), potentially exposing the data over a covert channel.\n\t\t  ",
        "detail": "**Extended Description:**\n\n\nMany commodity processors have Instruction Set Architecture (ISA) features that protect software components from one another. These features can include memory segmentation, virtual memory, privilege rings, trusted execution environments, and virtual machines, among others. For example, virtual memory provides each process with its own address space, which prevents processes from accessing each other's private data. Many of these features can be used to form hardware-enforced security boundaries between software components.\n\n\nMany commodity processors also share microarchitectural resources that cache (temporarily store) data, which may be confidential. These resources may be shared across processor contexts, including across SMT threads, privilege rings, or others.\n\n\nWhen transient operations allow access to ISA-protected data in a shared microarchitectural resource, this might violate users' expectations of the ISA feature that is bypassed. For example, if transient operations can access a victim's private data in a shared microarchitectural resource, then the operations' microarchitectural side effects may correspond to the accessed data. If an attacker can trigger these transient operations and observe their side effects through a covert channel [REF-1400], then the attacker may be able to infer the victim's private data. Private data could include sensitive program data, OS/VMM data, page table data (such as memory addresses), system configuration data (see Demonstrative Example 3), or any other data that the attacker does not have the required privileges to access.\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced during hardware architecture and design if a data path allows architecturally restricted data to propagate to operations that execute before an older mis-prediction or processor event (such as an exception) is caught.\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced during system software implementation if state-sanitizing operations are not invoked when switching from one context to another, according to the hardware vendor's recommendations for mitigating the weakness.\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced if the system has not been configured according to the hardware vendor's recommendations for mitigating the weakness.\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced when an access control check (for example, checking page permissions) can proceed in parallel with the access operation (for example, a load) that is being checked. If the processor can allow the access operation to execute before the check completes, this race condition may allow subsequent transient operations to expose sensitive information.\n\n\n**Consequence Note:** \n\n<<put the information here>>\n\n",
        "parent": [
            "1420"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can be detected in hardware by manually inspecting processor specifications. Features that exhibit this weakness may include microarchitectural predictors, access control checks that occur out-of-order, or any other features that can allow operations to execute without committing to architectural state. Academic researchers have demonstrated that new hardware weaknesses can be discovered by examining publicly available patent filings, for example [REF-1405] and [REF-1406]. Hardware designers can also scrutinize aspects of the instruction set architecture that have undefined behavior; these can become a focal point when applying other detection methods. \n\n\n**Detection:** \n\nThis weakness can be detected (pre-discovery) in hardware by employing static or dynamic taint analysis methods [REF-1401]. These methods can label data in one context (for example, kernel data) and perform information flow analysis (or a simulation, etc.) to determine whether tainted data can appear in another context (for example, user mode). Alternatively, stale or invalid data in shared microarchitectural resources can be marked as tainted, and the taint analysis framework can identify when transient operations encounter tainted data.\n\n\n**Detection:** \n\nSoftware vendors can release tools that detect presence of known weaknesses (post-discovery) on a processor. For example, some of these tools can attempt to transiently execute a vulnerable code sequence and detect whether code successfully leaks data in a manner consistent with the weakness under test. Alternatively, some hardware vendors provide enumeration for the presence of a weakness (or lack of a weakness). These enumeration bits can be checked and reported by system software. For example, Linux supports these checks for many commodity processors:\n\n\n$ cat /proc/cpuinfo | grep bugs | head -n 1\n\n\nbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit srbds mmio_stale_data retbleed\n\n\n**Detection:** Academic researchers have demonstrated that this weakness can be detected in hardware using software fuzzing tools that treat the underlying hardware as a black box ([REF-1406], [REF-1430])\n\n**Mitigation:** \n\nHardware designers may choose to engineer the processor's pipeline to prevent architecturally restricted data from being used by operations that can execute transiently.\n\n\n**Mitigation:** \n\nHardware designers may choose not to share microarchitectural resources that can contain sensitive data, such as fill buffers and store buffers.\n\n\n**Effectiveness:** \n\nThis can be highly effective at preventing this weakness from being exposed across different SMT threads or different processor cores. It is generally less practical to isolate these resources between different contexts (for example, user and kernel) that may execute on the same SMT thread or processor core.\n\n\n**Mitigation:** \n\nHardware designers may choose to sanitize specific microarchitectural state (for example, store buffers) when the processor transitions to a different context, such as whenever a system call is invoked. Alternatively, the hardware may expose instruction(s) that allow software to sanitize microarchitectural state according to the user or system administrator's threat model. These mitigation approaches are similar to those that address CWE-226; however, sanitizing microarchitectural state may not be the optimal or best way to mitigate this weakness on every processor design.\n\n\n**Effectiveness:** \n\nSanitizing shared state on context transitions may not be practical for all processors, especially when the amount of shared state affected by the weakness is relatively large. Additionally, this technique may not be practical unless there is a synchronous transition between two processor contexts that would allow the affected resource to be sanitized. For example, this technique alone may not suffice to mitigate asynchronous access to a resource that is shared by two SMT threads.\n\n\n**Mitigation:** \n\nThe hardware designer can attempt to prevent transient execution from causing observable discrepancies in specific covert channels.\n\n\n**Effectiveness:** \n\nThis technique has many pitfalls. For example, InvisiSpec was an early attempt to mitigate this weakness by blocking \"micro-architectural covert and side channels through the multiprocessor data cache hierarchy due to speculative loads\" [REF-1417]. Commodity processors and SoCs have many covert and side channels that exist outside of the data cache hierarchy. Even when some of these channels are blocked, others (such as execution ports [REF-1418]) may allow an attacker to infer confidential data. Mitigation strategies that attempt to prevent transient execution from causing observable discrepancies also have other pitfalls, for example, see [REF-1419].\n\n\n**Mitigation:** \n\nSoftware architects may design software to enforce strong isolation between different contexts. For example, kernel page table isolation (KPTI) mitigates the Meltdown vulnerability [REF-1401] by separating user-mode page tables from kernel-mode page tables, which prevents user-mode processes from using Meltdown to transiently access kernel memory [REF-1404].\n\n\n**Effectiveness:** \n\nIsolating different contexts across a process boundary (or another kind of architectural boundary) may only be effective for some weaknesses.\n\n\n**Mitigation:** \n\nIf the weakness is exposed by a single instruction (or a small set of instructions), then the compiler (or JIT, etc.) can be configured to prevent the affected instruction(s) from being generated, and instead generate an alternate sequence of instructions that is not affected by the weakness.\n\n\n**Effectiveness:** \n\nThis technique may only be fully effective if it is applied to all software that runs on the system. Also, relatively few observed examples of this weakness have exposed data through only a single instruction.\n\n\n**Mitigation:** \n\nUse software techniques (including the use of serialization instructions) that are intended to reduce the number of instructions that can be executed transiently after a processor event or misprediction.\n\n\n**Effectiveness:** \n\nSome transient execution weaknesses can be exploited even if a single instruction is executed transiently after a processor event or mis-prediction. This mitigation strategy has many other pitfalls that prevent it from eliminating this weakness entirely. For example, see [REF-1389].\n\n\n**Mitigation:** \n\nSystem software can mitigate this weakness by invoking state-sanitizing operations when switching from one context to another, according to the hardware vendor's recommendations.\n\n\n**Effectiveness:** \n\nThis technique may not be able to mitigate weaknesses that arise from resource sharing across SMT threads.\n\n\n**Mitigation:** \n\nSome systems may allow the user to disable (for example, in the BIOS) sharing of the affected resource.\n\n\n**Effectiveness:** \n\nDisabling resource sharing (for example, by disabling SMT) may result in significant performance overhead.\n\n\n**Mitigation:** \n\nSome systems may allow the user to disable (for example, in the BIOS) microarchitectural features that allow transient access to architecturally restricted data.\n\n\n**Effectiveness:** \n\nDisabling microarchitectural features such as predictors may result in significant performance overhead.\n\n\n**Mitigation:** \n\nThe hardware vendor may provide a patch to sanitize the affected shared microarchitectural state when the processor transitions to a different context.\n\n\n**Effectiveness:** \n\nThis technique may not be able to mitigate weaknesses that arise from resource sharing across SMT threads.\n\n\n**Mitigation:** \n\nThis kind of patch may not be feasible or implementable for all processors or all weaknesses.\n\n\n**Mitigation:** \n\nProcessor designers, system software vendors, or other agents may choose to restrict the ability of unprivileged software to access to high-resolution timers that are commonly used to monitor covert channels.\n\n\n**Effectiveness:** \n\nSpecific software algorithms can be used by an attacker to compensate for a lack of a high-resolution time source [REF-1420].\n\n",
        "languages": []
    },
    {
        "cwe": "1422",
        "name": "Exposure of Sensitive Information caused by Incorrect Data Forwarding during Transient Execution",
        "description": "A processor event or prediction may allow incorrect or stale data to\n\t\t  be forwarded to transient operations, potentially exposing data over a\n\t\t  covert channel.",
        "detail": "**Extended Description:**\n\n\nSoftware may use a variety of techniques to preserve the confidentiality of private data that is accessible within the current processor context. For example, the memory safety and type safety properties of some high-level programming languages help to prevent software written in those languages from exposing private data. As a second example, software sandboxes may co-locate multiple users' software within a single process. The processor's Instruction Set Architecture (ISA) may permit one user's software to access another user's data (because the software shares the same address space), but the sandbox prevents these accesses by using software techniques such as bounds checking.\n\n\nIf incorrect or stale data can be forwarded (for example, from a cache) to transient operations, then the operations' microarchitectural side effects may correspond to the data. If an attacker can trigger these transient operations and observe their side effects through a covert channel, then the attacker may be able to infer the data. For example, an attacker process may induce transient execution in a victim process that causes the victim to inadvertently access and then expose its private data via a covert channel. In the software sandbox example, an attacker sandbox may induce transient execution in its own code, allowing it to transiently access and expose data in a victim sandbox that shares the same address space.\n\n\nConsequently, weaknesses that arise from incorrect/stale data forwarding might violate users' expectations of software-based memory safety and isolation techniques. If the data forwarding behavior is not properly documented by the hardware vendor, this might violate the software vendor's expectation of how the hardware should behave.\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced by data speculation techniques, or when the processor pipeline is designed to check exception conditions concurrently with other operations. This weakness can also persist after a CWE-1421 weakness has been mitigated. For example, suppose that a processor can forward stale data from a shared microarchitectural buffer to dependent transient operations, and furthermore suppose that the processor has been patched to flush the buffer on context switches. This mitigates the CWE-1421 weakness, but the stale-data forwarding behavior may persist as a CWE-1422 weakness unless this behavior is also patched.\n\n",
        "parent": [
            "1420"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** \n\nA variety of automated static analysis tools can identify potentially exploitable code sequences in software. These tools may perform the analysis on source code, on binary code, or on an intermediate code representation (for example, during compilation).\n\n\n**Detection:** \n\nThis weakness can be detected in hardware by manually inspecting processor specifications. Features that exhibit this weakness may include microarchitectural predictors, access control checks that occur out-of-order, or any other features that can allow operations to execute without committing to architectural state.Hardware designers can also scrutinize aspects of the instruction set architecture that have undefined behavior; these can become a focal point when applying other detection methods. \n\n\n**Detection:** \n\nSoftware vendors can release tools that detect presence of known weaknesses on a processor. For example, some of these tools can attempt to transiently execute a vulnerable code sequence and detect whether code successfully leaks data in a manner consistent with the weakness under test. Alternatively, some hardware vendors provide enumeration for the presence of a weakness (or lack of a weakness). These enumeration bits can be checked and reported by system software. For example, Linux supports these checks for many commodity processors:\n\n\n$ cat /proc/cpuinfo | grep bugs | head -n 1\n\n\nbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit srbds mmio_stale_data retbleed\n\n\n**Mitigation:** \n\nThe hardware designer can attempt to prevent transient execution from causing observable discrepancies in specific covert channels.\n\n\n**Effectiveness:** Instructions or features that constrain transient execution or suppress its side effects may impact performance.\n\n**Mitigation:** \n\nProcessor designers, system software vendors, or other agents may choose to restrict the ability of unprivileged software to access to high-resolution timers that are commonly used to monitor covert channels.\n\n\n**Effectiveness:** Disabling specific predictors or other hardware features may result in significant performance overhead.\n\n**Mitigation:** \n\nProcessor designers may expose instructions or other architectural features that allow software to mitigate the effects of transient execution, but without disabling predictors. These features may also help to limit opportunities for data exposure.\n\n\n**Effectiveness:** \n\nInstructions or features that constrain transient execution or suppress its side effects may impact performance.\n\n\n**Mitigation:** \n\nProcessor designers may expose registers (for example, control registers or model-specific registers) that allow privileged and/or user software to disable specific predictors or other hardware features that can cause confidential data to be exposed during transient execution.\n\n\n**Effectiveness:** \n\nDisabling specific predictors or other hardware features may result in significant performance overhead.\n\n\n**Mitigation:** \n\nUse software techniques (including the use of serialization instructions) that are intended to reduce the number of instructions that can be executed transiently after a processor event or misprediction.\n\n\n**Effectiveness:** \n\nSome transient execution weaknesses can be exploited even if a single instruction is executed transiently after a processor event or mis-prediction. This mitigation strategy has many other pitfalls that prevent it from eliminating this weakness entirely. For example, see [REF-1389].\n\n\n**Mitigation:** \n\nIsolate sandboxes or managed runtimes in separate address spaces (separate processes).\n\n\n**Effectiveness:** \n\nProcess isolation is also an effective strategy to mitigate many other kinds of weaknesses.\n\n\n**Mitigation:** \n\nInclude serialization instructions (for example, LFENCE) that prevent processor events or mis-predictions prior to the serialization instruction from causing transient execution after the serialization instruction. For some weaknesses, a serialization instruction can also prevent a processor event or a mis-prediction from occurring after the serialization instruction (for example, CVE-2018-3639 can allow a processor to predict that a load will not depend on an older store; a serialization instruction between the store and the load may allow the store to update memory and prevent the mis-prediction from happening at all).\n\n\n**Effectiveness:** \n\nWhen used to comprehensively mitigate a transient execution weakness, serialization instructions can introduce significant performance overhead.\n\n\n**Mitigation:** \n\nUse software techniques that can mitigate the consequences of transient execution. For example, address masking can be used in some circumstances to prevent out-of-bounds transient reads.\n\n\n**Effectiveness:** \n\nAddress masking and related software mitigation techniques have been used to harden specific code sequences that could potentially be exploited via transient execution. For example, the Linux kernel makes limited use of this technique to mitigate bounds-check bypass [REF-1390].\n\n\n**Mitigation:** \n\nIf the weakness is exposed by a single instruction (or a small set of instructions), then the compiler (or JIT, etc.) can be configured to prevent the affected instruction(s) from being generated, and instead generate an alternate sequence of instructions that is not affected by the weakness.\n\n\n**Effectiveness:** \n\nThis technique is only effective for software that is compiled with this mitigation.\n\n\n**Mitigation:** \n\nIf a hardware feature can allow incorrect or stale data to be forwarded to transient operations, the hardware designer may opt to disclose this behavior in architecture documentation. This documentation can inform users about potential consequences and effective mitigations.\n\n",
        "languages": []
    },
    {
        "cwe": "1423",
        "name": "Exposure of Sensitive Information caused by Shared Microarchitectural Predictor State that Influences Transient Execution",
        "description": "Shared microarchitectural predictor state may allow code to influence\n\t\t\t\ttransient execution across a hardware boundary, potentially exposing\n\t\t\t\tdata that is accessible beyond the boundary over a covert channel.\n\t\t\t",
        "detail": "**Extended Description:**\n\n\nMany commodity processors have Instruction Set Architecture (ISA) features that protect software components from one another. These features can include memory segmentation, virtual memory, privilege rings, trusted execution environments, and virtual machines, among others. For example, virtual memory provides each process with its own address space, which prevents processes from accessing each other's private data. Many of these features can be used to form hardware-enforced security boundaries between software components.\n\n\nWhen separate software components (for example, two processes) share microarchitectural predictor state across a hardware boundary, code in one component may be able to influence microarchitectural predictor behavior in another component. If the predictor can cause transient execution, the shared predictor state may allow an attacker to influence transient execution in a victim, and in a manner that could allow the attacker to infer private data from the victim by monitoring observable discrepancies (CWE-203) in a covert channel [REF-1400].\n\n\nPredictor state may be shared when the processor transitions from one component to another (for example, when a process makes a system call to enter the kernel). Many commodity processors have features which prevent microarchitectural predictions that occur before a boundary from influencing predictions that occur after the boundary.\n\n\nPredictor state may also be shared between hardware threads, for example, sibling hardware threads on a processor that supports simultaneous multithreading (SMT). This sharing may be benign if the hardware threads are simultaneously executing in the same software component, or it could expose a weakness if one sibling is a malicious software component, and the other sibling is a victim software component. Processors that share microarchitectural predictors between hardware threads may have features which prevent microarchitectural predictions that occur on one hardware thread from influencing predictions that occur on another hardware thread.\n\n\nFeatures that restrict predictor state sharing across transitions or between hardware threads may be always-on, on by default, or may require opt-in from software.\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced during hardware architecture and design if predictor state is not properly isolated between modes (for example, user mode and kernel mode), if predictor state is not isolated between hardware threads, or if it is not isolated between other kinds of execution contexts supported by the processor.\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced during system software implementation if predictor-state-sanitizing operations (for example, the indirect branch prediction barrier on Intel x86) are not invoked when switching from one context to another.\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced if the system has not been configured according to the hardware vendor's recommendations for mitigating the weakness.\n\n",
        "parent": [
            "1420"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can be detected in hardware by manually inspecting processor specifications. Features that exhibit this weakness may have microarchitectural predictor state that is shared between hardware threads, execution contexts (for example, user and kernel), or other components that may host mutually distrusting software (or firmware, etc.).\n\n\n**Detection:** \n\nSoftware vendors can release tools that detect presence of known weaknesses on a processor. For example, some of these tools can attempt to transiently execute a vulnerable code sequence and detect whether code successfully leaks data in a manner consistent with the weakness under test. Alternatively, some hardware vendors provide enumeration for the presence of a weakness (or lack of a weakness). These enumeration bits can be checked and reported by system software. For example, Linux supports these checks for many commodity processors:\n\n\n$ cat /proc/cpuinfo | grep bugs | head -n 1\n\n\nbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit srbds mmio_stale_data retbleed\n\n\n**Detection:** \n\nThis weakness can be detected in hardware by employing static or dynamic taint analysis methods [REF-1401]. These methods can label each predictor entry (or prediction history, etc.) according to the processor context that created it. Taint analysis or information flow analysis can then be applied to detect when predictor state created in one context can influence predictions made in another context.\n\n\n**Mitigation:** \n\nThe hardware designer can attempt to prevent transient execution from causing observable discrepancies in specific covert channels.\n\n\n**Mitigation:** \n\nHardware designers may choose to use microarchitectural bits to tag predictor entries. For example, each predictor entry may be tagged with a kernel-mode bit which, when set, indicates that the predictor entry was created in kernel mode. The processor can use this bit to enforce that predictions in the current mode must have been trained in the current mode. This can prevent malicious cross-mode training, such as when user-mode software attempts to create predictor entries that influence transient execution in the kernel. Predictor entry tags can also be used to associate each predictor entry with the SMT thread that created it, and thus the processor can enforce that each predictor entry can only be used by the SMT thread that created it. This can prevent an SMT thread from using predictor entries crafted by a malicious sibling SMT thread.\n\n\n**Effectiveness:** \n\nTagging can be highly effective for predictor state that is comprised of discrete elements, such as an array of recently visited branch targets. Predictor state can also have different representations that are not conducive to tagging. For example, some processors keep a compressed digest of branch history which does not contain discrete elements that can be individually tagged.\n\n\n**Mitigation:** \n\nHardware designers may choose to sanitize microarchitectural predictor state (for example, branch prediction history) when the processor transitions to a different context, for example, whenever a system call is invoked. Alternatively, the hardware may expose instruction(s) that allow software to sanitize predictor state according to the user's threat model. For example, this can allow operating system software to sanitize predictor state when performing a context switch from one process to another.\n\n\n**Effectiveness:** \n\nThis technique may not be able to mitigate weaknesses that arise from predictor state that is shared across SMT threads. Sanitizing predictor state on context switches may also negatively impact performance, either by removing predictor entries that could be reused when returning to the previous context, or by slowing down the context switch itself.\n\n\n**Mitigation:** \n\nSystem software can mitigate this weakness by invoking predictor-state-sanitizing operations (for example, the indirect branch prediction barrier on Intel x86) when switching from one context to another, according to the hardware vendor's recommendations.\n\n\n**Effectiveness:** \n\nThis technique may not be able to mitigate weaknesses that arise from predictor state shared across SMT threads. Sanitizing predictor state may also negatively impact performance in some circumstances.\n\n\n**Mitigation:** \n\nIf the weakness is exposed by a single instruction (or a small set of instructions), then the compiler (or JIT, etc.) can be configured to prevent the affected instruction(s) from being generated. One prominent example of this mitigation is retpoline ([REF-1414]).\n\n\n**Effectiveness:** \n\nThis technique is only effective for software that is compiled with this mitigation. Additionally, an alternate instruction sequence may mitigate the weakness on some processors but not others, even when the processors share the same ISA. For example, retpoline has been documented as effective on some x86 processors, but not fully effective on other x86 processors.\n\n\n**Mitigation:** \n\nUse control-flow integrity (CFI) techniques to constrain the behavior of instructions that redirect the instruction pointer, such as indirect branch instructions.\n\n\n**Effectiveness:** \n\nSome CFI techniques may not be able to constrain transient execution, even though they are effective at constraining architectural execution. Or they may be able to provide some additional protection against a transient execution weakness, but without comprehensively mitigating the weakness. For example, Clang-CFI provides strong architectural CFI properties and can make some transient execution weaknesses more difficult to exploit [REF-1398].\n\n\n**Mitigation:** \n\nUse software techniques (including the use of serialization instructions) that are intended to reduce the number of instructions that can be executed transiently after a processor event or misprediction.\n\n\n**Effectiveness:** \n\nSome transient execution weaknesses can be exploited even if a single instruction is executed transiently after a processor event or mis-prediction. This mitigation strategy has many other pitfalls that prevent it from eliminating this weakness entirely. For example, see [REF-1389].\n\n\n**Mitigation:** \n\nSome systems may allow the user to disable predictor sharing. For example, this could be a BIOS configuration, or a model-specific register (MSR) that can be configured by the operating system or virtual machine monitor.\n\n\n**Effectiveness:** \n\nDisabling predictor sharing can negatively impact performance for some workloads that benefit from shared predictor state.\n\n\n**Mitigation:** \n\nThe hardware vendor may provide a patch to, for example, sanitize predictor state when the processor transitions to a different context, or to prevent predictor entries from being shared across SMT threads. A patch may also introduce new ISA that allows software to toggle a mitigation.\n\n\n**Effectiveness:** \n\nThis mitigation may only be fully effective if the patch prevents predictor sharing across all contexts that are affected by the weakness. Additionally, sanitizing predictor state and/or preventing shared predictor state can negatively impact performance in some circumstances.\n\n\n**Mitigation:** \n\nIf a hardware feature can allow microarchitectural predictor state to be shared between contexts, SMT threads, or other architecturally defined boundaries, the hardware designer may opt to disclose this behavior in architecture documentation. This documentation can inform users about potential consequences and effective mitigations.\n\n\n**Mitigation:** \n\nProcessor designers, system software vendors, or other agents may choose to restrict the ability of unprivileged software to access to high-resolution timers that are commonly used to monitor covert channels.\n\n",
        "languages": []
    },
    {
        "cwe": "1426",
        "name": "Improper Validation of Generative AI Output",
        "description": "The product invokes a generative AI/ML\n\t\t\tcomponent whose behaviors and outputs cannot be directly\n\t\t\tcontrolled, but the product does not validate or\n\t\t\tinsufficiently validates the outputs to ensure that they\n\t\t\talign with the intended security, content, or privacy\n\t\t\tpolicy.",
        "detail": "**Mode of Introduction:** \n\nDevelopers may rely heavily on protection mechanisms such as input filtering and model alignment, assuming they are more effective than they actually are.\n\n\n**Mode of Introduction:** \n\nDevelopers may rely heavily on protection mechanisms such as input filtering and model alignment, assuming they are more effective than they actually are.\n\n\n**Consequence Note:** \n\nIn an agent-oriented setting, output could be used to cause unpredictable agent invocation, i.e., to control or influence agents that might be invoked from the output. The impact varies depending on the access that is granted to the tools, such as creating a database or writing files.\n\n",
        "parent": [
            "707"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Use known techniques for prompt injection and other attacks, and adjust the attacks to be more specific to the model or system.\n\n**Detection:** Use known techniques for prompt injection and other attacks, and adjust the attacks to be more specific to the model or system.\n\n**Detection:** Review of the product design can be effective, but it works best in conjunction with dynamic analysis.\n\n**Mitigation:** Since the output from a generative AI component (such as an LLM) cannot be trusted, ensure that it operates in an untrusted or non-privileged space.\n\n**Mitigation:** Use \"semantic comparators,\" which are mechanisms that provide semantic comparison to identify objects that might appear different but are semantically similar.\n\n**Mitigation:** \n\nUse components that operate externally to the system to monitor the output and act as a moderator. These components are called different terms, such as supervisors or guardrails.\n\n\n**Mitigation:** \n\nDuring model training, use an appropriate variety of good and bad examples to guide preferred outputs.\n\n",
        "languages": []
    },
    {
        "cwe": "1427",
        "name": "Improper Neutralization of Input Used for LLM Prompting",
        "description": "The product uses externally-provided data to build prompts provided to\nlarge language models (LLMs), but the way these prompts are constructed\ncauses the LLM to fail to distinguish between user-supplied inputs and\ndeveloper provided system directives.",
        "detail": "**Extended Description:**\n\n\n When prompts are constructed using externally controllable data, it is often possible to cause an LLM to ignore the original guidance provided by its creators (known as the \"system prompt\") by inserting malicious instructions in plain human language or using bypasses such as special characters or tags. Because LLMs are designed to treat all instructions as legitimate, there is often no way for the model to differentiate between what prompt language is malicious when it performs inference and returns data. Many LLM systems incorporate data from other adjacent products or external data sources like Wikipedia using API calls and retrieval augmented generation (RAG). Any external sources in use that may contain untrusted data should also be considered potentially malicious. \n\n\n**Alternate Terms:** prompt injection\n\n**Mode of Introduction:** \n\nLLM-connected applications that do not distinguish between trusted and untrusted input may introduce this weakness. If such systems are designed in a way where trusted and untrusted instructions are provided to the model for inference without differentiation, they may be susceptible to prompt injection and similar attacks.\n\n\n**Mode of Introduction:** \n\nWhen designing the application, input validation should be applied to user input used to construct LLM system prompts. Input validation should focus on mitigating well-known software security risks (in the event the LLM is given agency to use tools or perform API calls) as well as preventing LLM-specific syntax from being included (such as markup tags or similar).\n\n\n**Mode of Introduction:** \n\nThis weakness could be introduced if training does not account for potentially malicious inputs.\n\n\n**Mode of Introduction:** \n\nConfiguration could enable model parameters to be manipulated when this was not intended.\n\n\n**Mode of Introduction:** \n\nThis weakness can occur when integrating the model into the software.\n\n\n**Mode of Introduction:** \n\nThis weakness can occur when bundling the model with the software.\n\n\n**Consequence Note:** \n\nThe consequences are entirely contextual, depending on the system that the model is integrated into. For example, the consequence could include output that would not have been desired by the model designer, such as using racial slurs. On the other hand, if the output is attached to a code interpreter, remote code execution (RCE) could result.\n\n\n**Consequence Note:** \n\nAn attacker might be able to extract sensitive information from the model.\n\n\n**Consequence Note:** \n\nThe extent to which integrity can be impacted is dependent on the LLM application use case.\n\n\n**Consequence Note:** \n\nThe extent to which access control can be impacted is dependent on the LLM application use case.\n\n",
        "parent": [
            "77"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nUse known techniques for prompt injection and other attacks, and adjust the attacks to be more specific to the model or system.\n\n\n**Detection:** \n\nUse known techniques for prompt injection and other attacks, and adjust the attacks to be more specific to the model or system.\n\n\n**Detection:** \n\nReview of the product design can be effective, but it works best in conjunction with dynamic analysis.\n\n\n**Mitigation:** \n\nLLM-enabled applications should be designed to ensure proper sanitization of user-controllable input, ensuring that no intentionally misleading or dangerous characters can be included. Additionally, they should be designed in a way that ensures that user-controllable input is identified as untrusted and potentially dangerous.\n\n\n**Mitigation:** \n\nLLM prompts should be constructed in a way that effectively differentiates between user-supplied input and developer-constructed system prompting to reduce the chance of model confusion at inference-time.\n\n\n**Mitigation:** \n\nLLM-enabled applications should be designed to ensure proper sanitization of user-controllable input, ensuring that no intentionally misleading or dangerous characters can be included. Additionally, they should be designed in a way that ensures that user-controllable input is identified as untrusted and potentially dangerous.\n\n\n**Mitigation:** \n\nEnsure that model training includes training examples that avoid leaking secrets and disregard malicious inputs. Train the model to recognize secrets, and label training data appropriately. Note that due to the non-deterministic nature of prompting LLMs, it is necessary to perform testing of the same test case several times in order to ensure that troublesome behavior is not possible. Additionally, testing should be performed each time a new model is used or a model's weights are updated.\n\n\n**Mitigation:** \n\nDuring deployment/operation, use components that operate externally to the system to monitor the output and act as a moderator. These components are called different terms, such as supervisors or guardrails.\n\n\n**Mitigation:** \n\nDuring system configuration, the model could be fine-tuned to better control and neutralize potentially dangerous inputs.\n\n",
        "languages": []
    },
    {
        "cwe": "1428",
        "name": "Reliance on HTTP instead of HTTPS",
        "description": "The product provides or relies on use of HTTP communications when HTTPS is available.",
        "detail": "**Extended Description:**\n\n\nBecause HTTP communications are not encrypted, HTTP is subject to various attacks against confidentiality, integrity, and authenticity. However, unlike many other protocols, HTTPS is widely available as a more secure alternative, because it uses encryption.\n\n\n**Mode of Introduction:** The product might be designed in a way that assumes that HTTP will be used, e.g., by excluding considerations of encrypted communications between client and server.\n\n**Mode of Introduction:** Product requirements might not include encrypted communications, which could make it easier for designers and developers to choose HTTP.\n\n**Mode of Introduction:** Developers might choose to use unencrypted protocols such as HTTP because they would not require development of additional mechanisms to support encryption, e.g., key or certificate management.\n\n**Mode of Introduction:** When generating content that references web sites such as email messages, ensure that the https:// prefix is included. If a domain name is presented without such a prefix, then clients might automatically treat the link as if it had an \"http\" prefix. For example, referencing a domain like \"mysite.example.com\" could cause it to be treated like \"http://mysite.example.com\", thereby sending unencrypted HTTP requests.\n\n**Mode of Introduction:** Designers might assume that the responsibility for encrypted communications might belong to operators and/or network administrators.\n\n**Consequence Note:** HTTP can be subjected to attacks against confidentiality (by reading cleartext packets); integrity (by modifying sessions); and authenticity (by compromising servers and/or clients using cache poisoning, phishing, or other attacks that enable attackers to spoof a legitimate entity in the communication channel).\n",
        "parent": [
            "319"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Explicitly require HTTPS or another mechanism that ensures that communication is encrypted [REF-1464].\n\n**Mitigation:** Avoid using \"mixed content,\" i.e., serving a web page over HTTPS in which the page includes elements that use \"http:\" URLs [REF-1466] [REF-1467]. This is often done for images or other resources that do not seem to have privacy or security implications.\n\n**Mitigation:** Perform \"HTTPS forcing,\" that is, redirecting HTTP requests to HTTPS.\n\n**Mitigation:** If the product supports multiple protocols, ensure that encrypted protocols (such as HTTPS) are required, and remove any unencrypted protocols (such as HTTP).\n",
        "languages": []
    },
    {
        "cwe": "1429",
        "name": "Missing Security-Relevant Feedback for Unexecuted Operations in Hardware Interface",
        "description": "The product has a hardware interface that silently discards operations\n\t\t\tin situations for which feedback would be security-relevant, such as\n\t\t\tthe timely detection of failures or attacks.",
        "detail": "**Extended Description:**\n\n\nWhile some systems intentionally withhold feedback as a security measure, this approach must be strictly controlled to ensure it does not obscure operational failures that require prompt detection and remediation. Without these essential confirmations, failures go undetected, increasing the risk of data loss, security vulnerabilities, and overall system instability. Even when withholding feedback is an intentional part of a security policy designed, for example, to prevent attackers from gleaning sensitive internal details, the absence of expected feedback becomes a critical weakness when it masks operational failures that require prompt detection and remediation.\n\n\nFor instance, certain encryption algorithms always return ciphertext regardless of errors to prevent attackers from gaining insight into internal state details. However, if such an algorithm fails to generate the expected ciphertext and provides no error feedback, the system cannot distinguish between a legitimate output and a malfunction. This can lead to undetected cryptographic failures, potentially compromising data security and system reliability. Without proper notification, a critical failure might remain hidden, undermining both the reliability and security of the process.\n\n\nTherefore, this weakness captures issues across various hardware interfaces where operations are discarded without any feedback, error handling, or logging. Such omissions can lead to data loss, security vulnerabilities, and system instability, with potential impacts ranging from minor to catastrophic.\n\n\nFor some kinds of hardware products, some errors may be correctly identified and subsequently discarded, and the lack of feedback may have been an intentional design decision. However, this could result in a weakness if system operators or other authorized entities are not provided feedback about security-critical operations or failures that could prevent the operators from detecting and responding to an attack.\n\n\nFor example:\n\n\n  - In a System-on-Chip (SoC) platform, write operations to reserved memory addresses might be correctly identified as invalid and subsequently discarded. However, if no feedback is provided to system operators, they may misinterpret the device's state, failing to recognize conditions that could lead to broader failures or security vulnerabilities. For example, if an attacker attempts unauthorized writes to protected regions, the system may silently discard these writes without alerting security mechanisms. This lack of feedback could obscure intrusion attempts or misconfigurations, increasing the risk of unnoticed system compromise\n\n  - Microcontroller Interrupt Systems: When interrupts are silently ignored due to priority conflicts or internal errors without notifying higher-level control, it becomes challenging to diagnose system failures or detect potential security breaches in a timely manner.\n\n  - Network Interface Controllers: Dropping packets - perhaps due to buffer overflows - without any error feedback can not only cause data loss but may also contribute to exploitable timing discrepancies that reveal sensitive internal processing details.\n\n\n\n**Mode of Introduction:** \n\nThis weakness can be introduced during the architecture and design phase when the system does not incorporate proper mechanisms for error reporting or feedback for discarded operations, such as when handling reserved addresses or unexecuted instructions.\n\n\n**Mode of Introduction:** \n\nIt can also arise during implementation if developers fail to include appropriate feedback or logging for critical operations. This leads to silent failures in certain scenarios like interrupt handling or network buffer overflows.\n\n\n**Mode of Introduction:** \n\nA further layer of complexity emerges when considering specifications. The weakness may stem either from ambiguous product design specifications that fail to delineate when feedback should occur or from implementations that do not adhere to existing requirements. In either case, the result is the same: feedback that is critical for detecting operational failures or security breaches is missing.\n\n\n**Consequence Note:** \n\nCritical data may be exposed if operations are unexecuted or discarded silently, allowing attackers to exploit the lack of feedback.\n\n\n**Consequence Note:** \n\nOperations may proceed based on incorrect assumptions, potentially causing data corruption or incorrect system behavior. In integrity-sensitive contexts, failing to signal that an operation did not occur as expected can mask errors that disrupt data consistency. Without feedback, the mitigation measures that should ensure updates have been performed cannot be verified, leaving the system vulnerable to both accidental and malicious data alterations\n\n\n**Consequence Note:** \n\nUnhandled discarded operations can lead to resource exhaustion, triggering system crashes or denial of service. For availability, consistent feedback is crucial. Without proper notification of discarded operations, administrators or other authorized entities might miss early warning signs of resource imbalances. This delayed detection could allow a DoS condition to develop, compromising the system's ability to serve legitimate requests and maintain continuous operations.\n\n",
        "parent": [
            "223"
        ],
        "children": [],
        "related": [
            "392"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nScans code for missing error handling or feedback mechanisms.\n\n\n**Detection:** \n\nExperts manually inspect the code for unhandled operations.\n\n\n**Mitigation:** \n\nIncorporate logging and feedback mechanisms during the design phase to ensure proper handling of discarded operations.\n\n\n**Effectiveness:** \n\nAddressing the issue at the design stage prevents the weakness from manifesting later.\n\n\n**Mitigation:** \n\nDevelopers should ensure that every critical operation includes proper logging or error feedback mechanisms.\n\n\n**Effectiveness:** \n\nImplementation-level checks complement design-phase measures.\n\n",
        "languages": [
            "C",
            "C++",
            "Verilog"
        ]
    },
    {
        "cwe": "143",
        "name": "Improper Neutralization of Record Delimiters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as record delimiters when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.\n",
        "parent": [
            "140"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that record delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "1431",
        "name": "Driving Intermediate Cryptographic State/Results to Hardware Module Outputs",
        "description": "The product uses a hardware module implementing a cryptographic\n\t\t  algorithm that writes sensitive information about the intermediate\n\t\t  state or results of its cryptographic operations via one of its output\n\t\t  wires (typically the output port containing the final result).",
        "detail": "**Mode of Introduction:** \n\nThis can occur when intermediate cryptographic states are directly assigned to output wires or ports.\n\n\n**Consequence Note:** \n\nMathematically sound cryptographic algorithms rely on their correct implementation for security. These assumptions might break when a hardware crypto module leaks intermediate encryption states or results such that they can be observed by an adversary. If intermediate state is observed, it might be possible for an attacker to identify the secrets used in the cryptographic operation.\n\n",
        "parent": [
            "200"
        ],
        "children": [],
        "related": [
            "497"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** \n\nAutomated static analysis can find some instances of this weakness by analyzing source register-transfer level (RTL) code without having to simulate it or analyze it with a formal verification engine. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (signals with intermediate cryptographic state/results) with \"sinks\" (hardware module outputs and other signals outside of trusted cryptographic zone) without any control flow.\n\n\n**Detection:** \n\nSimulation/emulation based analysis can find some instances of this weakness by simulating source register-transfer level (RTL) code along with a set of assertions that incorporate the simulated values of relevant design signals. Typically, these assertions will capture desired or undesired behavior. Analysis can be improved by using simulation-based information flow tracking (IFT) to more precisely detect unexpected results.\n\n\n**Detection:** \n\nFormal verification can find some instances of this weakness by exhaustively analyzing whether a given assertion holds true for a given hardware design specified in register-transfer level (RTL) code. Typically, these assertions will capture desired or undesired behavior. For this weakness, an assertion should check for undesired behavior in which one output is a signal that captures when a cryptographic algorithm has completely finished; another output is a signal with intermediate cryptographic state/results; and there is an assignment to a hardware module output or other signal outside of a trusted cryptographic zone.\n\n\nAlternatively, when using a formal IFT verification, the same undesired behavior can be detected by checking if computation results can ever leak to an output when the cryptographic result is not copmlete.\n\n\n**Detection:** \n\nManual analysis can find some instances of this weakness by manually reviewing relevant lines of source register-transfer level (RTL) code to detect potentially-vulnerable patterns. Typically, the reviewer will trace the sequence of assignments that connect \"sources\" (signals with intermediate cryptographic state/results) with \"sinks\" (hardware module outputs and other signals outside of trusted cryptographic zone). If this sequence of assignments is missing adequate control flow, then the weakness is likely to exist.\n\n\n**Mitigation:** \n\nDesigners/developers should add or modify existing control flow logic along any data flow paths that connect \"sources\" (signals with intermediate cryptographic state/results) with \"sinks\" (hardware module outputs and other signals outside of trusted cryptographic zone). The control flow logic should only allow cryptographic results to be driven to \"sinks\" when appropriate conditions are satisfied (typically when the final result for a cryptographic operation has been generated). When the appropriate conditions are not satisfied (i.e., before or during a cryptographic operation), the control flow logic should drive a safe default value to \"sinks\".\n\n\n**Mitigation:** \n\nDesigners/developers should add or modify existing control flow logic along any data flow paths that connect \"sources\" (signals with intermediate cryptographic state/results) with \"sinks\" (hardware module outputs and other signals outside of trusted cryptographic zone). The control flow logic should only allow cryptographic results to be driven to \"sinks\" when appropriate conditions are satisfied (typically when the final result for a cryptographic operation has been generated). When the appropriate conditions are not satisfied (i.e., before or during a cryptographic operation), the control flow logic should drive a safe default value to \"sinks\".\n\n",
        "languages": []
    },
    {
        "cwe": "144",
        "name": "Improper Neutralization of Line Delimiters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as line delimiters when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.\n",
        "parent": [
            "140"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that line delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "145",
        "name": "Improper Neutralization of Section Delimiters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as section delimiters when they are sent to a downstream component.",
        "detail": "**Extended Description:**\n\n\nAs data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.\n\n\nOne example of a section delimiter is the boundary string in a multipart MIME message. In many cases, doubled line delimiters can serve as a section delimiter.\n\n",
        "parent": [
            "140"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that section delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "146",
        "name": "Improper Neutralization of Expression/Command Delimiters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as expression or command delimiters when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.\n",
        "parent": [
            "140"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that inter-expression and inter-command delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "147",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "148",
        "name": "Improper Neutralization of Input Leaders",
        "description": "The product does not properly handle when a leading character or sequence (\"leader\") is missing or malformed, or if multiple leaders are used when only one should be allowed.",
        "detail": null,
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that leading characters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "149",
        "name": "Improper Neutralization of Quoting Syntax",
        "description": "Quotes injected into a product can be used to compromise a system. As data are parsed, an injected/absent/duplicate/malformed use of quotes may cause the process to take unexpected actions.",
        "detail": null,
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that quotes will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "15",
        "name": "External Control of System or Configuration Setting",
        "description": "One or more system settings or configuration elements can be externally controlled by a user.",
        "detail": "**Extended Description:**\nAllowing external control of system settings can disrupt service or cause an application to behave in unexpected, and potentially malicious ways.\n\n**Mode of Introduction:** Setting manipulation vulnerabilities occur when an attacker can control values that govern the behavior of the system, manage specific resources, or in some way affect the functionality of the application.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "20",
            "610",
            "642"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n\n**Mitigation:** Because setting manipulation covers a diverse set of functions, any attempt at illustrating it will inevitably be incomplete. Rather than searching for a tight-knit relationship between the functions addressed in the setting manipulation category, take a step back and consider the sorts of system values that an attacker should not be allowed to control.\n\n**Mitigation:** In general, do not allow user-provided or otherwise untrusted data to control sensitive values. The leverage that an attacker gains by controlling these values is not always immediately obvious, but do not underestimate the creativity of the attacker.\n",
        "languages": []
    },
    {
        "cwe": "150",
        "name": "Improper Neutralization of Escape, Meta, or Control Sequences",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as escape, meta, or control character sequences when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected/absent/malformed delimiter may cause the process to take unexpected actions.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that escape, meta and control characters/sequences will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "151",
        "name": "Improper Neutralization of Comment Delimiters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as comment delimiters when they are sent to a downstream component.",
        "detail": null,
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that comments will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "152",
        "name": "Improper Neutralization of Macro Symbols",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as macro symbols when they are sent to a downstream component.",
        "detail": null,
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that macro symbols will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "153",
        "name": "Improper Neutralization of Substitution Characters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as substitution characters when they are sent to a downstream component.",
        "detail": null,
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that substitution characters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "154",
        "name": "Improper Neutralization of Variable Name Delimiters",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as variable name delimiters when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected delimiter may cause the process to take unexpected actions that result in an attack. Example: \"$\" for an environment variable.\n",
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that variable name delimiters will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "155",
        "name": "Improper Neutralization of Wildcards or Matching Symbols",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as wildcards or matching symbols when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected element may cause the process to take unexpected actions.\n",
        "parent": [
            "138"
        ],
        "children": [
            "56"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that wildcard or matching elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "156",
        "name": "Improper Neutralization of Whitespace",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could be interpreted as whitespace when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nThis can include space, tab, etc.\n\n**Alternate Terms:** White space\n",
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that whitespace will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "157",
        "name": "Failure to Sanitize Paired Delimiters",
        "description": "The product does not properly handle the characters that are used to mark the beginning and ending of a group of entities, such as parentheses, brackets, and braces.",
        "detail": "**Extended Description:**\n\n\nPaired delimiters might include:\n\n\n  - < and > angle brackets\n\n  - ( and ) parentheses\n\n  - { and } braces\n\n  - [ and ] square brackets\n\n  - \" \" double quotes\n\n  - ' ' single quotes\n\n\n",
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that grouping elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "158",
        "name": "Improper Neutralization of Null Byte or NUL Character",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes NUL characters or null bytes when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, an injected NUL character or null byte may cause the product to believe the input is terminated earlier than it actually is, or otherwise cause the input to be misinterpreted. This could then be used to inject potentially dangerous input that occurs after the null byte or otherwise bypass validation routines and other protection mechanisms.\n",
        "parent": [
            "138"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that null characters or null bytes will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "159",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "166",
            "167",
            "168"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "160",
        "name": "Improper Neutralization of Leading Special Elements",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes leading special elements that could be interpreted in unexpected ways when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, improperly handled leading special elements may cause the process to take unexpected actions that result in an attack.\n",
        "parent": [
            "138"
        ],
        "children": [
            "161",
            "37"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that leading special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "161",
        "name": "Improper Neutralization of Multiple Leading Special Elements",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes multiple leading special elements that could be interpreted in unexpected ways when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, improperly handled multiple leading special elements may cause the process to take unexpected actions that result in an attack.\n",
        "parent": [
            "160"
        ],
        "children": [
            "50"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that multiple leading special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "162",
        "name": "Improper Neutralization of Trailing Special Elements",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes trailing special elements that could be interpreted in unexpected ways when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, improperly handled trailing special elements may cause the process to take unexpected actions that result in an attack.\n",
        "parent": [
            "138"
        ],
        "children": [
            "163",
            "42",
            "46",
            "49",
            "54"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that trailing special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "163",
        "name": "Improper Neutralization of Multiple Trailing Special Elements",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes multiple trailing special elements that could be interpreted in unexpected ways when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, improperly handled multiple trailing special elements may cause the process to take unexpected actions that result in an attack.\n",
        "parent": [
            "162"
        ],
        "children": [
            "43",
            "52"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that multiple trailing special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "164",
        "name": "Improper Neutralization of Internal Special Elements",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes internal special elements that could be interpreted in unexpected ways when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, improperly handled internal special elements may cause the process to take unexpected actions that result in an attack.\n",
        "parent": [
            "138"
        ],
        "children": [
            "165"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that internal special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "165",
        "name": "Improper Neutralization of Multiple Internal Special Elements",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes multiple internal special elements that could be interpreted in unexpected ways when they are sent to a downstream component.",
        "detail": "**Extended Description:**\nAs data is parsed, improperly handled multiple internal special elements may cause the process to take unexpected actions that result in an attack.\n",
        "parent": [
            "164"
        ],
        "children": [
            "45",
            "53"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that multiple internal special elements will be injected/removed/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "166",
        "name": "Improper Handling of Missing Special Element",
        "description": "The product receives input from an upstream component, but it does not handle or incorrectly handles when an expected special element is missing.",
        "detail": null,
        "parent": [
            "159",
            "228"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that special elements will be removed in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "167",
        "name": "Improper Handling of Additional Special Element",
        "description": "The product receives input from an upstream component, but it does not handle or incorrectly handles when an additional unexpected special element is provided.",
        "detail": null,
        "parent": [
            "159",
            "228"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that extra special elements will be injected in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "168",
        "name": "Improper Handling of Inconsistent Special Elements",
        "description": "The product does not properly handle input in which an inconsistency exists between two or more special characters or reserved words.",
        "detail": "**Extended Description:**\nAn example of this problem would be if paired characters appear in the wrong order, or if the special characters are not properly nested.\n",
        "parent": [
            "159",
            "228"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Developers should anticipate that inconsistent special elements will be injected/manipulated in the input vectors of their product. Use an appropriate combination of denylists and allowlists to ensure only valid, expected and appropriate input is processed by the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "170",
        "name": "Improper Null Termination",
        "description": "The product does not terminate or incorrectly terminates a string or array with a null character or equivalent terminator.",
        "detail": "**Extended Description:**\nNull termination errors frequently occur in two different ways. An off-by-one error could cause a null to be written out of bounds, leading to an overflow. Or, a program could use a strncpy() function call incorrectly, which prevents a null terminator from being added at all. Other scenarios are possible.\n\n**Consequence Note:** The case of an omitted null character is the most dangerous of the possible issues. This will almost certainly result in information disclosure, and possibly a buffer overflow condition, which may be exploited to execute arbitrary code.\n\n**Consequence Note:** If a null character is omitted from a string, then most string-copying functions will read data until they locate a null character, even outside of the intended boundaries of the string. This could: cause a crash due to a segmentation fault cause sensitive adjacent memory to be copied and sent to an outsider trigger a buffer overflow when the copy is being written to a fixed-size buffer.\n\n**Consequence Note:** Misplaced null characters may result in any number of security problems. The biggest issue is a subset of buffer overflow, and write-what-where conditions, where data corruption occurs from the writing of a null character over valid data, or even instructions. A randomly placed null character may put the system into an undefined state, and therefore make it prone to crashing. A misplaced null character may corrupt other data in memory.\n\n**Consequence Note:** Should the null character corrupt the process flow, or affect a flag controlling access, it may lead to logical errors which allow for the execution of arbitrary code.\n",
        "parent": [
            "20",
            "707"
        ],
        "children": [],
        "related": [
            "120",
            "126",
            "463",
            "464"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use a language that is not susceptible to these issues. However, be careful of null byte interaction errors (CWE-626) with lower-level constructs that may be written in a language that is susceptible.\n\n**Mitigation:** Ensure that all string functions used are understood fully as to how they append null characters. Also, be wary of off-by-one errors when appending nulls to the end of strings.\n\n**Mitigation:** If performance constraints permit, special code can be added that validates null-termination of string buffers, this is a rather naive and error-prone solution.\n\n**Mitigation:** Switch to bounded string manipulation functions. Inspect buffer lengths involved in the buffer overrun trace reported with the defect.\n\n**Mitigation:** Add code that fills buffers with nulls (however, the length of buffers still needs to be inspected, to ensure that the non null-terminated string is not written at the physical end of the buffer).\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "172",
        "name": "Encoding Error",
        "description": "The product does not properly encode or decode the data, resulting in unexpected values.",
        "detail": null,
        "parent": [
            "707"
        ],
        "children": [
            "173",
            "174",
            "175",
            "176",
            "177"
        ],
        "related": [
            "22",
            "41"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "173",
        "name": "Improper Handling of Alternate Encoding",
        "description": "The product does not properly handle when an input uses an alternate encoding that is valid for the control sphere to which the input is being sent.",
        "detail": null,
        "parent": [
            "172"
        ],
        "children": [],
        "related": [
            "289"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "174",
        "name": "Double Decoding of the Same Data",
        "description": "The product decodes the same input twice, which can limit the effectiveness of any protection mechanism that occurs in between the decoding operations.",
        "detail": null,
        "parent": [
            "172",
            "675"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "175",
        "name": "Improper Handling of Mixed Encoding",
        "description": "The product does not properly handle when the same input uses several different (mixed) encodings.",
        "detail": null,
        "parent": [
            "172"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Use and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "176",
        "name": "Improper Handling of Unicode Encoding",
        "description": "The product does not properly handle when an input contains Unicode encoding.",
        "detail": null,
        "parent": [
            "172"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "177",
        "name": "Improper Handling of URL Encoding (Hex Encoding)",
        "description": "The product does not properly handle when all or part of an input has been URL encoded.",
        "detail": null,
        "parent": [
            "172"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "178",
        "name": "Improper Handling of Case Sensitivity",
        "description": "The product does not properly account for differences in case sensitivity when accessing or determining the properties of a resource, leading to inconsistent results.",
        "detail": "**Extended Description:**\n\n\nImproperly handled case sensitive data can lead to several possible consequences, including:\n\n\n  - case-insensitive passwords reducing the size of the key space, making brute force attacks easier\n\n  - bypassing filters or access controls using alternate names\n\n  - multiple interpretation errors using alternate names.\n\n\n",
        "parent": [
            "706"
        ],
        "children": [],
        "related": [
            "1289",
            "289",
            "433"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "179",
        "name": "Incorrect Behavior Order: Early Validation",
        "description": "The product validates input before applying protection mechanisms that modify the input, which could allow an attacker to bypass the validation via dangerous inputs that only arise after the modification.",
        "detail": "**Extended Description:**\nProduct needs to validate data at the proper time, after data has been canonicalized and cleansed. Early validation is susceptible to various manipulations that result in dangerous inputs that are produced by canonicalization and cleansing.\n\n**Mode of Introduction:** Since early validation errors usually arise from improperly implemented defensive mechanisms, it is likely that these will be introduced more frequently as secure programming becomes implemented more widely.\n\n**Consequence Note:** An attacker could include dangerous input that bypasses validation protection mechanisms which can be used to launch various attacks including injection attacks, execute arbitrary code or cause other unintended behavior.\n",
        "parent": [
            "20",
            "696"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "180",
        "name": "Incorrect Behavior Order: Validate Before Canonicalize",
        "description": "The product validates input before it is canonicalized, which prevents the product from detecting data that becomes invalid after the canonicalization step.",
        "detail": "**Extended Description:**\nThis can be used by an attacker to bypass the validation and launch attacks that expose weaknesses that would otherwise be prevented, such as injection.\n",
        "parent": [
            "179"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "181",
        "name": "Incorrect Behavior Order: Validate Before Filter",
        "description": "The product validates data before it has been filtered, which prevents the product from detecting data that becomes invalid after the filtering step.",
        "detail": "**Extended Description:**\nThis can be used by an attacker to bypass the validation and launch attacks that expose weaknesses that would otherwise be prevented, such as injection.\n\n**Alternate Terms:** Validate-before-cleanse\n",
        "parent": [
            "179"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being filtered.\n",
        "languages": []
    },
    {
        "cwe": "182",
        "name": "Collapse of Data into Unsafe Value",
        "description": "The product filters data in a way that causes it to be reduced or \"collapsed\" into an unsafe value that violates an expected security property.",
        "detail": null,
        "parent": [
            "707"
        ],
        "children": [],
        "related": [
            "33",
            "34",
            "35"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n\n**Mitigation:** Canonicalize the name to match that of the file system's representation of the name. This can sometimes be achieved with an available API (e.g. in Win32 the GetFullPathName function).\n",
        "languages": []
    },
    {
        "cwe": "183",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "625"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "184",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "625"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "185",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "625"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "186",
        "name": "Overly Restrictive Regular Expression",
        "description": "A regular expression is overly restrictive, which prevents dangerous values from being detected.",
        "detail": "**Extended Description:**\nThis weakness is not about regular expression complexity. Rather, it is about a regular expression that does not match all values that are intended. Consider the use of a regexp to identify acceptable values or to spot unwanted terms. An overly restrictive regexp misses some potentially security-relevant values leading to either false positives *or* false negatives, depending on how the regexp is being used within the code. Consider the expression /[0-8]/ where the intention was /[0-9]/. This expression is not \"complex\" but the value \"9\" is not matched when maybe the programmer planned to check for it.\n",
        "parent": [
            "185"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Regular expressions can become error prone when defining a complex language even for those experienced in writing grammars. Determine if several smaller regular expressions simplify one large regular expression. Also, subject your regular expression to thorough testing techniques such as equivalence partitioning, boundary value analysis, and robustness. After testing and a reasonable confidence level is achieved, a regular expression may not be foolproof. If an exploit is allowed to slip through, then record the exploit and refactor your regular expression.\n",
        "languages": []
    },
    {
        "cwe": "187",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "625"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "188",
        "name": "Reliance on Data/Memory Layout",
        "description": "The product makes invalid assumptions about how protocol data or memory is organized at a lower level, resulting in unintended program behavior.",
        "detail": "**Extended Description:**\n\n\nWhen changing platforms or protocol versions, in-memory organization of data may change in unintended ways. For example, some architectures may place local variables A and B right next to each other with A on top; some may place them next to each other with B on top; and others may add some padding to each. The padding size may vary to ensure that each variable is aligned to a proper word size.\n\n\nIn protocol implementations, it is common to calculate an offset relative to another field to pick out a specific piece of data. Exceptional conditions, often involving new protocol versions, may add corner cases that change the data layout in an unusual way. The result can be that an implementation accesses an unintended field in the packet, treating data of one type as data of another type.\n\n\n**Consequence Note:** Can result in unintended modifications or exposure of sensitive memory.\n",
        "parent": [
            "1105",
            "435"
        ],
        "children": [
            "198"
        ],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Mitigation:** In flat address space situations, never allow computing memory addresses as offsets from another memory address.\n\n**Mitigation:** Fully specify protocol layout unambiguously, providing a structured grammar (e.g., a compilable yacc grammar).\n\n**Mitigation:** Testing: Test that the implementation properly handles each case in the protocol grammar.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "190",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "128"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "191",
        "name": "Integer Underflow (Wrap or Wraparound)",
        "description": "The product subtracts one value from another, such that the result is less than the minimum allowable integer value, which produces a value that is not equal to the correct result.",
        "detail": "**Extended Description:**\nThis can happen in signed and unsigned cases.\n\n**Alternate Terms:** Integer underflow\n\n**Consequence Note:** This weakness will generally lead to undefined behavior and therefore crashes. In the case of overflows involving loop index variables, the likelihood of infinite loops is also high.\n\n**Consequence Note:** If the value in question is important to data (as opposed to flow), simple data corruption has occurred. Also, if the wrap around results in other conditions such as buffer overflows, further memory corruption may occur.\n\n**Consequence Note:** This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "192",
        "name": "Integer Coercion Error",
        "description": "Integer coercion refers to a set of flaws pertaining to the type casting, extension, or truncation of primitive data types.",
        "detail": "**Extended Description:**\nSeveral flaws fall under the category of integer coercion errors. For the most part, these errors in and of themselves result only in availability and data integrity issues. However, in some circumstances, they may result in other, more complicated security related flaws, such as buffer overflow conditions.\n\n**Consequence Note:** Integer coercion often leads to undefined states of execution resulting in infinite loops or crashes.\n\n**Consequence Note:** In some cases, integer coercion errors can lead to exploitable buffer overflow conditions, resulting in the execution of arbitrary code.\n\n**Consequence Note:** Integer coercion errors result in an incorrect value being stored for the variable in question.\n",
        "parent": [
            "681"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** A language which throws exceptions on ambiguous data casts might be chosen.\n\n**Mitigation:** Design objects and program flow such that multiple or complex casts are unnecessary\n\n**Mitigation:** Ensure that any data type casting that you must used is entirely understood in order to reduce the plausibility of error in use.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "193",
        "name": "Off-by-one Error",
        "description": "A product calculates or uses an incorrect maximum or minimum value that is 1 more, or 1 less, than the correct value.",
        "detail": "**Alternate Terms:** off-by-five\n\n**Consequence Note:** This weakness will generally lead to undefined behavior and therefore crashes. In the case of overflows involving loop index variables, the likelihood of infinite loops is also high.\n\n**Consequence Note:** If the value in question is important to data (as opposed to flow), simple data corruption has occurred. Also, if the wrap around results in other conditions such as buffer overflows, further memory corruption may occur.\n\n**Consequence Note:** This weakness can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [
            "119",
            "170",
            "617"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** When copying character arrays or using character manipulation methods, the correct size parameter must be used to account for the null terminator that needs to be added at the end of the array. Some examples of functions susceptible to this weakness in C include strcpy(), strncpy(), strcat(), strncat(), printf(), sprintf(), scanf() and sscanf().\n",
        "languages": [
            "C"
        ]
    },
    {
        "cwe": "194",
        "name": "Unexpected Sign Extension",
        "description": "The product performs an operation on a number that causes it to be sign extended when it is transformed into a larger data type. When the original number is negative, this can produce unexpected values that lead to resultant weaknesses.",
        "detail": "**Consequence Note:** When an unexpected sign extension occurs in code that operates directly on memory buffers, such as a size value or a memory index, then it could cause the program to write or read outside the boundaries of the intended buffer. If the numeric value is associated with an application-level resource, such as a quantity or price for a product in an e-commerce site, then the sign extension could produce a value that is much higher (or lower) than the application's allowable range.\n",
        "parent": [
            "681"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Avoid using signed variables if you don't need to represent negative values. When negative values are needed, perform validation after you save those values to larger data types, or before passing them to functions that are expecting unsigned values.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "195",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "839"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "196",
        "name": "Unsigned to Signed Conversion Error",
        "description": "The product uses an unsigned primitive and performs a cast to a signed primitive, which can produce an unexpected value if the value of the unsigned primitive can not be represented using a signed primitive.",
        "detail": "**Extended Description:**\nAlthough less frequent an issue than signed-to-unsigned conversion, unsigned-to-signed conversion can be the perfect precursor to dangerous buffer underwrite conditions that allow attackers to move down the stack where they otherwise might not have access in a normal buffer overflow condition. Buffer underwrites occur frequently when large unsigned values are cast to signed values, and then used as indexes into a buffer or for pointer arithmetic.\n\n**Consequence Note:** Incorrect sign conversions generally lead to undefined behavior, and therefore crashes.\n\n**Consequence Note:** If a poor cast lead to a buffer overflow or similar condition, data integrity may be affected.\n\n**Consequence Note:** Improper signed-to-unsigned conversions without proper checking can sometimes trigger buffer overflows which can be used to execute arbitrary code. This is usually outside the scope of a program's implicit security policy.\n",
        "parent": [
            "681"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Choose a language which is not subject to these casting flaws.\n\n**Mitigation:** Design object accessor functions to implicitly check values for valid sizes. Ensure that all functions which will be used as a size are checked previous to use as a size. If the language permits, throw exceptions rather than using in-band errors.\n\n**Mitigation:** Error check the return values of all functions. Be aware of implicit casts made, and use unsigned variables for sizes if at all possible.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "197",
        "name": "Numeric Truncation Error",
        "description": "Truncation errors occur when a primitive is cast to a primitive of a smaller size and data is lost in the conversion.",
        "detail": "**Extended Description:**\nWhen a primitive is cast to a smaller primitive, the high order bits of the large value are lost in the conversion, potentially resulting in an unexpected value that is not equal to the original value. This value may be required as an index into a buffer, a loop iterator, or simply necessary state data. In any case, the value cannot be trusted and the system will be in an undefined state. While this method may be employed viably to isolate the low bits of a value, this usage is rare, and truncation usually implies that an implementation error has occurred.\n\n**Consequence Note:** The true value of the data is lost and corrupted data is used.\n",
        "parent": [
            "681"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Ensure that no casts, implicit or explicit, take place that move from a larger size primitive or a smaller size primitive.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "198",
        "name": "Use of Incorrect Byte Ordering",
        "description": "The product receives input from an upstream component, but it does not account for byte ordering (e.g. big-endian and little-endian) when processing the input, causing an incorrect number or value to be used.",
        "detail": null,
        "parent": [
            "188"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Because byte ordering bugs are usually very noticeable even with normal inputs, this bug is more likely to occur in rarely triggered error conditions, making them difficult to detect using black box methods.\n",
        "languages": []
    },
    {
        "cwe": "20",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "112",
            "117",
            "1173",
            "120",
            "1284",
            "1285",
            "1286",
            "1287",
            "1288",
            "1289",
            "15",
            "170",
            "179",
            "470",
            "73"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "200",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "201",
            "209",
            "213",
            "215",
            "359",
            "497",
            "538"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "201",
        "name": "Insertion of Sensitive Information Into Sent Data",
        "description": "The code transmits data to another actor, but a portion of the data includes sensitive information that should not be accessible to that actor.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Sensitive data may be exposed to attackers.\n",
        "parent": [
            "200"
        ],
        "children": [],
        "related": [
            "212"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Specify which data in the software should be regarded as sensitive. Consider which types of users should have access to which types of data.\n\n**Mitigation:** Ensure that any possibly sensitive data specified in the requirements is verified with designers to ensure that it is either a calculated risk or mitigated elsewhere. Any information that is not necessary to the functionality should be removed in order to lower both the overhead and the possibility of security sensitive data being sent.\n\n**Mitigation:** Setup default error messages so that unexpected errors do not disclose sensitive information.\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n",
        "languages": []
    },
    {
        "cwe": "202",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "203",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "204",
            "205",
            "208"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "204",
        "name": "Observable Response Discrepancy",
        "description": "The product provides different responses to incoming requests in a way that reveals internal state information to an unauthorized actor outside of the intended control sphere.",
        "detail": "**Mode of Introduction:** An observable response discrepancy frequently occurs during authentication, where a difference in failed-login messages could allow an attacker to determine if the username is valid or not. The discrepancy could be inadvertent (bug) or intentional (design).\n\n**Mode of Introduction:** An observable response discrepancy frequently occurs during authentication, where a difference in failed-login messages could allow an attacker to determine if the username is valid or not. The discrepancy could be inadvertent (bug) or intentional (design).\n",
        "parent": [
            "203"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n\n**Mitigation:** \n\nEnsure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n\n\nIf errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\n\nAvoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n\n",
        "languages": []
    },
    {
        "cwe": "205",
        "name": "Observable Behavioral Discrepancy",
        "description": "The product's behaviors indicate important differences that may be observed by unauthorized actors in a way that reveals (1) its internal state or decision process, or (2) differences from other products with equivalent functionality.",
        "detail": "**Extended Description:**\nIdeally, a product should provide as little information about its internal operations as possible. Otherwise, attackers could use knowledge of these internal operations to simplify or optimize their attack. In some cases, behavioral discrepancies can be used by attackers to form a side channel.\n",
        "parent": [
            "203"
        ],
        "children": [],
        "related": [
            "514"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "206",
        "name": "Observable Internal Behavioral Discrepancy",
        "description": "The product performs multiple behaviors that are combined to produce a single result, but the individual behaviors are observable separately in a way that allows attackers to reveal internal state or internal decision points.",
        "detail": "**Extended Description:**\nIdeally, a product should provide as little information as possible to an attacker. Any hints that the attacker may be making progress can then be used to simplify or optimize the attack. For example, in a login procedure that requires a username and password, ultimately there is only one decision: success or failure. However, internally, two separate actions are performed: determining if the username exists, and checking if the password is correct. If the product behaves differently based on whether the username exists or not, then the attacker only needs to concentrate on the password.\n",
        "parent": [
            "205"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Setup generic response pages for error conditions. The error page should not disclose information about the success or failure of a sensitive operation. For instance, the login page should not confirm that the login is correct and the password incorrect. The attacker who tries random account name may be able to guess some of them. Confirming that the account exists would make the login page more susceptible to brute force attack.\n",
        "languages": []
    },
    {
        "cwe": "207",
        "name": "Observable Behavioral Discrepancy With Equivalent Products",
        "description": "The product operates in an environment in which its existence or specific identity should not be known, but it behaves differently than other products with equivalent functionality, in a way that is observable to an attacker.",
        "detail": "**Extended Description:**\nFor many kinds of products, multiple products may be available that perform the same functionality, such as a web server, network interface, or intrusion detection system. Attackers often perform \"fingerprinting,\" which uses discrepancies in order to identify which specific product is in use. Once the specific product has been identified, the attacks can be made more customized and efficient. Often, an organization might intentionally allow the specific product to be identifiable. However, in some environments, the ability to identify a distinct product is unacceptable, and it is expected that every product would behave in exactly the same way. In these more restricted environments, a behavioral difference might pose an unacceptable risk if it makes it easier to identify the product's vendor, model, configuration, version, etc.\n",
        "parent": [
            "205"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "208",
        "name": "Observable Timing Discrepancy",
        "description": "Two separate operations in a product require different amounts of time to complete, in a way that is observable to an actor and reveals security-relevant information about the state of the product, such as whether a particular operation was successful or not.",
        "detail": "**Extended Description:**\nIn security-relevant contexts, even small variations in timing can be exploited by attackers to indirectly infer certain details about the product's internal operations. For example, in some cryptographic algorithms, attackers can use timing differences to infer certain properties about a private key, making the key easier to guess. Timing discrepancies effectively form a timing side channel.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "203"
        ],
        "children": [],
        "related": [
            "327",
            "385"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "209",
        "name": "Generation of Error Message Containing Sensitive Information",
        "description": "The product generates an error message that includes sensitive information about its environment, users, or associated data.",
        "detail": "**Extended Description:**\n\n\nThe sensitive information may be valuable information on its own (such as a password), or it may be useful for launching other, more serious attacks. The error message may be created in different ways:\n\n\n  - self-generated: the source code explicitly constructs the error message and delivers it\n\n  - externally-generated: the external environment, such as a language interpreter, handles the error and constructs its own message, whose contents are not under direct control by the programmer\n\nAn attacker may use the contents of error messages to help launch another, more focused attack. For example, an attempt to exploit a path traversal weakness (CWE-22) might yield the full pathname of the installed application. In turn, this could be used to select the proper number of \"..\" sequences to navigate to the targeted file. An attack using SQL injection (CWE-89) might not initially succeed, but an error message could reveal the malformed query, which would expose query logic and possibly even passwords or other sensitive information used within the query.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Often this will either reveal sensitive information which may be used for a later attack or private information stored in the server.\n",
        "parent": [
            "200",
            "755"
        ],
        "children": [],
        "related": [
            "756"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** This weakness generally requires domain-specific interpretation using manual analysis. However, the number of potential error conditions may be too large to cover completely within limited time constraints.\n\n**Detection:** Automated methods may be able to detect certain idioms automatically, such as exposed stack traces or pathnames, but violation of business rules or privacy requirements is not typically feasible.\n\n**Detection:** \n\nThis weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n\nError conditions may be triggered with a stress-test by calling the software simultaneously from a large number of threads or processes, and look for evidence of any unexpected behavior.\n\n\n**Detection:** Identify error conditions that are not likely to occur during normal usage and trigger them. For example, run the program under low memory conditions, run with insufficient privileges or permissions, interrupt a transaction before it is completed, or disable connectivity to basic network services such as DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled exception or similar error that was discovered and handled by the application's environment, it may still indicate unexpected conditions that were not handled by the application itself.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nEnsure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n\n\nIf errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\n\nAvoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n\n\n**Mitigation:** Handle exceptions internally and do not display errors containing potentially sensitive information to a user.\n\n**Mitigation:** Use naming conventions and strong types to make it easier to spot when sensitive data is being used. When creating structures, objects, or other complex entities, separate the sensitive and non-sensitive data as much as possible.\n\n**Effectiveness:** This makes it easier to spot places in the code where data is being used that is unencrypted.\n\n**Mitigation:** Debugging information should not make its way into a production release.\n\n**Mitigation:** Debugging information should not make its way into a production release.\n\n**Mitigation:** Where available, configure the environment to use less verbose error messages. For example, in PHP, disable the display_errors setting during configuration, or at runtime using the error_reporting() function.\n\n**Mitigation:** Create default error pages or messages that do not leak any information.\n",
        "languages": [
            "Java",
            "PHP"
        ]
    },
    {
        "cwe": "210",
        "name": "Self-generated Error Message Containing Sensitive Information",
        "description": "The product identifies an error condition and creates its own diagnostic or error messages that contain sensitive information.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "209"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Debugging information should not make its way into a production release.\n\n**Mitigation:** Debugging information should not make its way into a production release.\n",
        "languages": []
    },
    {
        "cwe": "211",
        "name": "Externally-Generated Error Message Containing Sensitive Information",
        "description": "The product performs an operation that triggers an external diagnostic or error message that is not directly generated or controlled by the product, such as an error generated by the programming language interpreter that a software application uses. The error can contain sensitive system information.",
        "detail": "**Mode of Introduction:** PHP applications are often targeted for having this issue when the PHP interpreter generates the error outside of the application's control. However, other languages/environments exhibit the same issue.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "209"
        ],
        "children": [
            "535",
            "536",
            "537"
        ],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Configure the application's environment in a way that prevents errors from being generated. For example, in PHP, disable display_errors.\n\n**Mitigation:** Debugging information should not make its way into a production release.\n\n**Mitigation:** Debugging information should not make its way into a production release.\n\n**Mitigation:** Handle exceptions internally and do not display errors containing potentially sensitive information to a user. Create default error pages if necessary.\n\n**Mitigation:** The best way to prevent this weakness during implementation is to avoid any bugs that could trigger the external error message. This typically happens when the program encounters fatal errors, such as a divide-by-zero. You will not always be able to control the use of error pages, and you might not be using a language that handles exceptions.\n",
        "languages": [
            "PHP"
        ]
    },
    {
        "cwe": "212",
        "name": "Improper Removal of Sensitive Information Before Storage or Transfer",
        "description": "The product stores, transfers, or shares a resource that contains sensitive information, but it does not properly remove that information before the product makes the resource available to unauthorized actors.",
        "detail": "**Extended Description:**\n\n\nResources that may contain sensitive data include documents, packets, messages, databases, etc. While this data may be useful to an individual user or small set of users who share the resource, it may need to be removed before the resource can be shared outside of the trusted group. The process of removal is sometimes called cleansing or scrubbing.\n\n\nFor example, a product for editing documents might not remove sensitive data such as reviewer comments or the local pathname where the document is stored. Or, a proxy might not remove an internal IP address from headers before making an outgoing request to an Internet site.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Sensitive data may be exposed to an unauthorized actor in another control sphere. This may have a wide range of secondary consequences which will depend on what data is exposed. One possibility is the exposure of system data allowing an attacker to craft a specific, more effective attack.\n",
        "parent": [
            "669"
        ],
        "children": [],
        "related": [
            "201"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Clearly specify which information should be regarded as private or sensitive, and require that the product offers functionality that allows the user to cleanse the sensitive information from the resource before it is published or exported to other parties.\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n\n**Mitigation:** Use naming conventions and strong types to make it easier to spot when sensitive data is being used. When creating structures, objects, or other complex entities, separate the sensitive and non-sensitive data as much as possible.\n\n**Effectiveness:** This makes it easier to spot places in the code where data is being used that is unencrypted.\n\n**Mitigation:** Avoid errors related to improper resource shutdown or release (CWE-404), which may leave the sensitive data within the resource if it is in an incomplete state.\n",
        "languages": []
    },
    {
        "cwe": "213",
        "name": "Exposure of Sensitive Information Due to Incompatible Policies",
        "description": "The product's intended functionality exposes information to certain actors in accordance with the developer's security policy, but this information is regarded as sensitive according to the intended security policies of other stakeholders such as the product's administrator, users, or others whose information is being processed.",
        "detail": "**Extended Description:**\n\n\nWhen handling information, the developer must consider whether the information is regarded as sensitive by different stakeholders, such as users or administrators. Each stakeholder effectively has its own intended security policy that the product is expected to uphold. When a developer does not treat that information as sensitive, this can introduce a vulnerability that violates the expectations of the product's users.\n\n\n**Mode of Introduction:** This can occur when the product's policy does not account for all relevant stakeholders, or when the policies of other stakeholders are not interpreted properly.\n\n**Mode of Introduction:** This can occur when requirements do not explicitly account for all relevant stakeholders.\n\n**Mode of Introduction:** Communications or data exchange frameworks may be chosen that exchange or provide access to more information than strictly needed.\n\n**Mode of Introduction:** This can occur when the developer does not properly track the flow of sensitive information and how it is exposed, e.g., via an API.\n",
        "parent": [
            "200"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "214",
        "name": "Invocation of Process Using Visible Sensitive Information",
        "description": "A process is invoked with sensitive command-line arguments, environment variables, or other elements that can be seen by other processes on the operating system.",
        "detail": "**Extended Description:**\nMany operating systems allow a user to list information about processes that are owned by other users. Other users could see information such as command line arguments or environment variable settings. When this data contains sensitive information such as credentials, it might allow other users to launch an attack against the product or related resources.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "497"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "215",
        "name": "Insertion of Sensitive Information Into Debugging Code",
        "description": "The product inserts sensitive information into debugging code, which could expose this information if the debugging code is not disabled in production.",
        "detail": "**Extended Description:**\nWhen debugging, it may be necessary to report detailed information to the programmer. However, if the debugging code is not disabled when the product is operating in a production environment, then this sensitive information may be exposed to attackers.\n",
        "parent": [
            "200"
        ],
        "children": [],
        "related": [
            "489"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not leave debug statements that could be executed in the source code. Ensure that all debug information is eradicated before releasing the software.\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n",
        "languages": []
    },
    {
        "cwe": "219",
        "name": "Storage of File with Sensitive Data Under Web Root",
        "description": "The product stores sensitive data under the web document root with insufficient access control, which might make it accessible to untrusted parties.",
        "detail": "**Extended Description:**\nBesides public-facing web pages and code, products may store sensitive data, code that is not directly invoked, or other files under the web document root of the web server. If the server is not configured or otherwise used to prevent direct access to those files, then attackers may obtain this sensitive data.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "552"
        ],
        "children": [
            "433"
        ],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Avoid storing information under the web root directory.\n\n**Mitigation:** Access control permissions should be set to prevent reading/writing of sensitive files inside/outside of the web directory.\n",
        "languages": []
    },
    {
        "cwe": "22",
        "name": "Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')",
        "description": "The product uses external input to construct a pathname that is intended to identify a file or directory that is located underneath a restricted parent directory, but the product does not properly neutralize special elements within the pathname that can cause the pathname to resolve to a location that is outside of the restricted directory.",
        "detail": "**Extended Description:**\n\n\nMany file operations are intended to take place within a restricted directory. By using special elements such as \"..\" and \"/\" separators, attackers can escape outside of the restricted location to access files or directories that are elsewhere on the system. One of the most common special elements is the \"../\" sequence, which in most modern operating systems is interpreted as the parent directory of the current location. This is referred to as relative path traversal. Path traversal also covers the use of absolute pathnames such as \"/usr/local/bin\" to access unexpected files. This is referred to as absolute path traversal.\n\n\n**Alternate Terms:** Directory traversal, Path traversal\n\n**Consequence Note:** The attacker may be able to create or overwrite critical files that are used to execute code, such as programs or libraries.\n\n**Consequence Note:** The attacker may be able to overwrite or create critical files, such as programs, libraries, or important data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, appending a new account at the end of a password file may allow an attacker to bypass authentication.\n\n**Consequence Note:** The attacker may be able read the contents of unexpected files and expose sensitive data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, by reading a password file, the attacker could conduct brute force password guessing attacks in order to break into an account on the system.\n\n**Consequence Note:** The attacker may be able to overwrite, delete, or corrupt unexpected critical files such as programs, libraries, or important data. This may prevent the product from working at all and in the case of protection mechanisms such as authentication, it has the potential to lock out product users.\n",
        "parent": [
            "706"
        ],
        "children": [],
        "related": [
            "668",
            "73"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated techniques can find areas where path traversal weaknesses exist. However, tuning or customization may be required to remove or de-prioritize path-traversal problems that are only exploitable by the product's administrator - or other privileged users - and thus potentially valid behavior or, at worst, a bug instead of a vulnerability.\n\n**Detection:** Manual white box techniques may be able to provide sufficient code coverage and reduction of false positives if all file access operations can be assessed within limited time constraints.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nInputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n\n\nUse a built-in path canonicalization function (such as realpath() in C) that produces the canonical version of the pathname, which effectively removes \"..\" sequences and symbolic links (CWE-23, CWE-59). This includes:\n\n\n  - realpath() in C\n\n  - getCanonicalPath() in Java\n\n  - GetFullPath() in ASP.NET\n\n  - realpath() or abs_path() in Perl\n\n  - realpath() in PHP\n\n\n\n**Mitigation:** Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n**Mitigation:** Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.\n\n**Effectiveness:** An application firewall might not cover all possible input vectors. In addition, attack techniques might be available to bypass the protection mechanism, such as using malformed inputs that can still be processed by the component that receives those inputs. Depending on functionality, an application firewall might inadvertently reject or modify legitimate requests. Finally, some manual effort may be required for customization.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** \n\nWhen the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n\nFor example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\". Features such as the ESAPI AccessReferenceMap [REF-185] provide this capability.\n\n\n**Mitigation:** \n\nRun the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n\n\nOS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Effectiveness:** The effectiveness of this mitigation depends on the prevention capabilities of the specific sandbox or jail being used and might only help to reduce the scope of an attack, such as restricting the attacker to certain system calls or limiting the portion of the file system that can be accessed.\n\n**Mitigation:** \n\nStore library, include, and utility files outside of the web document root, if possible. Otherwise, store them in a separate directory and use the web server's access control capabilities to prevent attackers from directly requesting them. One common practice is to define a fixed constant in each calling program, then check for the existence of the constant in the library/include file; if the constant does not exist, then the file was directly requested, and it can exit immediately.\n\n\nThis significantly reduces the chance of an attacker being able to bypass any protection mechanisms that are in the base program but not in the include files. It will also reduce the attack surface.\n\n\n**Mitigation:** \n\nEnsure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n\n\nIf errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\n\nAvoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n\n\nIn the context of path traversal, error messages which disclose path information can help attackers craft the appropriate attack strings to move through the file system hierarchy.\n\n\n**Mitigation:** When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n",
        "languages": []
    },
    {
        "cwe": "220",
        "name": "Storage of File With Sensitive Data Under FTP Root",
        "description": "The product stores sensitive data under the FTP server root with insufficient access control, which might make it accessible to untrusted parties.",
        "detail": "**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Background Details:**\n['Various Unix FTP servers require a password file that is under the FTP root, due to use of chroot.']\n",
        "parent": [
            "552"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Avoid storing information under the FTP root directory.\n\n**Mitigation:** Access control permissions should be set to prevent reading/writing of sensitive files inside/outside of the FTP directory.\n",
        "languages": []
    },
    {
        "cwe": "221",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "222",
            "223",
            "224",
            "396",
            "397"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "222",
        "name": "Truncation of Security-relevant Information",
        "description": "The product truncates the display, recording, or processing of security-relevant information in a way that can obscure the source or nature of an attack.",
        "detail": "**Consequence Note:** The source of an attack will be difficult or impossible to determine. This can allow attacks to the system to continue without notice.\n",
        "parent": [
            "221"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Non-Repudiation"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "223",
        "name": "Omission of Security-relevant Information",
        "description": "The product does not record or display information that would be important for identifying the source or nature of an attack, or determining if an action is safe.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** The source of an attack will be difficult or impossible to determine. This can allow attacks to the system to continue without notice.\n",
        "parent": [
            "221"
        ],
        "children": [
            "778"
        ],
        "related": [],
        "scopes": [
            "Non-Repudiation"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "224",
        "name": "Obscured Security-relevant Information by Alternate Name",
        "description": "The product records security-relevant information according to an alternate name of the affected entity, instead of the canonical name.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "221"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Non-Repudiation"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "226",
        "name": "Sensitive Information in Resource Not Removed Before Reuse",
        "description": "The product releases a resource such as memory or a file so that it can be made available for reuse, but it does not clear or \"zeroize\" the information contained in the resource before the product performs a critical state transition or makes the resource available for reuse by other entities.",
        "detail": "**Extended Description:**\n\n\nWhen resources are released, they can be made available for reuse. For example, after memory is de-allocated, an operating system may make the memory available to another process, or disk space may be reallocated when a file is deleted. As removing information requires time and additional resources, operating systems do not usually clear the previously written information.\n\n\nEven when the resource is reused by the same process, this weakness can arise when new data is not as large as the old data, which leaves portions of the old data still available. Equivalent errors can occur in other situations where the length of data is variable but the associated data structure is not. If memory is not cleared after use, the information may be read by less trustworthy parties when the memory is reallocated.\n\n\nThis weakness can apply in hardware, such as when a device or system switches between power, sleep, or debug states during normal operation, or when execution changes to different users or privilege levels.\n\n",
        "parent": [
            "212",
            "459"
        ],
        "children": [
            "1239",
            "1272",
            "1301",
            "1342",
            "244"
        ],
        "related": [
            "201"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Write a known pattern into each sensitive location. Trigger the release of the resource or cause the desired state transition to occur. Read data back from the sensitive locations. If the reads are successful, and the data is the same as the pattern that was originally written, the test fails and the product needs to be fixed. Note that this test can likely be automated.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** During critical state transitions, information not needed in the next state should be removed or overwritten with fixed patterns (such as all 0's) or random data, before the transition to the next state.\n\n**Mitigation:** When releasing, de-allocating, or deleting a resource, overwrite its data and relevant metadata with fixed patterns or random data. Be cautious about complex resource types whose underlying representation might be non-contiguous or change at a low level, such as how a file might be split into different chunks on a file system, even though \"logical\" file positions are contiguous at the application layer. Such resource types might require invocation of special modes or APIs to tell the underlying operating system to perform the necessary clearing, such as SDelete (Secure Delete) on Windows, although the appropriate functionality might not be available at the application layer.\n",
        "languages": []
    },
    {
        "cwe": "228",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "166",
            "167",
            "168",
            "229",
            "233",
            "237",
            "241"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "229",
        "name": "Improper Handling of Values",
        "description": "The product does not properly handle when the expected number of values for parameters, fields, or arguments is not provided in input, or if those values are undefined.",
        "detail": null,
        "parent": [
            "228"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "23",
        "name": "Relative Path Traversal",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize sequences such as \"..\" that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n**Alternate Terms:** Zip Slip\n\n**Consequence Note:** The attacker may be able to create or overwrite critical files that are used to execute code, such as programs or libraries.\n\n**Consequence Note:** The attacker may be able to overwrite or create critical files, such as programs, libraries, or important data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, appending a new account at the end of a password file may allow an attacker to bypass authentication.\n\n**Consequence Note:** The attacker may be able read the contents of unexpected files and expose sensitive data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, by reading a password file, the attacker could conduct brute force password guessing attacks in order to break into an account on the system.\n\n**Consequence Note:** The attacker may be able to overwrite, delete, or corrupt unexpected critical files such as programs, libraries, or important data. This may prevent the product from working at all and in the case of a protection mechanisms such as authentication, it has the potential to lockout every user of the product.\n",
        "parent": [
            "22"
        ],
        "children": [
            "24",
            "25",
            "26",
            "27",
            "28",
            "29",
            "30",
            "31",
            "32",
            "33",
            "34",
            "35"
        ],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** \n\nInputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n\n\nUse a built-in path canonicalization function (such as realpath() in C) that produces the canonical version of the pathname, which effectively removes \"..\" sequences and symbolic links (CWE-23, CWE-59). This includes:\n\n\n  - realpath() in C\n\n  - getCanonicalPath() in Java\n\n  - GetFullPath() in ASP.NET\n\n  - realpath() or abs_path() in Perl\n\n  - realpath() in PHP\n\n\n",
        "languages": []
    },
    {
        "cwe": "230",
        "name": "Improper Handling of Missing Values",
        "description": "The product does not handle or incorrectly handles when a parameter, field, or argument name is specified, but the associated value is missing, i.e. it is empty, blank, or null.",
        "detail": null,
        "parent": [
            "229"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "231",
        "name": "Improper Handling of Extra Values",
        "description": "The product does not handle or incorrectly handles when more values are provided than expected.",
        "detail": "**Mode of Introduction:** This typically occurs in situations when only one value is expected.\n",
        "parent": [
            "229"
        ],
        "children": [],
        "related": [
            "120"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "232",
        "name": "Improper Handling of Undefined Values",
        "description": "The product does not handle or incorrectly handles when a value is not defined or supported for the associated parameter, field, or argument name.",
        "detail": null,
        "parent": [
            "229"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "233",
        "name": "Improper Handling of Parameters",
        "description": "The product does not properly handle when the expected number of parameters, fields, or arguments is not provided in input, or if those parameters are undefined.",
        "detail": null,
        "parent": [
            "228"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "234",
        "name": "Failure to Handle Missing Parameter",
        "description": "If too few arguments are sent to a function, the function will still pop the expected number of arguments from the stack. Potentially, a variable number of arguments could be exhausted in a function as well.",
        "detail": "**Consequence Note:** There is the potential for arbitrary code execution with privileges of the vulnerable program if function parameter list is exhausted.\n\n**Consequence Note:** Potentially a program could fail if it needs more arguments then are available.\n",
        "parent": [
            "233"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** This issue can be simply combated with the use of proper build process.\n\n**Mitigation:** Forward declare all functions. This is the recommended solution. Properly forward declaration of all used functions will result in a compiler error if too few arguments are sent to a function.\n",
        "languages": []
    },
    {
        "cwe": "235",
        "name": "Improper Handling of Extra Parameters",
        "description": "The product does not handle or incorrectly handles when the number of parameters, fields, or arguments with the same name exceeds the expected amount.",
        "detail": "**Mode of Introduction:** This typically occurs in situations when only one element is expected to be specified.\n",
        "parent": [
            "233"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "236",
        "name": "Improper Handling of Undefined Parameters",
        "description": "The product does not handle or incorrectly handles when a particular parameter, field, or argument name is not defined or supported by the product.",
        "detail": null,
        "parent": [
            "233"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "237",
        "name": "Improper Handling of Structural Elements",
        "description": "The product does not handle or incorrectly handles inputs that are related to complex structures.",
        "detail": null,
        "parent": [
            "228"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "238",
        "name": "Improper Handling of Incomplete Structural Elements",
        "description": "The product does not handle or incorrectly handles when a particular structural element is not completely specified.",
        "detail": null,
        "parent": [
            "237"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "239",
        "name": "Failure to Handle Incomplete Element",
        "description": "The product does not properly handle when a particular element is not completely specified.",
        "detail": null,
        "parent": [
            "237"
        ],
        "children": [],
        "related": [
            "404"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "24",
        "name": "Path Traversal: '../filedir'",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize \"../\" sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nThe \"../\" manipulation is the canonical manipulation for operating systems that use \"/\" as directory separators, such as UNIX- and Linux-based systems. In some cases, it is useful for bypassing protection schemes in environments for which \"/\" is supported but not the primary separator, such as Windows, which uses \"\\\" but can also accept \"/\".\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "240",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "130"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "241",
        "name": "Improper Handling of Unexpected Data Type",
        "description": "The product does not handle or incorrectly handles when a particular element is not the expected type, e.g. it expects a digit (0-9) but is provided with a letter (A-Z).",
        "detail": null,
        "parent": [
            "228"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "242",
        "name": "Use of Inherently Dangerous Function",
        "description": "The product calls a function that can never be guaranteed to work safely.",
        "detail": "**Extended Description:**\nCertain functions behave in dangerous ways regardless of how they are used. Functions in this category were often implemented without taking security concerns into account. The gets() function is unsafe because it does not perform bounds checking on the size of its input. An attacker can easily send arbitrarily-sized input to gets() and overflow the destination buffer. Similarly, the >> operator is unsafe to use when reading into a statically-allocated character array because it does not perform bounds checking on the size of its input. An attacker can easily send arbitrarily-sized input to the >> operator and overflow the destination buffer.\n",
        "parent": [
            "1177"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Ban the use of dangerous functions. Use their safe equivalent.\n\n**Mitigation:** Use grep or static analysis tools to spot usage of dangerous functions.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "243",
        "name": "Creation of chroot Jail Without Changing Working Directory",
        "description": "The product uses the chroot() system call to create a jail, but does not change the working directory afterward. This does not prevent access to files outside of the jail.",
        "detail": "**Extended Description:**\nImproper use of chroot() may allow attackers to escape from the chroot jail. The chroot() function call does not change the process's current working directory, so relative paths may still refer to file system resources outside of the chroot jail after chroot() has been called.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Background Details:**\n['The chroot() system call allows a process to change its perception of the root directory of the file system. After properly invoking chroot(), a process cannot access any files outside the directory tree defined by the new root directory. Such an environment is called a chroot jail and is commonly used to prevent the possibility that a processes could be subverted and used to access unauthorized files. For instance, many FTP servers run in chroot jails to prevent an attacker who discovers a new vulnerability in the server from being able to download the password file or other sensitive files on the system.']\n",
        "parent": [
            "573",
            "669"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "244",
        "name": "Improper Clearing of Heap Memory Before Release ('Heap Inspection')",
        "description": "Using realloc() to resize buffers that store sensitive information can leave the sensitive information exposed to attack, because it is not removed from memory.",
        "detail": "**Extended Description:**\nWhen sensitive data such as a password or an encryption key is not removed from memory, it could be exposed to an attacker using a \"heap inspection\" attack that reads the sensitive data using memory dumps or other methods. The realloc() function is commonly used to increase the size of a block of allocated memory. This operation often requires copying the contents of the old memory block into a new and larger block. This operation leaves the contents of the original block intact but inaccessible to the program, preventing the program from being able to scrub sensitive data from memory. If an attacker can later examine the contents of a memory dump, the sensitive data could be exposed.\n\n**Consequence Note:** Be careful using vfork() and fork() in security sensitive code. The process state will not be cleaned up and will contain traces of data from past use.\n",
        "parent": [
            "226"
        ],
        "children": [],
        "related": [
            "669"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "245",
        "name": "J2EE Bad Practices: Direct Management of Connections",
        "description": "The J2EE application directly manages connections, instead of using the container's connection management facilities.",
        "detail": "**Extended Description:**\nThe J2EE standard forbids the direct management of connections. It requires that applications use the container's resource management facilities to obtain connections to resources. Every major web application container provides pooled database connection management as part of its resource management framework. Duplicating this functionality in an application is difficult and error prone, which is part of the reason it is forbidden under the J2EE standard.\n",
        "parent": [
            "695"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "246",
        "name": "J2EE Bad Practices: Direct Use of Sockets",
        "description": "The J2EE application directly uses sockets instead of using framework method calls.",
        "detail": "**Extended Description:**\n\n\nThe J2EE standard permits the use of sockets only for the purpose of communication with legacy systems when no higher-level protocol is available. Authoring your own communication protocol requires wrestling with difficult security issues.\n\n\nWithout significant scrutiny by a security expert, chances are good that a custom communication protocol will suffer from security problems. Many of the same issues apply to a custom implementation of a standard protocol. While there are usually more resources available that address security concerns related to implementing a standard protocol, these resources are also available to attackers.\n\n",
        "parent": [
            "695"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use framework method calls instead of using sockets directly.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "248",
        "name": "Uncaught Exception",
        "description": "An exception is thrown from a function, but it is not caught.",
        "detail": "**Extended Description:**\nWhen an exception is not caught, it may cause the program to crash or expose sensitive information.\n\n**Consequence Note:** An uncaught exception could cause the system to be placed in a state that could lead to a crash, exposure of sensitive information or other unintended behaviors.\n",
        "parent": [
            "703",
            "705",
            "755"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": [
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "25",
        "name": "Path Traversal: '/../filedir'",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize \"/../\" sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nSometimes a program checks for \"../\" at the beginning of the input, so a \"/../\" can bypass that check.\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "250",
        "name": "Execution with Unnecessary Privileges",
        "description": "The product performs an operation at a privilege level that is higher than the minimum level required, which creates new weaknesses or amplifies the consequences of other weaknesses.",
        "detail": "**Extended Description:**\n\n\nNew weaknesses can be exposed because running with extra privileges, such as root or Administrator, can disable the normal security checks being performed by the operating system or surrounding environment. Other pre-existing weaknesses can turn into security vulnerabilities if they occur while operating at raised privileges.\n\n\nPrivilege management functions can behave in some less-than-obvious ways, and they have different quirks on different platforms. These inconsistencies are particularly pronounced if you are transitioning from one non-root user to another. Signal handlers and spawned processes run at the privilege of the owning process, so if a process is running as root when a signal fires or a sub-process is executed, the signal handler or sub-process will operate with root privileges.\n\n\n**Mode of Introduction:** \n\nREALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n\n**Mode of Introduction:** \n\nIf an application has this design problem, then it can be easier for the developer to make implementation-related errors such as CWE-271 (Privilege Dropping / Lowering Errors). In addition, the consequences of Privilege Chaining (CWE-268) can become more severe.\n\n\n**Consequence Note:** An attacker will be able to gain access to any resources that are allowed by the extra privileges. Common results include executing code, disabling services, and reading restricted data.\n",
        "parent": [
            "269",
            "657"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** This weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.\n\n**Detection:** \n\nUse monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.\n\n\nAttach the monitor to the process and perform a login. Look for library functions and system calls that indicate when privileges are being raised or dropped. Look for accesses of resources that are restricted to normal users.\n\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tCompare binary / bytecode to application permission manifest\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tHost-based Vulnerability Scanners - Examine configuration for flaws, verifying that audit mechanisms work, ensure host configuration meets certain predefined criteria\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tHost Application Interface Scanner\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tConfiguration Checker\n\t\tPermission Manifest Analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAttack Modeling\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** Identify the functionality that requires additional privileges, such as access to privileged operating system resources. Wrap and centralize this functionality if possible, and isolate the privileged code as much as possible from other code [REF-76]. Raise privileges as late as possible, and drop them as soon as possible to avoid CWE-271. Avoid weaknesses such as CWE-288 and CWE-420 by protecting all possible communication channels that could interact with the privileged code, such as a secondary socket that is only intended to be accessed by administrators.\n\n**Mitigation:** Identify the functionality that requires additional privileges, such as access to privileged operating system resources. Wrap and centralize this functionality if possible, and isolate the privileged code as much as possible from other code [REF-76]. Raise privileges as late as possible, and drop them as soon as possible to avoid CWE-271. Avoid weaknesses such as CWE-288 and CWE-420 by protecting all possible communication channels that could interact with the privileged code, such as a secondary socket that is only intended to be accessed by administrators.\n\n**Mitigation:** Perform extensive input validation for any privileged code that must be exposed to the user and reject anything that does not fit your strict requirements.\n\n**Mitigation:** When dropping privileges, ensure that they have been dropped successfully to avoid CWE-273. As protection mechanisms in the environment get stronger, privilege-dropping calls may fail even if it seems like they would always succeed.\n\n**Mitigation:** If circumstances force you to run with extra privileges, then determine the minimum access level necessary. First identify the different permissions that the software and its users will need to perform their actions, such as file read and write permissions, network socket permissions, and so forth. Then explicitly allow those actions while denying all else [REF-76]. Perform extensive input validation and canonicalization to minimize the chances of introducing a separate vulnerability. This mitigation is much more prone to error than dropping the privileges in the first place.\n\n**Mitigation:** Ensure that the software runs properly under the United States Government Configuration Baseline (USGCB) [REF-199] or an equivalent hardening configuration guide, which many organizations use to limit the attack surface and potential risk of deployed software.\n",
        "languages": []
    },
    {
        "cwe": "252",
        "name": "Unchecked Return Value",
        "description": "The product does not check the return value from a method or function, which can prevent it from detecting unexpected states and conditions.",
        "detail": "**Extended Description:**\nTwo common programmer assumptions are \"this function call can never fail\" and \"it doesn't matter if this function call fails\". If an attacker can force the function to fail or otherwise return a value that is not expected, then the subsequent program logic could lead to a vulnerability, because the product is not in a state that the programmer assumes. For example, if the program calls a function to drop privileges but does not check the return code to ensure that privileges were successfully dropped, then the program will continue to operate with the higher privileges.\n\n**Background Details:**\n['Many functions will return some value about the success of their actions. This will alert the program whether or not to handle any errors caused by that function.']\n\n**Consequence Note:** An unexpected return value could place the system in a state that could lead to a crash or other unintended behaviors.\n",
        "parent": [
            "754"
        ],
        "children": [],
        "related": [
            "273",
            "476"
        ],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Check the results of all functions that return a value and verify that the value is expected.\n\n**Effectiveness:** Checking the return value of the function will typically be sufficient, however beware of race conditions (CWE-362) in a concurrent environment.\n\n**Mitigation:** Ensure that you account for all possible return values from the function.\n\n**Mitigation:** When designing a function, make sure you return a value or throw an exception in case of an error.\n",
        "languages": []
    },
    {
        "cwe": "253",
        "name": "Incorrect Check of Function Return Value",
        "description": "The product incorrectly checks a return value from a function, which prevents it from detecting errors or exceptional conditions.",
        "detail": "**Extended Description:**\nImportant and common functions will return some value about the success of its actions. This will alert the program whether or not to handle any errors caused by that function.\n\n**Consequence Note:** An unexpected return value could place the system in a state that could lead to a crash or other unintended behaviors.\n",
        "parent": [
            "573",
            "754"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use a language or compiler that uses exceptions and requires the catching of those exceptions.\n\n**Mitigation:** Properly check all functions which return a value.\n\n**Mitigation:** When designing any function make sure you return a value or throw an exception in case of an error.\n",
        "languages": []
    },
    {
        "cwe": "256",
        "name": "Plaintext Storage of a Password",
        "description": "Storing a password in plaintext may result in a system compromise.",
        "detail": "**Extended Description:**\nPassword management issues occur when a password is stored in plaintext in an application's properties, configuration file, or memory. Storing a plaintext password in a configuration file allows anyone who can read the file access to the password-protected resource. In some contexts, even storage of a plaintext password in memory is considered a security risk if the password is not cleared immediately after it is used.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Mode of Introduction:** Developers sometimes believe that they cannot defend the application from someone who has access to the configuration, but this belief makes an attacker's job easier.\n",
        "parent": [
            "522"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid storing passwords in easily accessible locations.\n\n**Mitigation:** Consider storing cryptographic hashes of passwords as an alternative to storing in plaintext.\n\n**Mitigation:** A programmer might attempt to remedy the password management problem by obscuring the password with an encoding function, such as base 64 encoding, but this effort does not adequately protect the password because the encoding can be detected and decoded easily.\n",
        "languages": []
    },
    {
        "cwe": "257",
        "name": "Storing Passwords in a Recoverable Format",
        "description": "The storage of passwords in a recoverable format makes them subject to password reuse attacks by malicious users. In fact, it should be noted that recoverable encrypted passwords provide no significant benefit over plaintext passwords since they are subject not only to reuse by malicious attackers but also by malicious insiders. If a system administrator can recover a password directly, or use a brute force search on the available information, the administrator can use the password on other accounts.",
        "detail": "**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** User's passwords may be revealed.\n\n**Consequence Note:** Revealed passwords may be reused elsewhere to impersonate the users in question.\n",
        "parent": [
            "522"
        ],
        "children": [],
        "related": [
            "259",
            "798"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use strong, non-reversible encryption to protect stored passwords.\n",
        "languages": []
    },
    {
        "cwe": "258",
        "name": "Empty Password in Configuration File",
        "description": "Using an empty string as a password is insecure.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "260",
            "521"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Passwords should be at least eight characters long -- the longer the better. Avoid passwords that are in any way similar to other passwords you have. Avoid using words that may be found in a dictionary, names book, on a map, etc. Consider incorporating numbers and/or punctuation into your password. If you do use common words, consider replacing letters in that word with numbers and punctuation. However, do not use \"similar-looking\" punctuation. For example, it is not a good idea to change cat to c@t, ca+, (@+, or anything similar. Finally, it is never appropriate to use an empty string as a password.\n",
        "languages": []
    },
    {
        "cwe": "259",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "257",
            "656"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "26",
        "name": "Path Traversal: '/dir/../filename'",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize \"/dir/../filename\" sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nThe '/dir/../filename' manipulation is useful for bypassing some path traversal protection schemes. Sometimes a program only checks for \"../\" at the beginning of the input, so a \"/../\" can bypass that check.\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "260",
        "name": "Password in Configuration File",
        "description": "The product stores a password in a configuration file that might be accessible to actors who do not know the password.",
        "detail": "**Extended Description:**\nThis can result in compromise of the system for which the password is used. An attacker could gain access to this file and learn the stored password or worse yet, change the password to one of their choosing.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "522"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid storing passwords in easily accessible locations.\n\n**Mitigation:** Consider storing cryptographic hashes of passwords as an alternative to storing in plaintext.\n",
        "languages": []
    },
    {
        "cwe": "261",
        "name": "Weak Encoding for Password",
        "description": "Obscuring a password with a trivial encoding does not protect the password.",
        "detail": "**Extended Description:**\nPassword management issues occur when a password is stored in plaintext in an application's properties or configuration file. A programmer can attempt to remedy the password management problem by obscuring the password with an encoding function, such as base 64 encoding, but this effort does not adequately protect the password.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "522"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Passwords should be encrypted with keys that are at least 128 bits in length for adequate security.\n",
        "languages": []
    },
    {
        "cwe": "262",
        "name": "Not Using Password Aging",
        "description": "The product does not have a mechanism in place for managing password aging.",
        "detail": "**Extended Description:**\n\n\nPassword aging (or password rotation) is a policy that forces users to change their passwords after a defined time period passes, such as every 30 or 90 days. Without mechanisms such as aging, users might not change their passwords in a timely manner.\n\n\nNote that while password aging was once considered an important security feature, it has since fallen out of favor by many, because it is not as effective against modern threats compared to other mechanisms such as slow hashes. In addition, forcing frequent changes can unintentionally encourage users to select less-secure passwords. However, password aging is still in use due to factors such as compliance requirements, e.g., Payment Card Industry Data Security Standard (PCI DSS).\n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** As passwords age, the probability that they are compromised grows.\n",
        "parent": [
            "1390"
        ],
        "children": [],
        "related": [
            "309",
            "324"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** As part of a product's design, require users to change their passwords regularly and avoid reusing previous passwords.\n\n**Mitigation:** Developers might disable clipboard paste operations into password fields as a way to discourage users from pasting a password into a clipboard. However, this might encourage users to choose less-secure passwords that are easier to type, and it can reduce the usability of password managers [REF-1294].\n",
        "languages": []
    },
    {
        "cwe": "263",
        "name": "Password Aging with Long Expiration",
        "description": "The product supports password aging, but the expiration period is too long.",
        "detail": "**Extended Description:**\n\n\nPassword aging (or password rotation) is a policy that forces users to change their passwords after a defined time period passes, such as every 30 or 90 days. A long expiration provides more time for attackers to conduct password cracking before users are forced to change to a new password.\n\n\nNote that while password aging was once considered an important security feature, it has since fallen out of favor by many, because it is not as effective against modern threats compared to other mechanisms such as slow hashes. In addition, forcing frequent changes can unintentionally encourage users to select less-secure passwords. However, password aging is still in use due to factors such as compliance requirements, e.g., Payment Card Industry Data Security Standard (PCI DSS).\n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** As passwords age, the probability that they are compromised grows.\n",
        "parent": [
            "1390"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Ensure that password aging is limited so that there is a defined maximum age for passwords. Note that if the expiration window is too short, it can cause users to generate poor or predictable passwords.\n\n**Mitigation:** Ensure that the user is notified several times leading up to the password expiration.\n\n**Mitigation:** Create mechanisms to prevent users from reusing passwords or creating similar passwords.\n\n**Mitigation:** Developers might disable clipboard paste operations into password fields as a way to discourage users from pasting a password into a clipboard. However, this might encourage users to choose less-secure passwords that are easier to type, and it can reduce the usability of password managers [REF-1294].\n",
        "languages": []
    },
    {
        "cwe": "266",
        "name": "Incorrect Privilege Assignment",
        "description": "A product incorrectly assigns a privilege to a particular actor, creating an unintended sphere of control for that actor.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** A user can access restricted functionality and/or sensitive information that may include administrative functionality and user accounts.\n",
        "parent": [
            "269"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n",
        "languages": []
    },
    {
        "cwe": "267",
        "name": "Privilege Defined With Unsafe Actions",
        "description": "A particular privilege, role, capability, or right can be used to perform unsafe actions that were not intended, even when it is assigned to the correct entity.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** A user can access restricted functionality and/or sensitive information that may include administrative functionality and user accounts.\n",
        "parent": [
            "269"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n",
        "languages": []
    },
    {
        "cwe": "268",
        "name": "Privilege Chaining",
        "description": "Two distinct privileges, roles, capabilities, or rights can be combined in a way that allows an entity to perform unsafe actions that would not be allowed without that combination.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** A user can be given or gain access rights of another user. This can give the user unauthorized access to sensitive information including the access information of another user.\n",
        "parent": [
            "269"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.\n\n**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n",
        "languages": []
    },
    {
        "cwe": "269",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "648"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "27",
        "name": "Path Traversal: 'dir/../../filename'",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize multiple internal \"../\" sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nThe 'directory/../../filename' manipulation is useful for bypassing some path traversal protection schemes. Sometimes a program only removes one \"../\" sequence, so multiple \"../\" can bypass that check. Alternately, this manipulation could be used to bypass a check for \"../\" at the beginning of the pathname, moving up more than one directory level.\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "270",
        "name": "Privilege Context Switching Error",
        "description": "The product does not properly manage privileges while it is switching between different contexts that have different privileges or spheres of control.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** A user can assume the identity of another user with separate privileges in another context. This will give the user unauthorized access that may allow them to acquire the access information of other users.\n",
        "parent": [
            "269"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.\n",
        "languages": []
    },
    {
        "cwe": "271",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "272",
            "273"
        ],
        "related": [
            "274"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "272",
        "name": "Least Privilege Violation",
        "description": "The elevated privilege level required to perform operations such as chroot() should be dropped immediately after the operation is performed.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker may be able to access resources with the elevated privilege that could not be accessed with the attacker's original privileges. This is particularly likely in conjunction with another flaw, such as a buffer overflow.\n",
        "parent": [
            "271"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tCompare binary / bytecode to application permission manifest\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tHost-based Vulnerability Scanners - Examine configuration for flaws, verifying that audit mechanisms work, ensure host configuration meets certain predefined criteria\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tPermission Manifest Analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAttack Modeling\n\n**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** Follow the principle of least privilege when assigning access rights to entities in a software system.\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n",
        "languages": []
    },
    {
        "cwe": "273",
        "name": "Improper Check for Dropped Privileges",
        "description": "The product attempts to drop privileges but does not check or incorrectly checks to see if the drop succeeded.",
        "detail": "**Extended Description:**\nIf the drop fails, the product will continue to run with the raised privileges, which might provide additional access to unprivileged users.\n\n**Mode of Introduction:** \n\nREALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n\nThis issue is likely to occur in restrictive environments in which the operating system or application provides fine-grained control over privilege management.\n\n\n**Background Details:**\n['In Windows based environments that have access control, impersonation is used so that access checks can be performed on a client identity by a server with higher privileges. By impersonating the client, the server is restricted to client-level security -- although in different threads it may have much higher privileges.']\n\n**Consequence Note:** If privileges are not dropped, neither are access rights of the user. Often these rights can be prevented from being dropped.\n\n**Consequence Note:** If privileges are not dropped, in some cases the system may record actions as the user which is being impersonated rather than the impersonator.\n",
        "parent": [
            "271",
            "754"
        ],
        "children": [],
        "related": [
            "252"
        ],
        "scopes": [
            "Access Control",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n\n**Mitigation:** Check the results of all functions that return a value and verify that the value is expected.\n\n**Effectiveness:** Checking the return value of the function will typically be sufficient, however beware of race conditions (CWE-362) in a concurrent environment.\n\n**Mitigation:** In Windows, make sure that the process token has the SeImpersonatePrivilege(Microsoft Server 2003). Code that relies on impersonation for security must ensure that the impersonation succeeded, i.e., that a proper privilege demotion happened.\n",
        "languages": []
    },
    {
        "cwe": "274",
        "name": "Improper Handling of Insufficient Privileges",
        "description": "The product does not handle or incorrectly handles when it has insufficient privileges to perform an operation, leading to resultant weaknesses.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "269",
            "755"
        ],
        "children": [],
        "related": [
            "271"
        ],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "276",
        "name": "Incorrect Default Permissions",
        "description": "During installation, installed file permissions are set to allow anyone to modify those files.",
        "detail": null,
        "parent": [
            "732"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInter-application Flow Analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tHost-based Vulnerability Scanners - Examine configuration for flaws, verifying that audit mechanisms work, ensure host configuration meets certain predefined criteria\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tHost Application Interface Scanner\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\t\tAutomated Monitored Execution\n\t\tForced Path Execution\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tConfiguration Checker\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** The architecture needs to access and modification attributes for files to only those users who actually require those actions.\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n",
        "languages": []
    },
    {
        "cwe": "277",
        "name": "Insecure Inherited Permissions",
        "description": "A product defines a set of insecure permissions that are inherited by objects that are created by the program.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "732"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n",
        "languages": []
    },
    {
        "cwe": "278",
        "name": "Insecure Preserved Inherited Permissions",
        "description": "A product inherits a set of insecure permissions for an object, e.g. when copying from an archive file, without user awareness or involvement.",
        "detail": null,
        "parent": [
            "732"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n",
        "languages": []
    },
    {
        "cwe": "279",
        "name": "Incorrect Execution-Assigned Permissions",
        "description": "While it is executing, the product sets the permissions of an object in a way that violates the intended permissions that have been specified by the user.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "732"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n",
        "languages": []
    },
    {
        "cwe": "28",
        "name": "Path Traversal: '..\\filedir'",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize \"..\\\" sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nThe '..\\' manipulation is the canonical manipulation for operating systems that use \"\\\" as directory separators, such as Windows. However, it is also useful for bypassing path traversal protection schemes that only assume that the \"/\" separator is valid.\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "280",
        "name": "Improper Handling of Insufficient Permissions or Privileges ",
        "description": "The product does not handle or incorrectly handles when it has insufficient privileges to access resources or functionality as specified by their permissions. This may cause it to follow unexpected code paths that may leave the product in an invalid state.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "755"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nCompartmentalize the system to have \"safe\" areas where trust boundaries can be unambiguously drawn. Do not allow sensitive data to go outside of the trust boundary and always be careful when interfacing with a compartment outside of the safe area.\n\n\nEnsure that appropriate compartmentalization is built into the system design, and the compartmentalization allows for and reinforces privilege separation functionality. Architects and designers should rely on the principle of least privilege to decide the appropriate time to use privileges and the time to drop privileges.\n\n\n**Mitigation:** Always check to see if you have successfully accessed a resource or system functionality, and use proper error handling if it is unsuccessful. Do this even when you are operating in a highly privileged mode, because errors or environmental conditions might still cause a failure. For example, environments with highly granular permissions/privilege models, such as Windows or Linux capabilities, can cause unexpected failures.\n",
        "languages": []
    },
    {
        "cwe": "281",
        "name": "Improper Preservation of Permissions",
        "description": "The product does not preserve permissions or incorrectly preserves permissions when copying, restoring, or sharing objects, which can cause them to have less restrictive permissions than intended.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "732"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "282",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "283",
            "708"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "283",
        "name": "Unverified Ownership",
        "description": "The product does not properly verify that a critical resource is owned by the proper entity.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could gain unauthorized access to system resources.\n",
        "parent": [
            "282"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Very carefully manage the setting, management, and handling of privileges. Explicitly manage trust zones in the software.\n\n**Mitigation:** Consider following the principle of separation of privilege. Require multiple conditions to be met before permitting access to a system resource.\n",
        "languages": []
    },
    {
        "cwe": "284",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "346",
            "639",
            "749"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "285",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1230",
            "552"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "286",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "842"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "287",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "290",
            "294",
            "295",
            "306",
            "307",
            "521",
            "640",
            "645",
            "798"
        ],
        "related": [
            "613"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "288",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "425"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "289",
        "name": "Authentication Bypass by Alternate Name",
        "description": "The product performs authentication based on the name of a resource being accessed, or the name of the actor performing the access, but it does not properly check all possible names for that resource or actor.",
        "detail": "**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "1390"
        ],
        "children": [],
        "related": [
            "178"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Avoid making decisions based on names of resources (e.g. files) if those resources can have alternate names.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "29",
        "name": "Path Traversal: '\\..\\filename'",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize '\\..\\filename' (leading backslash dot dot) sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nThis is similar to CWE-25, except using \"\\\" instead of \"/\". Sometimes a program checks for \"..\\\" at the beginning of the input, so a \"\\..\\\" can bypass that check. It is also useful for bypassing path traversal protection schemes that only assume that the \"/\" separator is valid.\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "290",
        "name": "Authentication Bypass by Spoofing",
        "description": "This attack-focused weakness is caused by incorrectly implemented authentication schemes that are subject to spoofing attacks.",
        "detail": "**Consequence Note:** This weakness can allow an attacker to access resources which are not otherwise accessible without proper authentication.\n",
        "parent": [
            "1390",
            "287"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "291",
        "name": "Reliance on IP Address for Authentication",
        "description": "The product uses an IP address for authentication.",
        "detail": "**Extended Description:**\nIP addresses can be easily spoofed. Attackers can forge the source IP address of the packets they send, but response packets will return to the forged IP address. To see the response packets, the attacker has to sniff the traffic between the victim machine and the forged IP address. In order to accomplish the required sniffing, attackers typically attempt to locate themselves on the same subnet as the victim machine. Attackers may be able to circumvent this requirement by using source routing, but source routing is disabled across much of the Internet today. In summary, IP address verification can be a useful part of an authentication scheme, but it should not be the single factor required for authentication.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** Malicious users can fake authentication information, impersonating any IP address.\n",
        "parent": [
            "290",
            "923"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Use other means of identity verification that cannot be simply spoofed. Possibilities include a username/password or certificate.\n",
        "languages": []
    },
    {
        "cwe": "293",
        "name": "Using Referer Field for Authentication",
        "description": "The referer field in HTTP requests can be easily modified and, as such, is not a valid means of message integrity checking.",
        "detail": "**Alternate Terms:** referrer\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Background Details:**\n['The referer field in HTML requests can be simply modified by malicious users, rendering it useless as a means of checking the validity of the request in question.']\n\n**Consequence Note:** Actions, which may not be authorized otherwise, can be carried out as if they were validated by the server referred to.\n",
        "parent": [
            "290"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** In order to usefully check if a given action is authorized, some means of strong authentication and method protection must be used. Use other means of authorization that cannot be simply spoofed. Possibilities include a username/password or certificate.\n",
        "languages": []
    },
    {
        "cwe": "294",
        "name": "Authentication Bypass by Capture-replay",
        "description": "A capture-replay flaw exists when the design of the product makes it possible for a malicious user to sniff network traffic and bypass authentication by replaying it to the server in question to the same effect as the original message (or with minor changes).",
        "detail": "**Extended Description:**\nCapture-replay attacks are common and can be difficult to defeat without cryptography. They are a subset of network injection attacks that rely on observing previously-sent valid commands, then changing them slightly if necessary and resending the same commands to the server.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** Messages sent with a capture-relay attack allow access to resources which are not otherwise accessible without proper authentication.\n",
        "parent": [
            "1390",
            "287"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Utilize some sequence or time stamping functionality along with a checksum which takes this into account in order to ensure that messages can be parsed only once.\n\n**Mitigation:** Since any attacker who can listen to traffic can see sequence numbers, it is necessary to sign messages with some kind of cryptography to ensure that sequence numbers are not simply doctored along with content.\n",
        "languages": []
    },
    {
        "cwe": "295",
        "name": "Improper Certificate Validation",
        "description": "The product does not validate, or incorrectly validates, a certificate.",
        "detail": "**Extended Description:**\nWhen a certificate is invalid or malicious, it might allow an attacker to spoof a trusted entity by interfering in the communication path between the host and client. The product might connect to a malicious host while believing it is a trusted host, or the product might be deceived into accepting spoofed data that appears to originate from a trusted host.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Mode of Introduction:** When the product uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.\n\n**Background Details:**\n['A certificate is a token that associates an identity (principal) to a cryptographic key. Certificates can be used to check if a public key belongs to the assumed owner.']\n",
        "parent": [
            "287"
        ],
        "children": [],
        "related": [
            "322"
        ],
        "scopes": [
            "Authentication",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tMan-in-the-middle attack tool\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** Certificates should be carefully managed and checked to assure that data are encrypted with the intended owner's public key.\n\n**Mitigation:** If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the hostname.\n",
        "languages": []
    },
    {
        "cwe": "296",
        "name": "Improper Following of a Certificate's Chain of Trust",
        "description": "The product does not follow, or incorrectly follows, the chain of trust for a certificate back to a trusted root certificate, resulting in incorrect trust of any resource that is associated with that certificate.",
        "detail": "**Extended Description:**\n\n\nIf a system does not follow the chain of trust of a certificate to a root server, the certificate loses all usefulness as a metric of trust. Essentially, the trust gained from a certificate is derived from a chain of trust -- with a reputable trusted entity at the end of that list. The end user must trust that reputable source, and this reputable source must vouch for the resource in question through the medium of the certificate.\n\n\nIn some cases, this trust traverses several entities who vouch for one another. The entity trusted by the end user is at one end of this trust chain, while the certificate-wielding resource is at the other end of the chain. If the user receives a certificate at the end of one of these trust chains and then proceeds to check only that the first link in the chain, no real trust has been derived, since the entire chain must be traversed back to a trusted source to verify the certificate.\n\n\nThere are several ways in which the chain of trust might be broken, including but not limited to:\n\n\n  - Any certificate in the chain is self-signed, unless it the root.\n\n  - Not every intermediate certificate is checked, starting from the original certificate all the way up to the root certificate.\n\n  - An intermediate, CA-signed certificate does not have the expected Basic Constraints or other important extensions.\n\n  - The root certificate has been compromised or authorized to the wrong party.\n\n\n\n**Mode of Introduction:** When the product uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Exploitation of this flaw can lead to the trust of data that may have originated with a spoofed source.\n\n**Consequence Note:** Data, requests, or actions taken by the attacking entity can be carried out as a spoofed benign entity.\n",
        "parent": [
            "295",
            "573"
        ],
        "children": [],
        "related": [
            "370"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Ensure that proper certificate checking is included in the system design.\n\n**Mitigation:** Understand, and properly implement all checks necessary to ensure the integrity of certificate trust integrity.\n\n**Mitigation:** If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the full chain of trust.\n",
        "languages": []
    },
    {
        "cwe": "297",
        "name": "Improper Validation of Certificate with Host Mismatch",
        "description": "The product communicates with a host that provides a certificate, but the product does not properly ensure that the certificate is actually associated with that host.",
        "detail": "**Extended Description:**\n\n\nEven if a certificate is well-formed, signed, and follows the chain of trust, it may simply be a valid certificate for a different site than the site that the product is interacting with. If the certificate's host-specific data is not properly checked - such as the Common Name (CN) in the Subject or the Subject Alternative Name (SAN) extension of an X.509 certificate - it may be possible for a redirection or spoofing attack to allow a malicious host with a valid certificate to provide data, impersonating a trusted host. In order to ensure data integrity, the certificate must be valid and it must pertain to the site that is being accessed.\n\n\nEven if the product attempts to check the hostname, it is still possible to incorrectly check the hostname. For example, attackers could create a certificate with a name that begins with a trusted name followed by a NUL byte, which could cause some string-based comparisons to only examine the portion that contains the trusted name.\n\n\nThis weakness can occur even when the product uses Certificate Pinning, if the product does not verify the hostname at the time a certificate is pinned.\n\n\n**Mode of Introduction:** When the product uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** The data read from the system vouched for by the certificate may not be from the expected system.\n\n**Consequence Note:** Trust afforded to the system in question - based on the malicious certificate - may allow for spoofing or redirection attacks.\n",
        "parent": [
            "295",
            "923"
        ],
        "children": [],
        "related": [
            "370"
        ],
        "scopes": [
            "Access Control",
            "Authentication"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Detection:** Set up an untrusted endpoint (e.g. a server) with which the product will connect. Create a test certificate that uses an invalid hostname but is signed by a trusted CA and provide this certificate from the untrusted endpoint. If the product performs any operations instead of disconnecting and reporting an error, then this indicates that the hostname is not being checked and the test certificate has been accepted.\n\n**Detection:** When Certificate Pinning is being used in a mobile application, consider using a tool such as Spinner [REF-955]. This methodology might be extensible to other technologies.\n\n**Mitigation:** Fully check the hostname of the certificate and provide the user with adequate information about the nature of the problem and how to proceed.\n\n**Mitigation:** If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the hostname.\n",
        "languages": []
    },
    {
        "cwe": "298",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "324"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "299",
        "name": "Improper Check for Certificate Revocation",
        "description": "The product does not check or incorrectly checks the revocation status of a certificate, which may cause it to use a certificate that has been compromised.",
        "detail": "**Extended Description:**\nAn improper check for certificate revocation is a far more serious flaw than related certificate failures. This is because the use of any revoked certificate is almost certainly malicious. The most common reason for certificate revocation is compromise of the system in question, with the result that no legitimate servers will be using a revoked certificate, unless they are sorely out of sync.\n\n**Mode of Introduction:** When the product uses certificate pinning, the developer might not properly validate all relevant components of the certificate before pinning the certificate. This can make it difficult or expensive to test after the pinning is complete.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Trust may be assigned to an entity who is not who it claims to be.\n\n**Consequence Note:** Data from an untrusted (and possibly malicious) source may be integrated.\n\n**Consequence Note:** Data may be disclosed to an entity impersonating a trusted entity, resulting in information disclosure.\n",
        "parent": [
            "295",
            "404"
        ],
        "children": [
            "370"
        ],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Ensure that certificates are checked for revoked status.\n\n**Mitigation:** If certificate pinning is being used, ensure that all relevant properties of the certificate are fully validated before the certificate is pinned, including the revoked status.\n",
        "languages": []
    },
    {
        "cwe": "30",
        "name": "Path Traversal: '\\dir\\..\\filename'",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize '\\dir\\..\\filename' (leading backslash dot dot) sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nThis is similar to CWE-26, except using \"\\\" instead of \"/\". The '\\dir\\..\\filename' manipulation is useful for bypassing some path traversal protection schemes. Sometimes a program only checks for \"..\\\" at the beginning of the input, so a \"\\..\\\" can bypass that check.\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "300",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "603"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "301",
        "name": "Reflection Attack in an Authentication Protocol",
        "description": "Simple authentication protocols are subject to reflection attacks if a malicious user can use the target machine to impersonate a trusted user.",
        "detail": "**Extended Description:**\n\n\nA mutual authentication protocol requires each party to respond to a random challenge by the other party by encrypting it with a pre-shared key. Often, however, such protocols employ the same pre-shared key for communication with a number of different entities. A malicious user or an attacker can easily compromise this protocol without possessing the correct key by employing a reflection attack on the protocol.\n\n\nReflection attacks capitalize on mutual authentication schemes in order to trick the target into revealing the secret shared between it and another valid user. In a basic mutual-authentication scheme, a secret is known to both the valid user and the server; this allows them to authenticate. In order that they may verify this shared secret without sending it plainly over the wire, they utilize a Diffie-Hellman-style scheme in which they each pick a value, then request the hash of that value as keyed by the shared secret. In a reflection attack, the attacker claims to be a valid user and requests the hash of a random value from the server. When the server returns this value and requests its own value to be hashed, the attacker opens another connection to the server. This time, the hash requested by the attacker is the value which the server requested in the first connection. When the server returns this hashed value, it is used in the first connection, authenticating the attacker successfully as the impersonated valid user.\n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** The primary result of reflection attacks is successful authentication with a target machine -- as an impersonated user.\n",
        "parent": [
            "1390"
        ],
        "children": [],
        "related": [
            "327"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Use different keys for the initiator and responder or of a different type of challenge for the initiator and responder.\n\n**Mitigation:** Let the initiator prove its identity before proceeding.\n",
        "languages": []
    },
    {
        "cwe": "302",
        "name": "Authentication Bypass by Assumed-Immutable Data",
        "description": "The authentication scheme or implementation uses key data elements that are assumed to be immutable, but can be controlled or modified by the attacker.",
        "detail": "**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "1390",
            "807"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Implement proper protection for immutable data (e.g. environment variable, hidden form fields, etc.)\n",
        "languages": []
    },
    {
        "cwe": "303",
        "name": "Incorrect Implementation of Authentication Algorithm",
        "description": "The requirements for the product dictate the use of an established authentication algorithm, but the implementation of the algorithm is incorrect.",
        "detail": "**Extended Description:**\nThis incorrect implementation may allow authentication to be bypassed.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "1390"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "304",
        "name": "Missing Critical Step in Authentication",
        "description": "The product implements an authentication technique, but it skips a step that weakens the technique.",
        "detail": "**Extended Description:**\nAuthentication techniques should follow the algorithms that define them exactly, otherwise authentication can be bypassed or more easily subjected to brute force attacks.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** This weakness can lead to the exposure of resources or functionality to unintended actors, possibly providing attackers with sensitive information or allowing attackers to execute arbitrary code.\n",
        "parent": [
            "303",
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "305",
        "name": "Authentication Bypass by Primary Weakness",
        "description": "The authentication algorithm is sound, but the implemented mechanism can be bypassed as the result of a separate weakness that is primary to the authentication error.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "1390"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "306",
        "name": "Missing Authentication for Critical Function",
        "description": "The product does not perform any authentication for functionality that requires a provable user identity or consumes a significant amount of resources.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Mode of Introduction:** Developers sometimes perform authentication at the primary channel, but open up a secondary channel that is assumed to be private. For example, a login mechanism may be listening on one network port, but after successful authentication, it may open up a second port where it waits for the connection, but avoids authentication because it assumes that only the authenticated party will connect to the port.\n\n**Mode of Introduction:** When migrating data to the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), there is a risk of losing the protections that were originally provided by hosting on internal networks. If access does not require authentication, it can be easier for attackers to access the data from anywhere on the Internet.\n\n**Consequence Note:** Exposing critical functionality essentially provides an attacker with the privilege level of that functionality. The consequences will depend on the associated functionality, but they can range from reading or modifying sensitive data, accessing administrative or other privileged functionality, or possibly even executing arbitrary code.\n",
        "parent": [
            "287"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.\n\n\nSpecifically, manual static analysis is useful for evaluating the correctness of custom authentication mechanisms.\n\n\n**Detection:** \n\nAutomated static analysis is useful for detecting commonly-used idioms for authentication. A tool may be able to analyze related configuration files, such as .htaccess in Apache web servers, or detect the usage of commonly-used authentication libraries.\n\n\nGenerally, automated static analysis tools have difficulty detecting custom authentication schemes. In addition, the software's design may include some functionality that is accessible to any user and does not require an established identity; an automated technique that detects the absence of authentication may report false positives.\n\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tHost Application Interface Scanner\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAttack Modeling\n\n**Mitigation:** \n\nDivide the software into anonymous, normal, privileged, and administrative areas. Identify which of these areas require a proven user identity, and use a centralized authentication capability.\n\n\nIdentify all potential communication channels, or other means of interaction with the software, to ensure that all channels are appropriately protected, including those channels that are assumed to be accessible only by authorized parties. Developers sometimes perform authentication at the primary channel, but open up a secondary channel that is assumed to be private. For example, a login mechanism may be listening on one network port, but after successful authentication, it may open up a second port where it waits for the connection, but avoids authentication because it assumes that only the authenticated party will connect to the port.\n\n\nIn general, if the software or protocol allows a single session or user state to persist across multiple connections or channels, authentication and appropriate credential management need to be used throughout.\n\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nWhere possible, avoid implementing custom, \"grow-your-own\" authentication routines and consider using authentication capabilities as provided by the surrounding framework, operating system, or environment. These capabilities may avoid common weaknesses that are unique to authentication; support automatic auditing and tracking; and make it easier to provide a clear separation between authentication tasks and authorization tasks.\n\n\nIn environments such as the World Wide Web, the line between authentication and authorization is sometimes blurred. If custom authentication routines are required instead of those provided by the server, then these routines must be applied to every single page, since these pages could be requested directly.\n\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, consider using libraries with authentication capabilities such as OpenSSL or the ESAPI Authenticator [REF-45].\n\n\n**Mitigation:** When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to require strong authentication for users who should be allowed to access the data [REF-1297] [REF-1298] [REF-1302].\n",
        "languages": []
    },
    {
        "cwe": "307",
        "name": "Improper Restriction of Excessive Authentication Attempts",
        "description": "The product does not implement sufficient measures to prevent multiple failed authentication attempts within a short time frame.",
        "detail": "**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** An attacker could perform an arbitrary number of authentication attempts using different passwords, and eventually gain access to the targeted account using a brute force attack.\n",
        "parent": [
            "1390",
            "287",
            "799"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tHost-based Vulnerability Scanners - Examine configuration for flaws, verifying that audit mechanisms work, ensure host configuration meets certain predefined criteria\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tForced Path Execution\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tConfiguration Checker\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** \n\nCommon protection mechanisms include:\n\n\n  - Disconnecting the user after a small number of failed attempts\n\n  - Implementing a timeout\n\n  - Locking out a targeted account\n\n  - Requiring a computational task on the user's part.\n\n\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nConsider using libraries with authentication capabilities such as OpenSSL or the ESAPI Authenticator. [REF-45]\n\n",
        "languages": []
    },
    {
        "cwe": "308",
        "name": "Use of Single-factor Authentication",
        "description": "The use of single-factor authentication can lead to unnecessary risk of compromise when compared with the benefits of a dual-factor authentication scheme.",
        "detail": "**Extended Description:**\nWhile the use of multiple authentication schemes is simply piling on more complexity on top of authentication, it is inestimably valuable to have such measures of redundancy. The use of weak, reused, and common passwords is rampant on the internet. Without the added protection of multiple authentication schemes, a single mistake can result in the compromise of an account. For this reason, if multiple schemes are possible and also easy to use, they should be implemented and required.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** If the secret in a single-factor authentication scheme gets compromised, full authentication is possible.\n",
        "parent": [
            "1390",
            "654"
        ],
        "children": [],
        "related": [
            "309"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Use multiple independent authentication schemes, which ensures that -- if one of the methods is compromised -- the system itself is still likely safe from compromise.\n",
        "languages": []
    },
    {
        "cwe": "309",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "262"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "31",
        "name": "Path Traversal: 'dir\\..\\..\\filename'",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize 'dir\\..\\..\\filename' (multiple internal backslash dot dot) sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nThe 'dir\\..\\..\\filename' manipulation is useful for bypassing some path traversal protection schemes. Sometimes a program only removes one \"..\\\" sequence, so multiple \"..\\\" can bypass that check. Alternately, this manipulation could be used to bypass a check for \"..\\\" at the beginning of the pathname, moving up more than one directory level.\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "311",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "312",
            "319"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "312",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "313",
        "name": "Cleartext Storage in a File or on Disk",
        "description": "The product stores sensitive information in cleartext in a file, or on disk.",
        "detail": "**Extended Description:**\nThe sensitive information could be read by attackers with access to the file, or with physical or administrator access to the raw disk. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "312"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "314",
        "name": "Cleartext Storage in the Registry",
        "description": "The product stores sensitive information in cleartext in the registry.",
        "detail": "**Extended Description:**\nAttackers can read the information by accessing the registry key. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "312"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "315",
        "name": "Cleartext Storage of Sensitive Information in a Cookie",
        "description": "The product stores sensitive information in cleartext in a cookie.",
        "detail": "**Extended Description:**\nAttackers can use widely-available tools to view the cookie and read the sensitive information. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "312"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "316",
        "name": "Cleartext Storage of Sensitive Information in Memory",
        "description": "The product stores sensitive information in cleartext in memory.",
        "detail": "**Extended Description:**\n\n\nThe sensitive memory might be saved to disk, stored in a core dump, or remain uncleared if the product crashes, or if the programmer does not properly clear the memory before freeing it.\n\n\nIt could be argued that such problems are usually only exploitable by those with administrator privileges. However, swapping could cause the memory to be written to disk and leave it accessible to physical attack afterwards. Core dump files might have insecure permissions or be stored in archive files that are accessible to untrusted people. Or, uncleared sensitive memory might be inadvertently exposed to attackers due to another weakness.\n\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "312"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "317",
        "name": "Cleartext Storage of Sensitive Information in GUI",
        "description": "The product stores sensitive information in cleartext within the GUI.",
        "detail": "**Extended Description:**\nAn attacker can often obtain data from a GUI, even if hidden, by using an API to directly access GUI objects such as windows and menus. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "312"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "318",
        "name": "Cleartext Storage of Sensitive Information in Executable",
        "description": "The product stores sensitive information in cleartext in an executable.",
        "detail": "**Extended Description:**\nAttackers can reverse engineer binary code to obtain secret data. This is especially easy when the cleartext is plain ASCII. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.\n",
        "parent": [
            "312"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "319",
        "name": "Cleartext Transmission of Sensitive Information",
        "description": "The product transmits sensitive or security-critical data in cleartext in a communication channel that can be sniffed by unauthorized actors.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Mode of Introduction:** For hardware, this may be introduced when design does not plan for an attacker having physical access while a legitimate user is remotely operating the device.\n\n**Consequence Note:** Anyone can read the information by gaining access to the channel being used for communication. Many communication channels can be \"sniffed\" (monitored) by adversaries during data transmission. For example, in networking, packets can traverse many intermediary nodes from the source to the destination, whether across the internet, an internal network, the cloud, etc. Some actors might have privileged access to a network interface or any link along the channel, such as a router, but they might not be authorized to collect the underlying data. As a result, network traffic could be sniffed by adversaries, spilling security-critical data.\n\n**Consequence Note:** When full communications are recorded or logged, such as with a packet dump, an adversary could attempt to obtain the dump long after the transmission has occurred and try to \"sniff\" the cleartext from the recorded communications in the dump itself. Even if the information is encoded in a way that is not human-readable, certain techniques could determine which encoding is being used, then decode the information.\n",
        "parent": [
            "311"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nUse monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.\n\n\nAttach the monitor to the process, trigger the feature that sends the data, and look for the presence or absence of common cryptographic functions in the call tree. Monitor the network and determine if the data packets contain readable commands. Tools exist for detecting if certain encodings are in use. If the traffic contains high entropy, this might indicate the usage of encryption.\n\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Before transmitting, encrypt the data using reliable, confidentiality-protecting cryptographic protocols.\n\n**Mitigation:** When using web applications with SSL, use SSL for the entire session from login to logout, not just for the initial login page.\n\n**Mitigation:** When designing hardware platforms, ensure that approved encryption algorithms (such as those recommended by NIST) protect paths from security critical data to trusted user applications.\n\n**Mitigation:** Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.\n\n**Mitigation:** Configure servers to use encrypted channels for communication, which may include SSL or other secure protocols.\n",
        "languages": []
    },
    {
        "cwe": "32",
        "name": "Path Traversal: '...' (Triple Dot)",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize '...' (triple dot) sequences that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\n\n\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n\nThe '...' manipulation is useful for bypassing some path traversal protection schemes. On some Windows systems, it is equivalent to \"..\\..\" and might bypass checks that assume only two dots are valid. Incomplete filtering, such as removal of \"./\" sequences, can ultimately produce valid \"..\" sequences due to a collapse into unsafe value (CWE-182).\n\n",
        "parent": [
            "23"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "321",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "656"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "322",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "295"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "323",
        "name": "Reusing a Nonce, Key Pair in Encryption",
        "description": "Nonces should be used for the present occasion and only once.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Background Details:**\n['Nonces are often bundled with a key in a communication exchange to produce a new session key for each exchange.']\n\n**Consequence Note:** Potentially a replay attack, in which an attacker could send the same data twice, could be crafted if nonces are allowed to be reused. This could allow a user to send a message which masquerades as a valid message from a valid user.\n",
        "parent": [
            "344"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Refuse to reuse nonce values.\n\n**Mitigation:** Use techniques such as requiring incrementing, time based and/or challenge response to assure uniqueness of nonces.\n",
        "languages": []
    },
    {
        "cwe": "324",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "262"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "325",
        "name": "Missing Cryptographic Step",
        "description": "The product does not implement a required step in a cryptographic algorithm, resulting in weaker encryption than advertised by the algorithm.",
        "detail": "**Mode of Introduction:** Developers sometimes omit \"expensive\" (resource-intensive) steps in order to improve performance, especially in devices with limited memory or slower CPUs. This step may be taken under a mistaken impression that the step is unnecessary for the cryptographic algorithm.\n\n**Mode of Introduction:** This issue may happen when the requirements for the cryptographic algorithm are not clearly stated.\n",
        "parent": [
            "573"
        ],
        "children": [],
        "related": [
            "358"
        ],
        "scopes": [
            "Access Control",
            "Accountability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "326",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "328"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "327",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1240",
            "328",
            "916"
        ],
        "related": [
            "208",
            "301"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "328",
        "name": "Use of Weak Hash",
        "description": "The product uses an algorithm that produces a digest (output value) that does not meet security expectations for a hash function that allows an adversary to reasonably determine the original input (preimage attack), find another input that can produce the same hash (2nd preimage attack), or find multiple inputs that evaluate to the same hash (birthday attack).",
        "detail": "**Extended Description:**\n\n\nA hash function is defined as an algorithm that maps arbitrarily sized data into a fixed-sized digest (output) such that the following properties hold:\n\n\n  1. The algorithm is not invertible (also called \"one-way\" or \"not reversible\")\n\n  1. The algorithm is deterministic; the same input produces the same digest every time\n\n Building on this definition, a cryptographic hash function must also ensure that a malicious actor cannot leverage the hash function to have a reasonable chance of success at determining any of the following:\n\n  1. the original input (preimage attack), given only the digest\n\n  1. another input that can produce the same digest (2nd preimage attack), given the original input\n\n  1. a set of two or more inputs that evaluate to the same digest (birthday attack), given the actor can arbitrarily choose the inputs to be hashed and can do so a reasonable amount of times\n\nWhat is regarded as \"reasonable\" varies by context and threat model, but in general, \"reasonable\" could cover any attack that is more efficient than brute force (i.e., on average, attempting half of all possible combinations). Note that some attacks might be more efficient than brute force but are still not regarded as achievable in the real world.\n\nAny algorithm that does not meet the above conditions will generally be considered weak for general use in hashing.\n\n\nIn addition to algorithmic weaknesses, a hash function can be made weak by using the hash in a security context that breaks its security guarantees. For example, using a hash function without a salt for storing passwords (that are sufficiently short) could enable an adversary to create a \"rainbow table\" [REF-637] to recover the password under certain conditions; this attack works against such hash functions as MD5, SHA-1, and SHA-2.\n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "326",
            "327"
        ],
        "children": [
            "916"
        ],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nUse an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n\n\nSome hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n\n\nNote that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.\n\n",
        "languages": []
    },
    {
        "cwe": "329",
        "name": "Generation of Predictable IV with CBC Mode",
        "description": "The product generates and uses a predictable initialization Vector (IV) with Cipher Block Chaining (CBC) Mode, which causes algorithms to be susceptible to dictionary attacks when they are encrypted under the same key.",
        "detail": "**Extended Description:**\n\n\nCBC mode eliminates a weakness of Electronic Code Book (ECB) mode by allowing identical plaintext blocks to be encrypted to different ciphertext blocks. This is possible by the XOR-ing of an IV with the initial plaintext block so that every plaintext block in the chain is XOR'd with a different value before encryption. If IVs are reused, then identical plaintexts would be encrypted to identical ciphertexts. However, even if IVs are not identical but are predictable, then they still break the security of CBC mode against Chosen Plaintext Attacks (CPA).\n\n\n**Mode of Introduction:** Developers might dismiss the importance of an unpredictable IV and choose an easier implementation to save effort, weakening the scheme in the process.\n\n**Background Details:**\n['\\n\\nCBC mode is a commonly used mode of operation for a block cipher. It works by XOR-ing an IV with the initial block of a plaintext prior to encryption and then XOR-ing each successive block of plaintext with the previous block of ciphertext before encryption.\\n\\n```\\n\\t C_0 = IV\\n\\t C_i = E_k{M_i XOR C_{i-1}} \\n```\\n When used properly, CBC mode provides security against chosen plaintext attacks. Having an unpredictable IV is a crucial underpinning of this. See [REF-1171].']\n\n**Consequence Note:** If the IV is not properly initialized, data that is encrypted can be compromised and leak information.\n",
        "parent": [
            "1204",
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** NIST recommends two methods of generating unpredictable IVs for CBC mode [REF-1172]. The first is to generate the IV randomly. The second method is to encrypt a nonce with the same key and cipher to be used to encrypt the plaintext. In this case the nonce must be unique but can be predictable, since the block cipher will act as a pseudo random permutation.\n",
        "languages": []
    },
    {
        "cwe": "33",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "182"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "330",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1241",
            "331",
            "334",
            "335",
            "338",
            "344"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "331",
        "name": "Insufficient Entropy",
        "description": "The product uses an algorithm or scheme that produces insufficient entropy, leaving patterns or clusters of values that are more likely to occur than others.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could guess the random numbers generated and could gain unauthorized access to a system if the random numbers are used for authentication and authorization.\n",
        "parent": [
            "330"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Determine the necessary entropy to adequately provide for randomness and predictability. This can be achieved by increasing the number of bits of objects such as keys and seeds.\n",
        "languages": []
    },
    {
        "cwe": "332",
        "name": "Insufficient Entropy in PRNG",
        "description": "The lack of entropy available for, or used by, a Pseudo-Random Number Generator (PRNG) can be a stability and security threat.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** If a pseudo-random number generator is using a limited entropy source which runs out (if the generator fails closed), the program may pause or crash.\n\n**Consequence Note:** If a PRNG is using a limited entropy source which runs out, and the generator fails open, the generator could produce predictable random numbers. Potentially a weak source of random numbers could weaken the encryption method used for authentication of users.\n",
        "parent": [
            "331"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability"
        ],
        "mitigation": "**Mitigation:** Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n**Mitigation:** Consider a PRNG that re-seeds itself as needed from high-quality pseudo-random output, such as hardware devices.\n\n**Mitigation:** When deciding which PRNG to use, look at its sources of entropy. Depending on what your security needs are, you may need to use a random number generator that always uses strong random data -- i.e., a random number generator that attempts to be strong but will fail in a weak way or will always provide some middle ground of protection through techniques like re-seeding. Generally, something that always provides a predictable amount of strength is preferable.\n",
        "languages": []
    },
    {
        "cwe": "333",
        "name": "Improper Handling of Insufficient Entropy in TRNG",
        "description": "True random number generators (TRNG) generally have a limited source of entropy and therefore can fail or block.",
        "detail": "**Extended Description:**\nThe rate at which true random numbers can be generated is limited. It is important that one uses them only when they are needed for security.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** A program may crash or block if it runs out of random numbers.\n",
        "parent": [
            "331",
            "755"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Rather than failing on a lack of random numbers, it is often preferable to wait for more numbers to be created.\n",
        "languages": []
    },
    {
        "cwe": "334",
        "name": "Small Space of Random Values",
        "description": "The number of possible random values is smaller than needed by the product, making it more susceptible to brute force attacks.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could easily guess the values used. This could lead to unauthorized access to a system if the seed is used for authentication and authorization.\n",
        "parent": [
            "330"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n",
        "languages": []
    },
    {
        "cwe": "335",
        "name": "Incorrect Usage of Seeds in Pseudo-Random Number Generator (PRNG)",
        "description": "The product uses a Pseudo-Random Number Generator (PRNG) but does not correctly manage seeds.",
        "detail": "**Extended Description:**\n\n\n PRNGs are deterministic and, while their output appears random, they cannot actually create entropy. They rely on cryptographically secure and unique seeds for entropy so proper seeding is critical to the secure operation of the PRNG.\n\n\n Management of seeds could be broken down into two main areas: \n\n\n  -  (1) protecting seeds as cryptographic material (such as a cryptographic key); \n\n  -  (2) whenever possible, using a uniquely generated seed from a cryptographically secure source \n\n PRNGs require a seed as input to generate a stream of numbers that are functionally indistinguishable from random numbers. While the output is, in many cases, sufficient for cryptographic uses, the output of any PRNG is directly determined by the seed provided as input. If the seed can be ascertained by a third party, the entire output of the PRNG can be made known to them. As such, the seed should be kept secret and should ideally not be able to be guessed. For example, the current time may be a poor seed. Knowing the approximate time the PRNG was seeded greatly reduces the possible key space. \n\n Seeds do not necessarily need to be unique, but reusing seeds may open up attacks if the seed is discovered. \n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** If a PRNG is used incorrectly, such as using the same seed for each initialization or using a predictable seed, then an attacker may be able to easily guess the seed and thus the random numbers. This could lead to unauthorized access to a system if the seed is used for authentication and authorization.\n",
        "parent": [
            "330"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "336",
        "name": "Same Seed in Pseudo-Random Number Generator (PRNG)",
        "description": "A Pseudo-Random Number Generator (PRNG) uses the same seed each time the product is initialized.",
        "detail": "**Extended Description:**\nGiven the deterministic nature of PRNGs, using the same seed for each initialization will lead to the same output in the same order. If an attacker can guess (or knows) the seed, then the attacker may be able to determine the random numbers that will be produced from the PRNG.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "335"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not reuse PRNG seeds. Consider a PRNG that periodically re-seeds itself as needed from a high quality pseudo-random output, such as hardware devices.\n\n**Mitigation:** Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.\n",
        "languages": []
    },
    {
        "cwe": "337",
        "name": "Predictable Seed in Pseudo-Random Number Generator (PRNG)",
        "description": "A Pseudo-Random Number Generator (PRNG) is initialized from a predictable seed, such as the process ID or system time.",
        "detail": "**Extended Description:**\nThe use of predictable seeds significantly reduces the number of possible seeds that an attacker would need to test in order to predict which random numbers will be generated by the PRNG.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "335"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Use non-predictable inputs for seed generation.\n\n**Mitigation:** Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.\n\n**Mitigation:** Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.\n",
        "languages": []
    },
    {
        "cwe": "338",
        "name": "Use of Cryptographically Weak Pseudo-Random Number Generator (PRNG)",
        "description": "The product uses a Pseudo-Random Number Generator (PRNG) in a security context, but the PRNG's algorithm is not cryptographically strong.",
        "detail": "**Extended Description:**\n\n\nWhen a non-cryptographic PRNG is used in a cryptographic context, it can expose the cryptography to certain types of attacks.\n\n\nOften a pseudo-random number generator (PRNG) is not designed for cryptography. Sometimes a mediocre source of randomness is sufficient or preferable for algorithms that use random numbers. Weak generators generally take less processing power and/or do not use the precious, finite, entropy sources on a system. While such PRNGs might have very useful features, these same features could be used to break the cryptography.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** If a PRNG is used for authentication and authorization, such as a session ID or a seed for generating a cryptographic key, then an attacker may be able to easily guess the ID or cryptographic key and gain access to restricted functionality.\n",
        "parent": [
            "330"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use functions or hardware which use a hardware-based random number generation for all crypto. This is the recommended solution. Use CyptGenRandom on Windows, or hw_rand() on Linux.\n",
        "languages": []
    },
    {
        "cwe": "339",
        "name": "Small Seed Space in PRNG",
        "description": "A Pseudo-Random Number Generator (PRNG) uses a relatively small seed space, which makes it more susceptible to brute force attacks.",
        "detail": "**Extended Description:**\nPRNGs are entirely deterministic once seeded, so it should be extremely difficult to guess the seed. If an attacker can collect the outputs of a PRNG and then brute force the seed by trying every possibility to see which seed matches the observed output, then the attacker will know the output of any subsequent calls to the PRNG. A small seed space implies that the attacker will have far fewer possible values to try to exhaust all possibilities.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "335"
        ],
        "children": [],
        "related": [
            "341"
        ],
        "scopes": [],
        "mitigation": "**Mitigation:** Use well vetted pseudo-random number generating algorithms with adequate length seeds. Pseudo-random number generators can produce predictable numbers if the generator is known and the seed can be guessed. A 256-bit seed is a good starting point for producing a \"random enough\" number.\n\n**Mitigation:** Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems, or use the more recent FIPS 140-3 [REF-1192] if possible.\n",
        "languages": []
    },
    {
        "cwe": "34",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "182"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "340",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "341",
            "342",
            "343"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "341",
        "name": "Predictable from Observable State",
        "description": "A number or object is predictable based on observations that the attacker can make about the state of the system or network, such as time, process ID, etc.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** This weakness could be exploited by an attacker in a number ways depending on the context. If a predictable number is used to generate IDs or keys that are used within protection mechanisms, then an attacker could gain unauthorized access to the system. If predictable filenames are used for storing sensitive information, then an attacker might gain access to the system and may be able to gain access to the information in the file.\n",
        "parent": [
            "340"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Increase the entropy used to seed a PRNG.\n\n**Mitigation:** Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n**Mitigation:** Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.\n",
        "languages": []
    },
    {
        "cwe": "342",
        "name": "Predictable Exact Value from Previous Values",
        "description": "An exact value or random number can be precisely predicted by observing previous values.",
        "detail": null,
        "parent": [
            "340"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Increase the entropy used to seed a PRNG.\n\n**Mitigation:** Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n**Mitigation:** Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.\n",
        "languages": []
    },
    {
        "cwe": "343",
        "name": "Predictable Value Range from Previous Values",
        "description": "The product's random number generator produces a series of values which, when observed, can be used to infer a relatively small range of possibilities for the next value that could be generated.",
        "detail": "**Extended Description:**\nThe output of a random number generator should not be predictable based on observations of previous values. In some cases, an attacker cannot predict the exact value that will be produced next, but can narrow down the possibilities significantly. This reduces the amount of effort to perform a brute force attack. For example, suppose the product generates random numbers between 1 and 100, but it always produces a larger value until it reaches 100. If the generator produces an 80, then the attacker knows that the next value will be somewhere between 81 and 100. Instead of 100 possibilities, the attacker only needs to consider 20.\n",
        "parent": [
            "340"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Increase the entropy used to seed a PRNG.\n\n**Mitigation:** Use products or modules that conform to FIPS 140-2 [REF-267] to avoid obvious entropy problems. Consult FIPS 140-2 Annex C (\"Approved Random Number Generators\").\n\n**Mitigation:** Use a PRNG that periodically re-seeds itself using input from high-quality sources, such as hardware devices with high entropy. However, do not re-seed too frequently, or else the entropy source might block.\n",
        "languages": []
    },
    {
        "cwe": "344",
        "name": "Use of Invariant Value in Dynamically Changing Context",
        "description": "The product uses a constant value, name, or reference, but this value can (or should) vary across different environments.",
        "detail": null,
        "parent": [
            "330"
        ],
        "children": [
            "587",
            "798"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "345",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "346",
            "347",
            "348",
            "349",
            "351",
            "353",
            "360",
            "494",
            "649",
            "924"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "346",
        "name": "Origin Validation Error",
        "description": "The product does not properly verify that the source of data or communication is valid.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker can access any functionality that is inadvertently accessible to the source.\n",
        "parent": [
            "284",
            "345"
        ],
        "children": [
            "940"
        ],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "347",
        "name": "Improper Verification of Cryptographic Signature",
        "description": "The product does not verify, or incorrectly verifies, the cryptographic signature for data.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could gain access to sensitive data and possibly execute unauthorized code.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "348",
        "name": "Use of Less Trusted Source",
        "description": "The product has two different sources of the same data or information, but it uses the source that has less support for verification, is less trusted, or is less resistant to attack.",
        "detail": "**Consequence Note:** An attacker could utilize the untrusted data source to bypass protection mechanisms and gain access to sensitive data.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "349",
        "name": "Acceptance of Extraneous Untrusted Data With Trusted Data",
        "description": "The product, when processing trusted data, accepts any untrusted data that is also included with the trusted data, treating the untrusted data as if it were trusted.",
        "detail": "**Consequence Note:** An attacker could package untrusted data with trusted data to bypass protection mechanisms to gain access to and possibly modify sensitive data.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "35",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "182"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "350",
        "name": "Reliance on Reverse DNS Resolution for a Security-Critical Action",
        "description": "The product performs reverse DNS resolution on an IP address to obtain the hostname and make a security decision, but it does not properly ensure that the IP address is truly associated with the hostname.",
        "detail": "**Extended Description:**\n\n\nSince DNS names can be easily spoofed or misreported, and it may be difficult for the product to detect if a trusted DNS server has been compromised, DNS names do not constitute a valid authentication mechanism.\n\n\nWhen the product performs a reverse DNS resolution for an IP address, if an attacker controls the DNS server for that IP address, then the attacker can cause the server to return an arbitrary hostname. As a result, the attacker may be able to bypass authentication, cause the wrong hostname to be recorded in log files to hide activities, or perform other attacks.\n\n\nAttackers can spoof DNS names by either (1) compromising a DNS server and modifying its records (sometimes called DNS cache poisoning), or (2) having legitimate control over a DNS server associated with their IP address.\n\n\n**Consequence Note:** Malicious users can fake authentication information by providing false DNS information.\n",
        "parent": [
            "290",
            "807"
        ],
        "children": [],
        "related": [
            "923"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use other means of identity verification that cannot be simply spoofed. Possibilities include a username/password or certificate.\n\n**Mitigation:** Perform proper forward and reverse DNS lookups to detect DNS spoofing.\n",
        "languages": []
    },
    {
        "cwe": "351",
        "name": "Insufficient Type Distinction",
        "description": "The product does not properly distinguish between different types of elements in a way that leads to insecure behavior.",
        "detail": null,
        "parent": [
            "345"
        ],
        "children": [],
        "related": [
            "436"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "352",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "79"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "353",
        "name": "Missing Support for Integrity Check",
        "description": "The product uses a transmission protocol that does not include a mechanism for verifying the integrity of the data during transmission, such as a checksum.",
        "detail": "**Extended Description:**\nIf integrity check values or \"checksums\" are omitted from a protocol, there is no way of determining if data has been corrupted in transmission. The lack of checksum functionality in a protocol removes the first application-level check of data that can be used. The end-to-end philosophy of checks states that integrity checks should be performed at the lowest level that they can be completely implemented. Excluding further sanity checks and input validation performed by applications, the protocol's checksum is the most important level of checksum, since it can be performed more completely than at any previous level and takes into account entire messages, as opposed to single packets.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** Data that is parsed and used may be corrupted.\n\n**Consequence Note:** Without a checksum it is impossible to determine if any changes have been made to the data after it was sent.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [
            "354"
        ],
        "scopes": [
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Add an appropriately sized checksum to the protocol, ensuring that data received may be simply validated before it is parsed and used.\n\n**Mitigation:** Ensure that the checksums present in the protocol design are properly implemented and added to each message before it is sent.\n",
        "languages": []
    },
    {
        "cwe": "354",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "353"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "356",
        "name": "Product UI does not Warn User of Unsafe Actions",
        "description": "The product's user interface does not warn the user before undertaking an unsafe action on behalf of that user. This makes it easier for attackers to trick users into inflicting damage to their system.",
        "detail": "**Extended Description:**\nProduct systems should warn users that a potentially dangerous action may occur if the user proceeds. For example, if the user downloads a file from an unknown source and attempts to execute the file on their machine, then the application's GUI can indicate that the file is unsafe.\n",
        "parent": [
            "221"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Non-Repudiation"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "357",
        "name": "Insufficient UI Warning of Dangerous Operations",
        "description": "The user interface provides a warning to a user regarding dangerous or sensitive operations, but the warning is not noticeable enough to warrant attention.",
        "detail": null,
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Non-Repudiation"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "358",
        "name": "Improperly Implemented Security Check for Standard",
        "description": "The product does not implement or incorrectly implements one or more security-relevant checks as specified by the design of a standardized algorithm, protocol, or technique.",
        "detail": "**Mode of Introduction:** \n\nThis is an implementation error, in which the algorithm/technique requires certain security-related behaviors or conditions that are not implemented or checked properly, thus causing a vulnerability.\n\n",
        "parent": [
            "573",
            "693"
        ],
        "children": [],
        "related": [
            "325"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "359",
        "name": "Exposure of Private Personal Information to an Unauthorized Actor",
        "description": "The product does not properly prevent a person's private, personal information from being accessed by actors who either (1) are not explicitly authorized to access the information or (2) do not have the implicit consent of the person about whom the information is collected.",
        "detail": "**Alternate Terms:** Privacy violation, Privacy leak, Privacy leakage\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "200"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** \n\nPrivate personal data can enter a program in a variety of ways:\n\n\n  - Directly from the user in the form of a password or personal information\n\n  - Accessed from a database or other data store by the application\n\n  - Indirectly from a partner or other third party\n\nIf the data is written to an external location - such as the console, file system, or network - a privacy violation may occur.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nIdentify and consult all relevant regulations for personal privacy. An organization may be required to comply with certain federal and state regulations, depending on its location, the type of business it conducts, and the nature of any private data it handles. Regulations may include Safe Harbor Privacy Framework [REF-340], Gramm-Leach Bliley Act (GLBA) [REF-341], Health Insurance Portability and Accountability Act (HIPAA) [REF-342], General Data Protection Regulation (GDPR) [REF-1047], California Consumer Privacy Act (CCPA) [REF-1048], and others.\n\n\n**Mitigation:** \n\nCarefully evaluate how secure design may interfere with privacy, and vice versa. Security and privacy concerns often seem to compete with each other. From a security perspective, all important operations should be recorded so that any anomalous activity can later be identified. However, when private data is involved, this practice can in fact create risk. Although there are many ways in which private data can be handled unsafely, a common risk stems from misplaced trust. Programmers often trust the operating environment in which a program runs, and therefore believe that it is acceptable store private information on the file system, in the registry, or in other locally-controlled resources. However, even if access to certain resources is restricted, this does not guarantee that the individuals who do have access can be trusted.\n\n",
        "languages": []
    },
    {
        "cwe": "36",
        "name": "Absolute Path Traversal",
        "description": "The product uses external input to construct a pathname that should be within a restricted directory, but it does not properly neutralize absolute path sequences such as \"/abs/path\" that can resolve to a location that is outside of that directory.",
        "detail": "**Extended Description:**\nThis allows attackers to traverse the file system to access files or directories that are outside of the restricted directory.\n\n**Consequence Note:** The attacker may be able to create or overwrite critical files that are used to execute code, such as programs or libraries.\n\n**Consequence Note:** The attacker may be able to overwrite or create critical files, such as programs, libraries, or important data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, appending a new account at the end of a password file may allow an attacker to bypass authentication.\n\n**Consequence Note:** The attacker may be able read the contents of unexpected files and expose sensitive data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, by reading a password file, the attacker could conduct brute force password guessing attacks in order to break into an account on the system.\n\n**Consequence Note:** The attacker may be able to overwrite, delete, or corrupt unexpected critical files such as programs, libraries, or important data. This may prevent the product from working at all and in the case of a protection mechanisms such as authentication, it has the potential to lockout every user of the product.\n",
        "parent": [
            "22"
        ],
        "children": [
            "37",
            "38",
            "39",
            "40"
        ],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "360",
        "name": "Trust of System Event Data",
        "description": "Security based on event locations are insecure and can be spoofed.",
        "detail": "**Extended Description:**\nEvents are a messaging system which may provide control data to programs listening for events. Events often do not have any type of authentication framework to allow them to be verified from a trusted source. Any application, in Windows, on a given desktop can send a message to any window on the same desktop. There is no authentication framework for these messages. Therefore, any message can be used to manipulate any process on the desktop if the process does not check the validity and safeness of those messages.\n\n**Consequence Note:** If one trusts the system-event information and executes commands based on it, one could potentially take actions based on a spoofed identity.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Never trust or rely any of the information in an Event for security.\n",
        "languages": []
    },
    {
        "cwe": "362",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "364",
            "366",
            "367"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "363",
        "name": "Race Condition Enabling Link Following",
        "description": "The product checks the status of a file or directory before accessing it, which produces a race condition in which the file can be replaced with a link before the access is performed, causing the product to access the wrong file.",
        "detail": "**Extended Description:**\nWhile developers might expect that there is a very narrow time window between the time of check and time of use, there is still a race condition. An attacker could cause the product to slow down (e.g. with memory consumption), causing the time window to become larger. Alternately, in some situations, the attacker could win the race by performing a large number of attacks.\n",
        "parent": [
            "367"
        ],
        "children": [],
        "related": [
            "59"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "364",
        "name": "Signal Handler Race Condition",
        "description": "The product uses a signal handler that introduces a race condition.",
        "detail": "**Extended Description:**\n\n\nRace conditions frequently occur in signal handlers, since signal handlers support asynchronous actions. These race conditions have a variety of root causes and symptoms. Attackers may be able to exploit a signal handler race condition to cause the product state to be corrupted, possibly leading to a denial of service or even code execution.\n\n\nThese issues occur when non-reentrant functions, or state-sensitive actions occur in the signal handler, where they may be called at any time. These behaviors can violate assumptions being made by the \"regular\" code that is interrupted, or by other signal handlers that may also be invoked. If these functions are called at an inopportune moment - such as while a non-reentrant function is already running - memory corruption could occur that may be exploitable for code execution. Another signal race condition commonly found occurs when free is called within a signal handler, resulting in a double free and therefore a write-what-where condition. Even if a given pointer is set to NULL after it has been freed, a race condition still exists between the time the memory was freed and the pointer was set to NULL. This is especially problematic if the same signal handler has been set for more than one signal -- since it means that the signal handler itself may be reentered.\n\n\nThere are several known behaviors related to signal handlers that have received the label of \"signal handler race condition\":\n\n\n  - Shared state (e.g. global data or static variables) that are accessible to both a signal handler and \"regular\" code\n\n  - Shared state between a signal handler and other signal handlers\n\n  - Use of non-reentrant functionality within a signal handler - which generally implies that shared state is being used. For example, malloc() and free() are non-reentrant because they may use global or static data structures for managing memory, and they are indirectly used by innocent-seeming functions such as syslog(); these functions could be exploited for memory corruption and, possibly, code execution.\n\n  - Association of the same signal handler function with multiple signals - which might imply shared state, since the same code and resources are accessed. For example, this can be a source of double-free and use-after-free weaknesses.\n\n  - Use of setjmp and longjmp, or other mechanisms that prevent a signal handler from returning control back to the original functionality\n\n  - While not technically a race condition, some signal handlers are designed to be called at most once, and being called more than once can introduce security problems, even when there are not any concurrent calls to the signal handler. This can be a source of double-free and use-after-free weaknesses.\n\nSignal handler vulnerabilities are often classified based on the absence of a specific protection mechanism, although this style of classification is discouraged in CWE because programmers often have a choice of several different mechanisms for addressing the weakness. Such protection mechanisms may preserve exclusivity of access to the shared resource, and behavioral atomicity for the relevant code:\n\n  - Avoiding shared state\n\n  - Using synchronization in the signal handler\n\n  - Using synchronization in the regular code\n\n  - Disabling or masking other signals, which provides atomicity (which effectively ensures exclusivity)\n\n\n\n**Consequence Note:** It may be possible to cause data corruption and possibly execute arbitrary code by modifying global variables or data structures at unexpected times, violating the assumptions of code that uses this global data.\n\n**Consequence Note:** If a signal handler interrupts code that is executing with privileges, it may be possible that the signal handler will also be executed with elevated privileges, possibly making subsequent exploits more severe.\n",
        "parent": [
            "362"
        ],
        "children": [],
        "related": [
            "123",
            "415",
            "416"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n**Mitigation:** Design signal handlers to only set flags, rather than perform complex functionality. These flags can then be checked and acted upon within the main program loop.\n\n**Mitigation:** Only use reentrant functions within signal handlers. Also, use validation to ensure that state is consistent while performing asynchronous actions that affect the state of execution.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "366",
        "name": "Race Condition within a Thread",
        "description": "If two threads of execution use a resource simultaneously, there exists the possibility that resources may be used while invalid, in turn making the state of execution undefined.",
        "detail": "**Consequence Note:** The main problem is that -- if a lock is overcome -- data could be altered in a bad state.\n",
        "parent": [
            "362",
            "662"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use locking functionality. This is the recommended solution. Implement some form of locking mechanism around code which alters or reads persistent data in a multithreaded environment.\n\n**Mitigation:** Create resource-locking validation checks. If no inherent locking mechanisms exist, use flags and signals to enforce your own blocking scheme when resources are being used by other threads of execution.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "367",
        "name": "Time-of-check Time-of-use (TOCTOU) Race Condition",
        "description": "The product checks the state of a resource before using that resource, but the resource's state can change between the check and the use in a way that invalidates the results of the check. This can cause the product to perform invalid actions when the resource is in an unexpected state.",
        "detail": "**Extended Description:**\nThis weakness can be security-relevant when an attacker can influence the state of the resource between check and use. This can happen with shared resources such as files, memory, or even variables in multithreaded programs.\n\n**Alternate Terms:** TOCTTOU, TOCCTOU\n\n**Consequence Note:** The attacker can gain access to otherwise unauthorized resources.\n\n**Consequence Note:** Race conditions such as this kind may be employed to gain read or write access to resources which are not normally readable or writable by the user in question.\n\n**Consequence Note:** The resource in question, or other resources (through the corrupted one), may be changed in undesirable ways by a malicious user.\n\n**Consequence Note:** If a file or other resource is written in this method, as opposed to in a valid way, logging of the activity may not occur.\n\n**Consequence Note:** In some cases it may be possible to delete files a malicious user might not otherwise have access to, such as log files.\n",
        "parent": [
            "362"
        ],
        "children": [],
        "related": [
            "386",
            "609"
        ],
        "scopes": [
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** The most basic advice for TOCTOU vulnerabilities is to not perform a check before the use. This does not resolve the underlying issue of the execution of a function on a resource whose state and identity cannot be assured, but it does help to limit the false sense of security given by the check.\n\n**Mitigation:** When the file being altered is owned by the current user and group, set the effective gid and uid to that of the current user and group when executing this statement.\n\n**Mitigation:** Limit the interleaving of operations on files from multiple processes.\n\n**Mitigation:** If you cannot perform operations atomically and you must share access to the resource between multiple processes or threads, then try to limit the amount of time (CPU cycles) between the check and use of the resource. This will not fix the problem, but it could make it more difficult for an attack to succeed.\n\n**Mitigation:** Recheck the resource after the use call to verify that the action was taken appropriately.\n\n**Mitigation:** Ensure that some environmental locking mechanism can be used to protect resources effectively.\n\n**Mitigation:** Ensure that locking occurs before the check, as opposed to afterwards, such that the resource, as checked, is the same as it is when in use.\n",
        "languages": []
    },
    {
        "cwe": "368",
        "name": "Context Switching Race Condition",
        "description": "A product performs a series of non-atomic actions to switch between contexts that cross privilege or other security boundaries, but a race condition allows an attacker to modify or misrepresent the product's behavior during the switch.",
        "detail": "**Extended Description:**\nThis is commonly seen in web browser vulnerabilities in which the attacker can perform certain actions while the browser is transitioning from a trusted to an untrusted domain, or vice versa, and the browser performs the actions on one domain using the trust level and resources of the other domain.\n",
        "parent": [
            "362"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "369",
        "name": "Divide By Zero",
        "description": "The product divides a value by zero.",
        "detail": "**Extended Description:**\nThis weakness typically occurs when an unexpected value is provided to the product, or if an error occurs that is not properly detected. It frequently occurs in calculations involving physical dimensions such as size, length, width, and height.\n\n**Consequence Note:** A Divide by Zero results in a crash.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n",
        "languages": []
    },
    {
        "cwe": "37",
        "name": "Path Traversal: '/absolute/pathname/here'",
        "description": "The product accepts input in the form of a slash absolute path ('/absolute/pathname/here') without appropriate validation, which can allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "160",
            "36"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "370",
        "name": "Missing Check for Certificate Revocation after Initial Check",
        "description": "The product does not check the revocation status of a certificate after its initial revocation check, which can cause the product to perform privileged actions even after the certificate is revoked at a later time.",
        "detail": "**Extended Description:**\nIf the revocation status of a certificate is not checked before each action that requires privileges, the system may be subject to a race condition. If a certificate is revoked after the initial check, all subsequent actions taken with the owner of the revoked certificate will lose all benefits guaranteed by the certificate. In fact, it is almost certain that the use of a revoked certificate indicates malicious activity.\n\n**Consequence Note:** Trust may be assigned to an entity who is not who it claims to be.\n\n**Consequence Note:** Data from an untrusted (and possibly malicious) source may be integrated.\n\n**Consequence Note:** Data may be disclosed to an entity impersonating a trusted entity, resulting in information disclosure.\n",
        "parent": [
            "299"
        ],
        "children": [],
        "related": [
            "296",
            "297",
            "298"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Ensure that certificates are checked for revoked status before each use of a protected resource. If the certificate is checked before each access of a protected resource, the delay subject to a possible race condition becomes almost negligible and significantly reduces the risk associated with this issue.\n",
        "languages": []
    },
    {
        "cwe": "372",
        "name": "Incomplete Internal State Distinction",
        "description": "The product does not properly determine which state it is in, causing it to assume it is in state X when in fact it is in state Y, causing it to perform incorrect operations in a security-relevant manner.",
        "detail": null,
        "parent": [
            "664"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "374",
        "name": "Passing Mutable Objects to an Untrusted Method",
        "description": "The product sends non-cloned mutable data as an argument to a method or function.",
        "detail": "**Extended Description:**\nThe function or method that has been called can alter or delete the mutable data. This could violate assumptions that the calling function has made about its state. In situations where unknown code is called with references to mutable data, this external code could make changes to the data sent. If this data was not previously cloned, the modified data might not be valid in the context of execution.\n\n**Consequence Note:** Potentially data could be tampered with by another function which should not have been tampered with.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Pass in data which should not be altered as constant or immutable.\n\n**Mitigation:** Clone all mutable data before passing it into an external function . This is the preferred mitigation. This way, regardless of what changes are made to the data, a valid copy is retained for use by the class.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "375",
        "name": "Returning a Mutable Object to an Untrusted Caller",
        "description": "Sending non-cloned mutable data as a return value may result in that data being altered or deleted by the calling function.",
        "detail": "**Extended Description:**\nIn situations where functions return references to mutable data, it is possible that the external code which called the function may make changes to the data sent. If this data was not previously cloned, the class will then be using modified data which may violate assumptions about its internal state.\n\n**Consequence Note:** Potentially data could be tampered with by another function which should not have been tampered with.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Declare returned data which should not be altered as constant or immutable.\n\n**Mitigation:** Clone all mutable data before returning references to it. This is the preferred mitigation. This way, regardless of what changes are made to the data, a valid copy is retained for use by the class.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "377",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "378",
            "379"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "378",
        "name": "Creation of Temporary File With Insecure Permissions",
        "description": "Opening temporary files without appropriate measures or controls can leave the file, its contents and any function that it impacts vulnerable to attack.",
        "detail": "**Consequence Note:** If the temporary file can be read by the attacker, sensitive information may be in that file which could be revealed.\n\n**Consequence Note:** If that file can be written to by the attacker, the file might be moved into a place to which the attacker does not have access. This will allow the attacker to gain selective resource access-control privileges.\n\n**Consequence Note:** Depending on the data stored in the temporary file, there is the potential for an attacker to gain an additional input vector which is trusted as non-malicious. It may be possible to make arbitrary changes to data structures, user information, or even process ownership.\n",
        "parent": [
            "377"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Authorization",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Many contemporary languages have functions which properly handle this condition. Older C temp file functions are especially susceptible.\n\n**Mitigation:** Ensure that you use proper file permissions. This can be achieved by using a safe temp file function. Temporary files should be writable and readable only by the process that owns the file.\n\n**Mitigation:** Randomize temporary file names. This can also be achieved by using a safe temp-file function. This will ensure that temporary files will not be created in predictable places.\n",
        "languages": []
    },
    {
        "cwe": "379",
        "name": "Creation of Temporary File in Directory with Insecure Permissions",
        "description": "The product creates a temporary file in a directory whose permissions allow unintended actors to determine the file's existence or otherwise access that file.",
        "detail": "**Extended Description:**\nOn some operating systems, the fact that the temporary file exists may be apparent to any user with sufficient privileges to access that directory. Since the file is visible, the application that is using the temporary file could be known. If one has access to list the processes on the system, the attacker has gained information about what the user is doing at that time. By correlating this with the applications the user is running, an attacker could potentially discover what a user's actions are. From this, higher levels of security could be breached.\n\n**Consequence Note:** Since the file is visible and the application which is using the temp file could be known, the attacker has gained information about what the user is doing at that time.\n",
        "parent": [
            "377"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Many contemporary languages have functions which properly handle this condition. Older C temp file functions are especially susceptible.\n\n**Mitigation:** Try to store sensitive tempfiles in a directory which is not world readable -- i.e., per-user directories.\n\n**Mitigation:** Avoid using vulnerable temp file functions.\n",
        "languages": []
    },
    {
        "cwe": "38",
        "name": "Path Traversal: '\\absolute\\pathname\\here'",
        "description": "The product accepts input in the form of a backslash absolute path ('\\absolute\\pathname\\here') without appropriate validation, which can allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "36"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "382",
        "name": "J2EE Bad Practices: Use of System.exit()",
        "description": "A J2EE application uses System.exit(), which also shuts down its container.",
        "detail": "**Extended Description:**\nIt is never a good idea for a web application to attempt to shut down the application container. Access to a function that can shut down the application is an avenue for Denial of Service (DoS) attacks.\n\n**Mode of Introduction:** A call to System.exit() is probably part of leftover debug code or code imported from a non-J2EE application.\n",
        "parent": [
            "705"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** The shutdown function should be a privileged function available only to a properly authorized administrative user\n\n**Mitigation:** Web applications should not call methods that cause the virtual machine to exit, such as System.exit()\n\n**Mitigation:** Web applications should also not throw any Throwables to the application server as this may adversely affect the container.\n\n**Mitigation:** Non-web applications may have a main() method that contains a System.exit(), but generally should not call System.exit() from other locations in the code\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "383",
        "name": "J2EE Bad Practices: Direct Use of Threads",
        "description": "Thread management in a Web application is forbidden in some circumstances and is always highly error prone.",
        "detail": "**Extended Description:**\nThread management in a web application is forbidden by the J2EE standard in some circumstances and is always highly error prone. Managing threads is difficult and is likely to interfere in unpredictable ways with the behavior of the application container. Even without interfering with the container, thread management usually leads to bugs that are hard to detect and diagnose like deadlock, race conditions, and other synchronization errors.\n",
        "parent": [
            "695"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** For EJB, use framework approaches for parallel execution, instead of using threads.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "384",
        "name": "Session Fixation",
        "description": "Authenticating a user, or otherwise establishing a new user session, without invalidating any existing session identifier gives an attacker the opportunity to steal authenticated sessions.",
        "detail": "**Extended Description:**\n\n\nSuch a scenario is commonly observed when:\n\n\n  - A web application authenticates a user without first invalidating the existing session, thereby continuing to use the session already associated with the user.\n\n  - An attacker is able to force a known session identifier on a user so that, once the user authenticates, the attacker has access to the authenticated session.\n\n  - The application or container uses predictable session identifiers.\n\nIn the generic exploit of session fixation vulnerabilities, an attacker creates a new session on a web application and records the associated session identifier. The attacker then causes the victim to associate, and possibly authenticate, against the server using that session identifier, giving the attacker access to the user's account through the active session.\n",
        "parent": [
            "610"
        ],
        "children": [],
        "related": [
            "340"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Invalidate any existing session identifiers prior to authorizing a new user session.\n\n**Mitigation:** For platforms such as ASP that do not generate new values for sessionid cookies, utilize a secondary cookie. In this approach, set a secondary cookie on the user's browser to a random value and set a session variable to the same value. If the session variable and the cookie value ever don't match, invalidate the session, and force the user to log on again.\n",
        "languages": []
    },
    {
        "cwe": "385",
        "name": "Covert Timing Channel",
        "description": "Covert timing channels convey information by modulating some aspect of system behavior over time, so that the program receiving the information can observe system behavior and infer protected information.",
        "detail": "**Extended Description:**\n\n\nIn some instances, knowing when data is transmitted between parties can provide a malicious user with privileged information. Also, externally monitoring the timing of operations can potentially reveal sensitive data. For example, a cryptographic operation can expose its internal state if the time it takes to perform the operation varies, based on the state.\n\n\nCovert channels are frequently classified as either storage or timing channels. Some examples of covert timing channels are the system's paging rate, the time a certain transaction requires to execute, and the time it takes to gain access to a shared bus.\n\n\n**Consequence Note:** Information exposure.\n",
        "parent": [
            "514"
        ],
        "children": [],
        "related": [
            "208"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Whenever possible, specify implementation strategies that do not introduce time variances in operations.\n\n**Mitigation:** Often one can artificially manipulate the time which operations take or -- when operations occur -- can remove information from the attacker.\n\n**Mitigation:** It is reasonable to add artificial or random delays so that the amount of CPU time consumed is independent of the action being taken by the application.\n",
        "languages": []
    },
    {
        "cwe": "386",
        "name": "Symbolic Name not Mapping to Correct Object",
        "description": "A constant symbolic reference to an object is used, even though the reference can resolve to a different object over time.",
        "detail": "**Consequence Note:** The attacker can gain access to otherwise unauthorized resources.\n\n**Consequence Note:** Race conditions such as this kind may be employed to gain read or write access to resources not normally readable or writable by the user in question.\n\n**Consequence Note:** The resource in question, or other resources (through the corrupted one) may be changed in undesirable ways by a malicious user.\n\n**Consequence Note:** If a file or other resource is written in this method, as opposed to a valid way, logging of the activity may not occur.\n\n**Consequence Note:** In some cases it may be possible to delete files that a malicious user might not otherwise have access to -- such as log files.\n",
        "parent": [
            "706"
        ],
        "children": [],
        "related": [
            "367",
            "486",
            "610"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "39",
        "name": "Path Traversal: 'C:dirname'",
        "description": "The product accepts input that contains a drive letter or Windows volume letter ('C:dirname') that potentially redirects access to an unintended location or arbitrary file.",
        "detail": "**Consequence Note:** The attacker may be able to create or overwrite critical files that are used to execute code, such as programs or libraries.\n\n**Consequence Note:** The attacker may be able to overwrite or create critical files, such as programs, libraries, or important data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, appending a new account at the end of a password file may allow an attacker to bypass authentication.\n\n**Consequence Note:** The attacker may be able read the contents of unexpected files and expose sensitive data. If the targeted file is used for a security mechanism, then the attacker may be able to bypass that mechanism. For example, by reading a password file, the attacker could conduct brute force password guessing attacks in order to break into an account on the system.\n\n**Consequence Note:** The attacker may be able to overwrite, delete, or corrupt unexpected critical files such as programs, libraries, or important data. This may prevent the software from working at all and in the case of a protection mechanisms such as authentication, it has the potential to lockout every user of the software.\n",
        "parent": [
            "36"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "390",
        "name": "Detection of Error Condition Without Action",
        "description": "The product detects a specific error, but takes no actions to handle the error.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could utilize an ignored error condition to place the system in an unexpected state that could lead to the execution of unintended logic and could cause other unintended behavior.\n",
        "parent": [
            "755"
        ],
        "children": [],
        "related": [
            "401"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Properly handle each exception. This is the recommended solution. Ensure that all exceptions are handled in such a way that you can be sure of the state of your system at any given moment.\n\n**Mitigation:** If a function returns an error, it is important to either fix the problem and try again, alert the user that an error has happened and let the program continue, or alert the user and close and cleanup the program.\n\n**Mitigation:** Subject the product to extensive testing to discover some of the possible instances of where/how errors or return values are not handled. Consider testing techniques such as ad hoc, equivalence partitioning, robustness and fault tolerance, mutation, and fuzzing.\n",
        "languages": []
    },
    {
        "cwe": "392",
        "name": "Missing Report of Error Condition",
        "description": "The product encounters an error but does not provide a status code or return value to indicate that an error has occurred.",
        "detail": "**Consequence Note:** Errors that are not properly reported could place the system in an unexpected state that could lead to unintended behaviors.\n",
        "parent": [
            "684",
            "703",
            "755"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "393",
        "name": "Return of Wrong Status Code",
        "description": "A function or operation returns an incorrect return value or status code that does not indicate the true result of execution, causing the product to modify its behavior based on the incorrect result.",
        "detail": "**Extended Description:**\nThis can lead to unpredictable behavior. If the function is used to make security-critical decisions or provide security-critical information, then the wrong status code can cause the product to assume that an action is safe or correct, even when it is not.\n\n**Consequence Note:** This weakness could place the system in a state that could lead unexpected logic to be executed or other unintended behaviors.\n",
        "parent": [
            "684",
            "703"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n",
        "languages": []
    },
    {
        "cwe": "394",
        "name": "Unexpected Status Code or Return Value",
        "description": "The product does not properly check when a function or operation returns a value that is legitimate for the function, but is not expected by the product.",
        "detail": null,
        "parent": [
            "754"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "395",
        "name": "Use of NullPointerException Catch to Detect NULL Pointer Dereference",
        "description": "Catching NullPointerException should not be used as an alternative to programmatic checks to prevent dereferencing a null pointer.",
        "detail": "**Extended Description:**\n\n\nProgrammers typically catch NullPointerException under three circumstances:\n\n\n  - The program contains a null pointer dereference. Catching the resulting exception was easier than fixing the underlying problem.\n\n  - The program explicitly throws a NullPointerException to signal an error condition.\n\n  - The code is part of a test harness that supplies unexpected input to the classes under test.\n\nOf these three circumstances, only the last is acceptable.\n",
        "parent": [
            "705",
            "755"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** Do not extensively rely on catching exceptions (especially for validating user input) to handle errors. Handling exceptions can decrease the performance of an application.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "396",
        "name": "Declaration of Catch for Generic Exception",
        "description": "Catching overly broad exceptions promotes complex error handling code that is more likely to contain security vulnerabilities.",
        "detail": "**Extended Description:**\nMultiple catch blocks can get ugly and repetitive, but \"condensing\" catch blocks by catching a high-level class like Exception can obscure exceptions that deserve special treatment or that should not be caught at this point in the program. Catching an overly broad exception essentially defeats the purpose of a language's typed exceptions, and can become particularly dangerous if the program grows and begins to throw new types of exceptions. The new exception types will not receive any attention.\n\n**Consequence Note:** A generic exception can hide details about unexpected adversary activities by making it difficult to properly troubleshoot error conditions during execution.\n",
        "parent": [
            "221",
            "705",
            "755"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": [
            "C#",
            "C++",
            "Java",
            "Python"
        ]
    },
    {
        "cwe": "397",
        "name": "Declaration of Throws for Generic Exception",
        "description": "The product throws or raises an overly broad exceptions that can hide important details and produce inappropriate responses to certain conditions.",
        "detail": "**Extended Description:**\nDeclaring a method to throw Exception or Throwable promotes generic error handling procedures that make it difficult for callers to perform proper error handling and error recovery. For example, Java's exception mechanism makes it easy for callers to anticipate what can go wrong and write code to handle each specific exceptional circumstance. Declaring that a method throws a generic form of exception defeats this system.\n\n**Consequence Note:** Throwing a generic exception can hide details about unexpected adversary activities by making it difficult to properly troubleshoot error conditions during execution.\n",
        "parent": [
            "221",
            "703",
            "705"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": [
            "C#",
            "C++",
            "Java",
            "Python"
        ]
    },
    {
        "cwe": "40",
        "name": "Path Traversal: '\\\\UNC\\share\\name\\' (Windows UNC Share)",
        "description": "The product accepts input that identifies a Windows UNC share ('\\\\UNC\\share\\name') that potentially redirects access to an unintended location or arbitrary file.",
        "detail": null,
        "parent": [
            "36"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "400",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "770",
            "771",
            "779",
            "920"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "401",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "390"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "402",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "619"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "403",
        "name": "Exposure of File Descriptor to Unintended Control Sphere ('File Descriptor Leak')",
        "description": "A process does not close sensitive file descriptors before invoking a child process, which allows the child to perform unauthorized I/O operations using those descriptors.",
        "detail": "**Extended Description:**\nWhen a new process is forked or executed, the child process inherits any open file descriptors. When the child process has fewer privileges than the parent process, this might introduce a vulnerability if the child process can access the file descriptor but does not have the privileges to access the associated file.\n\n**Alternate Terms:** File descriptor leak\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "402"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": [
            "C"
        ]
    },
    {
        "cwe": "404",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "763",
            "772"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "405",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1050",
            "1089",
            "776"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "406",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "941"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "407",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1333"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "408",
        "name": "Incorrect Behavior Order: Early Amplification",
        "description": "The product allows an entity to perform a legitimate but expensive operation before authentication or authorization has taken place.",
        "detail": "**Consequence Note:** System resources, CPU and memory, can be quickly consumed. This can lead to poor system performance or system crash.\n",
        "parent": [
            "405",
            "696"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "409",
        "name": "Improper Handling of Highly Compressed Data (Data Amplification)",
        "description": "The product does not handle or incorrectly handles a compressed input with a very high compression ratio that produces a large output.",
        "detail": "**Extended Description:**\nAn example of data amplification is a \"decompression bomb,\" a small ZIP file that can produce a large amount of data when it is decompressed.\n\n**Consequence Note:** System resources, CPU and memory, can be quickly consumed. This can lead to poor system performance or system crash.\n",
        "parent": [
            "405"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "41",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "1289",
            "73"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "410",
        "name": "Insufficient Resource Pool",
        "description": "The product's resource pool is not large enough to handle peak demand, which allows an attacker to prevent others from accessing the resource by using a (relatively) large number of requests for resources.",
        "detail": "**Extended Description:**\nFrequently the consequence is a \"flood\" of connection or sessions.\n\n**Consequence Note:** Floods often cause a crash or other problem besides denial of the resource itself; these are likely examples of *other* vulnerabilities, not an insufficient resource pool.\n",
        "parent": [
            "664"
        ],
        "children": [],
        "related": [
            "400"
        ],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Do not perform resource-intensive transactions for unauthenticated users and/or invalid requests.\n\n**Mitigation:** Consider implementing a velocity check mechanism which would detect abusive behavior.\n\n**Mitigation:** Consider load balancing as an option to handle heavy loads.\n\n**Mitigation:** Make sure that resource handles are properly closed when no longer needed.\n\n**Mitigation:** Identify the system's resource intensive operations and consider protecting them from abuse (e.g. malicious automated script which runs the resources out).\n",
        "languages": []
    },
    {
        "cwe": "412",
        "name": "Unrestricted Externally Accessible Lock",
        "description": "The product properly checks for the existence of a lock, but the lock can be externally controlled or influenced by an actor that is outside of the intended sphere of control.",
        "detail": "**Extended Description:**\nThis prevents the product from acting on associated resources or performing other behaviors that are controlled by the presence of the lock. Relevant locks might include an exclusive lock or mutex, or modifying a shared resource that is treated as a lock. If the lock can be held for an indefinite period of time, then the denial of service could be permanent.\n\n**Consequence Note:** When an attacker can control a lock, the program may wait indefinitely until the attacker releases the lock, causing a denial of service to other users of the program. This is especially problematic if there is a blocking operation on the lock.\n",
        "parent": [
            "667"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** Automated code analysis techniques might not be able to reliably detect this weakness, since the application's behavior and general security model dictate which resource locks are critical. Interpretation of the weakness might require knowledge of the environment, e.g. if the existence of a file is used as a lock, but the file is created in a world-writable directory.\n\n**Mitigation:** Use any access control that is offered by the functionality that is offering the lock.\n\n**Mitigation:** Use unpredictable names or identifiers for the locks. This might not always be possible or feasible.\n\n**Mitigation:** Consider modifying your code to use non-blocking synchronization methods.\n",
        "languages": []
    },
    {
        "cwe": "413",
        "name": "Improper Resource Locking",
        "description": "The product does not lock or does not correctly lock a resource when the product must have exclusive access to the resource.",
        "detail": "**Extended Description:**\nWhen a resource is not properly locked, an attacker could modify the resource while it is being operated on by the product. This might violate the product's assumption that the resource will not change, potentially leading to unexpected behaviors.\n",
        "parent": [
            "667"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use a non-conflicting privilege scheme.\n\n**Mitigation:** Use synchronization when locking a resource.\n",
        "languages": []
    },
    {
        "cwe": "414",
        "name": "Missing Lock Check",
        "description": "A product does not check to see if a lock is present before performing sensitive operations on a resource.",
        "detail": null,
        "parent": [
            "667"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Implement a reliable lock mechanism.\n",
        "languages": []
    },
    {
        "cwe": "415",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "364"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "416",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "1265",
            "364"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "419",
        "name": "Unprotected Primary Channel",
        "description": "The product uses a primary channel for administration or restricted functionality, but it does not properly protect the channel.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "923"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Do not expose administrative functionnality on the user UI.\n\n**Mitigation:** Protect the administrative/restricted functionality with a strong authentication mechanism.\n",
        "languages": []
    },
    {
        "cwe": "42",
        "name": "Path Equivalence: 'filename.' (Trailing Dot)",
        "description": "The product accepts path input in the form of trailing dot ('filedir.') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "162",
            "41"
        ],
        "children": [
            "43"
        ],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "420",
        "name": "Unprotected Alternate Channel",
        "description": "The product protects a primary channel, but it does not use the same level of protection for an alternate channel.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "923"
        ],
        "children": [
            "421"
        ],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Identify all alternate channels and use the same protection mechanisms that are used for the primary channels.\n",
        "languages": []
    },
    {
        "cwe": "421",
        "name": "Race Condition During Access to Alternate Channel",
        "description": "The product opens an alternate channel to communicate with an authorized user, but the channel is accessible to other actors.",
        "detail": "**Extended Description:**\nThis creates a race condition that allows an attacker to access the channel before the authorized user does.\n",
        "parent": [
            "362",
            "420"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "422",
        "name": "Unprotected Windows Messaging Channel ('Shatter')",
        "description": "The product does not properly verify the source of a message in the Windows Messaging System while running at elevated privileges, creating an alternate channel through which an attacker can directly send a message to the product.",
        "detail": null,
        "parent": [
            "360",
            "420"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Always verify and authenticate the source of the message.\n",
        "languages": []
    },
    {
        "cwe": "424",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "425"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "425",
        "name": "Direct Request ('Forced Browsing')",
        "description": "The web application does not adequately enforce appropriate authorization on all restricted URLs, scripts, or files.",
        "detail": "**Extended Description:**\nWeb applications susceptible to direct request attacks often make the false assumption that such resources can only be reached through a given navigation path and so only apply authorization at certain points in the path.\n\n**Alternate Terms:** forced browsing\n",
        "parent": [
            "288",
            "424",
            "862"
        ],
        "children": [],
        "related": [
            "471",
            "98"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Apply appropriate access control authorizations for each access to all restricted URLs, scripts or files.\n\n**Mitigation:** Consider using MVC based frameworks such as Struts.\n",
        "languages": []
    },
    {
        "cwe": "426",
        "name": "Untrusted Search Path",
        "description": "The product searches for critical resources using an externally-supplied search path that can point to resources that are not under the product's direct control.",
        "detail": "**Extended Description:**\n\n\nThis might allow attackers to execute their own programs, access unauthorized data files, or modify configuration in unexpected ways. If the product uses a search path to locate critical resources such as programs, then an attacker could modify that search path to point to a malicious program, which the targeted product would then execute. The problem extends to any type of critical resource that the product trusts.\n\n\nSome of the most common variants of untrusted search path are:\n\n\n  - In various UNIX and Linux-based systems, the PATH environment variable may be consulted to locate executable programs, and LD_PRELOAD may be used to locate a separate library.\n\n  - In various Microsoft-based systems, the PATH environment variable is consulted to locate a DLL, if the DLL is not found in other paths that appear earlier in the search order.\n\n\n\n**Alternate Terms:** Untrusted Path\n\n**Consequence Note:** There is the potential for arbitrary code execution with privileges of the vulnerable program.\n\n**Consequence Note:** The program could be redirected to the wrong files, potentially triggering a crash or hang when the targeted file is too large or does not have the expected format.\n\n**Consequence Note:** The program could send the output of unauthorized files to the attacker.\n",
        "parent": [
            "642",
            "668",
            "673"
        ],
        "children": [],
        "related": [
            "427",
            "428"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nUse monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.\n\n\nAttach the monitor to the process and look for library functions and system calls that suggest when a search path is being used. One pattern is when the program performs multiple accesses of the same file but in different directories, with repeated failures until the proper filename is found. Library calls such as getenv() or their equivalent can be checked to see if any path-related variables are being accessed.\n\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Detection:** Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.\n\n**Mitigation:** Hard-code the search path to a set of known-safe values (such as system directories), or only allow them to be specified by the administrator in a configuration file. Do not allow these settings to be modified by an external party. Be careful to avoid related weaknesses such as CWE-426 and CWE-428.\n\n**Mitigation:** When invoking other programs, specify those programs using fully-qualified pathnames. While this is an effective approach, code that uses fully-qualified pathnames might not be portable to other systems that do not use the same pathnames. The portability can be improved by locating the full-qualified paths in a centralized, easily-modifiable location within the source code, and having the code refer to these paths.\n\n**Mitigation:** Remove or restrict all environment settings before invoking other programs. This includes the PATH environment variable, LD_LIBRARY_PATH, and other settings that identify the location of code libraries, and any application-specific search paths.\n\n**Mitigation:** Check your search path before use and remove any elements that are likely to be unsafe, such as the current working directory or a temporary files directory.\n\n**Mitigation:** Use other functions that require explicit paths. Making use of any of the other readily available functions that require explicit paths is a safe way to avoid this problem. For example, system() in C does not require a full path since the shell can take care of it, while execl() and execv() require a full path.\n",
        "languages": []
    },
    {
        "cwe": "427",
        "name": "Uncontrolled Search Path Element",
        "description": "The product uses a fixed or controlled search path to find resources, but one or more locations in that path can be under the control of unintended actors.",
        "detail": "**Extended Description:**\n\n\nAlthough this weakness can occur with any type of resource, it is frequently introduced when a product uses a directory search path to find executables or code libraries, but the path contains a directory that can be modified by an attacker, such as \"/tmp\" or the current working directory.\n\n\nIn Windows-based systems, when the LoadLibrary or LoadLibraryEx function is called with a DLL name that does not contain a fully qualified path, the function follows a search order that includes two path elements that might be uncontrolled:\n\n\n  - the directory from which the program has been loaded\n\n  - the current working directory\n\nIn some cases, the attack can be conducted remotely, such as when SMB or WebDAV network shares are used.\n\nOne or more locations in that path could include the Windows drive root or its subdirectories. This often exists in Linux-based code assuming the controlled nature of the root directory (/) or its subdirectories (/etc, etc), or a code that recursively accesses the parent directory. In Windows, the drive root and some of its subdirectories have weak permissions by default, which makes them uncontrolled.\n\n\nIn some Unix-based systems, a PATH might be created that contains an empty element, e.g. by splicing an empty variable into the PATH. This empty element can be interpreted as equivalent to the current working directory, which might be an untrusted search element.\n\n\nIn software package management frameworks (e.g., npm, RubyGems, or PyPi), the framework may identify dependencies on third-party libraries or other packages, then consult a repository that contains the desired package. The framework may search a public repository before a private repository. This could be exploited by attackers by placing a malicious package in the public repository that has the same name as a package from the private repository. The search path might not be directly under control of the developer relying on the framework, but this search order effectively contains an untrusted element.\n\n\n**Alternate Terms:** DLL preloading, Binary planting, Insecure library loading, Dependency confusion\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [
            "426"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Hard-code the search path to a set of known-safe values (such as system directories), or only allow them to be specified by the administrator in a configuration file. Do not allow these settings to be modified by an external party. Be careful to avoid related weaknesses such as CWE-426 and CWE-428.\n\n**Mitigation:** When invoking other programs, specify those programs using fully-qualified pathnames. While this is an effective approach, code that uses fully-qualified pathnames might not be portable to other systems that do not use the same pathnames. The portability can be improved by locating the full-qualified paths in a centralized, easily-modifiable location within the source code, and having the code refer to these paths.\n\n**Mitigation:** Remove or restrict all environment settings before invoking other programs. This includes the PATH environment variable, LD_LIBRARY_PATH, and other settings that identify the location of code libraries, and any application-specific search paths.\n\n**Mitigation:** Check your search path before use and remove any elements that are likely to be unsafe, such as the current working directory or a temporary files directory. Since this is a denylist approach, it might not be a complete solution.\n\n**Mitigation:** Use other functions that require explicit paths. Making use of any of the other readily available functions that require explicit paths is a safe way to avoid this problem. For example, system() in C does not require a full path since the shell can take care of finding the program using the PATH environment variable, while execl() and execv() require a full path.\n",
        "languages": []
    },
    {
        "cwe": "428",
        "name": "Unquoted Search Path or Element",
        "description": "The product uses a search path that contains an unquoted element, in which the element contains whitespace or other separators. This can cause the product to access resources in a parent path.",
        "detail": "**Extended Description:**\nIf a malicious individual has access to the file system, it is possible to elevate privileges by inserting such a file as \"C:\\Program.exe\" to be run by a privileged program making use of WinExec.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [
            "426"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Properly quote the full search path before executing a program on the system.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "43",
        "name": "Path Equivalence: 'filename....' (Multiple Trailing Dot)",
        "description": "The product accepts path input in the form of multiple trailing dot ('filedir....') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "163",
            "42"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "430",
        "name": "Deployment of Wrong Handler",
        "description": "The wrong \"handler\" is assigned to process an object.",
        "detail": "**Extended Description:**\nAn example of deploying the wrong handler would be calling a servlet to reveal source code of a .JSP file, or automatically \"determining\" type of the object even if it is contradictory to an explicitly specified type.\n",
        "parent": [
            "691"
        ],
        "children": [],
        "related": [
            "433",
            "434"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Perform a type check before interpreting an object.\n\n**Mitigation:** Reject any inconsistent types, such as a file with a .GIF extension that appears to consist of PHP code.\n",
        "languages": []
    },
    {
        "cwe": "431",
        "name": "Missing Handler",
        "description": "A handler is not available or implemented.",
        "detail": "**Extended Description:**\nWhen an exception is thrown and not caught, the process has given up an opportunity to decide if a given failure or event is worth a change in execution.\n",
        "parent": [
            "691"
        ],
        "children": [],
        "related": [
            "433"
        ],
        "scopes": [],
        "mitigation": "**Mitigation:** Handle all possible situations (e.g. error condition).\n\n**Mitigation:** If an operation can throw an Exception, implement a handler for that specific exception.\n",
        "languages": []
    },
    {
        "cwe": "432",
        "name": "Dangerous Signal Handler not Disabled During Sensitive Operations",
        "description": "The product uses a signal handler that shares state with other signal handlers, but it does not properly mask or prevent those signal handlers from being invoked while the original signal handler is still running.",
        "detail": "**Extended Description:**\nDuring the execution of a signal handler, it can be interrupted by another handler when a different signal is sent. If the two handlers share state - such as global variables - then an attacker can corrupt the state by sending another signal before the first handler has completed execution.\n",
        "parent": [
            "364"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Turn off dangerous handlers when performing sensitive operations.\n",
        "languages": []
    },
    {
        "cwe": "433",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "178"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "434",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "73"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "435",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "439"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "436",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "115",
            "444"
        ],
        "related": [
            "351"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "437",
        "name": "Incomplete Model of Endpoint Features",
        "description": "A product acts as an intermediary or monitor between two or more endpoints, but it does not have a complete model of an endpoint's features, behaviors, or state, potentially causing the product to perform incorrect actions based on this incomplete model.",
        "detail": null,
        "parent": [
            "436"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "439",
        "name": "Behavioral Change in New Version or Environment",
        "description": "A's behavior or functionality changes with a new version of A, or a new environment, which is not known (or manageable) by B.",
        "detail": "**Alternate Terms:** Functional change\n",
        "parent": [
            "435"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "44",
        "name": "Path Equivalence: 'file.name' (Internal Dot)",
        "description": "The product accepts path input in the form of internal dot ('file.ordir') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "41"
        ],
        "children": [
            "45"
        ],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "440",
        "name": "Expected Behavior Violation",
        "description": "A feature, API, or function does not perform according to its specification.",
        "detail": null,
        "parent": [
            "684"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "441",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "918"
        ],
        "related": [
            "611"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "444",
        "name": "Inconsistent Interpretation of HTTP Requests ('HTTP Request/Response Smuggling')",
        "description": "The product acts as an intermediary HTTP agent\n         (such as a proxy or firewall) in the data flow between two\n         entities such as a client and server, but it does not\n         interpret malformed HTTP requests or responses in ways that\n         are consistent with how the messages will be processed by\n         those entities that are at the ultimate destination.",
        "detail": "**Extended Description:**\n\n\nHTTP requests or responses (\"messages\") can be malformed or unexpected in ways that cause web servers or clients to interpret the messages in different ways than intermediary HTTP agents such as load balancers, reverse proxies, web caching proxies, application firewalls, etc. For example, an adversary may be able to add duplicate or different header fields that a client or server might interpret as one set of messages, whereas the intermediary might interpret the same sequence of bytes as a different set of messages. For example, discrepancies can arise in how to handle duplicate headers like two Transfer-encoding (TE) or two Content-length (CL), or the malicious HTTP message will have different headers for TE and CL.\n\n\nThe inconsistent parsing and interpretation of messages can allow the adversary to \"smuggle\" a message to the client/server without the intermediary being aware of it.\n\n\nThis weakness is usually the result of the usage of outdated or incompatible HTTP protocol versions in the HTTP agents.\n\n\n**Alternate Terms:** HTTP Request Smuggling, HTTP Response Smuggling, HTTP Smuggling\n\n**Consequence Note:** An attacker could create HTTP messages to exploit a number of weaknesses including 1) the message can trick the web server to associate a URL with another URL's webpage and caching the contents of the webpage (web cache poisoning attack), 2) the message can be structured to bypass the firewall protection mechanisms and gain unauthorized access to a web application, and 3) the message can invoke a script or a page that returns client credentials (similar to a Cross Site Scripting attack).\n",
        "parent": [
            "436"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Use a web server that employs a strict HTTP parsing procedure, such as Apache [REF-433].\n\n**Mitigation:** Use only SSL communication.\n\n**Mitigation:** Terminate the client session after each request.\n\n**Mitigation:** Turn all pages to non-cacheable.\n",
        "languages": []
    },
    {
        "cwe": "446",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "447",
            "448",
            "449"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "447",
        "name": "Unimplemented or Unsupported Feature in UI",
        "description": "A UI function for a security feature appears to be supported and gives feedback to the user that suggests that it is supported, but the underlying functionality is not implemented.",
        "detail": null,
        "parent": [
            "446",
            "671"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Perform functionality testing before deploying the application.\n",
        "languages": []
    },
    {
        "cwe": "448",
        "name": "Obsolete Feature in UI",
        "description": "A UI function is obsolete and the product does not warn the user.",
        "detail": null,
        "parent": [
            "446"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Remove the obsolete feature from the UI. Warn the user that the feature is no longer supported.\n",
        "languages": []
    },
    {
        "cwe": "449",
        "name": "The UI Performs the Wrong Action",
        "description": "The UI performs the wrong action with respect to the user's request.",
        "detail": null,
        "parent": [
            "446"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Perform extensive functionality testing of the UI. The UI should behave as specified.\n",
        "languages": []
    },
    {
        "cwe": "45",
        "name": "Path Equivalence: 'file...name' (Multiple Internal Dot)",
        "description": "The product accepts path input in the form of multiple internal dot ('file...dir') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "165",
            "44"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "450",
        "name": "Multiple Interpretations of UI Input",
        "description": "The UI has multiple interpretations of user input but does not prompt the user when it selects the less secure interpretation.",
        "detail": null,
        "parent": [
            "357"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "451",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1007",
            "1021"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "453",
        "name": "Insecure Default Variable Initialization",
        "description": "The product, by default, initializes an internal variable with an insecure or less secure value than is possible.",
        "detail": "**Consequence Note:** An attacker could gain access to and modify sensitive data or system information.\n",
        "parent": [
            "1188"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Disable or change default settings when they can be used to abuse the system. Since those default settings are shipped with the product they are likely to be known by a potential attacker who is familiar with the product. For instance, default credentials should be changed or the associated accounts should be disabled.\n",
        "languages": [
            "PHP"
        ]
    },
    {
        "cwe": "454",
        "name": "External Initialization of Trusted Variables or Data Stores",
        "description": "The product initializes critical internal variables or data stores using inputs that can be modified by untrusted actors.",
        "detail": "**Extended Description:**\nA product system should be reluctant to trust variables that have been initialized outside of its trust boundary, especially if they are initialized by users. The variables may have been initialized incorrectly. If an attacker can initialize the variable, then they can influence what the vulnerable system will do.\n\n**Consequence Note:** An attacker could gain access to and modify sensitive data or system information.\n",
        "parent": [
            "1419"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** A product system should be reluctant to trust variables that have been initialized outside of its trust boundary. Ensure adequate checking (e.g. input validation) is performed when relying on input from outside a trust boundary.\n\n**Mitigation:** Avoid any external control of variables. If necessary, restrict the variables that can be modified using an allowlist, and use a different namespace or naming convention if possible.\n",
        "languages": [
            "PHP"
        ]
    },
    {
        "cwe": "455",
        "name": "Non-exit on Failed Initialization",
        "description": "The product does not exit or otherwise modify its operation when security-relevant errors occur during initialization, such as when a configuration file has a format error or a hardware security module (HSM) cannot be activated, which can cause the product to execute in a less secure fashion than intended by the administrator.",
        "detail": "**Consequence Note:** The application could be placed in an insecure state that may allow an attacker to modify sensitive data or allow unintended logic to be executed.\n",
        "parent": [
            "636",
            "665",
            "705"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Follow the principle of failing securely when an error occurs. The system should enter a state where it is not vulnerable and will not display sensitive error messages to a potential attacker.\n",
        "languages": []
    },
    {
        "cwe": "456",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "457",
        "name": "Use of Uninitialized Variable",
        "description": "The code uses a variable that has not been initialized, leading to unpredictable or unintended results.",
        "detail": "**Extended Description:**\nIn some languages such as C and C++, stack variables are not initialized by default. They generally contain junk data with the contents of stack memory before the function was invoked. An attacker can sometimes control or read these contents. In other languages or conditions, a variable that is not explicitly initialized can be given a default value that has security implications, depending on the logic of the program. The presence of an uninitialized variable can sometimes indicate a typographic error in the code.\n\n**Mode of Introduction:** In C, using an uninitialized char * in some string libraries will return incorrect results, as the libraries expect the null terminator to always be at the end of a string, even if the string is empty.\n\n**Consequence Note:** Initial variables usually contain junk, which can not be trusted for consistency. This can lead to denial of service conditions, or modify control flow in unexpected ways. In some cases, an attacker can \"pre-initialize\" the variable using previous actions, which might enable code execution. This can cause a race condition if a lock variable check passes when it should not.\n\n**Consequence Note:** Strings that are not initialized are especially dangerous, since many functions expect a null at the end -- and only at the end -- of a string.\n",
        "parent": [
            "665",
            "908"
        ],
        "children": [],
        "related": [
            "456"
        ],
        "scopes": [
            "Authorization",
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Assign all variables to an initial value.\n\n**Mitigation:** Most compilers will complain about the use of uninitialized variables if warnings are turned on.\n\n**Mitigation:** When using a language that does not require explicit declaration of variables, run or compile the software in a mode that reports undeclared or unknown variables. This may indicate the presence of a typographic error in the variable's name.\n\n**Mitigation:** The choice could be made to use a language that is not susceptible to these issues.\n\n**Mitigation:** Mitigating technologies such as safe string libraries and container abstractions could be introduced.\n",
        "languages": [
            "C",
            "C++",
            "PHP",
            "Perl"
        ]
    },
    {
        "cwe": "459",
        "name": "Incomplete Cleanup",
        "description": "The product does not properly \"clean up\" and remove temporary or supporting resources after they have been used.",
        "detail": "**Alternate Terms:** Insufficient Cleanup\n\n**Consequence Note:** It is possible to overflow the number of temporary files because directories typically have limits on the number of files allowed. This could create a denial of service problem.\n",
        "parent": [
            "404"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Temporary files and other supporting resources should be deleted/released immediately after they are no longer needed.\n",
        "languages": []
    },
    {
        "cwe": "46",
        "name": "Path Equivalence: 'filename ' (Trailing Space)",
        "description": "The product accepts path input in the form of trailing space ('filedir ') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "162",
            "41"
        ],
        "children": [],
        "related": [
            "289"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "460",
        "name": "Improper Cleanup on Thrown Exception",
        "description": "The product does not clean up its state or incorrectly cleans up its state when an exception is thrown, leading to unexpected state or control flow.",
        "detail": "**Extended Description:**\nOften, when functions or loops become complicated, some level of resource cleanup is needed throughout execution. Exceptions can disturb the flow of the code and prevent the necessary cleanup from happening.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** The code could be left in a bad state.\n",
        "parent": [
            "459",
            "755"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If one breaks from a loop or function by throwing an exception, make sure that cleanup happens or that you should exit the program. Use throwing exceptions sparsely.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "462",
        "name": "Duplicate Key in Associative List (Alist)",
        "description": "Duplicate keys in associative lists can lead to non-unique keys being mistaken for an error.",
        "detail": "**Extended Description:**\nA duplicate key entry -- if the alist is designed properly -- could be used as a constant time replace function. However, duplicate key entries could be inserted by mistake. Because of this ambiguity, duplicate key entries in an association list are not recommended and should not be allowed.\n",
        "parent": [
            "694"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Use a hash table instead of an alist.\n\n**Mitigation:** Use an alist which checks the uniqueness of hash keys with each entry before inserting the entry.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "463",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "170"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "464",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "170"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "466",
        "name": "Return of Pointer Value Outside of Expected Range",
        "description": "A function can return a pointer to memory that is outside of the buffer that the pointer is expected to reference.",
        "detail": null,
        "parent": [
            "119",
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "467",
        "name": "Use of sizeof() on a Pointer Type",
        "description": "The code calls sizeof() on a pointer type, which can be an incorrect calculation if the programmer intended to determine the size of the data that is being pointed to.",
        "detail": "**Extended Description:**\nThe use of sizeof() on a pointer can sometimes generate useful information. An obvious case is to find out the wordsize on a platform. More often than not, the appearance of sizeof(pointer) indicates a bug.\n\n**Consequence Note:** This error can often cause one to allocate a buffer that is much smaller than what is needed, leading to resultant weaknesses such as buffer overflows.\n",
        "parent": [
            "131"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use expressions such as \"sizeof(*pointer)\" instead of \"sizeof(pointer)\", unless you intend to run sizeof() on a pointer type to gain some platform independence or if you are allocating a variable on the stack.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "468",
        "name": "Incorrect Pointer Scaling",
        "description": "In C and C++, one may often accidentally refer to the wrong memory due to the semantics of when math operations are implicitly scaled.",
        "detail": "**Mode of Introduction:** Programmers may try to index from a pointer by adding a number of bytes. This is incorrect because C and C++ implicitly scale the operand by the size of the data type.\n\n**Consequence Note:** Incorrect pointer scaling will often result in buffer overflow conditions. Confidentiality can be compromised if the weakness is in the context of a buffer over-read or under-read.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use a platform with high-level memory abstractions.\n\n**Mitigation:** Always use array indexing instead of direct pointer manipulation.\n\n**Mitigation:** Use technologies for preventing buffer overflows.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "469",
        "name": "Use of Pointer Subtraction to Determine Size",
        "description": "The product subtracts one pointer from another in order to determine size, but this calculation can be incorrect if the pointers do not exist in the same memory chunk.",
        "detail": "**Consequence Note:** There is the potential for arbitrary code execution with privileges of the vulnerable program.\n",
        "parent": [
            "682"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Save an index variable. This is the recommended solution. Rather than subtract pointers from one another, use an index variable of the same size as the pointers in question. Use this variable to \"walk\" from one pointer to the other and calculate the difference. Always validate this number.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "47",
        "name": "Path Equivalence: ' filename' (Leading Space)",
        "description": "The product accepts path input in the form of leading space (' filedir') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "470",
        "name": "Use of Externally-Controlled Input to Select Classes or Code ('Unsafe Reflection')",
        "description": "The product uses external input with reflection to select which classes or code to use, but it does not sufficiently prevent the input from selecting improper classes or code.",
        "detail": "**Extended Description:**\nIf the product uses external inputs to determine which class to instantiate or which method to invoke, then an attacker could supply values to select unexpected classes or methods. If this occurs, then the attacker could create control flow paths that were not intended by the developer. These paths could bypass authentication or access control checks, or otherwise cause the product to behave in an unexpected manner. This situation becomes a doomsday scenario if the attacker can upload files into a location that appears on the product's classpath (CWE-427) or add new entries to the product's classpath (CWE-426). Under either of these conditions, the attacker can use reflection to introduce new, malicious behavior into the product.\n\n**Alternate Terms:** Reflection Injection\n\n**Consequence Note:** The attacker might be able to execute code that is not directly accessible to the attacker. Alternately, the attacker could call unexpected code in the wrong place or the wrong time, possibly modifying critical system state.\n\n**Consequence Note:** The attacker might be able to use reflection to call the wrong code, possibly with unexpected arguments that violate the API (CWE-227). This could cause the product to exit or hang.\n\n**Consequence Note:** By causing the wrong code to be invoked, the attacker might be able to trigger a runtime error that leaks sensitive information in the error message, such as CWE-536.\n",
        "parent": [
            "20",
            "610",
            "913"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Refactor your code to avoid using reflection.\n\n**Mitigation:** Do not use user-controlled inputs to select and load classes or code.\n\n**Mitigation:** Apply strict input validation by using allowlists or indirect selection to ensure that the user is only selecting allowable classes or code.\n",
        "languages": [
            "Java",
            "PHP"
        ]
    },
    {
        "cwe": "471",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "472"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "472",
        "name": "External Control of Assumed-Immutable Web Parameter",
        "description": "The web application does not sufficiently verify inputs that are assumed to be immutable but are actually externally controllable, such as hidden form fields.",
        "detail": "**Extended Description:**\n\n\nIf a web product does not properly protect assumed-immutable values from modification in hidden form fields, parameters, cookies, or URLs, this can lead to modification of critical data. Web applications often mistakenly make the assumption that data passed to the client in hidden fields or cookies is not susceptible to tampering. Improper validation of data that are user-controllable can lead to the application processing incorrect, and often malicious, input.\n\n\nFor example, custom cookies commonly store session data or persistent data across sessions. This kind of session data is normally involved in security related decisions on the server side, such as user authentication and access control. Thus, the cookies might contain sensitive data such as user credentials and privileges. This is a dangerous practice, as it can often lead to improper reliance on the value of the client-provided cookie by the server side application.\n\n\n**Alternate Terms:** Assumed-Immutable Parameter Tampering\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** Without appropriate protection mechanisms, the client can easily tamper with cookies and similar web data. Reliance on the cookies without detailed validation can lead to problems such as SQL injection. If you use cookie values for security related decisions on the server side, manipulating the cookies might lead to violations of security policies such as authentication bypassing, user impersonation and privilege escalation. In addition, storing sensitive data in the cookie without appropriate protection can also lead to disclosure of sensitive user data, especially data stored in persistent cookies.\n",
        "parent": [
            "471",
            "642"
        ],
        "children": [],
        "related": [
            "656"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "473",
        "name": "PHP External Variable Modification",
        "description": "A PHP application does not properly protect against the modification of variables from external sources, such as query parameters or cookies. This can expose the application to numerous weaknesses that would not exist otherwise.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "471"
        ],
        "children": [],
        "related": [
            "616",
            "98"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Carefully identify which variables can be controlled or influenced by an external user, and consider adopting a naming convention to emphasize when externally modifiable variables are being used. An application should be reluctant to trust variables that have been initialized outside of its trust boundary. Ensure adequate checking is performed when relying on input from outside a trust boundary. Do not allow your application to run with register_globals enabled. If you implement a register_globals emulator, be extremely careful of variable extraction, dynamic evaluation, and similar issues, since weaknesses in your emulation could allow external variable modification to take place even without register_globals.\n",
        "languages": [
            "PHP"
        ]
    },
    {
        "cwe": "474",
        "name": "Use of Function with Inconsistent Implementations",
        "description": "The code uses a function that has inconsistent implementations across operating systems and versions.",
        "detail": "**Extended Description:**\n\n\nThe use of inconsistent implementations can cause changes in behavior when the code is ported or built under a different environment than the programmer expects, which can lead to security problems in some cases.\n\n\nThe implementation of many functions varies by platform, and at times, even by different versions of the same platform. Implementation differences can include:\n\n\n  - Slight differences in the way parameters are interpreted leading to inconsistent results.\n\n  - Some implementations of the function carry significant security risks.\n\n  - The function might not be defined on all platforms.\n\n  - The function might change which return codes it can provide, or change the meaning of its return codes.\n\n\n",
        "parent": [
            "758"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not accept inconsistent behavior from the API specifications when the deviant behavior increase the risk level.\n",
        "languages": [
            "C",
            "PHP"
        ]
    },
    {
        "cwe": "475",
        "name": "Undefined Behavior for Input to API",
        "description": "The behavior of this function is undefined unless its control parameter is set to a specific value.",
        "detail": null,
        "parent": [
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "476",
        "name": "NULL Pointer Dereference",
        "description": "The product dereferences a pointer that it expects to be valid but is NULL.",
        "detail": "**Alternate Terms:** NPD, null deref, NPE, nil pointer dereference\n\n**Consequence Note:** NULL pointer dereferences usually result in the failure of the process unless exception handling (on some platforms) is available and implemented. Even when exception handling is being used, it can still be very difficult to return the software to a safe state of operation.\n\n**Consequence Note:** In rare circumstances, when NULL is equivalent to the 0x0 memory address and privileged code can access it, then writing or reading memory is possible, which may lead to code execution.\n",
        "parent": [
            "710",
            "754"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Detection:** Identify error conditions that are not likely to occur during normal usage and trigger them. For example, run the program under low memory conditions, run with insufficient privileges or permissions, interrupt a transaction before it is completed, or disable connectivity to basic network services such as DNS. Monitor the software for any unexpected behavior. If you trigger an unhandled exception or similar error that was discovered and handled by the application's environment, it may still indicate unexpected conditions that were not handled by the application itself.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** For any pointers that could have been modified or provided from a function that can return NULL, check the pointer for NULL before use. When working with a multithreaded or otherwise asynchronous environment, ensure that proper locking APIs are used to lock before the check, and unlock when it has finished.\n\n**Mitigation:** Select a programming language that is not susceptible to these issues.\n\n**Mitigation:** Check the results of all functions that return a value and verify that the value is non-null before acting upon it.\n\n**Effectiveness:** Checking the return value of the function will typically be sufficient, however beware of race conditions (CWE-362) in a concurrent environment. This solution does not handle the use of improperly initialized variables (CWE-665).\n\n**Mitigation:** Identify all variables and data stores that receive information from external sources, and apply input validation to make sure that they are only initialized to expected values.\n\n**Mitigation:** Explicitly initialize all variables and other data stores, either during declaration or just before the first usage.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Go",
            "Java"
        ]
    },
    {
        "cwe": "477",
        "name": "Use of Obsolete Function",
        "description": "The code uses deprecated or obsolete functions, which suggests that the code has not been actively reviewed or maintained.",
        "detail": "**Extended Description:**\n\n\nAs programming languages evolve, functions occasionally become obsolete due to:\n\n\n  - Advances in the language\n\n  - Improved understanding of how operations should be performed effectively and securely\n\n  - Changes in the conventions that govern certain operations\n\nFunctions that are removed are usually replaced by newer counterparts that perform the same task in some different and hopefully improved way.\n",
        "parent": [
            "710"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBinary / Bytecode Quality Analysis\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tDebugger\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource Code Quality Analyzer\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tOrigin Analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** Refer to the documentation for the obsolete function in order to determine why it is deprecated or obsolete and to learn about alternative ways to achieve the same functionality.\n\n**Mitigation:** Consider seriously the security implications of using an obsolete function. Consider using alternate functions.\n",
        "languages": []
    },
    {
        "cwe": "478",
        "name": "Missing Default Case in Multiple Condition Expression",
        "description": "The code does not have a default case in an expression with multiple conditions, such as a switch statement.",
        "detail": "**Extended Description:**\nIf a multiple-condition expression (such as a switch in C) omits the default case but does not consider or handle all possible values that could occur, then this might lead to complex logical errors and resultant weaknesses. Because of this, further decisions are made based on poor information, and cascading failure results. This cascading failure may result in any number of security issues, and constitutes a significant failure in the system.\n\n**Consequence Note:** Depending on the logical circumstances involved, any consequences may result: e.g., issues of confidentiality, authentication, authorization, availability, integrity, accountability, or non-repudiation.\n",
        "parent": [
            "1023"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Ensure that there are no cases unaccounted for when adjusting program flow or values based on the value of a given variable. In the case of switch style statements, the very simple act of creating a default case can, if done correctly, mitigate this situation. Often however, the default case is used simply to represent an assumed option, as opposed to working as a check for invalid input. This is poor practice and in some cases is as bad as omitting a default case entirely.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java",
            "JavaScript",
            "Python"
        ]
    },
    {
        "cwe": "479",
        "name": "Signal Handler Use of a Non-reentrant Function",
        "description": "The product defines a signal handler that calls a non-reentrant function.",
        "detail": "**Extended Description:**\n\n\nNon-reentrant functions are functions that cannot safely be called, interrupted, and then recalled before the first call has finished without resulting in memory corruption. This can lead to an unexpected system state and unpredictable results with a variety of potential consequences depending on context, including denial of service and code execution.\n\n\nMany functions are not reentrant, but some of them can result in the corruption of memory if they are used in a signal handler. The function call syslog() is an example of this. In order to perform its functionality, it allocates a small amount of memory as \"scratch space.\" If syslog() is suspended by a signal call and the signal handler calls syslog(), the memory used by both of these functions enters an undefined, and possibly, exploitable state. Implementations of malloc() and free() manage metadata in global structures in order to track which memory is allocated versus which memory is available, but they are non-reentrant. Simultaneous calls to these functions can cause corruption of the metadata.\n\n\n**Consequence Note:** It may be possible to execute arbitrary code through the use of a write-what-where condition.\n\n**Consequence Note:** Signal race conditions often result in data corruption.\n",
        "parent": [
            "663",
            "828"
        ],
        "children": [],
        "related": [
            "123"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Require languages or libraries that provide reentrant functionality, or otherwise make it easier to avoid this weakness.\n\n**Mitigation:** Design signal handlers to only set flags rather than perform complex functionality.\n\n**Mitigation:** Ensure that non-reentrant functions are not found in signal handlers.\n\n**Mitigation:** Use sanity checks to reduce the timing window for exploitation of race conditions. This is only a partial solution, since many attacks might fail, but other attacks still might work within the narrower window, even accidentally.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "48",
        "name": "Path Equivalence: 'file name' (Internal Whitespace)",
        "description": "The product accepts path input in the form of internal space ('file(SPACE)name') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "480",
        "name": "Use of Incorrect Operator",
        "description": "The product accidentally uses the wrong operator, which changes the logic in security-relevant ways.",
        "detail": "**Extended Description:**\nThese types of errors are generally the result of a typo by the programmer.\n\n**Consequence Note:** This weakness can cause unintended logic to be executed and other unexpected application behavior.\n",
        "parent": [
            "670"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** This weakness can be found easily using static analysis. However in some cases an operator might appear to be incorrect, but is actually correct and reflects unusual logic within the program.\n\n**Detection:** This weakness can be found easily using static analysis. However in some cases an operator might appear to be incorrect, but is actually correct and reflects unusual logic within the program.\n",
        "languages": [
            "C",
            "C++",
            "Perl"
        ]
    },
    {
        "cwe": "481",
        "name": "Assigning instead of Comparing",
        "description": "The code uses an operator for assignment when the intention was to perform a comparison.",
        "detail": "**Extended Description:**\nIn many languages the compare statement is very close in appearance to the assignment statement and are often confused. This bug is generally the result of a typo and usually causes obvious problems with program execution. If the comparison is in an if statement, the if statement will usually evaluate the value of the right-hand side of the predicate.\n",
        "parent": [
            "480"
        ],
        "children": [],
        "related": [
            "697"
        ],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Many IDEs and static analysis products will detect this problem.\n\n**Mitigation:** Place constants on the left. If one attempts to assign a constant with a variable, the compiler will produce an error.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "482",
        "name": "Comparing instead of Assigning",
        "description": "The code uses an operator for comparison when the intention was to perform an assignment.",
        "detail": "**Extended Description:**\nIn many languages, the compare statement is very close in appearance to the assignment statement; they are often confused.\n\n**Mode of Introduction:** This bug primarily originates from a typo.\n\n**Consequence Note:** The assignment will not take place, which should cause obvious program execution problems.\n",
        "parent": [
            "480"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Many IDEs and static analysis products will detect this problem.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "483",
        "name": "Incorrect Block Delimitation",
        "description": "The code does not explicitly delimit a block that is intended to contain 2 or more statements, creating a logic error.",
        "detail": "**Extended Description:**\nIn some languages, braces (or other delimiters) are optional for blocks. When the delimiter is omitted, it is possible to insert a logic error in which a statement is thought to be in a block but is not. In some cases, the logic error can have security implications.\n\n**Consequence Note:** This is a general logic error which will often lead to obviously-incorrect behaviors that are quickly noticed and fixed. In lightly tested or untested code, this error may be introduced it into a production environment and provide additional attack vectors by creating a control flow path leading to an unexpected state in the application. The consequences will depend on the types of behaviors that are being incorrectly executed.\n",
        "parent": [
            "670"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Always use explicit block delimitation and use static-analysis technologies to enforce this practice.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "484",
        "name": "Omitted Break Statement in Switch",
        "description": "The product omits a break statement within a switch or similar construct, causing code associated with multiple conditions to execute. This can cause problems when the programmer only intended to execute code associated with one condition.",
        "detail": "**Extended Description:**\nThis can lead to critical code executing in situations where it should not.\n\n**Consequence Note:** This weakness can cause unintended logic to be executed and other unexpected application behavior.\n",
        "parent": [
            "670",
            "710"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Omission of a break statement might be intentional, in order to support fallthrough. Automated detection methods might therefore be erroneous. Semantic understanding of expected product behavior is required to interpret whether the code is correct.\n\n**Detection:** Since this weakness is associated with a code construct, it would be indistinguishable from other errors that produce the same behavior.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Omitting a break statement so that one may fall through is often indistinguishable from an error, and therefore should be avoided. If you need to use fall-through capabilities, make sure that you have clearly documented this within the switch statement, and ensure that you have examined all the logical possibilities.\n\n**Mitigation:** The functionality of omitting a break statement could be clarified with an if statement. This method is much safer.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java",
            "PHP"
        ]
    },
    {
        "cwe": "486",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "386"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "487",
        "name": "Reliance on Package-level Scope",
        "description": "Java packages are not inherently closed; therefore, relying on them for code security is not a good practice.",
        "detail": "**Extended Description:**\nThe purpose of package scope is to prevent accidental access by other parts of a program. This is an ease-of-software-development feature but not a security feature.\n\n**Consequence Note:** Any data in a Java package can be accessed outside of the Java framework if the package is distributed.\n\n**Consequence Note:** The data in a Java class can be modified by anyone outside of the Java framework if the packages is distributed.\n",
        "parent": [
            "664"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Data should be private static and final whenever possible. This will assure that your code is protected by instantiating early, preventing access and tampering.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "488",
        "name": "Exposure of Data Element to Wrong Session",
        "description": "The product does not sufficiently enforce boundaries between the states of different sessions, causing data to be provided to, or used by, the wrong session.",
        "detail": "**Extended Description:**\n\n\nData can \"bleed\" from one session to another through member variables of singleton objects, such as Servlets, and objects from a shared pool.\n\n\nIn the case of Servlets, developers sometimes do not understand that, unless a Servlet implements the SingleThreadModel interface, the Servlet is a singleton; there is only one instance of the Servlet, and that single instance is used and re-used to handle multiple requests that are processed simultaneously by different threads. A common result is that developers use Servlet member fields in such a way that one user may inadvertently see another user's data. In other words, storing user data in Servlet member fields introduces a data access race condition.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Protect the application's sessions from information leakage. Make sure that a session's data is not used or visible by other sessions.\n\n**Mitigation:** Use a static analysis tool to scan the code for information leakage vulnerabilities (e.g. Singleton Member Field).\n\n**Mitigation:** In a multithreading environment, storing user data in Servlet member fields introduces a data access race condition. Do not use member fields to store information in the Servlet.\n",
        "languages": []
    },
    {
        "cwe": "489",
        "name": "Active Debug Code",
        "description": "The product is deployed to unauthorized actors with debugging code still enabled or active, which can create unintended entry points or expose sensitive information.",
        "detail": "**Extended Description:**\nA common development practice is to add \"back door\" code specifically designed for debugging or testing purposes that is not intended to be shipped or deployed with the product. These back door entry points create security risks because they are not considered during design or testing and fall outside of the expected operating conditions of the product.\n\n**Alternate Terms:** Leftover debug code\n\n**Mode of Introduction:** In web-based applications, debug code is used to test and modify web application properties, configuration information, and functions. If a debug application is left on a production server, this oversight during the \"software process\" allows attackers access to debug functionality.\n\n**Consequence Note:** The severity of the exposed debug application will depend on the particular instance. At the least, it will give an attacker sensitive information about the settings and mechanics of web applications on the server. At worst, as is often the case, the debug application will allow an attacker complete control over the web application and server, as well as confidential information that either of these access.\n",
        "parent": [
            "710"
        ],
        "children": [],
        "related": [
            "215"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Remove debug code before deploying the application.\n",
        "languages": []
    },
    {
        "cwe": "49",
        "name": "Path Equivalence: 'filename/' (Trailing Slash)",
        "description": "The product accepts path input in the form of trailing slash ('filedir/') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "162",
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "491",
        "name": "Public cloneable() Method Without Final ('Object Hijack')",
        "description": "A class has a cloneable() method that is not declared final, which allows an object to be created without calling the constructor. This can cause the object to be in an unexpected state.",
        "detail": null,
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Make the cloneable() method final.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "492",
        "name": "Use of Inner Class Containing Sensitive Data",
        "description": "Inner classes are translated into classes that are accessible at package scope and may expose code that the programmer intended to keep private to attackers.",
        "detail": "**Extended Description:**\nInner classes quietly introduce several security concerns because of the way they are translated into Java bytecode. In Java source code, it appears that an inner class can be declared to be accessible only by the enclosing class, but Java bytecode has no concept of an inner class, so the compiler must transform an inner class declaration into a peer class with package level access to the original outer class. More insidiously, since an inner class can access private fields in its enclosing class, once an inner class becomes a peer class in bytecode, the compiler converts private fields accessed by the inner class into protected fields.\n\n**Consequence Note:** \"Inner Classes\" data confidentiality aspects can often be overcome.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Using sealed classes protects object-oriented encapsulation paradigms and therefore protects code from being extended in unforeseen ways.\n\n**Mitigation:** Inner Classes do not provide security. Warning: Never reduce the security of the object from an outer class, going to an inner class. If an outer class is final or private, ensure that its inner class is private as well.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "493",
        "name": "Critical Public Variable Without Final Modifier",
        "description": "The product has a critical public variable that is not final, which allows the variable to be modified to contain unexpected values.",
        "detail": "**Extended Description:**\nIf a field is non-final and public, it can be changed once the value is set by any function that has access to the class which contains the field. This could lead to a vulnerability if other parts of the program make assumptions about the contents of that field.\n\n**Background Details:**\n[\"Mobile code, such as a Java Applet, is code that is transmitted across a network and executed on a remote machine. Because mobile code developers have little if any control of the environment in which their code will execute, special security concerns become relevant. One of the biggest environmental threats results from the risk that the mobile code will run side-by-side with other, potentially malicious, mobile code. Because all of the popular web browsers execute code from multiple sources together in the same JVM, many of the security guidelines for mobile code are focused on preventing manipulation of your objects' state and behavior by adversaries who have access to the same virtual machine where your program is running.\", 'Final provides security by only allowing non-mutable objects to be changed after being set. However, only objects which are not extended can be made final.']\n\n**Consequence Note:** The object could potentially be tampered with.\n\n**Consequence Note:** The object could potentially allow the object to be read.\n",
        "parent": [
            "668"
        ],
        "children": [
            "500"
        ],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Declare all public fields as final when possible, especially if it is used to maintain internal state of an Applet or of classes used by an Applet. If a field must be public, then perform all appropriate sanity checks before accessing the field from your code.\n",
        "languages": [
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "494",
        "name": "Download of Code Without Integrity Check",
        "description": "The product downloads source code or an executable from a remote location and executes the code without sufficiently verifying the origin and integrity of the code.",
        "detail": "**Extended Description:**\nAn attacker can execute malicious code by compromising the host server, performing DNS spoofing, or modifying the code in transit.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** Executing untrusted code could compromise the control flow of the program. The untrusted code could execute attacker-controlled commands, read or modify sensitive resources, or prevent the software from functioning correctly for legitimate users.\n",
        "parent": [
            "345",
            "669"
        ],
        "children": [],
        "related": [
            "79"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can be detected using tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session.\n\n\nSpecifically, manual static analysis is typically required to find the behavior that triggers the download of code, and to determine whether integrity-checking methods are in use.\n\n\n**Detection:** \n\nUse monitoring tools that examine the software's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the software was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.\n\n\nAttach the monitor to the process and also sniff the network connection. Trigger features related to product updates or plugin installation, which is likely to force a code download. Monitor when files are downloaded and separately executed, or if they are otherwise read back into the process. Look for evidence of cryptographic library calls that use integrity checking.\n\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Perform proper forward and reverse DNS lookups to detect DNS spoofing.\n\n**Effectiveness:** This is only a partial solution since it will not prevent your code from being modified on the hosting site or in transit.\n\n**Mitigation:** \n\nEncrypt the code with a reliable encryption scheme before transmitting.\n\n\nThis will only be a partial solution, since it will not detect DNS spoofing and it will not prevent your code from being modified on the hosting site.\n\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nSpeficially, it may be helpful to use tools or frameworks to perform integrity checking on the transmitted code.\n\n\n  - When providing the code that is to be downloaded, such as for automatic updates of the software, then use cryptographic signatures for the code and modify the download clients to verify the signatures. Ensure that the implementation does not contain CWE-295, CWE-320, CWE-347, and related weaknesses.\n\n  - Use code signing technologies such as Authenticode. See references [REF-454] [REF-455] [REF-456].\n\n\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** \n\nRun the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n\n\nOS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Effectiveness:** The effectiveness of this mitigation depends on the prevention capabilities of the specific sandbox or jail being used and might only help to reduce the scope of an attack, such as restricting the attacker to certain system calls or limiting the portion of the file system that can be accessed.\n",
        "languages": []
    },
    {
        "cwe": "495",
        "name": "Private Data Structure Returned From A Public Method",
        "description": "The product has a method that is declared public, but returns a reference to a private data structure, which could then be modified in unexpected ways.",
        "detail": "**Consequence Note:** The contents of the data structure can be modified from outside the intended scope.\n",
        "parent": [
            "664"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Declare the method private.\n\n**Mitigation:** Clone the member data and keep an unmodified version of the data private to the object.\n\n**Mitigation:** Use public setter methods that govern how a private member can be modified.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "496",
        "name": "Public Data Assigned to Private Array-Typed Field",
        "description": "Assigning public data to a private array is equivalent to giving public access to the array.",
        "detail": "**Consequence Note:** The contents of the array can be modified from outside the intended scope.\n",
        "parent": [
            "664"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not allow objects to modify private members of a class.\n",
        "languages": [
            "C",
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "497",
        "name": "Exposure of Sensitive System Information to an Unauthorized Control Sphere",
        "description": "The product does not properly prevent sensitive system-level information from being accessed by unauthorized actors who do not have the same level of access to the underlying system as the product does.",
        "detail": "**Extended Description:**\n\n\nNetwork-based products, such as web applications, often run on top of an operating system or similar environment. When the product communicates with outside parties, details about the underlying system are expected to remain hidden, such as path names for data files, other OS users, installed packages, the application environment, etc. This system information may be provided by the product itself, or buried within diagnostic or debugging messages. Debugging information helps an adversary learn about the system and form an attack plan.\n\n\nAn information exposure occurs when system data or debugging information leaves the program through an output stream or logging function that makes it accessible to unauthorized parties. Using other weaknesses, an attacker could cause errors to occur; the response to these errors can reveal detailed system information, along with other impacts. An attacker can use messages that reveal technologies, operating systems, and product versions to tune the attack against known vulnerabilities in these technologies. A product may use diagnostic methods that provide significant implementation details such as stack traces as part of its error handling mechanism.\n\n",
        "parent": [
            "200"
        ],
        "children": [
            "214"
        ],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Production applications should never use methods that generate internal details such as stack traces and error messages unless that information is directly committed to a log that is not viewable by the end user. All error message text should be HTML entity encoded before being written to the log file to protect against potential cross-site scripting attacks against the viewer of the logs\n",
        "languages": []
    },
    {
        "cwe": "498",
        "name": "Cloneable Class Containing Sensitive Information",
        "description": "The code contains a class with sensitive data, but the class is cloneable. The data can then be accessed by cloning the class.",
        "detail": "**Extended Description:**\nCloneable classes are effectively open classes, since data cannot be hidden in them. Classes that do not explicitly deny cloning can be cloned by any other class without running the constructor.\n\n**Consequence Note:** A class that can be cloned can be produced without executing the constructor. This is dangerous since the constructor may perform security-related checks. By allowing the object to be cloned, those checks may be bypassed.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [
            "200"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** If you do make your classes clonable, ensure that your clone method is final and throw super.clone().\n",
        "languages": [
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "499",
        "name": "Serializable Class Containing Sensitive Data",
        "description": "The code contains a class with sensitive data, but the class does not explicitly deny serialization. The data can be accessed by serializing the class through another class.",
        "detail": "**Extended Description:**\nSerializable classes are effectively open classes since data cannot be hidden in them. Classes that do not explicitly deny serialization can be serialized by any other class, which can then in turn use the data stored inside it.\n\n**Consequence Note:** an attacker can write out the class to a byte stream, then extract the important data from it.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [
            "200"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** In Java, explicitly define final writeObject() to prevent serialization. This is the recommended solution. Define the writeObject() function to throw an exception explicitly denying serialization.\n\n**Mitigation:** Make sure to prevent serialization of your objects.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "5",
        "name": "J2EE Misconfiguration: Data Transmission Without Encryption",
        "description": "Information sent over a network can be compromised while in transit. An attacker may be able to read or modify the contents if the data are sent in plaintext or are weakly encrypted.",
        "detail": null,
        "parent": [
            "319"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** The product configuration should ensure that SSL or an encryption mechanism of equivalent strength and vetted reputation is used for all access-controlled pages.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "50",
        "name": "Path Equivalence: '//multiple/leading/slash'",
        "description": "The product accepts path input in the form of multiple leading slash ('//multiple/leading/slash') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "161",
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "500",
        "name": "Public Static Field Not Marked Final",
        "description": "An object contains a public static field that is not marked final, which might allow it to be modified in unexpected ways.",
        "detail": "**Extended Description:**\nPublic static variables can be read without an accessor and changed without a mutator by any classes in the application.\n\n**Background Details:**\n['When a field is declared public but not final, the field can be read and written to by arbitrary Java code.']\n\n**Consequence Note:** The object could potentially be tampered with.\n\n**Consequence Note:** The object could potentially allow the object to be read.\n",
        "parent": [
            "493"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Clearly identify the scope for all critical data elements, including whether they should be regarded as static.\n\n**Mitigation:** \n\nMake any static fields private and constant.\n\n\nA constant field is denoted by the keyword 'const' in C/C++ and ' final' in Java\n\n",
        "languages": [
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "501",
        "name": "Trust Boundary Violation",
        "description": "The product mixes trusted and untrusted data in the same data structure or structured message.",
        "detail": "**Extended Description:**\nA trust boundary can be thought of as line drawn through a program. On one side of the line, data is untrusted. On the other side of the line, data is assumed to be trustworthy. The purpose of validation logic is to allow data to safely cross the trust boundary - to move from untrusted to trusted. A trust boundary violation occurs when a program blurs the line between what is trusted and what is untrusted. By combining trusted and untrusted data in the same data structure, it becomes easier for programmers to mistakenly trust unvalidated data.\n",
        "parent": [
            "664"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "502",
        "name": "Deserialization of Untrusted Data",
        "description": "The product deserializes untrusted data without sufficiently ensuring that the resulting data will be valid.",
        "detail": "**Alternate Terms:** Marshaling, Unmarshaling, Pickling, Unpickling, PHP Object Injection\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Background Details:**\n['Serialization and deserialization refer to the process of taking program-internal object-related data, packaging it in a way that allows the data to be externally stored or transferred (\"serialization\"), then extracting the serialized data to reconstruct the original object (\"deserialization\").']\n\n**Consequence Note:** Attackers can modify unexpected objects or data that was assumed to be safe from modification. Deserialized data or code could be modified without using the provided accessor functions, or unexpected functions could be invoked.\n\n**Consequence Note:** If a function is making an assumption on when to terminate, based on a sentry in a string, it could easily never terminate.\n\n**Consequence Note:** The consequences can vary widely, because it depends on which objects or methods are being deserialized, and how they are used. Making an assumption that the code in the deserialized object is valid is dangerous and can enable exploitation. One example is attackers using gadget chains to perform unauthorized actions, such as generating a shell.\n",
        "parent": [
            "913"
        ],
        "children": [],
        "related": [
            "915"
        ],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If available, use the signing/sealing features of the programming language to assure that deserialized data has not been tainted. For example, a hash-based message authentication code (HMAC) could be used to ensure that data has not been modified.\n\n**Mitigation:** When deserializing data, populate a new object rather than just deserializing. The result is that the data flows through safe input validation and that the functions are safe.\n\n**Mitigation:** Explicitly define a final object() to prevent deserialization.\n\n**Mitigation:** \n\nMake fields transient to protect them from deserialization.\n\n\nAn attempt to serialize and then deserialize a class containing transient fields will result in NULLs where the transient data should be. This is an excellent way to prevent time, environment-based, or sensitive variables from being carried over and used improperly.\n\n\n**Mitigation:** Avoid having unnecessary types or gadgets (a sequence of instances and method invocations that can self-execute during the deserialization process, often found in libraries) available that can be leveraged for malicious ends. This limits the potential for unintended or unauthorized types and gadgets to be leveraged by the attacker. Add only acceptable classes to an allowlist. Note: new gadgets are constantly being discovered, so this alone is not a sufficient mitigation.\n\n**Mitigation:** Employ cryptography of the data or code for protection. However, it's important to note that it would still be client-side security. This is risky because if the client is compromised then the security implemented on the client (the cryptography) can be bypassed.\n",
        "languages": [
            "Java",
            "JavaScript",
            "PHP",
            "Python",
            "Ruby"
        ]
    },
    {
        "cwe": "506",
        "name": "Embedded Malicious Code",
        "description": "The product contains code that appears to be malicious in nature.",
        "detail": "**Extended Description:**\nMalicious flaws have acquired colorful names, including Trojan horse, trapdoor, timebomb, and logic-bomb. A developer might insert malicious code with the intent to subvert the security of a product or its host system at some time in the future. It generally refers to a program that performs a useful service but exploits rights of the program's user in a way the user does not intend.\n",
        "parent": [
            "912"
        ],
        "children": [
            "507",
            "510",
            "511",
            "512"
        ],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\t\tGenerated Code Inspection\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAutomated Monitored Execution\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tOrigin Analysis\n\n**Mitigation:** Remove the malicious code and start an effort to ensure that no more malicious code exists. This may require a detailed review of all code, as it is possible to hide a serious attack in only one or two lines of code. These lines may be located almost anywhere in an application and may have been intentionally obfuscated by the attacker.\n",
        "languages": []
    },
    {
        "cwe": "507",
        "name": "Trojan Horse",
        "description": "The product appears to contain benign or useful functionality, but it also contains code that is hidden from normal operation that violates the intended security policy of the user or the system administrator.",
        "detail": null,
        "parent": [
            "506"
        ],
        "children": [
            "508",
            "509"
        ],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Most antivirus software scans for Trojan Horses.\n\n**Mitigation:** Verify the integrity of the product that is being installed.\n",
        "languages": []
    },
    {
        "cwe": "508",
        "name": "Non-Replicating Malicious Code",
        "description": "Non-replicating malicious code only resides on the target system or product that is attacked; it does not attempt to spread to other systems.",
        "detail": null,
        "parent": [
            "507"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Antivirus software can help mitigate known malicious code.\n\n**Mitigation:** Verify the integrity of the software that is being installed.\n",
        "languages": []
    },
    {
        "cwe": "509",
        "name": "Replicating Malicious Code (Virus or Worm)",
        "description": "Replicating malicious code, including viruses and worms, will attempt to attack other systems once it has successfully compromised the target system or the product.",
        "detail": null,
        "parent": [
            "507"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Antivirus software scans for viruses or worms.\n\n**Mitigation:** Always verify the integrity of the software that is being installed.\n",
        "languages": []
    },
    {
        "cwe": "51",
        "name": "Path Equivalence: '/multiple//internal/slash'",
        "description": "The product accepts path input in the form of multiple internal slash ('/multiple//internal/slash/') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "510",
        "name": "Trapdoor",
        "description": "A trapdoor is a hidden piece of code that responds to a special input, allowing its user access to resources without passing through the normal security enforcement mechanism.",
        "detail": null,
        "parent": [
            "506"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInter-application Flow Analysis\n\t\tBinary / Bytecode simple extractor - strings, ELF readers, etc.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\t\tGenerated Code Inspection\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAutomated Monitored Execution\n\t\tForced Path Execution\n\t\tDebugger\n\t\tMonitored Virtual Environment - run potentially malicious code in sandbox / wrapper / virtual machine, see if it does anything suspicious\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\n**Mitigation:** Always verify the integrity of the software that is being installed.\n\n**Mitigation:** Identify and closely inspect the conditions for entering privileged areas of the code, especially those related to authentication, process invocation, and network communications.\n",
        "languages": []
    },
    {
        "cwe": "511",
        "name": "Logic/Time Bomb",
        "description": "The product contains code that is designed to disrupt the legitimate operation of the product (or its environment) when a certain time passes, or when a certain logical condition is met.",
        "detail": "**Extended Description:**\nWhen the time bomb or logic bomb is detonated, it may perform a denial of service such as crashing the system, deleting critical data, or degrading system response time. This bomb might be placed within either a replicating or non-replicating Trojan horse.\n",
        "parent": [
            "506"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Always verify the integrity of the product that is being installed.\n\n**Mitigation:** Conduct a code coverage analysis using live testing, then closely inspect any code that is not covered.\n",
        "languages": []
    },
    {
        "cwe": "512",
        "name": "Spyware",
        "description": "The product collects personally identifiable information about a human user or the user's activities, but the product accesses this information using other resources besides itself, and it does not require that user's explicit approval or direct input into the product.",
        "detail": "**Extended Description:**\n\"Spyware\" is a commonly used term with many definitions and interpretations. In general, it is meant to refer to products that collect information or install functionality that human users might not allow if they were fully aware of the actions being taken by the software. For example, a user might expect that tax software would collect a social security number and include it when filing a tax return, but that same user would not expect gaming software to obtain the social security number from that tax software's data.\n",
        "parent": [
            "506"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Use spyware detection and removal software.\n\n**Mitigation:** Always verify the integrity of the product that is being installed.\n",
        "languages": []
    },
    {
        "cwe": "514",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "385",
            "515"
        ],
        "related": [
            "205"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "515",
        "name": "Covert Storage Channel",
        "description": "A covert storage channel transfers information through the setting of bits by one program and the reading of those bits by another. What distinguishes this case from that of ordinary operation is that the bits are used to convey encoded information.",
        "detail": "**Extended Description:**\nCovert storage channels occur when out-of-band data is stored in messages for the purpose of memory reuse. Covert channels are frequently classified as either storage or timing channels. Examples would include using a file intended to hold only audit information to convey user passwords--using the name of a file or perhaps status bits associated with it that can be read by all users to signal the contents of the file. Steganography, concealing information in such a manner that no one but the intended recipient knows of the existence of the message, is a good example of a covert storage channel.\n\n**Consequence Note:** Covert storage channels may provide attackers with important information about the system in question.\n\n**Consequence Note:** If these messages or packets are sent with unnecessary data contained within, it may tip off malicious listeners as to the process that created the message. With this information, attackers may learn any number of things, including the hardware platform, operating system, or algorithms used by the sender. This information can be of significant value to the user in launching further attacks.\n",
        "parent": [
            "514"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Ensure that all reserved fields are set to zero before messages are sent and that no unnecessary information is included.\n",
        "languages": []
    },
    {
        "cwe": "52",
        "name": "Path Equivalence: '/multiple/trailing/slash//'",
        "description": "The product accepts path input in the form of multiple trailing slash ('/multiple/trailing/slash//') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "163",
            "41"
        ],
        "children": [],
        "related": [
            "289"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "520",
        "name": ".NET Misconfiguration: Use of Impersonation",
        "description": "Allowing a .NET application to run at potentially escalated levels of access to the underlying operating and file systems can be dangerous and result in various forms of attacks.",
        "detail": "**Extended Description:**\n.NET server applications can optionally execute using the identity of the user authenticated to the client. The intention of this functionality is to bypass authentication and access control checks within the .NET application code. Authentication is done by the underlying web server (Microsoft Internet Information Service IIS), which passes the authenticated token, or unauthenticated anonymous token, to the .NET application. Using the token to impersonate the client, the application then relies on the settings within the NTFS directories and files to control access. Impersonation enables the application, on the server running the .NET application, to both execute code and access resources in the context of the authenticated and authorized user.\n",
        "parent": [
            "266"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Run the application with limited privilege to the underlying operating and file system.\n",
        "languages": []
    },
    {
        "cwe": "521",
        "name": "Weak Password Requirements",
        "description": "The product does not require that users should have strong passwords, which makes it easier for attackers to compromise user accounts.",
        "detail": "**Extended Description:**\nAuthentication mechanisms often rely on a memorized secret (also known as a password) to provide an assertion of identity for a user of a system. It is therefore important that this password be of sufficient complexity and impractical for an adversary to guess. The specific requirements around how complex a password needs to be depends on the type of system being protected. Selecting the correct password requirements and enforcing them through implementation are critical to the overall success of the authentication mechanism.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Mode of Introduction:** Not enforcing the password policy stated in a products design can allow users to create passwords that do not provide the necessary level of protection.\n\n**Consequence Note:** An attacker could easily guess user passwords and gain access user accounts.\n",
        "parent": [
            "1391",
            "287"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nA product's design should require adherance to an appropriate password policy. Specific password requirements depend strongly on contextual factors, but it is recommended to contain the following attributes:\n\n\n  - Enforcement of a minimum and maximum length\n\n  - Restrictions against password reuse\n\n  - Restrictions against using common passwords\n\n  - Restrictions against using contextual string in the password (e.g., user id, app name)\n\nDepending on the threat model, the password policy may include several additional attributes.\n\n  - Complex passwords requiring mixed character sets (alpha, numeric, special, mixed case) \n   - Increasing the range of characters makes the password harder to crack and may be appropriate for systems relying on single factor authentication.\n\n   - Unfortunately, a complex password may be difficult to memorize, encouraging a user to select a short password or to incorrectly manage the password (write it down).\n\n   - Another disadvantage of this approach is that it often does not result in a significant increases in overal password complexity due to people's predictable usage of various symbols.\n\n\n\n  1. Large Minimum Length (encouraging passphrases instead of passwords) \n   - Increasing the number of characters makes the password harder to crack and may be appropriate for systems relying on single factor authentication.\n\n   - A disadvantage of this approach is that selecting a good passphrase is not easy and poor passwords can still be generated. Some prompting may be needed to encourage long un-predictable passwords.\n\n\n\n  1. Randomly Chosen Secrets \n   - Generating a password for the user can help make sure that length and complexity requirements are met, and can result in secure passwords being used.\n\n   - A disadvantage of this approach is that the resulting password or passpharse may be too difficult to memorize, encouraging them to be written down.\n\n\n\n  1. Password Expiration \n   - Requiring a periodic password change can reduce the time window that an adversary has to crack a password, while also limiting the damage caused by password exposures at other locations.\n\n   - Password expiration may be a good mitigating technique when long complex passwords are not desired.\n\n\n\nSee NIST 800-63B [REF-1053] for further information on password requirements.\n\n**Mitigation:** Consider a second authentication factor beyond the password, which prevents the password from being a single point of failure. See CWE-308 for further information.\n\n**Mitigation:** Consider implementing a password complexity meter to inform users when a chosen password meets the required attributes.\n",
        "languages": []
    },
    {
        "cwe": "522",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "257",
            "260",
            "261",
            "523",
            "549"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "523",
        "name": "Unprotected Transport of Credentials",
        "description": "Login pages do not use adequate measures to protect the user name and password while they are in transit from the client to the server.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Background Details:**\n['SSL (Secure Socket Layer) provides data confidentiality and integrity to HTTP. By encrypting HTTP messages, SSL protects from attackers eavesdropping or altering message contents.']\n",
        "parent": [
            "522"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Enforce SSL use for the login page or any page used to transmit user credentials or other sensitive information. Even if the entire site does not use SSL, it MUST use SSL for login. Additionally, to help prevent phishing attacks, make sure that SSL serves the login page. SSL allows the user to verify the identity of the server to which they are connecting. If the SSL serves login page, the user can be certain they are talking to the proper end system. A phishing attack would typically redirect a user to a site that does not have a valid trusted server certificate issued from an authorized supplier.\n",
        "languages": []
    },
    {
        "cwe": "524",
        "name": "Use of Cache Containing Sensitive Information",
        "description": "The code uses a cache that contains sensitive information, but the cache can be read by an actor outside of the intended control sphere.",
        "detail": "**Extended Description:**\nApplications may use caches to improve efficiency when communicating with remote entities or performing intensive calculations. A cache maintains a pool of objects, threads, connections, pages, financial data, passwords, or other resources to minimize the time it takes to initialize and access these resources. If the cache is accessible to unauthorized actors, attackers can read the cache and obtain this sensitive information.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Protect information stored in cache.\n\n**Mitigation:** Do not store unnecessarily sensitive information in the cache.\n\n**Mitigation:** Consider using encryption in the cache.\n",
        "languages": []
    },
    {
        "cwe": "525",
        "name": "Use of Web Browser Cache Containing Sensitive Information",
        "description": "The web application does not use an appropriate caching policy that specifies the extent to which each web page and associated form fields should be cached.",
        "detail": "**Consequence Note:** Browsers often store information in a client-side cache, which can leave behind sensitive information for other users to find and exploit, such as passwords or credit card numbers. The locations at most risk include public terminals, such as those in libraries and Internet cafes.\n",
        "parent": [
            "524"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Protect information stored in cache.\n\n**Mitigation:** Use a restrictive caching policy for forms and web pages that potentially contain sensitive information.\n\n**Mitigation:** Do not store unnecessarily sensitive information in the cache.\n\n**Mitigation:** Consider using encryption in the cache.\n",
        "languages": []
    },
    {
        "cwe": "526",
        "name": "Cleartext Storage of Sensitive Information in an Environment Variable",
        "description": "The product uses an environment variable to store unencrypted sensitive information.",
        "detail": "**Extended Description:**\nInformation stored in an environment variable can be accessible by other processes with the execution context, including child processes that dependencies are executed in, or serverless functions in cloud environments. An environment variable's contents can also be inserted into messages, headers, log files, or other outputs. Often these other dependencies have no need to use the environment variable in question. A weakness that discloses environment variables could expose this information.\n",
        "parent": [
            "312"
        ],
        "children": [],
        "related": [
            "214"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Encrypt information stored in the environment variable to protect it from being exposed to an unauthorized user. If encryption is not feasible or is considered too expensive for the business use of the application, then consider using a properly protected configuration file instead of an environment variable. It should be understood that unencrypted information in a config file is also not guaranteed to be protected, but it is still a better choice, because it reduces attack surface related to weaknesses such as CWE-214. In some settings, vaults might be a feasible option for safer data transfer. Users should be notified of the business choice made to not protect the sensitive information through encryption.\n\n**Mitigation:** If the environment variable is not necessary for the desired behavior, then remove it entirely, or clear it to an empty value.\n",
        "languages": []
    },
    {
        "cwe": "527",
        "name": "Exposure of Version-Control Repository to an Unauthorized Control Sphere",
        "description": "The product stores a CVS, git, or other repository in a directory, archive, or other resource that is stored, transferred, or otherwise made accessible to unauthorized actors.",
        "detail": "**Extended Description:**\nVersion control repositories such as CVS or git store version-specific metadata and other details within subdirectories. If these subdirectories are stored on a web server or added to an archive, then these could be used by an attacker. This information may include usernames, filenames, path root, IP addresses, and detailed \"diff\" data about how files have been changed - which could reveal source code snippets that were never intended to be made public.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "552"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Recommendations include removing any CVS directories and repositories from the production server, disabling the use of remote CVS repositories, and ensuring that the latest CVS patches and version updates have been performed.\n",
        "languages": []
    },
    {
        "cwe": "528",
        "name": "Exposure of Core Dump File to an Unauthorized Control Sphere",
        "description": "The product generates a core dump file in a directory, archive, or other resource that is stored, transferred, or otherwise made accessible to unauthorized actors.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "552"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Protect the core dump files from unauthorized access.\n",
        "languages": []
    },
    {
        "cwe": "529",
        "name": "Exposure of Access Control List Files to an Unauthorized Control Sphere",
        "description": "The product stores access control list files in a directory or other container that is accessible to actors outside of the intended control sphere.",
        "detail": "**Extended Description:**\nExposure of these access control list files may give the attacker information about the configuration of the site or system. This information may then be used to bypass the intended security policy or identify trusted systems from which an attack can be launched.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "552"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Protect access control list files.\n",
        "languages": []
    },
    {
        "cwe": "53",
        "name": "Path Equivalence: '\\multiple\\\\internal\\backslash'",
        "description": "The product accepts path input in the form of multiple internal backslash ('\\multiple\\trailing\\\\slash') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "165",
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "530",
        "name": "Exposure of Backup File to an Unauthorized Control Sphere",
        "description": "A backup file is stored in a directory or archive that is made accessible to unauthorized actors.",
        "detail": "**Extended Description:**\nOften, older backup files are renamed with an extension such as .~bk to distinguish them from production files. The source code for old files that have been renamed in this manner and left in the webroot can often be retrieved. This renaming may have been performed automatically by the web server, or manually by the administrator.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** At a minimum, an attacker who retrieves this file would have all the information contained in it, whether that be database calls, the format of parameters accepted by the application, or simply information regarding the architectural structure of your site.\n",
        "parent": [
            "552"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Recommendations include implementing a security policy within your organization that prohibits backing up web application source code in the webroot.\n",
        "languages": []
    },
    {
        "cwe": "531",
        "name": "Inclusion of Sensitive Information in Test Code",
        "description": "Accessible test applications can pose a variety of security risks. Since developers or administrators rarely consider that someone besides themselves would even know about the existence of these applications, it is common for them to contain sensitive information or functions.",
        "detail": null,
        "parent": [
            "540"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Remove test code before deploying the application into production.\n",
        "languages": []
    },
    {
        "cwe": "532",
        "name": "Insertion of Sensitive Information into Log File",
        "description": "The product writes sensitive information to a log file.",
        "detail": "**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** Logging sensitive user data, full path names, or system information often provides attackers with an additional, less-protected path to acquiring the information.\n",
        "parent": [
            "200",
            "538"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Consider seriously the sensitivity of the information written into log files. Do not write secrets into the log files.\n\n**Mitigation:** Remove debug log files before deploying the application into production.\n\n**Mitigation:** Protect log files against unauthorized read/write.\n\n**Mitigation:** Adjust configurations appropriately when software is transitioned from a debug state to production.\n",
        "languages": []
    },
    {
        "cwe": "535",
        "name": "Exposure of Information Through Shell Error Message",
        "description": "A command shell error message indicates that there exists an unhandled exception in the web application code. In many cases, an attacker can leverage the conditions that cause these errors in order to gain unauthorized access to the system.",
        "detail": null,
        "parent": [
            "211"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "536",
        "name": "Servlet Runtime Error Message Containing Sensitive Information",
        "description": "A servlet error message indicates that there exists an unhandled exception in your web application code and may provide useful information to an attacker.",
        "detail": "**Consequence Note:** The error message may contain the location of the file in which the offending function is located. This may disclose the web root's absolute path as well as give the attacker the location of application files or configuration information. It may even disclose the portion of code that failed. In many cases, an attacker can use the data to launch further attacks against the system.\n",
        "parent": [
            "211"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "537",
        "name": "Java Runtime Error Message Containing Sensitive Information",
        "description": "In many cases, an attacker can leverage the conditions that cause unhandled exception errors in order to gain unauthorized access to the system.",
        "detail": null,
        "parent": [
            "211"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Do not expose sensitive error information to the user.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "538",
        "name": "Insertion of Sensitive Information into Externally-Accessible File or Directory",
        "description": "The product places sensitive information into files or directories that are accessible to actors who are allowed to have access to the files, but not to the sensitive information.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "200"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not expose file and directory information to the user.\n",
        "languages": []
    },
    {
        "cwe": "539",
        "name": "Use of Persistent Cookies Containing Sensitive Information",
        "description": "The web application uses persistent cookies, but the cookies contain sensitive information.",
        "detail": "**Extended Description:**\nCookies are small bits of data that are sent by the web application but stored locally in the browser. This lets the application use the cookie to pass information between pages and store variable information. The web application controls what information is stored in a cookie and how it is used. Typical types of information stored in cookies are session identifiers, personalization and customization information, and in rare cases even usernames to enable automated logins. There are two different types of cookies: session cookies and persistent cookies. Session cookies just live in the browser's memory and are not stored anywhere, but persistent cookies are stored on the browser's hard drive. This can cause security and privacy issues depending on the information stored in the cookie and how it is accessed.\n",
        "parent": [
            "552"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not store sensitive information in persistent cookies.\n",
        "languages": []
    },
    {
        "cwe": "54",
        "name": "Path Equivalence: 'filedir\\' (Trailing Backslash)",
        "description": "The product accepts path input in the form of trailing backslash ('filedir\\') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "162",
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "540",
        "name": "Inclusion of Sensitive Information in Source Code",
        "description": "Source code on a web server or repository often contains sensitive information and should generally not be accessible to users.",
        "detail": "**Extended Description:**\nThere are situations where it is critical to remove source code from an area or server. For example, obtaining Perl source code on a system allows an attacker to understand the logic of the script and extract extremely useful information such as code bugs or logins and passwords.\n",
        "parent": [
            "538"
        ],
        "children": [
            "531",
            "541",
            "615"
        ],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Recommendations include removing this script from the web server and moving it to a location not accessible from the Internet.\n",
        "languages": []
    },
    {
        "cwe": "541",
        "name": "Inclusion of Sensitive Information in an Include File",
        "description": "If an include file source is accessible, the file can contain usernames and passwords, as well as sensitive information pertaining to the application and system.",
        "detail": null,
        "parent": [
            "540"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Do not store sensitive information in include files.\n\n**Mitigation:** Protect include files from being exposed.\n",
        "languages": []
    },
    {
        "cwe": "543",
        "name": "Use of Singleton Pattern Without Synchronization in a Multithreaded Context",
        "description": "The product uses the singleton pattern when creating a resource within a multithreaded environment.",
        "detail": "**Extended Description:**\nThe use of a singleton pattern may not be thread-safe.\n",
        "parent": [
            "662",
            "820"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use the Thread-Specific Storage Pattern. See References.\n\n**Mitigation:** Do not use member fields to store information in the Servlet. In multithreading environments, storing user data in Servlet member fields introduces a data access race condition.\n\n**Mitigation:** Avoid using the double-checked locking pattern in language versions that cannot guarantee thread safety. This pattern may be used to avoid the overhead of a synchronized call, but in certain versions of Java (for example), this has been shown to be unsafe because it still introduces a race condition (CWE-209).\n",
        "languages": [
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "544",
        "name": "Missing Standardized Error Handling Mechanism",
        "description": "The product does not use a standardized method for handling errors throughout the code, which might introduce inconsistent error handling and resultant weaknesses.",
        "detail": "**Extended Description:**\nIf the product handles error messages individually, on a one-by-one basis, this is likely to result in inconsistent error handling. The causes of errors may be lost. Also, detailed information about the causes of an error may be unintentionally returned to the user.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "755"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** define a strategy for handling errors of different severities, such as fatal errors versus basic log events. Use or create built-in language features, or an external package, that provides an easy-to-use API and define coding standards for the detection and handling of errors.\n",
        "languages": []
    },
    {
        "cwe": "546",
        "name": "Suspicious Comment",
        "description": "The code contains comments that suggest the presence of bugs, incomplete functionality, or weaknesses.",
        "detail": "**Extended Description:**\nMany suspicious comments, such as BUG, HACK, FIXME, LATER, LATER2, TODO, in the code indicate missing security functionality and checking. Others indicate code problems that programmers should fix, such as hard-coded variables, error handling, not using stored procedures, and performance issues.\n\n**Consequence Note:** Suspicious comments could be an indication that there are problems in the source code that may need to be fixed and is an indication of poor quality. This could lead to further bugs and the introduction of weaknesses.\n",
        "parent": [
            "1078"
        ],
        "children": [],
        "related": [
            "615"
        ],
        "scopes": [],
        "mitigation": "**Mitigation:** Remove comments that suggest the presence of bugs, incomplete functionality, or weaknesses, before deploying the application.\n",
        "languages": []
    },
    {
        "cwe": "547",
        "name": "Use of Hard-coded, Security-relevant Constants",
        "description": "The product uses hard-coded constants instead of symbolic names for security-critical values, which increases the likelihood of mistakes during code maintenance or security policy change.",
        "detail": "**Extended Description:**\nIf the developer does not find all occurrences of the hard-coded constants, an incorrect policy decision may be made if one of the constants is not changed. Making changes to these values will require code changes that may be difficult or impossible once the system is released to the field. In addition, these hard-coded values may become available to attackers if the code is ever disclosed.\n\n**Consequence Note:** The existence of hardcoded constants could cause unexpected behavior and the introduction of weaknesses during code maintenance or when making changes to the code if all occurrences are not modified. The use of hardcoded constants is an indication of poor quality.\n",
        "parent": [
            "1078"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid using hard-coded constants. Configuration files offer a more flexible solution.\n",
        "languages": []
    },
    {
        "cwe": "548",
        "name": "Exposure of Information Through Directory Listing",
        "description": "The product inappropriately exposes a directory listing with an index of all the resources located inside of the directory.",
        "detail": "**Consequence Note:** Exposing the contents of a directory can lead to an attacker gaining access to source code or providing useful information for the attacker to devise exploits, such as creation times of files or any information that may be encoded in file names. The directory listing may also compromise private or confidential data.\n",
        "parent": [
            "497"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Recommendations include restricting access to important directories or files by adopting a need to know requirement for both the document and server root, and turning off features such as Automatic Directory Listings that could expose private files and provide information that could be utilized by an attacker when formulating or conducting an attack.\n",
        "languages": []
    },
    {
        "cwe": "549",
        "name": "Missing Password Field Masking",
        "description": "The product does not mask passwords during entry, increasing the potential for attackers to observe and capture passwords.",
        "detail": null,
        "parent": [
            "522"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Recommendations include requiring all password fields in your web application be masked to prevent other users from seeing this information.\n",
        "languages": []
    },
    {
        "cwe": "55",
        "name": "Path Equivalence: '/./' (Single Dot Directory)",
        "description": "The product accepts path input in the form of single dot directory exploit ('/./') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "550",
        "name": "Server-generated Error Message Containing Sensitive Information",
        "description": "Certain conditions, such as network failure, will cause a server error message to be displayed.",
        "detail": "**Extended Description:**\nWhile error messages in and of themselves are not dangerous, per se, it is what an attacker can glean from them that might cause eventual problems.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "209"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Recommendations include designing and adding consistent error handling mechanisms which are capable of handling any user input to your web application, providing meaningful detail to end-users, and preventing error messages that might provide information useful to an attacker from being displayed.\n",
        "languages": []
    },
    {
        "cwe": "551",
        "name": "Incorrect Behavior Order: Authorization Before Parsing and Canonicalization",
        "description": "If a web server does not fully parse requested URLs before it examines them for authorization, it may be possible for an attacker to bypass authorization protection.",
        "detail": "**Extended Description:**\nFor instance, the character strings /./ and / both mean current directory. If /SomeDirectory is a protected directory and an attacker requests /./SomeDirectory, the attacker may be able to gain access to the resource if /./ is not converted to / before the authorization check is performed.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "696",
            "863"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** URL Inputs should be decoded and canonicalized to the application's current internal representation before being validated and processed for authorization. Make sure that your application does not decode the same input twice. Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "552",
        "name": "Files or Directories Accessible to External Parties",
        "description": "The product makes files or directories accessible to unauthorized actors, even though they should not be.",
        "detail": "**Extended Description:**\n\n\nWeb servers, FTP servers, and similar servers may store a set of files underneath a \"root\" directory that is accessible to the server's users. Applications may store sensitive files underneath this root without also using access control to limit which users may request those files, if any. Alternately, an application might package multiple files or directories into an archive file (e.g., ZIP or tar), but the application might not exclude sensitive files that are underneath those directories.\n\n\nIn cloud technologies and containers, this weakness might present itself in the form of misconfigured storage accounts that can be read or written by a public or anonymous user.\n\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n",
        "parent": [
            "285",
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** When storing data in the cloud (e.g., S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to disable public access.\n",
        "languages": []
    },
    {
        "cwe": "553",
        "name": "Command Shell in Externally Accessible Directory",
        "description": "A possible shell file exists in /cgi-bin/ or other accessible directories. This is extremely dangerous and can be used by an attacker to execute commands on the web server.",
        "detail": null,
        "parent": [
            "552"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Remove any Shells accessible under the web root folder and children directories.\n",
        "languages": []
    },
    {
        "cwe": "554",
        "name": "ASP.NET Misconfiguration: Not Using Input Validation Framework",
        "description": "The ASP.NET application does not use an input validation framework.",
        "detail": "**Consequence Note:** Unchecked input leads to cross-site scripting, process control, and SQL injection vulnerabilities, among others.\n",
        "parent": [
            "1173"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nUse the ASP.NET validation framework to check all program input before it is processed by the application. Example uses of the validation framework include checking to ensure that:\n\n\n  - Phone number fields contain only valid characters in phone numbers\n\n  - Boolean values are only \"T\" or \"F\"\n\n  - Free-form strings are of a reasonable length and composition\n\n\n",
        "languages": [
            "ASP.NET"
        ]
    },
    {
        "cwe": "555",
        "name": "J2EE Misconfiguration: Plaintext Password in Configuration File",
        "description": "The J2EE application stores a plaintext password in a configuration file.",
        "detail": "**Extended Description:**\nStoring a plaintext password in a configuration file allows anyone who can read the file to access the password-protected resource, making it an easy target for attackers.\n",
        "parent": [
            "260"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Do not hardwire passwords into your software.\n\n**Mitigation:** Use industry standard libraries to encrypt passwords before storage in configuration files.\n",
        "languages": []
    },
    {
        "cwe": "556",
        "name": "ASP.NET Misconfiguration: Use of Identity Impersonation",
        "description": "Configuring an ASP.NET application to run with impersonated credentials may give the application unnecessary privileges.",
        "detail": "**Extended Description:**\nThe use of impersonated credentials allows an ASP.NET application to run with either the privileges of the client on whose behalf it is executing or with arbitrary privileges granted in its configuration.\n",
        "parent": [
            "266"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Use the least privilege principle.\n",
        "languages": []
    },
    {
        "cwe": "558",
        "name": "Use of getlogin() in Multithreaded Application",
        "description": "The product uses the getlogin() function in a multithreaded context, potentially causing it to return incorrect values.",
        "detail": "**Extended Description:**\nThe getlogin() function returns a pointer to a string that contains the name of the user associated with the calling process. The function is not reentrant, meaning that if it is called from another process, the contents are not locked out and the value of the string can be changed by another process. This makes it very risky to use because the username can be changed by other processes, so the results of the function cannot be trusted.\n",
        "parent": [
            "663"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Using names for security purposes is not advised. Names are easy to forge and can have overlapping user IDs, potentially causing confusion or impersonation.\n\n**Mitigation:** Use getlogin_r() instead, which is reentrant, meaning that other processes are locked out from changing the username.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "56",
        "name": "Path Equivalence: 'filedir*' (Wildcard)",
        "description": "The product accepts path input in the form of asterisk wildcard ('filedir*') without appropriate validation, which can lead to ambiguous path resolution and allow an attacker to traverse the file system to unintended locations or access arbitrary files.",
        "detail": null,
        "parent": [
            "155",
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "560",
        "name": "Use of umask() with chmod-style Argument",
        "description": "The product calls umask() with an incorrect argument that is specified as if it is an argument to chmod().",
        "detail": null,
        "parent": [
            "687"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use umask() with the correct argument.\n\n**Mitigation:** If you suspect misuse of umask(), you can use grep to spot call instances of umask().\n",
        "languages": [
            "C"
        ]
    },
    {
        "cwe": "561",
        "name": "Dead Code",
        "description": "The product contains dead code, which can never be executed.",
        "detail": "**Extended Description:**\nDead code is code that can never be executed in a running program. The surrounding code makes it impossible for a section of code to ever be executed.\n\n**Consequence Note:** Dead code that results from code that can never be executed is an indication of problems with the source code that needs to be fixed and is an indication of poor quality.\n",
        "parent": [
            "1164"
        ],
        "children": [],
        "related": [
            "570",
            "571"
        ],
        "scopes": [],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAttack Modeling\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBinary / Bytecode Quality Analysis\n\t\tCompare binary / bytecode to application permission manifest\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAutomated Monitored Execution\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tPermission Manifest Analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource Code Quality Analyzer\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWarning Flags\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Mitigation:** Remove dead code before deploying the application.\n\n**Mitigation:** Use a static analysis tool to spot dead code.\n",
        "languages": []
    },
    {
        "cwe": "562",
        "name": "Return of Stack Variable Address",
        "description": "A function returns the address of a stack variable, which will cause unintended program behavior, typically in the form of a crash.",
        "detail": "**Extended Description:**\nBecause local variables are allocated on the stack, when a program returns a pointer to a local variable, it is returning a stack address. A subsequent function call is likely to re-use this same stack address, thereby overwriting the value of the pointer, which no longer corresponds to the same variable since a function's stack frame is invalidated when it returns. At best this will cause the value of the pointer to change unexpectedly. In many cases it causes the program to crash the next time the pointer is dereferenced.\n\n**Consequence Note:** If the returned stack buffer address is dereferenced after the return, then an attacker may be able to modify or read memory, depending on how the address is used. If the address is used for reading, then the address itself may be exposed, or the contents that the address points to. If the address is used for writing, this can lead to a crash and possibly code execution.\n",
        "parent": [
            "758"
        ],
        "children": [],
        "related": [
            "672",
            "825"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use static analysis tools to spot return of the address of a stack variable.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "563",
        "name": "Assignment to Variable without Use",
        "description": "The variable's value is assigned but never used, making it a dead store.",
        "detail": "**Extended Description:**\nAfter the assignment, the variable is either assigned another value or goes out of scope. It is likely that the variable is simply vestigial, but it is also possible that the unused variable points out a bug.\n\n**Alternate Terms:** Unused Variable\n\n**Consequence Note:** This weakness could be an indication of a bug in the program or a deprecated variable that was not removed and is an indication of poor quality. This could lead to further bugs and the introduction of weaknesses.\n",
        "parent": [
            "1164"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Remove unused variables from the code.\n",
        "languages": []
    },
    {
        "cwe": "564",
        "name": "SQL Injection: Hibernate",
        "description": "Using Hibernate to execute a dynamic SQL statement built with user-controlled input can allow an attacker to modify the statement's meaning or to execute arbitrary SQL commands.",
        "detail": null,
        "parent": [
            "89"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** A non-SQL style database which is not subject to this flaw may be chosen.\n\n**Mitigation:** Follow the principle of least privilege when creating user accounts to a SQL database. Users should only have the minimum privileges necessary to use their account. If the requirements of the system indicate that a user can read and modify their own data, then limit their privileges so they cannot read/write others' data.\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** Implement SQL strings using prepared statements that bind variables. Prepared statements that do not bind variables can be vulnerable to attack.\n\n**Mitigation:** Use vigorous allowlist style checking on any user input that may be used in a SQL command. Rather than escape meta-characters, it is safest to disallow them entirely. Reason: Later use of data that have been entered in the database may neglect to escape meta-characters before use. Narrowly define the set of safe characters based on the expected value of the parameter in the request.\n",
        "languages": [
            "SQL"
        ]
    },
    {
        "cwe": "565",
        "name": "Reliance on Cookies without Validation and Integrity Checking",
        "description": "The product relies on the existence or values of cookies when performing security-critical operations, but it does not properly ensure that the setting is valid for the associated user.",
        "detail": "**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** Attackers can easily modify cookies, within the browser or by implementing the client-side code outside of the browser. Reliance on cookies without detailed validation and integrity checking can allow attackers to bypass authentication, conduct injection attacks such as SQL injection and cross-site scripting, or otherwise modify inputs in unexpected ways.\n\n**Consequence Note:** It is dangerous to use cookies to set a user's privileges. The cookie can be manipulated to escalate an attacker's privileges to an administrative level.\n",
        "parent": [
            "602",
            "642",
            "669"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid using cookie data for a security-related decision.\n\n**Mitigation:** Perform thorough input validation (i.e.: server side validation) on the cookie data if you're going to use it for a security related decision.\n\n**Mitigation:** Add integrity checks to detect tampering.\n\n**Mitigation:** Protect critical cookies from replay attacks, since cross-site scripting or other attacks may allow attackers to steal a strongly-encrypted cookie that also passes integrity checks. This mitigation applies to cookies that should only be valid during a single transaction or session. By enforcing timeouts, you may limit the scope of an attack. As part of your integrity check, use an unpredictable, server-side value that is not exposed to the client.\n",
        "languages": []
    },
    {
        "cwe": "566",
        "name": "Authorization Bypass Through User-Controlled SQL Primary Key",
        "description": "The product uses a database table that includes records that should not be accessible to an actor, but it executes a SQL statement with a primary key that can be controlled by that actor.",
        "detail": "**Extended Description:**\n\n\nWhen a user can set a primary key to any value, then the user can modify the key to point to unauthorized records.\n\n\nDatabase access control errors occur when:\n\n\n  - Data enters a program from an untrusted source.\n\n  - The data is used to specify the value of a primary key in a SQL query.\n\n  - The untrusted source does not have the permissions to be able to access all rows in the associated table.\n\n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "639"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Assume all input is malicious. Use a standard input validation mechanism to validate all input for length, type, syntax, and business rules before accepting the data. Use an \"accept known good\" validation strategy.\n\n**Mitigation:** Use a parameterized query AND make sure that the accepted values conform to the business rules. Construct your SQL statement accordingly.\n",
        "languages": [
            "SQL"
        ]
    },
    {
        "cwe": "567",
        "name": "Unsynchronized Access to Shared Data in a Multithreaded Context",
        "description": "The product does not properly synchronize shared data, such as static variables across threads, which can lead to undefined behavior and unpredictable data changes.",
        "detail": "**Extended Description:**\n\n\nWithin servlets, shared static variables are not protected from concurrent access, but servlets are multithreaded. This is a typical programming mistake in J2EE applications, since the multithreading is handled by the framework. When a shared variable can be influenced by an attacker, one thread could wind up modifying the variable to contain data that is not valid for a different thread that is also using the data within the variable.\n\n\nNote that this weakness is not unique to servlets.\n\n\n**Consequence Note:** If the shared variable contains sensitive data, it may be manipulated or displayed in another user session. If this data is used to control the application, its value can be manipulated to cause the application to crash or perform poorly.\n",
        "parent": [
            "662",
            "820"
        ],
        "children": [],
        "related": [
            "488"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Remove the use of static variables used between servlets. If this cannot be avoided, use synchronized access for these variables.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "568",
        "name": "finalize() Method Without super.finalize()",
        "description": "The product contains a finalize() method that does not call super.finalize().",
        "detail": "**Extended Description:**\nThe Java Language Specification states that it is a good practice for a finalize() method to call super.finalize().\n",
        "parent": [
            "459",
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Call the super.finalize() method.\n\n**Mitigation:** Use static analysis tools to spot such issues in your code.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "57",
        "name": "Path Equivalence: 'fakedir/../realdir/filename'",
        "description": "The product contains protection mechanisms to restrict access to 'realdir/filename', but it constructs pathnames using external input in the form of 'fakedir/../realdir/filename' that are not handled by those mechanisms. This allows attackers to perform unauthorized actions against the targeted file.",
        "detail": null,
        "parent": [
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Inputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180). Make sure that the application does not decode the same input twice (CWE-174). Such errors could be used to bypass allowlist validation schemes by introducing dangerous inputs after they have been checked.\n",
        "languages": []
    },
    {
        "cwe": "570",
        "name": "Expression is Always False",
        "description": "The product contains an expression that will always evaluate to false.",
        "detail": null,
        "parent": [
            "710"
        ],
        "children": [],
        "related": [
            "561"
        ],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use Static Analysis tools to spot such conditions.\n",
        "languages": []
    },
    {
        "cwe": "571",
        "name": "Expression is Always True",
        "description": "The product contains an expression that will always evaluate to true.",
        "detail": null,
        "parent": [
            "710"
        ],
        "children": [],
        "related": [
            "561"
        ],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use Static Analysis tools to spot such conditions.\n",
        "languages": []
    },
    {
        "cwe": "572",
        "name": "Call to Thread run() instead of start()",
        "description": "The product calls a thread's run() method instead of calling start(), which causes the code to run in the thread of the caller instead of the callee.",
        "detail": "**Extended Description:**\nIn most cases a direct call to a Thread object's run() method is a bug. The programmer intended to begin a new thread of control, but accidentally called run() instead of start(), so the run() method will execute in the caller's thread of control.\n",
        "parent": [
            "821"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use the start() method instead of the run() method.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "573",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "243",
            "475",
            "580",
            "581",
            "628",
            "694",
            "695"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "574",
        "name": "EJB Bad Practices: Use of Synchronization Primitives",
        "description": "The product violates the Enterprise JavaBeans (EJB) specification by using thread synchronization primitives.",
        "detail": "**Extended Description:**\nThe Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"An enterprise bean must not use thread synchronization primitives to synchronize execution of multiple instances.\" The specification justifies this requirement in the following way: \"This rule is required to ensure consistent runtime semantics because while some EJB containers may use a single JVM to execute all enterprise bean's instances, others may distribute the instances across multiple JVMs.\"\n",
        "parent": [
            "695",
            "821"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Do not use Synchronization Primitives when writing EJBs.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "575",
        "name": "EJB Bad Practices: Use of AWT Swing",
        "description": "The product violates the Enterprise JavaBeans (EJB) specification by using AWT/Swing.",
        "detail": "**Extended Description:**\nThe Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"An enterprise bean must not use the AWT functionality to attempt to output information to a display, or to input information from a keyboard.\" The specification justifies this requirement in the following way: \"Most servers do not allow direct interaction between an application program and a keyboard/display attached to the server system.\"\n",
        "parent": [
            "695"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Do not use AWT/Swing when writing EJBs.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "576",
        "name": "EJB Bad Practices: Use of Java I/O",
        "description": "The product violates the Enterprise JavaBeans (EJB) specification by using the java.io package.",
        "detail": "**Extended Description:**\nThe Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"An enterprise bean must not use the java.io package to attempt to access files and directories in the file system.\" The specification justifies this requirement in the following way: \"The file system APIs are not well-suited for business components to access data. Business components should use a resource manager API, such as JDBC, to store data.\"\n",
        "parent": [
            "695"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Do not use Java I/O when writing EJBs.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "577",
        "name": "EJB Bad Practices: Use of Sockets",
        "description": "The product violates the Enterprise JavaBeans (EJB) specification by using sockets.",
        "detail": "**Extended Description:**\nThe Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"An enterprise bean must not attempt to listen on a socket, accept connections on a socket, or use a socket for multicast.\" The specification justifies this requirement in the following way: \"The EJB architecture allows an enterprise bean instance to be a network socket client, but it does not allow it to be a network server. Allowing the instance to become a network server would conflict with the basic function of the enterprise bean-- to serve the EJB clients.\"\n",
        "parent": [
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Do not use Sockets when writing EJBs.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "578",
        "name": "EJB Bad Practices: Use of Class Loader",
        "description": "The product violates the Enterprise JavaBeans (EJB) specification by using the class loader.",
        "detail": "**Extended Description:**\nThe Enterprise JavaBeans specification requires that every bean provider follow a set of programming guidelines designed to ensure that the bean will be portable and behave consistently in any EJB container. In this case, the product violates the following EJB guideline: \"The enterprise bean must not attempt to create a class loader; obtain the current class loader; set the context class loader; set security manager; create a new security manager; stop the JVM; or change the input, output, and error streams.\" The specification justifies this requirement in the following way: \"These functions are reserved for the EJB container. Allowing the enterprise bean to use these functions could compromise security and decrease the container's ability to properly manage the runtime environment.\"\n",
        "parent": [
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Do not use the Class Loader when writing EJBs.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "579",
        "name": "J2EE Bad Practices: Non-serializable Object Stored in Session",
        "description": "The product stores a non-serializable object as an HttpSession attribute, which can hurt reliability.",
        "detail": "**Extended Description:**\nA J2EE application can make use of multiple JVMs in order to improve application reliability and performance. In order to make the multiple JVMs appear as a single application to the end user, the J2EE container can replicate an HttpSession object across multiple JVMs so that if one JVM becomes unavailable another can step in and take its place without disrupting the flow of the application. This is only possible if all session data is serializable, allowing the session to be duplicated between the JVMs.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** In order for session replication to work, the values the product stores as attributes in the session must implement the Serializable interface.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "58",
        "name": "Path Equivalence: Windows 8.3 Filename",
        "description": "The product contains a protection mechanism that restricts access to a long filename on a Windows operating system, but it does not properly restrict access to the equivalent short \"8.3\" filename.",
        "detail": "**Extended Description:**\nOn later Windows operating systems, a file can have a \"long name\" and a short name that is compatible with older Windows file systems, with up to 8 characters in the filename and 3 characters for the extension. These \"8.3\" filenames, therefore, act as an alternate name for files with long names, so they are useful pathname equivalence manipulations.\n",
        "parent": [
            "41"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Disable Windows from supporting 8.3 filenames by editing the Windows registry. Preventing 8.3 filenames will not remove previously generated 8.3 filenames.\n",
        "languages": []
    },
    {
        "cwe": "580",
        "name": "clone() Method Without super.clone()",
        "description": "The product contains a clone() method that does not call super.clone() to obtain the new object.",
        "detail": "**Extended Description:**\nAll implementations of clone() should obtain the new object by calling super.clone(). If a class does not follow this convention, a subclass's clone() method will return an object of the wrong type.\n",
        "parent": [
            "573",
            "664"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Call super.clone() within your clone() method, when obtaining a new object.\n\n**Mitigation:** In some cases, you can eliminate the clone method altogether and use copy constructors.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "581",
        "name": "Object Model Violation: Just One of Equals and Hashcode Defined",
        "description": "The product does not maintain equal hashcodes for equal objects.",
        "detail": "**Extended Description:**\nJava objects are expected to obey a number of invariants related to equality. One of these invariants is that equal objects must have equal hashcodes. In other words, if a.equals(b) == true then a.hashCode() == b.hashCode().\n\n**Consequence Note:** If this invariant is not upheld, it is likely to cause trouble if objects of this class are stored in a collection. If the objects of the class in question are used as a key in a Hashtable or if they are inserted into a Map or Set, it is critical that equal objects have equal hashcodes.\n",
        "parent": [
            "573",
            "697"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Both Equals() and Hashcode() should be defined.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "582",
        "name": "Array Declared Public, Final, and Static",
        "description": "The product declares an array public, final, and static, which is not sufficient to prevent the array's contents from being modified.",
        "detail": "**Extended Description:**\nBecause arrays are mutable objects, the final constraint requires that the array object itself be assigned only once, but makes no guarantees about the values of the array elements. Since the array is public, a malicious program can change the values stored in the array. As such, in most cases an array declared public, final and static is a bug.\n\n**Background Details:**\n[\"Mobile code, in this case a Java Applet, is code that is transmitted across a network and executed on a remote machine. Because mobile code developers have little if any control of the environment in which their code will execute, special security concerns become relevant. One of the biggest environmental threats results from the risk that the mobile code will run side-by-side with other, potentially malicious, mobile code. Because all of the popular web browsers execute code from multiple sources together in the same JVM, many of the security guidelines for mobile code are focused on preventing manipulation of your objects' state and behavior by adversaries who have access to the same virtual machine where your product is running.\"]\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** In most situations the array should be made private.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "583",
        "name": "finalize() Method Declared Public",
        "description": "The product violates secure coding principles for mobile code by declaring a finalize() method public.",
        "detail": "**Extended Description:**\nA product should never call finalize explicitly, except to call super.finalize() inside an implementation of finalize(). In mobile code situations, the otherwise error prone practice of manual garbage collection can become a security threat if an attacker can maliciously invoke a finalize() method because it is declared with public access.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If you are using finalize() as it was designed, there is no reason to declare finalize() with anything other than protected access.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "584",
        "name": "Return Inside Finally Block",
        "description": "The code has a return statement inside a finally block, which will cause any thrown exception in the try block to be discarded.",
        "detail": null,
        "parent": [
            "705"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not use a return statement inside the finally block. The finally block should have \"cleanup\" code.\n",
        "languages": []
    },
    {
        "cwe": "585",
        "name": "Empty Synchronized Block",
        "description": "The product contains an empty synchronized block.",
        "detail": "**Extended Description:**\nAn empty synchronized block does not actually accomplish any synchronization and may indicate a troubled section of code. An empty synchronized block can occur because code no longer needed within the synchronized block is commented out without removing the synchronized block.\n\n**Consequence Note:** An empty synchronized block will wait until nobody else is using the synchronizer being specified. While this may be part of the desired behavior, because you haven't protected the subsequent code by placing it inside the synchronized block, nothing is stopping somebody else from modifying whatever it was you were waiting for while you run the subsequent code.\n",
        "parent": [
            "1071"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** When you come across an empty synchronized statement, or a synchronized statement in which the code has been commented out, try to determine what the original intentions were and whether or not the synchronized block is still necessary.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "586",
        "name": "Explicit Call to Finalize()",
        "description": "The product makes an explicit call to the finalize() method from outside the finalizer.",
        "detail": "**Extended Description:**\nWhile the Java Language Specification allows an object's finalize() method to be called from outside the finalizer, doing so is usually a bad idea. For example, calling finalize() explicitly means that finalize() will be called more than once: the first time will be the explicit call and the last time will be the call that is made after the object is garbage collected.\n",
        "parent": [
            "1076"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not make explicit calls to finalize(). Use static analysis tools to spot such instances.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "587",
        "name": "Assignment of a Fixed Address to a Pointer",
        "description": "The product sets a pointer to a specific address other than NULL or 0.",
        "detail": "**Extended Description:**\nUsing a fixed address is not portable, because that address will probably not be valid in all environments or platforms.\n\n**Consequence Note:** If one executes code at a known location, an attacker might be able to inject code there beforehand.\n\n**Consequence Note:** If the code is ported to another platform or environment, the pointer is likely to be invalid and cause a crash.\n\n**Consequence Note:** The data at a known pointer location can be easily read or influenced by an attacker.\n",
        "parent": [
            "344",
            "758"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Never set a pointer to a fixed address.\n",
        "languages": [
            "C",
            "C#",
            "C++"
        ]
    },
    {
        "cwe": "588",
        "name": "Attempt to Access Child of a Non-structure Pointer",
        "description": "Casting a non-structure type to a structure type and accessing a field can lead to memory access errors or data corruption.",
        "detail": "**Consequence Note:** Adjacent variables in memory may be corrupted by assignments performed on fields after the cast.\n\n**Consequence Note:** Execution may end due to a memory access error.\n",
        "parent": [
            "704",
            "758"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** The choice could be made to use a language that is not susceptible to these issues.\n\n**Mitigation:** Review of type casting operations can identify locations where incompatible types are cast.\n",
        "languages": []
    },
    {
        "cwe": "589",
        "name": "Call to Non-ubiquitous API",
        "description": "The product uses an API function that does not exist on all versions of the target platform. This could cause portability problems or inconsistencies that allow denial of service or other consequences.",
        "detail": "**Extended Description:**\nSome functions that offer security features supported by the OS are not available on all versions of the OS in common use. Likewise, functions are often deprecated or made obsolete for security reasons and should not be used.\n",
        "parent": [
            "474"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Always test your code on any platform on which it is targeted to run on.\n\n**Mitigation:** Test your code on the newest and oldest platform on which it is targeted to run on.\n\n**Mitigation:** Develop a system to test for API functions that are not portable.\n",
        "languages": []
    },
    {
        "cwe": "59",
        "name": "Improper Link Resolution Before File Access ('Link Following')",
        "description": "The product attempts to access a file based on the filename, but it does not properly prevent that filename from identifying a link or shortcut that resolves to an unintended resource.",
        "detail": "**Alternate Terms:** insecure temporary file, Zip Slip\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Background Details:**\n['Soft links are a UNIX term that is synonymous with simple shortcuts on Windows-based platforms.']\n\n**Consequence Note:** An attacker may be able to traverse the file system to unintended locations and read or overwrite the contents of unexpected files. If the files are used for a security mechanism then an attacker may be able to bypass the mechanism.\n\n**Consequence Note:** Windows simple shortcuts, sometimes referred to as soft links, can be exploited remotely since a \".LNK\" file can be uploaded like a normal file. This can enable remote execution.\n",
        "parent": [
            "706"
        ],
        "children": [],
        "related": [
            "73"
        ],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** \n\nFollow the principle of least privilege when assigning access rights to entities in a software system.\n\n\nDenying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.\n\n",
        "languages": []
    },
    {
        "cwe": "590",
        "name": "Free of Memory not on the Heap",
        "description": "The product calls free() on a pointer to memory that was not allocated using associated heap allocation functions such as malloc(), calloc(), or realloc().",
        "detail": "**Extended Description:**\nWhen free() is called on an invalid pointer, the program's memory management data structures may become corrupted. This corruption can cause the program to crash or, in some circumstances, an attacker may be able to cause free() to operate on controllable memory locations to modify critical program variables or execute code.\n\n**Consequence Note:** There is the potential for arbitrary code execution with privileges of the vulnerable program via a \"write, what where\" primitive. If pointers to memory which hold user information are freed, a malicious user will be able to write 4 bytes anywhere in memory.\n",
        "parent": [
            "762"
        ],
        "children": [],
        "related": [
            "123"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Only free pointers that you have called malloc on previously. This is the recommended solution. Keep track of which pointers point at the beginning of valid chunks and free them only once.\n\n**Mitigation:** Before freeing a pointer, the programmer should make sure that the pointer was previously allocated on the heap and that the memory belongs to the programmer. Freeing an unallocated pointer will cause undefined behavior in the program.\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, glibc in Linux provides protection against free of invalid pointers.\n\n\n**Mitigation:** Use a language that provides abstractions for memory allocation and deallocation.\n\n**Mitigation:** Use a tool that dynamically detects memory management problems, such as valgrind.\n",
        "languages": []
    },
    {
        "cwe": "591",
        "name": "Sensitive Data Storage in Improperly Locked Memory",
        "description": "The product stores sensitive data in memory that is not locked, or that has been incorrectly locked, which might cause the memory to be written to swap files on disk by the virtual memory manager. This can make the data more accessible to external actors.",
        "detail": "**Extended Description:**\nOn Windows systems the VirtualLock function can lock a page of memory to ensure that it will remain present in memory and not be swapped to disk. However, on older versions of Windows, such as 95, 98, or Me, the VirtualLock() function is only a stub and provides no protection. On POSIX systems the mlock() call ensures that a page will stay resident in memory but does not guarantee that the page will not appear in the swap. Therefore, it is unsuitable for use as a protection mechanism for sensitive data. Some platforms, in particular Linux, do make the guarantee that the page will not be swapped, but this is non-standard and is not portable. Calls to mlock() also require supervisor privilege. Return values for both of these calls must be checked to ensure that the lock operation was actually successful.\n\n**Consequence Note:** Sensitive data that is written to a swap file may be exposed.\n",
        "parent": [
            "413"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Identify data that needs to be protected from swapping and choose platform-appropriate protection mechanisms.\n\n**Mitigation:** Check return values to ensure locking operations are successful.\n",
        "languages": []
    },
    {
        "cwe": "593",
        "name": "Authentication Bypass: OpenSSL CTX Object Modified after SSL Objects are Created",
        "description": "The product modifies the SSL context after connection creation has begun.",
        "detail": "**Extended Description:**\nIf the program modifies the SSL_CTX object after creating SSL objects from it, there is the possibility that older SSL objects created from the original context could all be affected by that change.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** No authentication takes place in this process, bypassing an assumed protection of encryption.\n\n**Consequence Note:** The encrypted communication between a user and a trusted host may be subject to a sniffing attack.\n",
        "parent": [
            "1390",
            "666"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Use a language or a library that provides a cryptography framework at a higher level of abstraction.\n\n**Mitigation:** Most SSL_CTX functions have SSL counterparts that act on SSL-type objects.\n\n**Mitigation:** Applications should set up an SSL_CTX completely, before creating SSL objects from it.\n",
        "languages": []
    },
    {
        "cwe": "594",
        "name": "J2EE Framework: Saving Unserializable Objects to Disk",
        "description": "When the J2EE container attempts to write unserializable objects to disk there is no guarantee that the process will complete successfully.",
        "detail": "**Extended Description:**\nIn heavy load conditions, most J2EE application frameworks flush objects to disk to manage memory requirements of incoming requests. For example, session scoped objects, and even application scoped objects, are written to disk when required. While these application frameworks do the real work of writing objects to disk, they do not enforce that those objects be serializable, thus leaving the web application vulnerable to crashes induced by serialization failure. An attacker may be able to mount a denial of service attack by sending enough requests to the server to force the web application to save objects to disk.\n\n**Consequence Note:** Data represented by unserializable objects can be corrupted.\n\n**Consequence Note:** Non-serializability of objects can lead to system crash.\n",
        "parent": [
            "1076"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** All objects that become part of session and application scope must implement the java.io.Serializable interface to ensure serializability of containing objects.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "595",
        "name": "Comparison of Object References Instead of Object Contents",
        "description": "The product compares object references instead of the contents of the objects themselves, preventing it from detecting equivalent objects.",
        "detail": "**Extended Description:**\nFor example, in Java, comparing objects using == usually produces deceptive results, since the == operator compares object references rather than values; often, this means that using == for strings is actually comparing the strings' references, not their values.\n\n**Consequence Note:** This weakness can lead to erroneous results that can cause unexpected application behaviors.\n",
        "parent": [
            "1025"
        ],
        "children": [
            "597"
        ],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** In Java, use the equals() method to compare objects instead of the == operator. If using ==, it is important for performance reasons that your objects are created by a static factory, not by a constructor.\n",
        "languages": [
            "Java",
            "JavaScript",
            "PHP"
        ]
    },
    {
        "cwe": "597",
        "name": "Use of Wrong Operator in String Comparison",
        "description": "The product uses the wrong operator when comparing a string, such as using \"==\" when the .equals() method should be used instead.",
        "detail": "**Extended Description:**\nIn Java, using == or != to compare two strings for equality actually compares two objects for equality rather than their string values for equality. Chances are good that the two references will never be equal. While this weakness often only affects program correctness, if the equality is used for a security decision, the unintended comparison result could be leveraged to affect program security.\n",
        "parent": [
            "480",
            "595"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Within Java, use .equals() to compare string values.\n Within JavaScript, use == to compare string values.\n Within PHP, use == to compare a numeric value to a string value. (PHP converts the string to a number.)\n",
        "languages": []
    },
    {
        "cwe": "598",
        "name": "Use of GET Request Method With Sensitive Query Strings",
        "description": "The web application uses the HTTP GET method to process a request and includes sensitive information in the query string of that request.",
        "detail": "**Consequence Note:** At a minimum, attackers can garner information from query strings that can be utilized in escalating their method of attack, such as information about the internal workings of the application or database column names. Successful exploitation of query string parameter vulnerabilities could lead to an attacker impersonating a legitimate user, obtaining proprietary data, or simply executing actions not intended by the application developers.\n",
        "parent": [
            "201"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** When sensitive information is sent, use the POST method (e.g. registration form).\n",
        "languages": []
    },
    {
        "cwe": "599",
        "name": "Missing Validation of OpenSSL Certificate",
        "description": "The product uses OpenSSL and trusts or uses a certificate without using the SSL_get_verify_result() function to ensure that the certificate satisfies all necessary security requirements.",
        "detail": "**Extended Description:**\nThis could allow an attacker to use an invalid certificate to claim to be a trusted host, use expired certificates, or conduct other attacks that could be detected if the certificate is properly validated.\n\n**Consequence Note:** The data read may not be properly secured, it might be viewed by an attacker.\n\n**Consequence Note:** Trust afforded to the system in question may allow for spoofing or redirection attacks.\n\n**Consequence Note:** If the certificate is not checked, it may be possible for a redirection or spoofing attack to allow a malicious host with a valid certificate to provide data under the guise of a trusted host. While the attacker in question may have a valid certificate, it may simply be a valid certificate for a different site. In order to ensure data integrity, we must check that the certificate is valid, and that it pertains to the site we wish to access.\n",
        "parent": [
            "295"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Ensure that proper authentication is included in the system design.\n\n**Mitigation:** Understand and properly implement all checks necessary to ensure the identity of entities involved in encrypted communications.\n",
        "languages": []
    },
    {
        "cwe": "6",
        "name": "J2EE Misconfiguration: Insufficient Session-ID Length",
        "description": "The J2EE application is configured to use an insufficient session ID length.",
        "detail": "**Extended Description:**\nIf an attacker can guess or steal a session ID, then they may be able to take over the user's session (called session hijacking). The number of possible session IDs increases with increased session ID length, making it more difficult to guess or steal a session ID.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Background Details:**\n[\"\\n\\nSession ID's can be used to identify communicating parties in a web environment.\\n\\n\\nThe expected number of seconds required to guess a valid session identifier is given by the equation: (2^B+1)/(2*A*S) Where: - B is the number of bits of entropy in the session identifier. - A is the number of guesses an attacker can try each second. - S is the number of valid session identifiers that are valid and available to be guessed at any given time. The number of bits of entropy in the session identifier is always less than the total number of bits in the session identifier. For example, if session identifiers were provided in ascending order, there would be close to zero bits of entropy in the session identifier no matter the identifier's length. Assuming that the session identifiers are being generated using a good source of random numbers, we will estimate the number of bits of entropy in a session identifier to be half the total number of bits in the session identifier. For realistic identifier lengths this is possible, though perhaps optimistic.\\n\"]\n\n**Consequence Note:** If an attacker can guess an authenticated user's session identifier, they can take over the user's session.\n",
        "parent": [
            "334"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Session identifiers should be at least 128 bits long to prevent brute-force session guessing. A shorter session identifier leaves the application open to brute-force session guessing attacks.\n\n**Mitigation:** A lower bound on the number of valid session identifiers that are available to be guessed is the number of users that are active on a site at any given moment. However, any users that abandon their sessions without logging out will increase this number. (This is one of many good reasons to have a short inactive session timeout.) With a 64 bit session identifier, assume 32 bits of entropy. For a large web site, assume that the attacker can try 1,000 guesses per second and that there are 10,000 valid session identifiers at any given moment. Given these assumptions, the expected time for an attacker to successfully guess a valid session identifier is less than 4 minutes. Now assume a 128 bit session identifier that provides 64 bits of entropy. With a very large web site, an attacker might try 10,000 guesses per second with 100,000 valid session identifiers available to be guessed. Given these assumptions, the expected time for an attacker to successfully guess a valid session identifier is greater than 292 years.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "600",
        "name": "Uncaught Exception in Servlet ",
        "description": "The Servlet does not catch all exceptions, which may reveal sensitive debugging information.",
        "detail": "**Extended Description:**\nWhen a Servlet throws an exception, the default error response the Servlet container sends back to the user typically includes debugging information. This information is of great value to an attacker. For example, a stack trace might show the attacker a malformed SQL query string, the type of database being used, and the version of the application container. This information enables the attacker to target known vulnerabilities in these components.\n\n**Alternate Terms:** Missing Catch Block\n",
        "parent": [
            "248"
        ],
        "children": [],
        "related": [
            "209",
            "390"
        ],
        "scopes": [
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Implement Exception blocks to handle all types of Exceptions.\n",
        "languages": []
    },
    {
        "cwe": "601",
        "name": "URL Redirection to Untrusted Site ('Open Redirect')",
        "description": "The web application accepts a user-controlled input that specifies a link to an external site, and uses that link in a redirect.",
        "detail": "**Alternate Terms:** Open Redirect, Cross-site Redirect, Cross-domain Redirect, Unvalidated Redirect\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Background Details:**\n['Phishing is a general term for deceptive attempts to coerce private information from users that will be used for identity theft.']\n\n**Consequence Note:** The user may be redirected to an untrusted page that contains malware which may then compromise the user's machine. This will expose the user to extensive risk and the user's interaction with the web server may also be compromised if the malware conducts keylogging or other attacks that steal credentials, personally identifiable information (PII), or other important data.\n\n**Consequence Note:** By modifying the URL value to a malicious site, an attacker may successfully launch a phishing scam. The user may be subjected to phishing attacks by being redirected to an untrusted page. The phishing attack may point to an attacker controlled web page that appears to be a trusted web site. The phishers may then steal the user's credentials and then use these credentials to access the legitimate web site. Because the server name in the modified link is identical to the original site, phishing attempts have a more trustworthy appearance.\n",
        "parent": [
            "610"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Since this weakness does not typically appear frequently within a single software package, manual white box techniques may be able to provide sufficient code coverage and reduction of false positives if all potentially-vulnerable operations can be assessed within limited time constraints.\n\n**Detection:** Automated black box tools that supply URLs to every input may be able to spot Location header modifications, but test case coverage is a factor, and custom redirects may not be detected.\n\n**Detection:** Automated static analysis tools may not be able to determine whether input influences the beginning of a URL, which is important for reducing false positives.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nUse a list of approved URLs or domains to be used for redirection.\n\n\n**Mitigation:** Use an intermediate disclaimer page that provides the user with a clear warning that they are leaving the current site. Implement a long timeout before the redirect occurs, or force the user to click on the link. Be careful to avoid XSS problems (CWE-79) when generating the disclaimer page.\n\n**Mitigation:** \n\nWhen the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n\nFor example, ID 1 could map to \"/login.asp\" and ID 2 could map to \"http://www.example.com/\". Features such as the ESAPI AccessReferenceMap [REF-45] provide this capability.\n\n\n**Mitigation:** Ensure that no externally-supplied requests are honored by requiring that all redirect requests include a unique nonce generated by the application [REF-483]. Be sure that the nonce is not predictable (CWE-330).\n\n**Effectiveness:** Note that this can be bypassed using XSS (CWE-79).\n\n**Mitigation:** \n\nUnderstand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n\n\nMany open redirect problems occur because the programmer assumed that certain inputs could not be modified, such as cookies and hidden form fields.\n\n\n**Mitigation:** Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.\n\n**Effectiveness:** An application firewall might not cover all possible input vectors. In addition, attack techniques might be available to bypass the protection mechanism, such as using malformed inputs that can still be processed by the component that receives those inputs. Depending on functionality, an application firewall might inadvertently reject or modify legitimate requests. Finally, some manual effort may be required for customization.\n",
        "languages": []
    },
    {
        "cwe": "602",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "603"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "603",
        "name": "Use of Client-Side Authentication",
        "description": "A client/server product performs authentication within client code but not in server code, allowing server-side authentication to be bypassed via a modified client that omits the authentication check.",
        "detail": "**Extended Description:**\nClient-side authentication is extremely weak and may be breached easily. Any attacker may read the source code and reverse-engineer the authentication mechanism to access parts of the application which would otherwise be protected.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "1390",
            "602"
        ],
        "children": [],
        "related": [
            "300",
            "656"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Do not rely on client side data. Always perform server side authentication.\n",
        "languages": []
    },
    {
        "cwe": "605",
        "name": "Multiple Binds to the Same Port",
        "description": "When multiple sockets are allowed to bind to the same port, other services on that port may be stolen or spoofed.",
        "detail": "**Extended Description:**\nOn most systems, a combination of setting the SO_REUSEADDR socket option, and a call to bind() allows any process to bind to a port to which a previous process has bound with INADDR_ANY. This allows a user to bind to the specific address of a server bound to INADDR_ANY on an unprivileged port, and steal its UDP packets/TCP connection.\n\n**Consequence Note:** Packets from a variety of network services may be stolen or the services spoofed.\n",
        "parent": [
            "666",
            "675"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Restrict server socket address to known local addresses.\n",
        "languages": []
    },
    {
        "cwe": "606",
        "name": "Unchecked Input for Loop Condition",
        "description": "The product does not properly check inputs that are used for loop conditions, potentially leading to a denial of service or other consequences because of excessive looping.",
        "detail": null,
        "parent": [
            "1284"
        ],
        "children": [],
        "related": [
            "834"
        ],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Do not use user-controlled data for loop conditions.\n\n**Mitigation:** Perform input validation.\n",
        "languages": []
    },
    {
        "cwe": "607",
        "name": "Public Static Final Field References Mutable Object",
        "description": "A public or protected static final field references a mutable object, which allows the object to be changed by malicious code, or accidentally from another package.",
        "detail": null,
        "parent": [
            "471"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Protect mutable objects by making them private. Restrict access to the getter and setter as well.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "608",
        "name": "Struts: Non-private Field in ActionForm Class",
        "description": "An ActionForm class contains a field that has not been declared private, which can be accessed without using a setter or getter.",
        "detail": null,
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Make all fields private. Use getter to get the value of the field. Setter should be used only by the framework; setting an action form field from other actions is bad practice and should be avoided.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "609",
        "name": "Double-Checked Locking",
        "description": "The product uses double-checked locking to access a resource without the overhead of explicit synchronization, but the locking is insufficient.",
        "detail": "**Extended Description:**\nDouble-checked locking refers to the situation where a programmer checks to see if a resource has been initialized, grabs a lock, checks again to see if the resource has been initialized, and then performs the initialization if it has not occurred yet. This should not be done, as it is not guaranteed to work in all languages and on all architectures. In summary, other threads may not be operating inside the synchronous block and are not guaranteed to see the operations execute in the same order as they would appear inside the synchronous block.\n",
        "parent": [
            "667"
        ],
        "children": [],
        "related": [
            "367"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** While double-checked locking can be achieved in some languages, it is inherently flawed in Java before 1.5, and cannot be achieved without compromising platform independence. Before Java 1.5, only use of the synchronized keyword is known to work. Beginning in Java 1.5, use of the \"volatile\" keyword allows double-checked locking to work successfully, although there is some debate as to whether it achieves sufficient performance gains. See references.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "61",
        "name": "UNIX Symbolic Link (Symlink) Following",
        "description": "The product, when opening a file or directory, does not sufficiently account for when the file is a symbolic link that resolves to a target outside of the intended control sphere. This could allow an attacker to cause the product to operate on unauthorized files.",
        "detail": "**Extended Description:**\nA product that allows UNIX symbolic links (symlink) as part of paths whether in internal code or through user input can allow an attacker to spoof the symbolic link and traverse the file system to unintended locations or access arbitrary files. The symbolic link can permit an attacker to read/write/corrupt a file that they originally did not have permissions to access.\n\n**Alternate Terms:** Symlink following, symlink vulnerability\n\n**Mode of Introduction:** These are typically reported for temporary files or privileged programs.\n",
        "parent": [
            "59"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Symbolic link attacks often occur when a program creates a tmp directory that stores files/links. Access to the directory should be restricted to the program as to prevent attackers from manipulating the files.\n\n**Mitigation:** \n\nFollow the principle of least privilege when assigning access rights to entities in a software system.\n\n\nDenying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.\n\n",
        "languages": []
    },
    {
        "cwe": "610",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "15",
            "470",
            "601",
            "611",
            "73",
            "918"
        ],
        "related": [
            "386"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "611",
        "name": "Improper Restriction of XML External Entity Reference",
        "description": "The product processes an XML document that can contain XML entities with URIs that resolve to documents outside of the intended sphere of control, causing the product to embed incorrect documents into its output.",
        "detail": "**Extended Description:**\n\n\nXML documents optionally contain a Document Type Definition (DTD), which, among other features, enables the definition of XML entities. It is possible to define an entity by providing a substitution string in the form of a URI. The XML parser can access the contents of this URI and embed these contents back into the XML document for further processing.\n\n\nBy submitting an XML file that defines an external entity with a file:// URI, an attacker can cause the processing application to read the contents of a local file. For example, a URI such as \"file:///c:/winnt/win.ini\" designates (in Windows) the file C:\\Winnt\\win.ini, or file:///etc/passwd designates the password file in Unix-based systems. Using URIs with other schemes such as http://, the attacker can force the application to make outgoing requests to servers that the attacker cannot reach directly, which can be used to bypass firewall restrictions or hide the source of attacks such as port scanning.\n\n\nOnce the content of the URI is read, it is fed back into the application that is processing the XML. This application may echo back the data (e.g. in an error message), thereby exposing the file contents.\n\n\n**Alternate Terms:** XXE\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** If the attacker is able to include a crafted DTD and a default entity resolver is enabled, the attacker may be able to access arbitrary files on the system.\n\n**Consequence Note:** The DTD may include arbitrary HTTP requests that the server may execute. This could lead to other attacks leveraging the server's trust relationship with other entities.\n\n**Consequence Note:** The product could consume excessive CPU cycles or memory using a URI that points to a large file, or a device that always returns data such as /dev/random. Alternately, the URI could reference a file that contains many nested or recursive entity references to further slow down parsing.\n",
        "parent": [
            "610"
        ],
        "children": [],
        "related": [
            "441"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Many XML parsers and validators can be configured to disable external entity expansion.\n",
        "languages": [
            "XML"
        ]
    },
    {
        "cwe": "612",
        "name": "Improper Authorization of Index Containing Sensitive Information",
        "description": "The product creates a search index of private or sensitive documents, but it does not properly limit index access to actors who are authorized to see the original information.",
        "detail": "**Extended Description:**\nWeb sites and other document repositories may apply an indexing routine against a group of private documents to facilitate search. If the index's results are available to parties who do not have access to the documents being indexed, then attackers could obtain portions of the documents by conducting targeted searches and reading the results. The risk is especially dangerous if search results include surrounding text that was not part of the search query. This issue can appear in search engines that are not configured (or implemented) to ignore critical files that should remain hidden; even without permissions to download these files directly, the remote user could read them.\n",
        "parent": [
            "1230"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "613",
        "name": "Insufficient Session Expiration",
        "description": "According to WASC, \"Insufficient Session Expiration is when a web site permits an attacker to reuse old session credentials or session IDs for authorization.\"",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "672"
        ],
        "children": [],
        "related": [
            "287"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Set sessions/credentials expiration date.\n",
        "languages": []
    },
    {
        "cwe": "614",
        "name": "Sensitive Cookie in HTTPS Session Without 'Secure' Attribute",
        "description": "The Secure attribute for sensitive cookies in HTTPS sessions is not set, which could cause the user agent to send those cookies in plaintext over an HTTP session.",
        "detail": null,
        "parent": [
            "319"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Always set the secure attribute when the cookie should sent via HTTPS only.\n",
        "languages": []
    },
    {
        "cwe": "615",
        "name": "Inclusion of Sensitive Information in Source Code Comments",
        "description": "While adding general comments is very useful, some programmers tend to leave important data, such as: filenames related to the web application, old links or links which were not meant to be browsed by users, old code fragments, etc.",
        "detail": "**Extended Description:**\nAn attacker who finds these comments can map the application's structure and files, expose hidden parts of the site, and study the fragments of code to reverse engineer the application, which may help develop further attacks against the site.\n",
        "parent": [
            "540"
        ],
        "children": [],
        "related": [
            "546"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Remove comments which have sensitive information about the design/implementation of the application. Some of the comments may be exposed to the user and affect the security posture of the application.\n",
        "languages": []
    },
    {
        "cwe": "616",
        "name": "Incomplete Identification of Uploaded File Variables (PHP)",
        "description": "The PHP application uses an old method for processing uploaded files by referencing the four global variables that are set for each file (e.g. $varname, $varname_size, $varname_name, $varname_type). These variables could be overwritten by attackers, causing the application to process unauthorized files.",
        "detail": "**Extended Description:**\nThese global variables could be overwritten by POST requests, cookies, or other methods of populating or overwriting these variables. This could be used to read or process arbitrary files by providing values such as \"/etc/passwd\".\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [
            "473"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use PHP 4 or later.\n\n**Mitigation:** If you must support older PHP versions, write your own version of is_uploaded_file() and run it against $HTTP_POST_FILES['userfile']))\n\n**Mitigation:** For later PHP versions, reference uploaded files using the $HTTP_POST_FILES or $_FILES variables, and use is_uploaded_file() or move_uploaded_file() to ensure that you are dealing with an uploaded file.\n",
        "languages": [
            "PHP"
        ]
    },
    {
        "cwe": "617",
        "name": "Reachable Assertion",
        "description": "The product contains an assert() or similar statement that can be triggered by an attacker, which leads to an application exit or other behavior that is more severe than necessary.",
        "detail": "**Extended Description:**\n\n\nWhile assertion is good for catching logic errors and reducing the chances of reaching more serious vulnerability conditions, it can still lead to a denial of service.\n\n\nFor example, if a server handles multiple simultaneous connections, and an assert() occurs in one single connection that causes all other connections to be dropped, this is a reachable assertion that leads to a denial of service.\n\n\n**Alternate Terms:** assertion failure\n\n**Consequence Note:** An attacker that can trigger an assert statement can still lead to a denial of service if the relevant code can be triggered by an attacker, and if the scope of the assert() extends beyond the attacker's own session.\n",
        "parent": [
            "670"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Make sensitive open/close operation non reachable by directly user-controlled data (e.g. open/close resources)\n\n**Mitigation:** Perform input validation on user data.\n",
        "languages": []
    },
    {
        "cwe": "618",
        "name": "Exposed Unsafe ActiveX Method",
        "description": "An ActiveX control is intended for use in a web browser, but it exposes dangerous methods that perform actions that are outside of the browser's security model (e.g. the zone or domain).",
        "detail": "**Extended Description:**\nActiveX controls can exercise far greater control over the operating system than typical Java or javascript. Exposed methods can be subject to various vulnerabilities, depending on the implemented behaviors of those methods, and whether input validation is performed on the provided arguments. If there is no integrity checking or origin validation, this method could be invoked by attackers.\n",
        "parent": [
            "749"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If you must expose a method, make sure to perform input validation on all arguments, and protect against all possible vulnerabilities.\n\n**Mitigation:** Use code signing, although this does not protect against any weaknesses that are already in the control.\n\n**Mitigation:** Where possible, avoid marking the control as safe for scripting.\n",
        "languages": []
    },
    {
        "cwe": "619",
        "name": "Dangling Database Cursor ('Cursor Injection')",
        "description": "If a database cursor is not closed properly, then it could become accessible to other users while retaining the same privileges that were originally assigned, leaving the cursor \"dangling.\"",
        "detail": "**Extended Description:**\nFor example, an improper dangling cursor could arise from unhandled exceptions. The impact of the issue depends on the cursor's role, but SQL injection attacks are commonly possible.\n\n**Mode of Introduction:** This issue is currently reported for unhandled exceptions, but it is theoretically possible any time the programmer does not close the cursor at the proper time.\n\n**Background Details:**\n['A cursor is a feature in Oracle PL/SQL and other languages that provides a handle for executing and accessing the results of SQL queries.']\n",
        "parent": [
            "402"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Close cursors immediately after access to them is complete. Ensure that you close cursors if exceptions occur.\n",
        "languages": [
            "SQL"
        ]
    },
    {
        "cwe": "62",
        "name": "UNIX Hard Link",
        "description": "The product, when opening a file or directory, does not sufficiently account for when the name is associated with a hard link to a target that is outside of the intended control sphere. This could allow an attacker to cause the product to operate on unauthorized files.",
        "detail": "**Extended Description:**\nFailure for a system to check for hard links can result in vulnerability to different types of attacks. For example, an attacker can escalate their privileges if a file used by a privileged program is replaced with a hard link to a sensitive file (e.g. /etc/passwd). When the process opens the file, the attacker can assume the privileges of that process.\n",
        "parent": [
            "59"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nFollow the principle of least privilege when assigning access rights to entities in a software system.\n\n\nDenying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.\n\n",
        "languages": []
    },
    {
        "cwe": "620",
        "name": "Unverified Password Change",
        "description": "When setting a new password for a user, the product does not require knowledge of the original password, or using another form of authentication.",
        "detail": "**Extended Description:**\nThis could be used by an attacker to change passwords for another user, thus gaining the privileges associated with that user.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "1390"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** When prompting for a password change, force the user to provide the original password in addition to the new password.\n\n**Mitigation:** Do not use \"forgotten password\" functionality. But if you must, ensure that you are only providing information to the actual user, e.g. by using an email address or challenge question that the legitimate user already provided in the past; do not allow the current user to change this identity information until the correct password has been provided.\n",
        "languages": []
    },
    {
        "cwe": "621",
        "name": "Variable Extraction Error",
        "description": "The product uses external input to determine the names of variables into which information is extracted, without verifying that the names of the specified variables are valid. This could cause the program to overwrite unintended variables.",
        "detail": "**Extended Description:**\n\n\nFor example, in PHP, extraction can be used to provide functionality similar to register_globals, a dangerous functionality that is frequently disabled in production systems. Calling extract() or import_request_variables() without the proper arguments could allow arbitrary global variables to be overwritten, including superglobals.\n\n\nSimilar functionality is possible in other interpreted languages, including custom languages.\n\n\n**Alternate Terms:** Variable overwrite\n\n**Consequence Note:** An attacker could modify sensitive data or program variables.\n",
        "parent": [
            "914"
        ],
        "children": [],
        "related": [
            "471"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use allowlists of variable names that can be extracted.\n\n**Mitigation:** Consider refactoring your code to avoid extraction routines altogether.\n\n**Mitigation:** In PHP, call extract() with options such as EXTR_SKIP and EXTR_PREFIX_ALL; call import_request_variables() with a prefix argument. Note that these capabilities are not present in all PHP versions.\n",
        "languages": [
            "PHP"
        ]
    },
    {
        "cwe": "622",
        "name": "Improper Validation of Function Hook Arguments",
        "description": "The product adds hooks to user-accessible API functions, but it does not properly validate the arguments. This could lead to resultant vulnerabilities.",
        "detail": "**Extended Description:**\nSuch hooks can be used in defensive software that runs with privileges, such as anti-virus or firewall, which hooks kernel calls. When the arguments are not validated, they could be used to bypass the protection scheme or attack the product itself.\n",
        "parent": [
            "20"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Ensure that all arguments are verified, as defined by the API you are protecting.\n\n**Mitigation:** Drop privileges before invoking such functions, if possible.\n",
        "languages": []
    },
    {
        "cwe": "623",
        "name": "Unsafe ActiveX Control Marked Safe For Scripting",
        "description": "An ActiveX control is intended for restricted use, but it has been marked as safe-for-scripting.",
        "detail": "**Extended Description:**\nThis might allow attackers to use dangerous functionality via a web page that accesses the control, which can lead to different resultant vulnerabilities, depending on the control's behavior.\n",
        "parent": [
            "267"
        ],
        "children": [],
        "related": [
            "618"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** During development, do not mark it as safe for scripting.\n\n**Mitigation:** After distribution, you can set the kill bit for the control so that it is not accessible from Internet Explorer.\n",
        "languages": []
    },
    {
        "cwe": "624",
        "name": "Executable Regular Expression Error",
        "description": "The product uses a regular expression that either (1) contains an executable component with user-controlled inputs, or (2) allows a user to enable execution by inserting pattern modifiers.",
        "detail": "**Extended Description:**\nCase (2) is possible in the PHP preg_replace() function, and possibly in other languages when a user-controlled input is inserted into a string that is later parsed as a regular expression.\n",
        "parent": [
            "77"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** The regular expression feature in some languages allows inputs to be quoted or escaped before insertion, such as \\Q and \\E in Perl.\n",
        "languages": [
            "PHP",
            "Perl"
        ]
    },
    {
        "cwe": "625",
        "name": "Permissive Regular Expression",
        "description": "The product uses a regular expression that does not sufficiently restrict the set of allowed values.",
        "detail": "**Extended Description:**\n\n\nThis effectively causes the regexp to accept substrings that match the pattern, which produces a partial comparison to the target. In some cases, this can lead to other weaknesses. Common errors include:\n\n\n  - not identifying the beginning and end of the target string\n\n  - using wildcards instead of acceptable character ranges\n\n  - others\n\n\n\n**Mode of Introduction:** This problem is frequently found when the regular expression is used in input validation or security features such as authentication.\n",
        "parent": [
            "185"
        ],
        "children": [],
        "related": [
            "183",
            "184",
            "187"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** When applicable, ensure that the regular expression marks beginning and ending string patterns, such as \"/^string$/\" for Perl.\n",
        "languages": [
            "PHP",
            "Perl"
        ]
    },
    {
        "cwe": "626",
        "name": "Null Byte Interaction Error (Poison Null Byte)",
        "description": "The product does not properly handle null bytes or NUL characters when passing data between different representations or components.",
        "detail": "**Extended Description:**\n\n\nA null byte (NUL character) can have different meanings across representations or languages. For example, it is a string terminator in standard C libraries, but Perl and PHP strings do not treat it as a terminator. When two representations are crossed - such as when Perl or PHP invokes underlying C functionality - this can produce an interaction error with unexpected results. Similar issues have been reported for ASP. Other interpreters written in C might also be affected.\n\n\nThe poison null byte is frequently useful in path traversal attacks by terminating hard-coded extensions that are added to a filename. It can play a role in regular expression processing in PHP.\n\n",
        "parent": [
            "147",
            "436"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Remove null bytes from all incoming strings.\n",
        "languages": [
            "ASP.NET",
            "PHP",
            "Perl"
        ]
    },
    {
        "cwe": "627",
        "name": "Dynamic Variable Evaluation",
        "description": "In a language where the user can influence the name of a variable at runtime, if the variable names are not controlled, an attacker can read or write to arbitrary variables, or access arbitrary functions.",
        "detail": "**Extended Description:**\nThe resultant vulnerabilities depend on the behavior of the application, both at the crossover point and in any control/data flow that is reachable by the related variables or functions.\n\n**Alternate Terms:** Dynamic evaluation\n\n**Background Details:**\n['Many interpreted languages support the use of a \"$$varname\" construct to set a variable whose name is specified by the $varname variable. In PHP, these are referred to as \"variable variables.\" Functions might also be invoked using similar syntax, such as $$funcname(arg1, arg2).']\n\n**Consequence Note:** An attacker could gain unauthorized access to internal program variables and execute arbitrary code.\n",
        "parent": [
            "914"
        ],
        "children": [],
        "related": [
            "183"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Refactor the code to avoid dynamic variable evaluation whenever possible.\n\n**Mitigation:** Use only allowlists of acceptable variable or function names.\n\n**Mitigation:** For function names, ensure that you are only calling functions that accept the proper number of arguments, to avoid unexpected null arguments.\n",
        "languages": [
            "PHP",
            "Perl"
        ]
    },
    {
        "cwe": "628",
        "name": "Function Call with Incorrectly Specified Arguments",
        "description": "The product calls a function, procedure, or routine with arguments that are not correctly specified, leading to always-incorrect behavior and resultant weaknesses.",
        "detail": "**Extended Description:**\n\n\nThere are multiple ways in which this weakness can be introduced, including:\n\n\n  - the wrong variable or reference;\n\n  - an incorrect number of arguments;\n\n  - incorrect order of arguments;\n\n  - wrong type of arguments; or\n\n  - wrong value.\n\n\n\n**Consequence Note:** This weakness can cause unintended behavior and can lead to additional weaknesses such as allowing an attacker to gain unintended access to system resources.\n",
        "parent": [
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Since these bugs typically introduce incorrect behavior that is obvious to users, they are found quickly, unless they occur in rarely-tested code paths. Managing the correct number of arguments can be made more difficult in cases where format strings are used, or when variable numbers of arguments are supported.\n\n**Mitigation:** Once found, these issues are easy to fix. Use code inspection tools and relevant compiler features to identify potential violations. Pay special attention to code that is not likely to be exercised heavily during QA.\n\n**Mitigation:** Make sure your API's are stable before you use them in production code.\n",
        "languages": []
    },
    {
        "cwe": "636",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "455"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "637",
        "name": "Unnecessary Complexity in Protection Mechanism (Not Using 'Economy of Mechanism')",
        "description": "The product uses a more complex mechanism than necessary, which could lead to resultant weaknesses when the mechanism is not correctly understood, modeled, configured, implemented, or used.",
        "detail": "**Extended Description:**\nSecurity mechanisms should be as simple as possible. Complex security mechanisms may engender partial implementations and compatibility problems, with resulting mismatches in assumptions and implemented security. A corollary of this principle is that data specifications should be as simple as possible, because complex data specifications result in complex validation code. Complex tasks and systems may also need to be guarded by complex security checks, so simple systems should be preferred.\n\n**Alternate Terms:** Unnecessary Complexity\n",
        "parent": [
            "657"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Avoid complex security mechanisms when simpler ones would meet requirements. Avoid complex data models, and unnecessarily complex operations. Adopt architectures that provide guarantees, simplify understanding through elegance and abstraction, and that can be implemented similarly. Modularize, isolate and do not trust complex code, and apply other secure programming principles on these modules (e.g., least privilege) to mitigate vulnerabilities.\n",
        "languages": []
    },
    {
        "cwe": "638",
        "name": "Not Using Complete Mediation",
        "description": "The product does not perform access checks on a resource every time the resource is accessed by an entity, which can create resultant weaknesses if that entity's rights or privileges change over time.",
        "detail": "**Consequence Note:** A user might retain access to a critical resource even after privileges have been revoked, possibly allowing access to privileged functionality or sensitive information, depending on the role of the resource.\n",
        "parent": [
            "657",
            "862"
        ],
        "children": [
            "424"
        ],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Invalidate cached privileges, file handles or descriptors, or other access credentials whenever identities, processes, policies, roles, capabilities or permissions change. Perform complete authentication checks before accepting, caching and reusing data, dynamic content and code (scripts). Avoid caching access control decisions as much as possible.\n\n**Mitigation:** Identify all possible code paths that might access sensitive resources. If possible, create and use a single interface that performs the access checks, and develop code standards that require use of this interface.\n",
        "languages": []
    },
    {
        "cwe": "639",
        "name": "Authorization Bypass Through User-Controlled Key",
        "description": "The system's authorization functionality does not prevent one user from gaining access to another user's data or record by modifying the key value identifying the data.",
        "detail": "**Extended Description:**\n\n\nRetrieval of a user record occurs in the system based on some key value that is under user control. The key would typically identify a user-related record stored in the system and would be used to lookup that record for presentation to the user. It is likely that an attacker would have to be an authenticated user in the system. However, the authorization process would not properly check the data access operation to ensure that the authenticated user performing the operation has sufficient entitlements to perform the requested data access, hence bypassing any other authorization checks present in the system.\n\n\nFor example, attackers can look at places where user specific data is retrieved (e.g. search screens) and determine whether the key for the item being looked up is controllable externally. The key may be a hidden field in the HTML form field, might be passed as a URL parameter or as an unencrypted cookie variable, then in each of these cases it will be possible to tamper with the key value.\n\n\nOne manifestation of this weakness is when a system uses sequential or otherwise easily-guessable session IDs that would allow one user to easily switch to another user's session and read/modify their data.\n\n\n**Alternate Terms:** Insecure Direct Object Reference / IDOR, Broken Object Level Authorization / BOLA, Horizontal Authorization\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Access control checks for specific user data or functionality can be bypassed.\n\n**Consequence Note:** Horizontal escalation of privilege is possible (one user can view/modify information of another user).\n\n**Consequence Note:** Vertical escalation of privilege is possible if the user-controlled key is actually a flag that indicates administrator status, allowing the attacker to gain administrative access.\n",
        "parent": [
            "284",
            "863"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** For each and every data access, ensure that the user has sufficient privilege to access the record that is being requested.\n\n**Mitigation:** Make sure that the key that is used in the lookup of a specific user's record is not controllable externally by the user or that any tampering can be detected.\n\n**Mitigation:** Use encryption in order to make it more difficult to guess other legitimate values of the key or associate a digital signature with the key so that the server can verify that there has been no tampering.\n",
        "languages": []
    },
    {
        "cwe": "64",
        "name": "Windows Shortcut Following (.LNK)",
        "description": "The product, when opening a file or directory, does not sufficiently handle when the file is a Windows shortcut (.LNK) whose target is outside of the intended control sphere. This could allow an attacker to cause the product to operate on unauthorized files.",
        "detail": "**Extended Description:**\nThe shortcut (file with the .lnk extension) can permit an attacker to read/write a file that they originally did not have permissions to access.\n\n**Alternate Terms:** Windows symbolic link following, symlink\n",
        "parent": [
            "59"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nFollow the principle of least privilege when assigning access rights to entities in a software system.\n\n\nDenying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.\n\n",
        "languages": []
    },
    {
        "cwe": "640",
        "name": "Weak Password Recovery Mechanism for Forgotten Password",
        "description": "The product contains a mechanism for users to recover or change their passwords without knowing the original password, but the mechanism is weak.",
        "detail": "**Extended Description:**\n\n\nIt is common for an application to have a mechanism that provides a means for a user to gain access to their account in the event they forget their password. Very often the password recovery mechanism is weak, which has the effect of making it more likely that it would be possible for a person other than the legitimate system user to gain access to that user's account. Weak password recovery schemes completely undermine a strong password authentication scheme.\n\n\nThis weakness may be that the security question is too easy to guess or find an answer to (e.g. because the question is too common, or the answers can be found using social media). Or there might be an implementation weakness in the password recovery mechanism code that may for instance trick the system into e-mailing the new password to an e-mail account other than that of the user. There might be no throttling done on the rate of password resets so that a legitimate user can be denied service by an attacker if an attacker tries to recover their password in a rapid succession. The system may send the original password to the user rather than generating a new temporary password. In summary, password recovery functionality, if not carefully designed and implemented can often become the system's weakest link that can be misused in a way that would allow an attacker to gain unauthorized access to the system.\n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** An attacker could gain unauthorized access to the system by retrieving legitimate user's authentication credentials.\n\n**Consequence Note:** An attacker could deny service to legitimate system users by launching a brute force attack on the password recovery mechanism using user ids of legitimate users.\n\n**Consequence Note:** The system's security functionality is turned against the system by the attacker.\n",
        "parent": [
            "1390",
            "287"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Make sure that all input supplied by the user to the password recovery mechanism is thoroughly filtered and validated.\n\n**Mitigation:** Do not use standard weak security questions and use several security questions.\n\n**Mitigation:** Make sure that there is throttling on the number of incorrect answers to a security question. Disable the password recovery functionality after a certain (small) number of incorrect guesses.\n\n**Mitigation:** Require that the user properly answers the security question prior to resetting their password and sending the new password to the e-mail address of record.\n\n**Mitigation:** Never allow the user to control what e-mail address the new password will be sent to in the password recovery mechanism.\n\n**Mitigation:** Assign a new temporary password rather than revealing the original password.\n",
        "languages": []
    },
    {
        "cwe": "641",
        "name": "Improper Restriction of Names for Files and Other Resources",
        "description": "The product constructs the name of a file or other resource using input from an upstream component, but it does not restrict or incorrectly restricts the resulting name.",
        "detail": "**Extended Description:**\nThis may produce resultant weaknesses. For instance, if the names of these resources contain scripting characters, it is possible that a script may get executed in the client's browser if the application ever displays the name of the resource on a dynamically generated web page. Alternately, if the resources are consumed by some application parser, a specially crafted name can exploit some vulnerability internal to the parser, potentially resulting in execution of arbitrary code on the server machine. The problems will vary based on the context of usage of such malformed resource names and whether vulnerabilities are present in or assumptions are made by the targeted technology that would make code execution possible.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Execution of arbitrary code in the context of usage of the resources with dangerous names.\n\n**Consequence Note:** Crash of the consumer code of these resources resulting in information leakage or denial of service.\n",
        "parent": [
            "99"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Do not allow users to control names of resources used on the server side.\n\n**Mitigation:** Perform allowlist input validation at entry points and also before consuming the resources. Reject bad file names rather than trying to cleanse them.\n\n**Mitigation:** Make sure that technologies consuming the resources are not vulnerable (e.g. buffer overflow, format string, etc.) in a way that would allow code execution if the name of the resource is malformed.\n",
        "languages": []
    },
    {
        "cwe": "642",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "15",
            "472",
            "73"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "643",
        "name": "Improper Neutralization of Data within XPath Expressions ('XPath Injection')",
        "description": "The product uses external input to dynamically construct an XPath expression used to retrieve data from an XML database, but it does not neutralize or incorrectly neutralizes that input. This allows an attacker to control the structure of the query.",
        "detail": "**Extended Description:**\nThe net effect is that the attacker will have control over the information selected from the XML database and may use that ability to control application flow, modify logic, retrieve unauthorized data, or bypass important checks (e.g. authentication).\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Controlling application flow (e.g. bypassing authentication).\n\n**Consequence Note:** The attacker could read restricted XML content.\n",
        "parent": [
            "91",
            "943"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use parameterized XPath queries (e.g. using XQuery). This will help ensure separation between data plane and control plane.\n\n**Mitigation:** Properly validate user input. Reject data where appropriate, filter where appropriate and escape where appropriate. Make sure input that will be used in XPath queries is safe in that context.\n",
        "languages": []
    },
    {
        "cwe": "644",
        "name": "Improper Neutralization of HTTP Headers for Scripting Syntax",
        "description": "The product does not neutralize or incorrectly neutralizes web scripting syntax in HTTP headers that can be used by web browser components that can process raw headers, such as Flash.",
        "detail": "**Extended Description:**\n\n\nAn attacker may be able to conduct cross-site scripting and other attacks against users who have these components enabled.\n\n\nIf a product does not neutralize user controlled data being placed in the header of an HTTP response coming from the server, the header may contain a script that will get executed in the client's browser context, potentially resulting in a cross site scripting vulnerability or possibly an HTTP response splitting attack. It is important to carefully control data that is being placed both in HTTP response header and in the HTTP response body to ensure that no scripting syntax is present, taking various encodings into account.\n\n\n**Consequence Note:** Run arbitrary code.\n\n**Consequence Note:** Attackers may be able to obtain sensitive information.\n",
        "parent": [
            "116"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Perform output validation in order to filter/escape/encode unsafe data that is being passed from the server in an HTTP response header.\n\n**Mitigation:** Disable script execution functionality in the clients' browser.\n",
        "languages": []
    },
    {
        "cwe": "645",
        "name": "Overly Restrictive Account Lockout Mechanism",
        "description": "The product contains an account lockout protection mechanism, but the mechanism is too restrictive and can be triggered too easily, which allows attackers to deny service to legitimate users by causing their accounts to be locked out.",
        "detail": "**Extended Description:**\nAccount lockout is a security feature often present in applications as a countermeasure to the brute force attack on the password based authentication mechanism of the system. After a certain number of failed login attempts, the users' account may be disabled for a certain period of time or until it is unlocked by an administrator. Other security events may also possibly trigger account lockout. However, an attacker may use this very security feature to deny service to legitimate system users. It is therefore important to ensure that the account lockout security mechanism is not overly restrictive.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** Users could be locked out of accounts.\n",
        "parent": [
            "287"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** Implement more intelligent password throttling mechanisms such as those which take IP address into account, in addition to the login name.\n\n**Mitigation:** Implement a lockout timeout that grows as the number of incorrect login attempts goes up, eventually resulting in a complete lockout.\n\n**Mitigation:** Consider alternatives to account lockout that would still be effective against password brute force attacks, such as presenting the user machine with a puzzle to solve (makes it do some computation).\n",
        "languages": []
    },
    {
        "cwe": "646",
        "name": "Reliance on File Name or Extension of Externally-Supplied File",
        "description": "The product allows a file to be uploaded, but it relies on the file name or extension of the file to determine the appropriate behaviors. This could be used by attackers to cause the file to be misclassified and processed in a dangerous fashion.",
        "detail": "**Extended Description:**\nAn application might use the file name or extension of a user-supplied file to determine the proper course of action, such as selecting the correct process to which control should be passed, deciding what data should be made available, or what resources should be allocated. If the attacker can cause the code to misclassify the supplied file, then the wrong action could occur. For example, an attacker could supply a file that ends in a \".php.gif\" extension that appears to be a GIF image, but would be processed as PHP code. In extreme cases, code execution is possible, but the attacker could also cause exhaustion of resources, denial of service, exposure of debug or system data (including application source code), or being bound to a particular server side process. This weakness may be due to a vulnerability in any of the technologies used by the web and application servers, due to misconfiguration, or resultant from another flaw in the application itself.\n\n**Consequence Note:** An attacker may be able to read sensitive data.\n\n**Consequence Note:** An attacker may be able to cause a denial of service.\n\n**Consequence Note:** An attacker may be able to gain privileges.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Make decisions on the server side based on file content and not on file name or extension.\n",
        "languages": []
    },
    {
        "cwe": "647",
        "name": "Use of Non-Canonical URL Paths for Authorization Decisions",
        "description": "The product defines policy namespaces and makes authorization decisions based on the assumption that a URL is canonical. This can allow a non-canonical URL to bypass the authorization.",
        "detail": "**Extended Description:**\n\n\nIf an application defines policy namespaces and makes authorization decisions based on the URL, but it does not require or convert to a canonical URL before making the authorization decision, then it opens the application to attack. For example, if the application only wants to allow access to http://www.example.com/mypage, then the attacker might be able to bypass this restriction using equivalent URLs such as:\n\n\n  - http://WWW.EXAMPLE.COM/mypage\n\n  - http://www.example.com/%6Dypage (alternate encoding)\n\n  - http://192.168.1.1/mypage (IP address)\n\n  - http://www.example.com/mypage/ (trailing /)\n\n  - http://www.example.com:80/mypage\n\nTherefore it is important to specify access control policy that is based on the path information in some canonical form with all alternate encodings rejected (which can be accomplished by a default deny rule).\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker may be able to bypass the authorization mechanism to gain access to the otherwise-protected URL.\n\n**Consequence Note:** If a non-canonical URL is used, the server may choose to return the contents of the file, instead of pre-processing the file (e.g. as a program).\n",
        "parent": [
            "863"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Make access control policy based on path information in canonical form. Use very restrictive regular expressions to validate that the path is in the expected form.\n\n**Mitigation:** Reject all alternate path encodings that are not in the expected canonical form.\n",
        "languages": []
    },
    {
        "cwe": "648",
        "name": "Incorrect Use of Privileged APIs",
        "description": "The product does not conform to the API requirements for a function call that requires extra privileges. This could allow attackers to gain privileges by causing the function to be called incorrectly.",
        "detail": "**Extended Description:**\n\n\nWhen a product contains certain functions that perform operations requiring an elevated level of privilege, the caller of a privileged API must be careful to:\n\n\n  - ensure that assumptions made by the APIs are valid, such as validity of arguments\n\n  - account for known weaknesses in the design/implementation of the API\n\n  - call the API from a safe context\n\nIf the caller of the API does not follow these requirements, then it may allow a malicious user or process to elevate their privilege, hijack the process, or steal sensitive data.\n\nFor instance, it is important to know if privileged APIs do not shed their privileges before returning to the caller or if the privileged function might make certain assumptions about the data, context or state information passed to it by the caller. It is important to always know when and how privileged APIs can be called in order to ensure that their elevated level of privilege cannot be exploited.\n\n\n**Consequence Note:** An attacker may be able to elevate privileges.\n\n**Consequence Note:** An attacker may be able to obtain sensitive information.\n\n**Consequence Note:** An attacker may be able to execute code.\n",
        "parent": [
            "269"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Before calling privileged APIs, always ensure that the assumptions made by the privileged code hold true prior to making the call.\n\n**Mitigation:** Know architecture and implementation weaknesses of the privileged APIs and make sure to account for these weaknesses before calling the privileged APIs to ensure that they can be called safely.\n\n**Mitigation:** If privileged APIs make certain assumptions about data, context or state validity that are passed by the caller, the calling code must ensure that these assumptions have been validated prior to making the call.\n\n**Mitigation:** If privileged APIs do not shed their privilege prior to returning to the calling code, then calling code needs to shed these privileges immediately and safely right after the call to the privileged APIs. In particular, the calling code needs to ensure that a privileged thread of execution will never be returned to the user or made available to user-controlled processes.\n\n**Mitigation:** Only call privileged APIs from safe, consistent and expected state.\n\n**Mitigation:** Ensure that a failure or an error will not leave a system in a state where privileges are not properly shed and privilege escalation is possible (i.e. fail securely with regards to handling of privileges).\n",
        "languages": []
    },
    {
        "cwe": "649",
        "name": "Reliance on Obfuscation or Encryption of Security-Relevant Inputs without Integrity Checking",
        "description": "The product uses obfuscation or encryption of inputs that should not be mutable by an external actor, but the product does not use integrity checks to detect if those inputs have been modified.",
        "detail": "**Extended Description:**\nWhen an application relies on obfuscation or incorrectly applied / weak encryption to protect client-controllable tokens or parameters, that may have an effect on the user state, system state, or some decision made on the server. Without protecting the tokens/parameters for integrity, the application is vulnerable to an attack where an adversary traverses the space of possible values of the said token/parameter in order to attempt to gain an advantage. The goal of the attacker is to find another admissible value that will somehow elevate their privileges in the system, disclose information or change the behavior of the system in some way beneficial to the attacker. If the application does not protect these critical tokens/parameters for integrity, it will not be able to determine that these values have been tampered with. Measures that are used to protect data for confidentiality should not be relied upon to provide the integrity service.\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** The inputs could be modified without detection, causing the product to have unexpected system state or make incorrect security decisions.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Protect important client controllable tokens/parameters for integrity using PKI methods (i.e. digital signatures) or other means, and checks for integrity on the server side.\n\n**Mitigation:** Repeated requests from a particular user that include invalid values of tokens/parameters (those that should not be changed manually by users) should result in the user account lockout.\n\n**Mitigation:** Client side tokens/parameters should not be such that it would be easy/predictable to guess another valid state.\n\n**Mitigation:** Obfuscation should not be relied upon. If encryption is used, it needs to be properly applied (i.e. proven algorithm and implementation, use padding, use random initialization vector, user proper encryption mode). Even with proper encryption where the ciphertext does not leak information about the plaintext or reveal its structure, compromising integrity is possible (although less likely) without the provision of the integrity service.\n",
        "languages": []
    },
    {
        "cwe": "65",
        "name": "Windows Hard Link",
        "description": "The product, when opening a file or directory, does not sufficiently handle when the name is associated with a hard link to a target that is outside of the intended control sphere. This could allow an attacker to cause the product to operate on unauthorized files.",
        "detail": "**Extended Description:**\nFailure for a system to check for hard links can result in vulnerability to different types of attacks. For example, an attacker can escalate their privileges if a file used by a privileged program is replaced with a hard link to a sensitive file (e.g. AUTOEXEC.BAT). When the process opens the file, the attacker can assume the privileges of that process, or prevent the program from accurately processing data.\n",
        "parent": [
            "59"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nFollow the principle of least privilege when assigning access rights to entities in a software system.\n\n\nDenying access to a file can prevent an attacker from replacing that file with a link to a sensitive file. Ensure good compartmentalization in the system to provide protected areas that can be trusted.\n\n",
        "languages": []
    },
    {
        "cwe": "650",
        "name": "Trusting HTTP Permission Methods on the Server Side",
        "description": "The server contains a protection mechanism that assumes that any URI that is accessed using HTTP GET will not cause a state change to the associated resource. This might allow attackers to bypass intended access restrictions and conduct resource modification and deletion attacks, since some applications allow GET to modify state.",
        "detail": "**Extended Description:**\nThe HTTP GET method and some other methods are designed to retrieve resources and not to alter the state of the application or resources on the server side. Furthermore, the HTTP specification requires that GET requests (and other requests) should not have side effects. Believing that it will be enough to prevent unintended resource alterations, an application may disallow the HTTP requests to perform DELETE, PUT and POST operations on the resource representation. However, there is nothing in the HTTP protocol itself that actually prevents the HTTP GET method from performing more than just query of the data. Developers can easily code programs that accept a HTTP GET request that do in fact create, update or delete data on the server. For instance, it is a common practice with REST based Web Services to have HTTP GET requests modifying resources on the server side. However, whenever that happens, the access control needs to be properly enforced in the application. No assumptions should be made that only HTTP DELETE, PUT, POST, and other methods have the power to alter the representation of the resource being accessed in the request.\n\n**Consequence Note:** An attacker could escalate privileges.\n\n**Consequence Note:** An attacker could modify resources.\n\n**Consequence Note:** An attacker could obtain sensitive information.\n",
        "parent": [
            "436"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Configure ACLs on the server side to ensure that proper level of access control is defined for each accessible resource representation.\n",
        "languages": []
    },
    {
        "cwe": "651",
        "name": "Exposure of WSDL File Containing Sensitive Information",
        "description": "The Web services architecture may require exposing a Web Service Definition Language (WSDL) file that contains information on the publicly accessible services and how callers of these services should interact with them (e.g. what parameters they expect and what types they return).",
        "detail": "**Extended Description:**\n\n\nAn information exposure may occur if any of the following apply:\n\n\n  - The WSDL file is accessible to a wider audience than intended.\n\n  - The WSDL file contains information on the methods/services that should not be publicly accessible or information about deprecated methods. This problem is made more likely due to the WSDL often being automatically generated from the code.\n\n  - Information in the WSDL file helps guess names/locations of methods/resources that should not be publicly accessible.\n\n\n\n**Consequence Note:** The attacker may find sensitive information located in the WSDL file.\n",
        "parent": [
            "538"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Limit access to the WSDL file as much as possible. If services are provided only to a limited number of entities, it may be better to provide WSDL privately to each of these entities than to publish WSDL publicly.\n\n**Mitigation:** Make sure that WSDL does not describe methods that should not be publicly accessible. Make sure to protect service methods that should not be publicly accessible with access controls.\n\n**Mitigation:** Do not use method names in WSDL that might help an adversary guess names of private methods/resources used by the service.\n",
        "languages": []
    },
    {
        "cwe": "652",
        "name": "Improper Neutralization of Data within XQuery Expressions ('XQuery Injection')",
        "description": "The product uses external input to dynamically construct an XQuery expression used to retrieve data from an XML database, but it does not neutralize or incorrectly neutralizes that input. This allows an attacker to control the structure of the query.",
        "detail": "**Extended Description:**\nThe net effect is that the attacker will have control over the information selected from the XML database and may use that ability to control application flow, modify logic, retrieve unauthorized data, or bypass important checks (e.g. authentication).\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker might be able to read sensitive information from the XML database.\n",
        "parent": [
            "91",
            "943"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Use parameterized queries. This will help ensure separation between data plane and control plane.\n\n**Mitigation:** Properly validate user input. Reject data where appropriate, filter where appropriate and escape where appropriate. Make sure input that will be used in XQL queries is safe in that context.\n",
        "languages": []
    },
    {
        "cwe": "653",
        "name": "Improper Isolation or Compartmentalization",
        "description": "The product does not properly compartmentalize or isolate functionality, processes, or resources that require different privilege levels, rights, or permissions.",
        "detail": "**Extended Description:**\nWhen a weakness occurs in functionality that is accessible by lower-privileged users, then without strong boundaries, an attack might extend the scope of the damage to higher-privileged users.\n\n**Alternate Terms:** Separation of Privilege\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** The exploitation of a weakness in low-privileged areas of the software can be leveraged to reach higher-privileged areas without having to overcome any additional obstacles.\n",
        "parent": [
            "657",
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tCompare binary / bytecode to application permission manifest\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAttack Modeling\n\n**Mitigation:** Break up privileges between different modules, objects, or entities. Minimize the interfaces between modules and require strong access control between them.\n",
        "languages": []
    },
    {
        "cwe": "654",
        "name": "Reliance on a Single Factor in a Security Decision",
        "description": "A protection mechanism relies exclusively, or to a large extent, on the evaluation of a single condition or the integrity of a single object or entity in order to make a decision about granting access to restricted resources or functionality.",
        "detail": "**Alternate Terms:** Separation of Privilege\n\n**Consequence Note:** If the single factor is compromised (e.g. by theft or spoofing), then the integrity of the entire security mechanism can be violated with respect to the user that is identified by that factor.\n\n**Consequence Note:** It can become difficult or impossible for the product to be able to distinguish between legitimate activities by the entity who provided the factor, versus illegitimate activities by an attacker.\n",
        "parent": [
            "657",
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Use multiple simultaneous checks before granting access to critical operations or granting critical privileges. A weaker but helpful mitigation is to use several successive checks (multiple layers of security).\n\n**Mitigation:** Use redundant access rules on different choke points (e.g., firewalls).\n",
        "languages": []
    },
    {
        "cwe": "655",
        "name": "Insufficient Psychological Acceptability",
        "description": "The product has a protection mechanism that is too difficult or inconvenient to use, encouraging non-malicious users to disable or bypass the mechanism, whether by accident or on purpose.",
        "detail": "**Consequence Note:** By bypassing the security mechanism, a user might leave the system in a less secure state than intended by the administrator, making it more susceptible to compromise.\n",
        "parent": [
            "657",
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Where possible, perform human factors and usability studies to identify where your product's security mechanisms are difficult to use, and why.\n\n**Mitigation:** Make the security mechanism as seamless as possible, while also providing the user with sufficient details when a security decision produces unexpected results.\n",
        "languages": []
    },
    {
        "cwe": "656",
        "name": "Reliance on Security Through Obscurity",
        "description": "The product uses a protection mechanism whose strength depends heavily on its obscurity, such that knowledge of its algorithms or key data is sufficient to defeat the mechanism.",
        "detail": "**Extended Description:**\nThis reliance on \"security through obscurity\" can produce resultant weaknesses if an attacker is able to reverse engineer the inner workings of the mechanism. Note that obscurity can be one small part of defense in depth, since it can create more work for an attacker; however, it is a significant risk if used as the primary means of protection.\n\n**Alternate Terms:** Never Assuming your secrets are safe\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** The security mechanism can be bypassed easily.\n",
        "parent": [
            "657",
            "693"
        ],
        "children": [],
        "related": [
            "259",
            "321",
            "472",
            "603"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Always consider whether knowledge of your code or design is sufficient to break it. Reverse engineering is a highly successful discipline, and financially feasible for motivated adversaries. Black-box techniques are established for binary analysis of executables that use obfuscation, runtime analysis of proprietary protocols, inferring file formats, and others.\n\n**Mitigation:** When available, use publicly-vetted algorithms and procedures, as these are more likely to undergo more extensive security analysis and testing. This is especially the case with encryption and authentication.\n",
        "languages": []
    },
    {
        "cwe": "657",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "653",
            "654",
            "656"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "66",
        "name": "Improper Handling of File Names that Identify Virtual Resources",
        "description": "The product does not handle or incorrectly handles a file name that identifies a \"virtual\" resource that is not directly specified within the directory that is associated with the file name, causing the product to perform file-based operations on a resource that is not a file.",
        "detail": "**Extended Description:**\nVirtual file names are represented like normal file names, but they are effectively aliases for other resources that do not behave like normal files. Depending on their functionality, they could be alternate entities. They are not necessarily listed in directories.\n",
        "parent": [
            "706"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n",
        "languages": []
    },
    {
        "cwe": "662",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1058",
            "366",
            "663",
            "764",
            "820",
            "821",
            "833"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "663",
        "name": "Use of a Non-reentrant Function in a Concurrent Context",
        "description": "The product calls a non-reentrant function in a concurrent context in which a competing code sequence (e.g. thread or signal handler) may have an opportunity to call the same function or otherwise influence its state.",
        "detail": null,
        "parent": [
            "662"
        ],
        "children": [],
        "related": [
            "1265"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use reentrant functions if available.\n\n**Mitigation:** Add synchronization to your non-reentrant function.\n\n**Mitigation:** In Java, use the ReentrantLock Class.\n",
        "languages": []
    },
    {
        "cwe": "664",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "487",
            "501",
            "580",
            "911"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "665",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1188",
            "770",
            "908",
            "909"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "666",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "605",
            "826"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "667",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "609",
            "764",
            "765",
            "832",
            "833"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "668",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "375",
            "488",
            "524",
            "767"
        ],
        "related": [
            "22"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "669",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "212",
            "243",
            "494",
            "829"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "67",
        "name": "Improper Handling of Windows Device Names",
        "description": "The product constructs pathnames from user input, but it does not handle or incorrectly handles a pathname containing a Windows device name such as AUX or CON. This typically leads to denial of service or an information exposure when the application attempts to process the pathname as a regular file.",
        "detail": "**Extended Description:**\nNot properly handling virtual filenames (e.g. AUX, CON, PRN, COM1, LPT1) can result in different types of vulnerabilities. In some cases an attacker can request a device via injection of a virtual filename in a URL, which may cause an error that leads to a denial of service or an error page that reveals sensitive information. A product that allows device names to bypass filtering runs the risk of an attacker injecting malicious code in a file with the name of a device.\n\n**Background Details:**\n['Historically, there was a bug in the Windows operating system that caused a blue screen of death. Even after that issue was fixed DOS device names continue to be a factor.']\n",
        "parent": [
            "66"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Be familiar with the device names in the operating system where your system is deployed. Check input for these device names.\n",
        "languages": []
    },
    {
        "cwe": "670",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "480",
            "483",
            "484",
            "617",
            "698",
            "783"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "671",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "447",
            "798"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "672",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "613",
            "825",
            "910"
        ],
        "related": [
            "826",
            "911"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "673",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "426"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "674",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "776"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "675",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "605",
            "764",
            "765"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "676",
        "name": "Use of Potentially Dangerous Function",
        "description": "The product invokes a potentially dangerous function that could introduce a vulnerability if it is used incorrectly, but the function can also be used safely.",
        "detail": "**Consequence Note:** If the function is used incorrectly, then it could result in security problems.\n",
        "parent": [
            "1177"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode Quality Analysis\n\t\tBinary / Bytecode simple extractor - strings, ELF readers, etc.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tDebugger\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tMonitored Virtual Environment - run potentially malicious code in sandbox / wrapper / virtual machine, see if it does anything suspicious\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWarning Flags\n\t\tSource Code Quality Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tOrigin Analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** Identify a list of prohibited API functions and prohibit developers from using these functions, providing safer alternatives. In some cases, automatic code analysis tools or the compiler can be instructed to spot use of prohibited functions, such as the \"banned.h\" include file from Microsoft's SDL. [REF-554] [REF-7]\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "680",
        "name": "Integer Overflow to Buffer Overflow",
        "description": "The product performs a calculation to determine how much memory to allocate, but an integer overflow can occur that causes less memory to be allocated than expected, leading to a buffer overflow.",
        "detail": null,
        "parent": [
            "190"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "681",
        "name": "Incorrect Conversion between Numeric Types",
        "description": "When converting from one data type to another, such as long to integer, data can be omitted or translated in a way that produces unexpected values. If the resulting values are used in a sensitive context, then dangerous behaviors may occur.",
        "detail": "**Consequence Note:** The program could wind up using the wrong number and generate incorrect results. If the number is used to allocate resources or make a security decision, then this could introduce a vulnerability.\n",
        "parent": [
            "704"
        ],
        "children": [],
        "related": [
            "682"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Avoid making conversion between numeric types. Always check for the allowed ranges.\n",
        "languages": [
            "C"
        ]
    },
    {
        "cwe": "682",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "128",
            "131"
        ],
        "related": [
            "681"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "683",
        "name": "Function Call With Incorrect Order of Arguments",
        "description": "The product calls a function, procedure, or routine, but the caller specifies the arguments in an incorrect order, leading to resultant weaknesses.",
        "detail": "**Extended Description:**\nWhile this weakness might be caught by the compiler in some languages, it can occur more frequently in cases in which the called function accepts variable numbers or types of arguments, such as format strings in C. It also can occur in languages or environments that do not enforce strong typing.\n\n**Mode of Introduction:** This problem typically occurs when the programmer makes a typo, or copy and paste errors.\n",
        "parent": [
            "628"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Use the function, procedure, or routine as specified.\n\n**Mitigation:** Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.\n",
        "languages": []
    },
    {
        "cwe": "684",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "393",
            "440"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "685",
        "name": "Function Call With Incorrect Number of Arguments",
        "description": "The product calls a function, procedure, or routine, but the caller specifies too many arguments, or too few arguments, which may lead to undefined behavior and resultant weaknesses.",
        "detail": "**Mode of Introduction:** This problem typically occurs when the programmer makes a typo, or copy and paste errors.\n",
        "parent": [
            "628"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** While this weakness might be caught by the compiler in some languages, it can occur more frequently in cases in which the called function accepts variable numbers of arguments, such as format strings in C. It also can occur in languages or environments that do not require that functions always be called with the correct number of arguments, such as Perl.\n\n**Mitigation:** Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.\n",
        "languages": [
            "C",
            "Perl"
        ]
    },
    {
        "cwe": "686",
        "name": "Function Call With Incorrect Argument Type",
        "description": "The product calls a function, procedure, or routine, but the caller specifies an argument that is the wrong data type, which may lead to resultant weaknesses.",
        "detail": "**Extended Description:**\nThis weakness is most likely to occur in loosely typed languages, or in strongly typed languages in which the types of variable arguments cannot be enforced at compilation time, or where there is implicit casting.\n",
        "parent": [
            "628"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.\n",
        "languages": []
    },
    {
        "cwe": "687",
        "name": "Function Call With Incorrectly Specified Argument Value",
        "description": "The product calls a function, procedure, or routine, but the caller specifies an argument that contains the wrong value, which may lead to resultant weaknesses.",
        "detail": null,
        "parent": [
            "628"
        ],
        "children": [
            "560"
        ],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** This might require an understanding of intended program behavior or design to determine whether the value is incorrect.\n",
        "languages": []
    },
    {
        "cwe": "688",
        "name": "Function Call With Incorrect Variable or Reference as Argument",
        "description": "The product calls a function, procedure, or routine, but the caller specifies the wrong variable or reference as one of the arguments, which may lead to undefined behavior and resultant weaknesses.",
        "detail": "**Mode of Introduction:** This problem typically occurs when the programmer makes a typo, or copy and paste errors.\n",
        "parent": [
            "628"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** While this weakness might be caught by the compiler in some languages, it can occur more frequently in cases in which the called function accepts variable numbers of arguments, such as format strings in C. It also can occur in loosely typed languages or environments. This might require an understanding of intended program behavior or design to determine whether the value is incorrect.\n\n**Mitigation:** Because this function call often produces incorrect behavior it will usually be detected during testing or normal operation of the product. During testing exercise all possible control paths will typically expose this weakness except in rare cases when the incorrect function call accidentally produces the correct results or if the provided argument type is very similar to the expected argument type.\n",
        "languages": [
            "C",
            "Perl"
        ]
    },
    {
        "cwe": "689",
        "name": "Permission Race Condition During Resource Copy",
        "description": "The product, while copying or cloning a resource, does not set the resource's permissions or access control until the copy is complete, leaving the resource exposed to other spheres while the copy is taking place.",
        "detail": "**Mode of Introduction:** \n\nCommon examples occur in file archive extraction, in which the product begins the extraction with insecure default permissions, then only sets the final permissions (as specified in the archive) once the copy is complete. The larger the archive, the larger the timing window for the race condition.\n\n\nThis weakness has also occurred in some operating system utilities that perform copies of deeply nested directories containing a large number of files.\n\n\nThis weakness can occur in any type of functionality that involves copying objects or resources in a multi-user environment, including at the application level. For example, a document management system might allow a user to copy a private document, but if it does not set the new copy to be private as soon as the copy begins, then other users might be able to view the document while the copy is still taking place.\n\n",
        "parent": [
            "362"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": [
            "C",
            "Perl"
        ]
    },
    {
        "cwe": "69",
        "name": "Improper Handling of Windows ::DATA Alternate Data Stream",
        "description": "The product does not properly prevent access to, or detect usage of, alternate data streams (ADS).",
        "detail": "**Extended Description:**\nAn attacker can use an ADS to hide information about a file (e.g. size, the name of the process) from a system or file browser tools such as Windows Explorer and 'dir' at the command line utility. Alternately, the attacker might be able to bypass intended access restrictions for the associated data fork.\n\n**Background Details:**\n['Alternate data streams (ADS) were first implemented in the Windows NT operating system to provide compatibility between NTFS and the Macintosh Hierarchical File System (HFS). In HFS, data and resource forks are used to store information about a file. The data fork provides information about the contents of the file while the resource fork stores metadata such as file type.']\n",
        "parent": [
            "66"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Software tools are capable of finding ADSs on your system.\n\n**Mitigation:** Ensure that the source code correctly parses the filename to read or write to the correct stream.\n",
        "languages": []
    },
    {
        "cwe": "690",
        "name": "Unchecked Return Value to NULL Pointer Dereference",
        "description": "The product does not check for an error after calling a function that can return with a NULL pointer if the function fails, which leads to a resultant NULL pointer dereference.",
        "detail": "**Extended Description:**\nWhile unchecked return value weaknesses are not limited to returns of NULL pointers (see the examples in CWE-252), functions often return NULL to indicate an error status. When this error condition is not checked, a NULL pointer dereference can occur.\n\n**Mode of Introduction:** A typical occurrence of this weakness occurs when an application includes user-controlled input to a malloc() call. The related code might be correct with respect to preventing buffer overflows, but if a large value is provided, the malloc() will fail due to insufficient memory. This problem also frequently occurs when a parsing routine expects that certain elements will always be present. If malformed input is provided, the parser might return NULL. For example, strtok() can return NULL.\n\n**Consequence Note:** In rare circumstances, when NULL is equivalent to the 0x0 memory address and privileged code can access it, then writing or reading memory is possible, which may lead to code execution.\n",
        "parent": [
            "252"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** This typically occurs in rarely-triggered error conditions, reducing the chances of detection during black box testing.\n\n**Detection:** Code analysis can require knowledge of API behaviors for library functions that might return NULL, reducing the chances of detection when unknown libraries are used.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "691",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1265",
            "841"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "692",
        "name": "Incomplete Denylist to Cross-Site Scripting",
        "description": "The product uses a denylist-based protection mechanism to defend against XSS attacks, but the denylist is incomplete, allowing XSS variants to succeed.",
        "detail": "**Extended Description:**\nWhile XSS might seem simple to prevent, web browsers vary so widely in how they parse web pages, that a denylist cannot keep track of all the variations. The \"XSS Cheat Sheet\" [REF-714] contains a large number of attacks that are intended to bypass incomplete denylists.\n",
        "parent": [
            "184"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "693",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "653",
            "654",
            "656",
            "807"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "694",
        "name": "Use of Multiple Resources with Duplicate Identifier",
        "description": "The product uses multiple resources that can have the same identifier, in a context in which unique identifiers are required.",
        "detail": "**Extended Description:**\nIf the product assumes that each resource has a unique identifier, the product could operate on the wrong resource if attackers can cause multiple resources to be associated with the same identifier.\n\n**Consequence Note:** If unique identifiers are assumed when protecting sensitive resources, then duplicate identifiers might allow attackers to bypass the protection.\n",
        "parent": [
            "573",
            "99"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Where possible, use unique identifiers. If non-unique identifiers are detected, then do not operate any resource with a non-unique identifier and report the error appropriately.\n",
        "languages": []
    },
    {
        "cwe": "695",
        "name": "Use of Low-Level Functionality",
        "description": "The product uses low-level functionality that is explicitly prohibited by the framework or specification under which the product is supposed to operate.",
        "detail": "**Extended Description:**\nThe use of low-level functionality can violate the specification in unexpected ways that effectively disable built-in protection mechanisms, introduce exploitable inconsistencies, or otherwise expose the functionality to attack.\n",
        "parent": [
            "573"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "696",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "179"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "697",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "581"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "698",
        "name": "Execution After Redirect (EAR)",
        "description": "The web application sends a redirect to another location, but instead of exiting, it executes additional code.",
        "detail": "**Alternate Terms:** Redirect Without Exit\n\n**Consequence Note:** This weakness could affect the control flow of the application and allow execution of untrusted code.\n",
        "parent": [
            "670",
            "705"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** This issue might not be detected if testing is performed using a web browser, because the browser might obey the redirect and move the user to a different page before the application has produced outputs that indicate something is amiss.\n",
        "languages": []
    },
    {
        "cwe": "7",
        "name": "J2EE Misconfiguration: Missing Custom Error Page",
        "description": "The default error page of a web application should not display sensitive information about the product.",
        "detail": "**Extended Description:**\n\n\nA Web application must define a default error page for 4xx errors (e.g. 404), 5xx (e.g. 500) errors and catch java.lang.Throwable exceptions to prevent attackers from mining information from the application container's built-in error response.\n\n\nWhen an attacker explores a web site looking for vulnerabilities, the amount of information that the site provides is crucial to the eventual success or failure of any attempted attacks.\n\n\n**Consequence Note:** A stack trace might show the attacker a malformed SQL query string, the type of database being used, and the version of the application container. This information enables the attacker to target known vulnerabilities in these components.\n",
        "parent": [
            "756"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Handle exceptions appropriately in source code.\n\n**Mitigation:** Always define appropriate error pages. The application configuration should specify a default error page in order to guarantee that the application will never leak error messages to an attacker. Handling standard HTTP error codes is useful and user-friendly in addition to being a good security practice, and a good configuration will also define a last-chance error handler that catches any exception that could possibly be thrown by the application.\n\n**Mitigation:** Do not attempt to process an error or attempt to mask it.\n\n**Mitigation:** Verify return values are correct and do not supply sensitive information about the system.\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "703",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "248",
            "393",
            "397"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "704",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1389",
            "681",
            "843"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "705",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "248",
            "395",
            "396",
            "397",
            "584",
            "698"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "706",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "178",
            "22",
            "386",
            "59",
            "66"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "707",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "170"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "708",
        "name": "Incorrect Ownership Assignment",
        "description": "The product assigns an owner to a resource, but the owner is outside of the intended control sphere.",
        "detail": "**Extended Description:**\nThis may allow the resource to be manipulated by actors outside of the intended control sphere.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could read and modify data for which they do not have permissions to access directly.\n",
        "parent": [
            "282"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Periodically review the privileges and their owners.\n\n**Mitigation:** Use automated tools to check for privilege settings.\n",
        "languages": []
    },
    {
        "cwe": "710",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1126",
            "1127",
            "476",
            "477",
            "484",
            "489"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "72",
        "name": "Improper Handling of Apple HFS+ Alternate Data Stream Path",
        "description": "The product does not properly handle special paths that may identify the data or resource fork of a file on the HFS+ file system.",
        "detail": "**Extended Description:**\nIf the product chooses actions to take based on the file name, then if an attacker provides the data or resource fork, the product may take unexpected actions. Further, if the product intends to restrict access to a file, then an attacker might still be able to bypass intended access restrictions by requesting the data or resource fork for that file.\n\n**Background Details:**\n['\\n\\nThe Apple HFS+ file system permits files to have multiple data input streams, accessible through special paths. The Mac OS X operating system provides a way to access the different data input streams through special paths and as an extended attribute:\\n\\n```\\n\\t\\t- Resource fork: file/..namedfork/rsrc, file/rsrc (deprecated), xattr:com.apple.ResourceFork\\n\\t\\t- Data fork: file/..namedfork/data (only versions prior to Mac OS X v10.5)\\n```\\nAdditionally, on filesystems that lack native support for multiple streams, the resource fork and file metadata may be stored in a file with \"._\" prepended to the name.\\n\\nForks can also be accessed through non-portable APIs.\\n\\n\\nForks inherit the file system access controls of the file they belong to.\\n\\n\\nPrograms need to control access to these paths, if the processing of a file system object is dependent on the structure of its path.\\n']\n",
        "parent": [
            "66"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "73",
        "name": "External Control of File Name or Path",
        "description": "The product allows user input to control or influence paths or file names that are used in filesystem operations.",
        "detail": "**Extended Description:**\n\n\nThis could allow an attacker to access or modify system files or other files that are critical to the application.\n\n\nPath manipulation errors occur when the following two conditions are met:\n\n```\n\t\t1. An attacker can specify a path used in an operation on the filesystem.\n\t\t2. By specifying the resource, the attacker gains a capability that would not otherwise be permitted.\n```\nFor example, the program may give the attacker the ability to overwrite the specified file or run with a configuration controlled by the attacker.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** The application can operate on unexpected files. Confidentiality is violated when the targeted filename is not directly readable by the attacker.\n\n**Consequence Note:** The application can operate on unexpected files. This may violate integrity if the filename is written to, or if the filename is for a program or other form of executable code.\n\n**Consequence Note:** The application can operate on unexpected files. Availability can be violated if the attacker specifies an unexpected file that the application modifies. Availability can also be affected if the attacker specifies a filename for a large file, or points to a special device or a file that does not have the format that the application expects.\n",
        "parent": [
            "20",
            "610",
            "642"
        ],
        "children": [],
        "related": [
            "22",
            "41",
            "434",
            "59",
            "98"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nThe external control or influence of filenames can often be detected using automated static analysis that models data flow within the product.\n\n\nAutomated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or require any code changes.\n\n\n**Mitigation:** When the set of filenames is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames, and reject all other inputs. For example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\". Features such as the ESAPI AccessReferenceMap provide this capability.\n\n**Mitigation:** \n\nRun your code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict all access to files within a particular directory.\n\n\nExamples include the Unix chroot jail and AppArmor. In general, managed code may provide some protection.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of your application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** Use a built-in path canonicalization function (such as realpath() in C) that produces the canonical version of the pathname, which effectively removes \"..\" sequences and symbolic links (CWE-23, CWE-59).\n\n**Mitigation:** Use OS-level permissions and run as a low-privileged user to limit the scope of any successful attack.\n\n**Mitigation:** If you are using PHP, configure your application so that it does not use register_globals. During implementation, develop your application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n\n**Mitigation:** Use tools and techniques that require manual (human) analysis, such as penetration testing, threat modeling, and interactive tools that allow the tester to record and modify an active session. These may be more effective than strictly automated techniques. This is especially the case with weaknesses that are related to design and business rules.\n",
        "languages": []
    },
    {
        "cwe": "732",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "277",
            "278",
            "279",
            "281",
            "766"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "733",
        "name": "Compiler Optimization Removal or Modification of Security-critical Code",
        "description": "The developer builds a security-critical protection mechanism into the software, but the compiler optimizes the program such that the mechanism is removed or modified.",
        "detail": null,
        "parent": [
            "1038"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** This specific weakness is impossible to detect using black box methods. While an analyst could examine memory to see that it has not been scrubbed, an analysis of the executable would not be successful. This is because the compiler has already removed the relevant code. Only the source code shows whether the programmer intended to clear the memory or not, so this weakness is indistinguishable from others.\n\n**Detection:** This weakness is only detectable using white box methods (see black box detection factor). Careful analysis is required to determine if the code is likely to be removed by the compiler.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "74",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "78",
            "79",
            "88",
            "89",
            "91",
            "917",
            "93",
            "94"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "749",
        "name": "Exposed Dangerous Method or Function",
        "description": "The product provides an Applications Programming Interface (API) or similar interface for interaction with external actors, but the interface includes a dangerous method or function that is not properly restricted.",
        "detail": "**Extended Description:**\n\n\nThis weakness can lead to a wide variety of resultant weaknesses, depending on the behavior of the exposed method. It can apply to any number of technologies and approaches, such as ActiveX controls, Java functions, IOCTLs, and so on.\n\n\nThe exposure can occur in a few different ways:\n\n\n  - The function/method was never intended to be exposed to outside actors.\n\n  - The function/method was only intended to be accessible to a limited set of actors, such as Internet-based access from a single web site.\n\n\n\n**Consequence Note:** Exposing critical functionality essentially provides an attacker with the privilege level of the exposed functionality. This could result in the modification or exposure of sensitive data or possibly even execution of arbitrary code.\n",
        "parent": [
            "284"
        ],
        "children": [
            "618"
        ],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If you must expose a method, make sure to perform input validation on all arguments, limit access to authorized parties, and protect against all possible vulnerabilities.\n\n**Mitigation:** \n\nIdentify all exposed functionality. Explicitly list all functionality that must be exposed to some user or set of users. Identify which functionality may be:\n\n\n  - accessible to all users\n\n  - restricted to a small set of privileged users\n\n  - prevented from being directly accessible at all\n\nEnsure that the implemented code follows these expectations. This includes setting the appropriate access modifiers where applicable (public, private, protected, etc.) or not marking ActiveX controls safe-for-scripting.\n",
        "languages": []
    },
    {
        "cwe": "75",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "76"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "754",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "394",
            "476"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "755",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "209",
            "248",
            "280",
            "395",
            "396",
            "544",
            "756"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "756",
        "name": "Missing Custom Error Page",
        "description": "The product does not return custom error pages to the user, possibly exposing sensitive information.",
        "detail": "**Consequence Note:** Attackers can leverage the additional information provided by a default error page to mount attacks targeted on the framework, database, or other resources used by the application.\n",
        "parent": [
            "755"
        ],
        "children": [],
        "related": [
            "209"
        ],
        "scopes": [
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "757",
        "name": "Selection of Less-Secure Algorithm During Negotiation ('Algorithm Downgrade')",
        "description": "A protocol or its implementation supports interaction between multiple actors and allows those actors to negotiate which algorithm should be used as a protection mechanism such as encryption or authentication, but it does not select the strongest algorithm that is available to both parties.",
        "detail": "**Extended Description:**\nWhen a security mechanism can be forced to downgrade to use a less secure algorithm, this can make it easier for attackers to compromise the product by exploiting weaker algorithm. The victim might not be aware that the less secure algorithm is being used. For example, if an attacker can force a communications channel to use cleartext instead of strongly-encrypted data, then the attacker could read the channel by sniffing, instead of going through extra effort of trying to decrypt the data using brute force techniques.\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [
            "1328"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "758",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1102",
            "474",
            "587"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "759",
        "name": "Use of a One-Way Hash without a Salt",
        "description": "The product uses a one-way cryptographic hash against an input that should not be reversible, such as a password, but the product does not also use a salt as part of the input.",
        "detail": "**Extended Description:**\n\n\nThis makes it easier for attackers to pre-compute the hash value using dictionary attack techniques such as rainbow tables.\n\n\nIt should be noted that, despite common perceptions, the use of a good salt with a hash does not sufficiently increase the effort for an attacker who is targeting an individual password, or who has a large amount of computing resources available, such as with cloud-based services or specialized, inexpensive hardware. Offline password cracking can still be effective if the hash function is not expensive to compute; many cryptographic functions are designed to be efficient and can be vulnerable to attacks using massive computing resources, even if the hash is cryptographically strong. The use of a salt only slightly increases the computing requirements for an attacker compared to other strategies such as adaptive hash functions. See CWE-916 for more details.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Background Details:**\n['In cryptography, salt refers to some random addition of data to an input before hashing to make dictionary attacks more difficult.']\n\n**Consequence Note:** If an attacker can gain access to the hashes, then the lack of a salt makes it easier to conduct brute force attacks using techniques such as rainbow tables.\n",
        "parent": [
            "916"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tConfiguration Checker\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** \n\nUse an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n\n\nSome hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n\n\nNote that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.\n\n\n**Mitigation:** If a technique that requires extra computational effort can not be implemented, then for each password that is processed, generate a new random salt using a strong random number generator with unpredictable seeds. Add the salt to the plaintext password before hashing it. When storing the hash, also store the salt. Do not use the same salt for every password.\n\n**Effectiveness:** Be aware that salts will not reduce the workload of a targeted attack against an individual hash (such as the password for a critical person), and in general they are less effective than other hashing techniques such as increasing the computation time or memory overhead. Without a built-in workload, modern attacks can compute large numbers of hashes, or even exhaust the entire space of all possible passwords, within a very short amount of time, using massively-parallel computing and GPU, ASIC, or FPGA hardware.\n\n**Mitigation:** When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.\n",
        "languages": []
    },
    {
        "cwe": "76",
        "name": "Improper Neutralization of Equivalent Special Elements",
        "description": "The product correctly neutralizes certain special elements, but it improperly neutralizes equivalent special elements.",
        "detail": "**Extended Description:**\nThe product may have a fixed list of special characters it believes is complete. However, there may be alternate encodings, or representations that also have the same meaning. For example, the product may filter out a leading slash (/) to prevent absolute path names, but does not account for a tilde (~) followed by a user name, which on some *nix systems could be expanded to an absolute pathname. Alternately, the product might filter a dangerous \"-e\" command-line switch when calling an external program, but it might not account for \"--exec\" or other switches that have the same semantics.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "75"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Programming languages and supporting technologies might be chosen which are not subject to these issues.\n\n**Mitigation:** Utilize an appropriate mix of allowlist and denylist parsing to filter equivalent special element syntax from all input.\n",
        "languages": []
    },
    {
        "cwe": "760",
        "name": "Use of a One-Way Hash with a Predictable Salt",
        "description": "The product uses a one-way cryptographic hash against an input that should not be reversible, such as a password, but the product uses a predictable salt as part of the input.",
        "detail": "**Extended Description:**\n\n\nThis makes it easier for attackers to pre-compute the hash value using dictionary attack techniques such as rainbow tables, effectively disabling the protection that an unpredictable salt would provide.\n\n\nIt should be noted that, despite common perceptions, the use of a good salt with a hash does not sufficiently increase the effort for an attacker who is targeting an individual password, or who has a large amount of computing resources available, such as with cloud-based services or specialized, inexpensive hardware. Offline password cracking can still be effective if the hash function is not expensive to compute; many cryptographic functions are designed to be efficient and can be vulnerable to attacks using massive computing resources, even if the hash is cryptographically strong. The use of a salt only slightly increases the computing requirements for an attacker compared to other strategies such as adaptive hash functions. See CWE-916 for more details.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Background Details:**\n['In cryptography, salt refers to some random addition of data to an input before hashing to make dictionary attacks more difficult.']\n",
        "parent": [
            "916"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nUse an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n\n\nSome hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n\n\nNote that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.\n\n\n**Mitigation:** If a technique that requires extra computational effort can not be implemented, then for each password that is processed, generate a new random salt using a strong random number generator with unpredictable seeds. Add the salt to the plaintext password before hashing it. When storing the hash, also store the salt. Do not use the same salt for every password.\n\n**Effectiveness:** Be aware that salts will not reduce the workload of a targeted attack against an individual hash (such as the password for a critical person), and in general they are less effective than other hashing techniques such as increasing the computation time or memory overhead. Without a built-in workload, modern attacks can compute large numbers of hashes, or even exhaust the entire space of all possible passwords, within a very short amount of time, using massively-parallel computing and GPU, ASIC, or FPGA hardware.\n",
        "languages": []
    },
    {
        "cwe": "761",
        "name": "Free of Pointer not at Start of Buffer",
        "description": "The product calls free() on a pointer to a memory resource that was allocated on the heap, but the pointer is not at the start of the buffer.",
        "detail": "**Extended Description:**\n\n\nThis can cause the product to crash, or in some cases, modify critical program variables or execute code.\n\n\nThis weakness often occurs when the memory is allocated explicitly on the heap with one of the malloc() family functions and free() is called, but pointer arithmetic has caused the pointer to be in the interior or end of the buffer.\n\n",
        "parent": [
            "404",
            "763"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** When utilizing pointer arithmetic to traverse a buffer, use a separate variable to track progress through memory and preserve the originally allocated address for later freeing.\n\n**Mitigation:** When programming in C++, consider using smart pointers provided by the boost library to help correctly and consistently manage memory.\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, glibc in Linux provides protection against free of invalid pointers.\n\n\n**Mitigation:** Use a language that provides abstractions for memory allocation and deallocation.\n\n**Mitigation:** Use a tool that dynamically detects memory management problems, such as valgrind.\n",
        "languages": []
    },
    {
        "cwe": "762",
        "name": "Mismatched Memory Management Routines",
        "description": "The product attempts to return a memory resource to the system, but it calls a release function that is not compatible with the function that was originally used to allocate that resource.",
        "detail": "**Extended Description:**\n\n\nThis weakness can be generally described as mismatching memory management routines, such as:\n\n\n  - The memory was allocated on the stack (automatically), but it was deallocated using the memory management routine free() (CWE-590), which is intended for explicitly allocated heap memory.\n\n  - The memory was allocated explicitly using one set of memory management functions, and deallocated using a different set. For example, memory might be allocated with malloc() in C++ instead of the new operator, and then deallocated with the delete operator.\n\nWhen the memory management functions are mismatched, the consequences may be as severe as code execution, memory corruption, or program crash. Consequences and ease of exploit will vary depending on the implementation of the routines and the object being managed.\n",
        "parent": [
            "404",
            "763"
        ],
        "children": [
            "590"
        ],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Only call matching memory management functions. Do not mix and match routines. For example, when you allocate a buffer with malloc(), dispose of the original pointer with free().\n\n**Mitigation:** \n\nChoose a language or tool that provides automatic memory management, or makes manual memory management less error-prone.\n\n\nFor example, glibc in Linux provides protection against free of invalid pointers.\n\n\nWhen using Xcode to target OS X or iOS, enable automatic reference counting (ARC) [REF-391].\n\n\nTo help correctly and consistently manage memory when programming in C++, consider using a smart pointer class such as std::auto_ptr (defined by ISO/IEC ISO/IEC 14882:2003), std::shared_ptr and std::unique_ptr (specified by an upcoming revision of the C++ standard, informally referred to as C++ 1x), or equivalent solutions such as Boost.\n\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, glibc in Linux provides protection against free of invalid pointers.\n\n\n**Mitigation:** Use a language that provides abstractions for memory allocation and deallocation.\n\n**Mitigation:** Use a tool that dynamically detects memory management problems, such as valgrind.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "763",
        "name": "Release of Invalid Pointer or Reference",
        "description": "The product attempts to return a memory resource to the system, but it calls the wrong release function or calls the appropriate release function incorrectly.",
        "detail": "**Extended Description:**\n\n\nThis weakness can take several forms, such as:\n\n\n  - The memory was allocated, explicitly or implicitly, via one memory management method and deallocated using a different, non-compatible function (CWE-762).\n\n  - The function calls or memory management routines chosen are appropriate, however they are used incorrectly, such as in CWE-761.\n\n\n\n**Consequence Note:** This weakness may result in the corruption of memory, and perhaps instructions, possibly leading to a crash. If the corrupted memory can be effectively controlled, it may be possible to execute arbitrary code.\n",
        "parent": [
            "404"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Mitigation:** Only call matching memory management functions. Do not mix and match routines. For example, when you allocate a buffer with malloc(), dispose of the original pointer with free().\n\n**Mitigation:** When programming in C++, consider using smart pointers provided by the boost library to help correctly and consistently manage memory.\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, glibc in Linux provides protection against free of invalid pointers.\n\n\n**Mitigation:** Use a language that provides abstractions for memory allocation and deallocation.\n\n**Mitigation:** Use a tool that dynamically detects memory management problems, such as valgrind.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "764",
        "name": "Multiple Locks of a Critical Resource",
        "description": "The product locks a critical resource more times than intended, leading to an unexpected state in the system.",
        "detail": "**Extended Description:**\nWhen a product is operating in a concurrent environment and repeatedly locks a critical resource, the consequences will vary based on the type of lock, the lock's implementation, and the resource being protected. In some situations such as with semaphores, the resources are pooled and extra locking calls will reduce the size of the total available pool, possibly leading to degraded performance or a denial of service. If this can be triggered by an attacker, it will be similar to an unrestricted lock (CWE-412). In the context of a binary lock, it is likely that any duplicate locking attempts will never succeed since the lock is already held and progress may not be possible.\n",
        "parent": [
            "662",
            "667",
            "675"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** When locking and unlocking a resource, try to be sure that all control paths through the code in which the resource is locked one or more times correspond to exactly as many unlocks. If the software acquires a lock and then determines it is not able to perform its intended behavior, be sure to release the lock(s) before waiting for conditions to improve. Reacquire the lock(s) before trying again.\n",
        "languages": []
    },
    {
        "cwe": "765",
        "name": "Multiple Unlocks of a Critical Resource",
        "description": "The product unlocks a critical resource more times than intended, leading to an unexpected state in the system.",
        "detail": "**Extended Description:**\nWhen the product is operating in a concurrent environment and repeatedly unlocks a critical resource, the consequences will vary based on the type of lock, the lock's implementation, and the resource being protected. In some situations such as with semaphores, the resources are pooled and extra calls to unlock will increase the count for the number of available resources, likely resulting in a crash or unpredictable behavior when the system nears capacity.\n",
        "parent": [
            "667",
            "675"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** When locking and unlocking a resource, try to be sure that all control paths through the code in which the resource is locked one or more times correspond to exactly as many unlocks. If the product acquires a lock and then determines it is not able to perform its intended behavior, be sure to release the lock(s) before waiting for conditions to improve. Reacquire the lock(s) before trying again.\n",
        "languages": []
    },
    {
        "cwe": "766",
        "name": "Critical Data Element Declared Public",
        "description": "The product declares a critical variable, field, or member to be public when intended security policy requires it to be private.",
        "detail": "**Extended Description:**\n\n\nThis issue makes it more difficult to maintain the product, which indirectly affects security by making it more difficult or time-consuming to find and/or fix vulnerabilities. It also might make it easier to introduce vulnerabilities.\n\n\n**Consequence Note:** Making a critical variable public allows anyone with access to the object in which the variable is contained to alter or read the value.\n",
        "parent": [
            "1061",
            "732"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Data should be private, static, and final whenever possible. This will assure that your code is protected by instantiating early, preventing access, and preventing tampering.\n",
        "languages": [
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "767",
        "name": "Access to Critical Private Variable via Public Method",
        "description": "The product defines a public method that reads or modifies a private variable.",
        "detail": "**Extended Description:**\nIf an attacker modifies the variable to contain unexpected values, this could violate assumptions from other parts of the code. Additionally, if an attacker can read the private variable, it may expose sensitive information or make it easier to launch further attacks.\n",
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use class accessor and mutator methods appropriately. Perform validation when accepting data from a public method that is intended to modify a critical private variable. Also be sure that appropriate access controls are being applied when a public method interfaces with critical data.\n",
        "languages": [
            "C#",
            "C++",
            "Java"
        ]
    },
    {
        "cwe": "768",
        "name": "Incorrect Short Circuit Evaluation",
        "description": "The product contains a conditional statement with multiple logical expressions in which one of the non-leading expressions may produce side effects. This may lead to an unexpected state in the program after the execution of the conditional, because short-circuiting logic may prevent the side effects from occurring.",
        "detail": "**Extended Description:**\n\n\nUsage of short circuit evaluation, though well-defined in the C standard, may alter control flow in a way that introduces logic errors that are difficult to detect, possibly causing errors later during the product's execution. If an attacker can discover such an inconsistency, it may be exploitable to gain arbitrary control over a system.\n\n\nIf the first condition of an \"or\" statement is assumed to be true under normal circumstances, or if the first condition of an \"and\" statement is assumed to be false, then any subsequent conditional may contain its own logic errors that are not detected during code review or testing.\n\n\nFinally, the usage of short circuit evaluation may decrease the maintainability of the code.\n\n\n**Consequence Note:** Widely varied consequences are possible if an attacker is aware of an unexpected state in the product after a conditional. It may lead to information exposure, a system crash, or even complete attacker control of the system.\n",
        "parent": [
            "691"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Minimizing the number of statements in a conditional that produce side effects will help to prevent the likelihood of short circuit evaluation to alter control flow in an unexpected way.\n",
        "languages": []
    },
    {
        "cwe": "77",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "624",
            "78",
            "88",
            "917"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "770",
        "name": "Allocation of Resources Without Limits or Throttling",
        "description": "The product allocates a reusable resource or group of resources on behalf of an actor without imposing any restrictions on the size or number of resources that can be allocated, in violation of the intended security policy for that actor.",
        "detail": "**Extended Description:**\n\n\nCode frequently has to work with limited resources, so programmers must be careful to ensure that resources are not consumed too quickly, or too easily. Without use of quotas, resource limits, or other protection mechanisms, it can be easy for an attacker to consume many resources by rapidly making many requests, or causing larger resources to be used than is needed. When too many resources are allocated, or if a single resource is too large, then it can prevent the code from working correctly, possibly leading to a denial of service.\n\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** When allocating resources without limits, an attacker could prevent other systems, applications, or processes from accessing the same type of resource.\n",
        "parent": [
            "400",
            "665"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** Manual static analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. If denial-of-service is not considered a significant risk, or if there is strong emphasis on consequences such as code execution, then manual analysis may not focus on this weakness at all.\n\n**Detection:** \n\nWhile fuzzing is typically geared toward finding low-level implementation bugs, it can inadvertently find uncontrolled resource allocation problems. This can occur when the fuzzer generates a large number of test cases but does not restart the targeted product in between test cases. If an individual test case produces a crash, but it does not do so reliably, then an inability to limit resource allocation may be the cause.\n\n\nWhen the allocation is directly affected by numeric inputs, then fuzzing may produce indications of this weakness.\n\n\n**Detection:** Certain automated dynamic analysis techniques may be effective in producing side effects of uncontrolled resource allocation problems, especially with resources such as processes, memory, and connections. The technique may involve generating a large number of requests to the product within a short time frame. Manual analysis is likely required to interpret the results.\n\n**Detection:** \n\nSpecialized configuration or tuning may be required to train automated tools to recognize this weakness.\n\n\nAutomated static analysis typically has limited utility in recognizing unlimited allocation problems, except for the missing release of program-independent system resources such as files, sockets, and processes, or unchecked arguments to memory. For system resources, automated static analysis may be able to detect circumstances in which resources are not released after they have expired, or if too much of a resource is requested at once, as can occur with memory. Automated analysis of configuration files may be able to detect settings that do not specify a maximum value.\n\n\nAutomated static analysis tools will not be appropriate for detecting exhaustion of custom resources, such as an intended security policy in which a bulletin board user is only allowed to make a limited number of posts per day.\n\n\n**Mitigation:** Clearly specify the minimum and maximum expectations for capabilities, and dictate which behaviors are acceptable when resource allocation reaches limits.\n\n**Mitigation:** Limit the amount of resources that are accessible to unprivileged users. Set per-user limits for resources. Allow the system administrator to define these limits. Be careful to avoid CWE-410.\n\n**Mitigation:** Design throttling mechanisms into the system architecture. The best protection is to limit the amount of resources that an unauthorized user can cause to be expended. A strong authentication and access control model will help prevent such attacks from occurring in the first place, and it will help the administrator to identify who is committing the abuse. The login application should be protected against DoS attacks as much as possible. Limiting the database access, perhaps by caching result sets, can help minimize the resources expended. To further limit the potential for a DoS attack, consider tracking the rate of requests received from users and blocking requests that exceed a defined rate threshold.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Effectiveness:** This will only be applicable to cases where user input can influence the size or frequency of resource allocations.\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nMitigation of resource exhaustion attacks requires that the target system either:\n\n\n  - recognizes the attack and denies that user further access for a given amount of time, typically by using increasing time delays\n\n  - uniformly throttles all requests in order to make it more difficult to consume resources more quickly than they can again be freed.\n\nThe first of these solutions is an issue in itself though, since it may allow attackers to prevent the use of the system by a particular valid user. If the attacker impersonates the valid user, they may be able to prevent the user from accessing the server in question.\n\nThe second solution can be difficult to effectively institute -- and even when properly done, it does not provide a full solution. It simply requires more resources on the part of the attacker.\n\n\n**Mitigation:** Ensure that protocols have specific limits of scale placed on them.\n\n**Mitigation:** \n\nIf the program must fail, ensure that it fails gracefully (fails closed). There may be a temptation to simply let the program fail poorly in cases such as low memory conditions, but an attacker may be able to assert control before the software has fully exited. Alternately, an uncontrolled failure could cause cascading problems with other downstream components; for example, the program could send a signal to a downstream process so the process immediately knows that a problem has occurred and has a better chance of recovery.\n\n\nEnsure that all failures in resource allocation place the system into a safe posture.\n\n\n**Mitigation:** \n\nUse resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n\n\nWhen the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n\n\nEnsure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).\n\n",
        "languages": []
    },
    {
        "cwe": "771",
        "name": "Missing Reference to Active Allocated Resource",
        "description": "The product does not properly maintain a reference to a resource that has been allocated, which prevents the resource from being reclaimed.",
        "detail": "**Extended Description:**\nThis does not necessarily apply in languages or frameworks that automatically perform garbage collection, since the removal of all references may act as a signal that the resource is ready to be reclaimed.\n\n**Consequence Note:** An attacker that can influence the allocation of resources that are not properly maintained could deplete the available resource pool and prevent all other processes from accessing the same type of resource.\n",
        "parent": [
            "400"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** \n\nUse resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n\n\nWhen the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n\n\nEnsure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).\n\n",
        "languages": []
    },
    {
        "cwe": "772",
        "name": "Missing Release of Resource after Effective Lifetime",
        "description": "The product does not release a resource after its effective lifetime has ended, i.e., after the resource is no longer needed.",
        "detail": "**Extended Description:**\nWhen a resource is not released after use, it can allow attackers to cause a denial of service by causing the allocation of resources without triggering their release. Frequently-affected resources include memory, CPU, disk space, power or battery, etc.\n\n**Consequence Note:** An attacker that can influence the allocation of resources that are not properly released could deplete the available resource pool and prevent all other processes from accessing the same type of resource.\n",
        "parent": [
            "404"
        ],
        "children": [],
        "related": [
            "911"
        ],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** \n\nUse a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, languages such as Java, Ruby, and Lisp perform automatic garbage collection that releases memory for objects that have been deallocated.\n\n\n**Mitigation:** It is good practice to be responsible for freeing all resources you allocate and to be consistent with how and where you free resources in a function. If you allocate resources that you intend to free upon completion of the function, you must be sure to free the resources at all exit points for that function including error conditions.\n\n**Mitigation:** \n\nUse resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n\n\nWhen the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n\n\nEnsure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).\n\n",
        "languages": []
    },
    {
        "cwe": "773",
        "name": "Missing Reference to Active File Descriptor or Handle",
        "description": "The product does not properly maintain references to a file descriptor or handle, which prevents that file descriptor/handle from being reclaimed.",
        "detail": "**Extended Description:**\nThis can cause the product to consume all available file descriptors or handles, which can prevent other processes from performing critical file processing operations.\n\n**Consequence Note:** An attacker that can influence the allocation of resources that are not properly maintained could deplete the available resource pool and prevent all other processes from accessing the same type of resource.\n",
        "parent": [
            "771"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** \n\nUse resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n\n\nWhen the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n\n\nEnsure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).\n\n",
        "languages": []
    },
    {
        "cwe": "774",
        "name": "Allocation of File Descriptors or Handles Without Limits or Throttling",
        "description": "The product allocates file descriptors or handles on behalf of an actor without imposing any restrictions on how many descriptors can be allocated, in violation of the intended security policy for that actor.",
        "detail": "**Extended Description:**\nThis can cause the product to consume all available file descriptors or handles, which can prevent other processes from performing critical file processing operations.\n\n**Alternate Terms:** File Descriptor Exhaustion\n\n**Consequence Note:** When allocating resources without limits, an attacker could prevent all other processes from accessing the same type of resource.\n",
        "parent": [
            "770"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** \n\nUse resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n\n\nWhen the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n\n\nEnsure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).\n\n",
        "languages": []
    },
    {
        "cwe": "775",
        "name": "Missing Release of File Descriptor or Handle after Effective Lifetime",
        "description": "The product does not release a file descriptor or handle after its effective lifetime has ended, i.e., after the file descriptor/handle is no longer needed.",
        "detail": "**Extended Description:**\nWhen a file descriptor or handle is not released after use (typically by explicitly closing it), attackers can cause a denial of service by consuming all available file descriptors/handles, or otherwise preventing other system processes from obtaining their own file descriptors/handles.\n\n**Consequence Note:** An attacker that can influence the allocation of resources that are not properly released could deplete the available resource pool and prevent all other processes from accessing the same type of resource.\n",
        "parent": [
            "404",
            "772"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Mitigation:** \n\nUse resource-limiting settings provided by the operating system or environment. For example, when managing system resources in POSIX, setrlimit() can be used to set limits for certain types of resources, and getrlimit() can determine how many resources are available. However, these functions are not available on all operating systems.\n\n\nWhen the current levels get close to the maximum that is defined for the application (see CWE-770), then limit the allocation of further resources to privileged users; alternately, begin releasing resources for less-privileged users. While this mitigation may protect the system from attack, it will not necessarily stop attackers from adversely impacting other users.\n\n\nEnsure that the application performs the appropriate error checks and error handling in case resources become unavailable (CWE-703).\n\n",
        "languages": []
    },
    {
        "cwe": "776",
        "name": "Improper Restriction of Recursive Entity References in DTDs ('XML Entity Expansion')",
        "description": "The product uses XML documents and allows their structure to be defined with a Document Type Definition (DTD), but it does not properly control the number of recursive definitions of entities.",
        "detail": "**Extended Description:**\nIf the DTD contains a large number of nested or recursive entities, this can lead to explosive growth of data when parsed, causing a denial of service.\n\n**Alternate Terms:** XEE, Billion Laughs Attack, XML Bomb\n\n**Consequence Note:** If parsed, recursive entity references allow the attacker to expand data exponentially, quickly consuming all system resources.\n",
        "parent": [
            "405",
            "674"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If possible, prohibit the use of DTDs or use an XML parser that limits the expansion of recursive DTD entities.\n\n**Mitigation:** Before parsing XML files with associated DTDs, scan for recursive entity declarations and do not continue parsing potentially explosive content.\n",
        "languages": [
            "XML"
        ]
    },
    {
        "cwe": "777",
        "name": "Regular Expression without Anchors",
        "description": "The product uses a regular expression to perform neutralization, but the regular expression is not anchored and may allow malicious or malformed data to slip through.",
        "detail": "**Extended Description:**\nWhen performing tasks such as validating against a set of allowed inputs (allowlist), data is examined and possibly modified to ensure that it is well-formed and adheres to a list of safe values. If the regular expression is not anchored, malicious or malformed data may be included before or after any string matching the regular expression. The type of malicious data that is allowed will depend on the context of the application and which anchors are omitted from the regular expression.\n\n**Background Details:**\n['Regular expressions are typically used to match a pattern of text. Anchors are used in regular expressions to specify where the pattern should match: at the beginning, the end, or both (the whole input).']\n\n**Consequence Note:** An unanchored regular expression in the context of an allowlist will possibly result in a protection mechanism failure, allowing malicious or malformed data to enter trusted regions of the program. The specific consequences will depend on what functionality the allowlist was protecting.\n",
        "parent": [
            "625"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Be sure to understand both what will be matched and what will not be matched by a regular expression. Anchoring the ends of the expression will allow the programmer to define an allowlist strictly limited to what is matched by the text in the regular expression. If you are using a package that only matches one line by default, ensure that you can match multi-line inputs if necessary.\n",
        "languages": []
    },
    {
        "cwe": "778",
        "name": "Insufficient Logging",
        "description": "When a security-critical event occurs, the product either does not record the event or omits important details about the event when logging it.",
        "detail": "**Extended Description:**\n\n\nWhen security-critical events are not logged properly, such as a failed login attempt, this can make malicious behavior more difficult to detect and may hinder forensic analysis after an attack succeeds.\n\n\nAs organizations adopt cloud storage resources, these technologies often require configuration changes to enable detailed logging information, since detailed logging can incur additional costs. This could lead to telemetry gaps in critical audit logs. For example, in Azure, the default value for logging is disabled. \n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** If security critical information is not recorded, there will be no trail for forensic analysis and discovering the cause of problems or the source of attacks may become more difficult or impossible.\n",
        "parent": [
            "223"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use a centralized logging mechanism that supports multiple levels of detail.\n\n**Mitigation:** Ensure that all security-related successes and failures can be logged. When storing data in the cloud (e.g., AWS S3 buckets, Azure blobs, Google Cloud Storage, etc.), use the provider's controls to enable and capture detailed logging information.\n\n**Mitigation:** Be sure to set the level of logging appropriately in a production environment. Sufficient data should be logged to enable system administrators to detect attacks, diagnose errors, and recover from attacks. At the same time, logging too much data (CWE-779) can cause the same problems, including unexpected costs when using a cloud environment.\n\n**Mitigation:** To enable storage logging using Azure's Portal, navigate to the name of the Storage Account, locate Monitoring (CLASSIC) section, and select Diagnostic settings (classic). For each of the various properties (blob, file, table, queue), ensure the status is properly set for the desired logging data. If using PowerShell, the Set-AzStorageServiceLoggingProperty command could be called using appropriate -ServiceType, -LoggingOperations, and -RetentionDays arguments.\n",
        "languages": []
    },
    {
        "cwe": "779",
        "name": "Logging of Excessive Data",
        "description": "The product logs too much information, making log files hard to process and possibly hindering recovery efforts or forensic analysis after an attack.",
        "detail": "**Extended Description:**\nWhile logging is a good practice in general, and very high levels of logging are appropriate for debugging stages of development, too much logging in a production environment might hinder a system administrator's ability to detect anomalous conditions. This can provide cover for an attacker while attempting to penetrate a system, clutter the audit trail for forensic analysis, or make it more difficult to debug problems in a production environment.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Log files can become so large that they consume excessive resources, such as disk and CPU, which can hinder the performance of the system.\n\n**Consequence Note:** Logging too much information can make the log files of less use to forensics analysts and developers when trying to diagnose a problem or recover from an attack.\n\n**Consequence Note:** If system administrators are unable to effectively process log files, attempted attacks may go undetected, possibly leading to eventual system compromise.\n",
        "parent": [
            "400"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** Suppress large numbers of duplicate log messages and replace them with periodic summaries. For example, syslog may include an entry that states \"last message repeated X times\" when recording repeated events.\n\n**Mitigation:** Support a maximum size for the log file that can be controlled by the administrator. If the maximum size is reached, the admin should be notified. Also, consider reducing functionality of the product. This may result in a denial-of-service to legitimate product users, but it will prevent the product from adversely impacting the entire system.\n\n**Mitigation:** Adjust configurations appropriately when the product is transitioned from a debug state to production.\n",
        "languages": []
    },
    {
        "cwe": "78",
        "name": "Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')",
        "description": "The product constructs all or part of an OS command using externally-influenced input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could modify the intended OS command when it is sent to a downstream component.",
        "detail": "**Extended Description:**\n\n\nThis weakness can lead to a vulnerability in environments in which the attacker does not have direct access to the operating system, such as in web applications. Alternately, if the weakness occurs in a privileged program, it could allow the attacker to specify commands that normally would not be accessible, or to call alternate commands with privileges that the attacker does not have. The problem is exacerbated if the compromised process does not follow the principle of least privilege, because the attacker-controlled commands may run with special system privileges that increases the amount of damage.\n\n\nThere are at least two subtypes of OS command injection:\n\n\n  - The application intends to execute a single, fixed program that is under its own control. It intends to use externally-supplied inputs as arguments to that program. For example, the program might use system(\"nslookup [HOSTNAME]\") to run nslookup and allow the user to supply a HOSTNAME, which is used as an argument. Attackers cannot prevent nslookup from executing. However, if the program does not remove command separators from the HOSTNAME argument, attackers could place the separators into the arguments, which allows them to execute their own program after nslookup has finished executing.\n\n  - The application accepts an input that it uses to fully select which program to run, as well as which commands to use. The application simply redirects this entire command to the operating system. For example, the program might use \"exec([COMMAND])\" to execute the [COMMAND] that was supplied by the user. If the COMMAND is under attacker control, then the attacker can execute arbitrary commands or programs. If the command is being executed using functions like exec() and CreateProcess(), the attacker might not be able to combine multiple commands together in the same line.\n\nFrom a weakness standpoint, these variants represent distinct programmer errors. In the first variant, the programmer clearly intends that input from untrusted parties will be part of the arguments in the command to be executed. In the second variant, the programmer does not intend for the command to be accessible to any untrusted party, but the programmer probably has not accounted for alternate ways in which malicious attackers can provide input.\n\n**Alternate Terms:** Shell injection, Shell metacharacters, OS Command Injection\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Attackers could execute unauthorized operating system commands, which could then be used to disable the product, or read and modify data for which the attacker does not have permissions to access directly. Since the targeted application is directly executing the commands instead of the attacker, any malicious activities may appear to come from the application or the application's owner.\n",
        "parent": [
            "74",
            "77"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.\n\n\nAutomated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or require any code changes.\n\n\nAutomated static analysis might not be able to detect the usage of custom API functions or third-party libraries that indirectly invoke OS commands, leading to false negatives - especially if the API/library code is not available for analysis.\n\n\n**Detection:** This weakness can be detected using dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Detection:** Since this weakness does not typically appear frequently within a single software package, manual white box techniques may be able to provide sufficient code coverage and reduction of false positives if all potentially-vulnerable operations can be assessed within limited time constraints.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** If at all possible, use library calls rather than external processes to recreate the desired functionality.\n\n**Mitigation:** \n\nRun the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n\n\nOS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Effectiveness:** The effectiveness of this mitigation depends on the prevention capabilities of the specific sandbox or jail being used and might only help to reduce the scope of an attack, such as restricting the attacker to certain system calls or limiting the portion of the file system that can be accessed.\n\n**Mitigation:** For any data that will be used to generate a command to be executed, keep as much of that data out of external control as possible. For example, in web applications, this may require storing the data locally in the session's state instead of sending it out to the client in a hidden form field.\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, consider using the ESAPI Encoding control [REF-45] or a similar tool, library, or framework. These will help the programmer encode outputs in a manner less prone to error.\n\n\n**Mitigation:** While it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n**Mitigation:** If the program to be executed allows arguments to be specified within an input file or from standard input, then consider using that mode to pass arguments instead of the command line.\n\n**Mitigation:** \n\nIf available, use structured mechanisms that automatically enforce the separation between data and code. These mechanisms may be able to provide the relevant quoting, encoding, and validation automatically, instead of relying on the developer to provide this capability at every point where output is generated.\n\n\nSome languages offer multiple functions that can be used to invoke commands. Where possible, identify any function that invokes a command shell using a single string, and replace it with a function that requires individual arguments. These functions typically perform appropriate quoting and filtering of arguments. For example, in C, the system() function accepts a string that contains the entire command to be executed, whereas execl(), execve(), and others require an array of strings, one for each argument. In Windows, CreateProcess() only accepts one command at a time. In Perl, if system() is provided with an array of arguments, then it will quote each of the arguments.\n\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen constructing OS command strings, use stringent allowlists that limit the character set based on the expected value of the parameter in the request. This will indirectly limit the scope of an attack, but this technique is less important than proper output encoding and escaping.\n\n\nNote that proper output encoding, escaping, and quoting is the most effective solution for preventing OS command injection, although input validation may provide some defense-in-depth. This is because it effectively limits what will appear in output. Input validation will not always prevent OS command injection, especially if you are required to support free-form text fields that could contain arbitrary characters. For example, when invoking a mail program, you might need to allow the subject field to contain otherwise-dangerous inputs like \";\" and \">\" characters, which would need to be escaped or otherwise handled. In this case, stripping the character might reduce the risk of OS command injection, but it would produce incorrect behavior because the subject field would not be recorded as the user intended. This might seem to be a minor inconvenience, but it could be more important when the program relies on well-structured subject lines in order to pass messages to other components.\n\n\nEven if you make a mistake in your validation (such as forgetting one out of 100 input fields), appropriate encoding is still likely to protect you from injection-based attacks. As long as it is not done in isolation, input validation is still a useful technique, since it may significantly reduce your attack surface, allow you to detect some attacks, and provide other security benefits that proper encoding does not address.\n\n\n**Mitigation:** When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n**Mitigation:** Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).\n\n**Mitigation:** Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).\n\n**Mitigation:** \n\nEnsure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n\n\nIf errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\n\nAvoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n\n\nIn the context of OS Command Injection, error information passed back to the user might reveal whether an OS command is being executed and possibly which command is being used.\n\n\n**Mitigation:** Use runtime policy enforcement to create an allowlist of allowable commands, then prevent use of any command that does not appear in the allowlist. Technologies such as AppArmor are available to do this.\n\n**Mitigation:** Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.\n\n**Effectiveness:** An application firewall might not cover all possible input vectors. In addition, attack techniques might be available to bypass the protection mechanism, such as using malformed inputs that can still be processed by the component that receives those inputs. Depending on functionality, an application firewall might inadvertently reject or modify legitimate requests. Finally, some manual effort may be required for customization.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n",
        "languages": []
    },
    {
        "cwe": "780",
        "name": "Use of RSA Algorithm without OAEP",
        "description": "The product uses the RSA algorithm but does not incorporate Optimal Asymmetric Encryption Padding (OAEP), which might weaken the encryption.",
        "detail": "**Extended Description:**\nPadding schemes are often used with cryptographic algorithms to make the plaintext less predictable and complicate attack efforts. The OAEP scheme is often used with RSA to nullify the impact of predictable common text.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Without OAEP in RSA encryption, it will take less work for an attacker to decrypt the data or to infer patterns from the ciphertext.\n",
        "parent": [
            "327"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "781",
        "name": "Improper Address Validation in IOCTL with METHOD_NEITHER I/O Control Code",
        "description": "The product defines an IOCTL that uses METHOD_NEITHER for I/O, but it does not validate or incorrectly validates the addresses that are provided.",
        "detail": "**Extended Description:**\nWhen an IOCTL uses the METHOD_NEITHER option for I/O control, it is the responsibility of the IOCTL to validate the addresses that have been supplied to it. If validation is missing or incorrect, attackers can supply arbitrary memory addresses, leading to code execution or a denial of service.\n\n**Consequence Note:** An attacker may be able to access memory that belongs to another process or user. If the attacker can control the contents that the IOCTL writes, it may lead to code execution at high privilege levels. At the least, a crash can occur.\n",
        "parent": [
            "1285"
        ],
        "children": [],
        "related": [
            "782",
            "822"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** If METHOD_NEITHER is required for the IOCTL, then ensure that all user-space addresses are properly validated before they are first accessed. The ProbeForRead and ProbeForWrite routines are available for this task. Also properly protect and manage the user-supplied buffers, since the I/O Manager does not do this when METHOD_NEITHER is being used. See References.\n\n**Mitigation:** If possible, avoid using METHOD_NEITHER in the IOCTL and select methods that effectively control the buffer size, such as METHOD_BUFFERED, METHOD_IN_DIRECT, or METHOD_OUT_DIRECT.\n\n**Mitigation:** If the IOCTL is part of a driver that is only intended to be accessed by trusted users, then use proper access control for the associated device or device namespace. See References.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "782",
        "name": "Exposed IOCTL with Insufficient Access Control",
        "description": "The product implements an IOCTL with functionality that should be restricted, but it does not properly enforce access control for the IOCTL.",
        "detail": "**Extended Description:**\n\n\nWhen an IOCTL contains privileged functionality and is exposed unnecessarily, attackers may be able to access this functionality by invoking the IOCTL. Even if the functionality is benign, if the programmer has assumed that the IOCTL would only be accessed by a trusted process, there may be little or no validation of the incoming data, exposing weaknesses that would never be reachable if the attacker cannot call the IOCTL directly.\n\n\nThe implementations of IOCTLs will differ between operating system types and versions, so the methods of attack and prevention may vary widely.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** Attackers can invoke any functionality that the IOCTL offers. Depending on the functionality, the consequences may include code execution, denial-of-service, and theft of data.\n",
        "parent": [
            "749"
        ],
        "children": [],
        "related": [
            "781"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** In Windows environments, use proper access control for the associated device or device namespace. See References.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "783",
        "name": "Operator Precedence Logic Error",
        "description": "The product uses an expression in which operator precedence causes incorrect logic to be used.",
        "detail": "**Extended Description:**\nWhile often just a bug, operator precedence logic errors can have serious consequences if they are used in security-critical code, such as making an authentication decision.\n\n**Mode of Introduction:** Logic errors related to operator precedence may cause problems even during normal operation, so they are probably discovered quickly during the testing phase. If testing is incomplete or there is a strong reliance on manual review of the code, then these errors may not be discovered before the software is deployed.\n\n**Consequence Note:** The consequences will vary based on the context surrounding the incorrect precedence. In a security decision, integrity or confidentiality are the most likely results. Otherwise, a crash may occur due to the software reaching an unexpected state.\n",
        "parent": [
            "670"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Regularly wrap sub-expressions in parentheses, especially in security-critical code.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "784",
        "name": "Reliance on Cookies without Validation and Integrity Checking in a Security Decision",
        "description": "The product uses a protection mechanism that relies on the existence or values of a cookie, but it does not properly ensure that the cookie is valid for the associated user.",
        "detail": "**Extended Description:**\nAttackers can easily modify cookies, within the browser or by implementing the client-side code outside of the browser. Attackers can bypass protection mechanisms such as authorization and authentication by modifying the cookie to contain an expected value.\n\n**Consequence Note:** It is dangerous to use cookies to set a user's privileges. The cookie can be manipulated to claim a high level of authorization, or to claim that successful authentication has occurred.\n",
        "parent": [
            "565",
            "807"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** Avoid using cookie data for a security-related decision.\n\n**Mitigation:** Perform thorough input validation (i.e.: server side validation) on the cookie data if you're going to use it for a security related decision.\n\n**Mitigation:** Add integrity checks to detect tampering.\n\n**Mitigation:** Protect critical cookies from replay attacks, since cross-site scripting or other attacks may allow attackers to steal a strongly-encrypted cookie that also passes integrity checks. This mitigation applies to cookies that should only be valid during a single transaction or session. By enforcing timeouts, you may limit the scope of an attack. As part of your integrity check, use an unpredictable, server-side value that is not exposed to the client.\n",
        "languages": []
    },
    {
        "cwe": "785",
        "name": "Use of Path Manipulation Function without Maximum-sized Buffer",
        "description": "The product invokes a function for normalizing paths or file names, but it provides an output buffer that is smaller than the maximum possible size, such as PATH_MAX.",
        "detail": "**Extended Description:**\nPassing an inadequately-sized output buffer to a path manipulation function can result in a buffer overflow. Such functions include realpath(), readlink(), PathAppend(), and others.\n\n**Background Details:**\n['Windows provides a large number of utility functions that manipulate buffers containing filenames. In most cases, the result is returned in a buffer that is passed in as input. (Usually the filename is modified in place.) Most functions require the buffer to be at least MAX_PATH bytes in length, but you should check the documentation for each function individually. If the buffer is not large enough to store the result of the manipulation, a buffer overflow can occur.']\n",
        "parent": [
            "120",
            "20",
            "676"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Always specify output buffers large enough to handle the maximum-size possible result from path manipulation functions.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "786",
        "name": "Access of Memory Location Before Start of Buffer",
        "description": "The product reads or writes to a buffer using an index or pointer that references a memory location prior to the beginning of the buffer.",
        "detail": "**Extended Description:**\nThis typically occurs when a pointer or its index is decremented to a position before the buffer, when pointer arithmetic results in a position before the beginning of the valid memory location, or when a negative index is used.\n\n**Consequence Note:** For an out-of-bounds read, the attacker may have access to sensitive information. If the sensitive information contains system details, such as the current buffer's position in memory, this knowledge can be used to craft further attacks, possibly with more severe consequences.\n\n**Consequence Note:** Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash.\n\n**Consequence Note:** If the corrupted memory can be effectively controlled, it may be possible to execute arbitrary code. If the corrupted memory is data rather than instructions, the system will continue to function with improper changes, possibly in violation of an implicit or explicit policy.\n",
        "parent": [
            "119"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "787",
        "name": "Out-of-bounds Write",
        "description": "The product writes data past the end, or before the beginning, of the intended buffer.",
        "detail": "**Alternate Terms:** Memory Corruption\n\n**Consequence Note:** Write operations could cause memory corruption. In some cases, an adversary can modify control data such as return addresses in order to execute unexpected code.\n\n**Consequence Note:** Attempting to access out-of-range, invalid, or unauthorized memory could cause the product to crash.\n\n**Consequence Note:** Subsequent write operations can produce undefined or unexpected results.\n",
        "parent": [
            "119"
        ],
        "children": [
            "120"
        ],
        "related": [
            "822",
            "823",
            "824",
            "825"
        ],
        "scopes": [
            "Availability",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.\n\n\nAutomated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges.\n\n\n**Detection:** This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Mitigation:** \n\nUse a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, many languages that perform their own memory management, such as Java and Perl, are not subject to buffer overflows. Other languages, such as Ada and C#, typically provide overflow protection, but the protection can be disabled by the programmer.\n\n\nBe wary that a language's interface to native code may still be subject to overflows, even if the language itself is theoretically safe.\n\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nExamples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57], and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer versions of overflow-prone string-handling functions.\n\n\n**Effectiveness:** This is not a complete solution, since many buffer overflows are not related to strings.\n\n**Mitigation:** \n\nUse automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking. \n\n\n D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail. \n\n\n**Effectiveness:** \n\n This is not necessarily a complete solution, since these mechanisms only detect certain types of overflows. In addition, the result is still a denial of service, since the typical response is to exit the application. \n\n\n**Mitigation:** \n\nConsider adhering to the following rules when allocating and managing an application's memory:\n\n\n  - Double check that the buffer is as large as specified.\n\n  - When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string.\n\n  - Check buffer boundaries if accessing the buffer in a loop and make sure there is no danger of writing past the allocated space.\n\n  - If necessary, truncate all input strings to a reasonable length before passing them to the copy and concatenation functions.\n\n\n\n**Mitigation:** \n\nRun or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code. \n\n\n Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking. \n\n\n For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335]. \n\n\n**Effectiveness:** These techniques do not provide a complete solution. For instance, exploits frequently use a bug that discloses memory addresses in order to maximize reliability of code execution [REF-1337]. It has also been shown that a side-channel attack can bypass ASLR [REF-1333].\n\n**Mitigation:** \n\n Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment. \n\n\n For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336]. \n\n\n**Effectiveness:** This is not a complete solution, since buffer overflows could be used to overwrite nearby variables to modify the software's state in dangerous ways. In addition, it cannot be used in cases in which self-modifying code is required. Finally, an attack could still cause a denial of service, since the typical response is to exit the application.\n\n**Mitigation:** Replace unbounded copy functions with analogous functions that support length arguments, such as strcpy with strncpy. Create these if they are not available.\n\n**Effectiveness:** This approach is still susceptible to calculation errors, including issues such as off-by-one errors (CWE-193) and incorrectly calculating buffer lengths (CWE-131).\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "788",
        "name": "Access of Memory Location After End of Buffer",
        "description": "The product reads or writes to a buffer using an index or pointer that references a memory location after the end of the buffer.",
        "detail": "**Extended Description:**\nThis typically occurs when a pointer or its index is incremented to a position after the buffer; or when pointer arithmetic results in a position after the buffer.\n\n**Consequence Note:** For an out-of-bounds read, the attacker may have access to sensitive information. If the sensitive information contains system details, such as the current buffer's position in memory, this knowledge can be used to craft further attacks, possibly with more severe consequences.\n\n**Consequence Note:** Out of bounds memory access will very likely result in the corruption of relevant memory, and perhaps instructions, possibly leading to a crash. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.\n\n**Consequence Note:** If the memory accessible by the attacker can be effectively controlled, it may be possible to execute arbitrary code, as with a standard buffer overflow. If the attacker can overwrite a pointer's worth of memory (usually 32 or 64 bits), they can redirect a function pointer to their own malicious code. Even when the attacker can only modify a single byte arbitrary code execution can be possible. Sometimes this is because the same problem can be exploited repeatedly to the same effect. Other times it is because the attacker can overwrite security-critical application-specific data -- such as a flag indicating whether the user is an administrator.\n",
        "parent": [
            "119"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Fuzz testing (fuzzing) is a powerful technique for generating large numbers of diverse inputs - either randomly or algorithmically - and dynamically invoking the code with those inputs. Even with random inputs, it is often capable of generating unexpected results such as crashes, memory corruption, or resource consumption. Fuzzing effectively produces repeatable test cases that clearly indicate bugs, which helps developers to diagnose the issues.\n\n**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "789",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "1284"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "79",
        "name": "Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
        "description": "The product does not neutralize or incorrectly neutralizes user-controllable input before it is placed in output that is used as a web page that is served to other users.",
        "detail": "**Extended Description:**\n\n\nThere are many variants of cross-site scripting, characterized by a variety of terms or involving different attack topologies. However, they all indicate the same fundamental weakness: improper neutralization of dangerous input between the adversary and a victim.\n\n\n**Alternate Terms:** XSS, HTML Injection, Reflected XSS / Non-Persistent XSS / Type 1 XSS, Stored XSS / Persistent XSS / Type 2 XSS, DOM-Based XSS / Type 0 XSS, CSS\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Background Details:**\n['\\n\\nThe Same Origin Policy states that browsers should limit the resources accessible to scripts running on a given web site, or \"origin\", to the resources associated with that web site on the client-side, and not the client-side resources of any other sites or \"origins\". The goal is to prevent one site from being able to modify or read the contents of an unrelated site. Since the World Wide Web involves interactions between many sites, this policy is important for browsers to enforce.\\n\\n\\nWhen referring to XSS, the Domain of a website is roughly equivalent to the resources associated with that website on the client-side of the connection. That is, the domain can be thought of as all resources the browser is storing for the user\\'s interactions with this particular site.\\n']\n\n**Consequence Note:** The most common attack performed with cross-site scripting involves the disclosure of private information stored in user cookies, such as session information. Typically, a malicious user will craft a client-side script, which -- when parsed by a web browser -- performs some activity on behalf of the victim to an attacker-controlled system (such as sending all site cookies to a given E-mail address). This could be especially dangerous to the site if the victim has administrator privileges to manage that site. This script will be loaded and run by each user visiting the web site. Since the site requesting to run the script has access to the cookies in question, the malicious script does also.\n\n**Consequence Note:** In some circumstances it may be possible to run arbitrary code on a victim's computer when cross-site scripting is combined with other flaws, for example, \"drive-by hacking.\"\n\n**Consequence Note:** The consequence of an XSS attack is the same regardless of whether it is stored or reflected. The difference is in how the payload arrives at the server. XSS can cause a variety of problems for the end user that range in severity from an annoyance to complete account compromise. Some cross-site scripting vulnerabilities can be exploited to manipulate or steal cookies, create requests that can be mistaken for those of a valid user, compromise confidential information, or execute malicious code on the end user systems for a variety of nefarious purposes. Other damaging attacks include the disclosure of end user files, installation of Trojan horse programs, redirecting the user to some other page or site, running \"Active X\" controls (under Microsoft Internet Explorer) from sites that a user perceives as trustworthy, and modifying presentation of content.\n",
        "parent": [
            "74"
        ],
        "children": [],
        "related": [
            "352",
            "494"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible, especially when multiple components are involved.\n\n**Detection:** Use the XSS Cheat Sheet [REF-714] or automated test-generation tools to help launch a wide variety of attacks against your web application. The Cheat Sheet contains many subtle XSS variations that are specifically targeted against weak XSS defenses.\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nExamples of libraries and frameworks that make it easier to generate properly encoded output include Microsoft's Anti-XSS library, the OWASP ESAPI Encoding module, and Apache Wicket.\n\n\n**Mitigation:** \n\nUnderstand the context in which your data will be used and the encoding that will be expected. This is especially important when transmitting data between different components, or when generating outputs that can contain multiple encodings at the same time, such as web pages or multi-part mail messages. Study all expected communication protocols and data representations to determine the required encoding strategies.\n\n\nFor any data that will be output to another web page, especially any data that was received from external inputs, use the appropriate encoding on all non-alphanumeric characters.\n\n\nParts of the same output document may require different encodings, which will vary depending on whether the output is in the:\n\n\n  - HTML body\n\n  - Element attributes (such as src=\"XYZ\")\n\n  - URIs\n\n  - JavaScript sections\n\n  - Cascading Style Sheets and style property\n\netc. Note that HTML Entity Encoding is only appropriate for the HTML body.\n\nConsult the XSS Prevention Cheat Sheet [REF-724] for more details on the types of encoding and escaping that are needed.\n\n\n**Mitigation:** Understand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n\n**Effectiveness:** This technique has limited effectiveness, but can be helpful when it is possible to store client state and sensitive information on the server side instead of in cookies, headers, hidden form fields, etc.\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** If available, use structured mechanisms that automatically enforce the separation between data and code. These mechanisms may be able to provide the relevant quoting, encoding, and validation automatically, instead of relying on the developer to provide this capability at every point where output is generated.\n\n**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** With Struts, write all data from form beans with the bean's filter attribute set to true.\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen dynamically constructing web pages, use stringent allowlists that limit the character set based on the expected value of the parameter in the request. All input should be validated and cleansed, not just parameters that the user is supposed to specify, but all data in the request, including hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. It is common to see data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.\n\n\nNote that proper output encoding, escaping, and quoting is the most effective solution for preventing XSS, although input validation may provide some defense-in-depth. This is because it effectively limits what will appear in output. Input validation will not always prevent XSS, especially if you are required to support free-form text fields that could contain arbitrary characters. For example, in a chat application, the heart emoticon (\"<3\") would likely pass the validation step, since it is commonly used. However, it cannot be directly inserted into the web page because it contains the \"<\" character, which would need to be escaped or otherwise handled. In this case, stripping the \"<\" might reduce the risk of XSS, but it would produce incorrect behavior because the emoticon would not be recorded. This might seem to be a minor inconvenience, but it would be more important in a mathematical forum that wants to represent inequalities.\n\n\nEven if you make a mistake in your validation (such as forgetting one out of 100 input fields), appropriate encoding is still likely to protect you from injection-based attacks. As long as it is not done in isolation, input validation is still a useful technique, since it may significantly reduce your attack surface, allow you to detect some attacks, and provide other security benefits that proper encoding does not address.\n\n\nEnsure that you perform input validation at well-defined interfaces within the application. This will help protect the application even if a component is reused or moved elsewhere.\n\n\n**Mitigation:** When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n**Mitigation:** Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.\n\n**Effectiveness:** An application firewall might not cover all possible input vectors. In addition, attack techniques might be available to bypass the protection mechanism, such as using malformed inputs that can still be processed by the component that receives those inputs. Depending on functionality, an application firewall might inadvertently reject or modify legitimate requests. Finally, some manual effort may be required for customization.\n\n**Mitigation:** When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n",
        "languages": []
    },
    {
        "cwe": "790",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "791"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "791",
        "name": "Incomplete Filtering of Special Elements",
        "description": "The product receives data from an upstream component, but does not completely filter special elements before sending it to a downstream component.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "790"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "792",
        "name": "Incomplete Filtering of One or More Instances of Special Elements",
        "description": "The product receives data from an upstream component, but does not completely filter one or more instances of special elements before sending it to a downstream component.",
        "detail": "**Extended Description:**\n\n\nIncomplete filtering of this nature involves either:\n\n\n  - only filtering a single instance of a special element when more exist, or\n\n  - not filtering all instances or all elements where multiple special elements exist.\n\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "791"
        ],
        "children": [
            "793",
            "794"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "793",
        "name": "Only Filtering One Instance of a Special Element",
        "description": "The product receives data from an upstream component, but only filters a single instance of a special element before sending it to a downstream component.",
        "detail": "**Extended Description:**\nIncomplete filtering of this nature may be location-dependent, as in only the first or last element is filtered.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "792"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "794",
        "name": "Incomplete Filtering of Multiple Instances of Special Elements",
        "description": "The product receives data from an upstream component, but does not filter all instances of a special element before sending it to a downstream component.",
        "detail": "**Extended Description:**\n\n\nIncomplete filtering of this nature may be applied to:\n\n\n  - sequential elements (special elements that appear next to each other) or\n\n  - non-sequential elements (special elements that appear multiple times in different locations).\n\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "792"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "795",
        "name": "Only Filtering Special Elements at a Specified Location",
        "description": "The product receives data from an upstream component, but only accounts for special elements at a specified location, thereby missing remaining special elements that may exist before sending it to a downstream component.",
        "detail": "**Extended Description:**\n\n\nA filter might only account for instances of special elements when they occur:\n\n\n  - relative to a marker (e.g. \"at the beginning/end of string; the second argument\"), or\n\n  - at an absolute position (e.g. \"byte number 10\").\n\nThis may leave special elements in the data that did not match the filter position, but still may be dangerous.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "791"
        ],
        "children": [
            "796",
            "797"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "796",
        "name": "Only Filtering Special Elements Relative to a Marker",
        "description": "The product receives data from an upstream component, but only accounts for special elements positioned relative to a marker (e.g. \"at the beginning/end of a string; the second argument\"), thereby missing remaining special elements that may exist before sending it to a downstream component.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "795"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "797",
        "name": "Only Filtering Special Elements at an Absolute Position",
        "description": "The product receives data from an upstream component, but only accounts for special elements at an absolute position (e.g. \"byte number 10\"), thereby missing remaining special elements that may exist before sending it to a downstream component.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "795"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "798",
        "name": "Use of Hard-coded Credentials",
        "description": "The product contains hard-coded credentials, such as a password or cryptographic key.",
        "detail": "**Extended Description:**\n\n\nThere are two main variations:\n\n\n  - Inbound: the product contains an authentication mechanism that checks the input credentials against a hard-coded set of credentials. In this variant, a default administration account is created, and a simple password is hard-coded into the product and associated with that account. This hard-coded password is the same for each installation of the product, and it usually cannot be changed or disabled by system administrators without manually modifying the program, or otherwise patching the product. It can also be difficult for the administrator to detect.\n\n  - Outbound: the product connects to another system or component, and it contains hard-coded credentials for connecting to that component. This variant applies to front-end systems that authenticate with a back-end service. The back-end service may require a fixed password that can be easily discovered. The programmer may simply hard-code those back-end credentials into the front-end product.\n\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** \n\nIf hard-coded passwords are used, it is almost certain that malicious users will gain access to the account in question.\n\n\nAny user of the product that hard-codes passwords may be able to extract the password. Client-side systems with hard-coded passwords pose even more of a threat, since the extraction of a password from a binary is usually very simple.\n\n\n**Consequence Note:** \n\nThis weakness can lead to the exposure of resources or functionality to unintended actors, possibly providing attackers with sensitive information or even execute arbitrary code.\n\n\nIf the password is ever discovered or published (a common occurrence on the Internet), then anybody with knowledge of this password can access the product. Finally, since all installations of the product will have the same password, even across different organizations, this enables massive attacks such as worms to take place.\n\n",
        "parent": [
            "1391",
            "287",
            "344",
            "671"
        ],
        "children": [],
        "related": [
            "257"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Credential storage in configuration files is findable using black box methods, but the use of hard-coded credentials for an incoming authentication routine typically involves an account that is not visible outside of the code.\n\n**Detection:** Automated white box techniques have been published for detecting hard-coded credentials for incoming authentication, but there is some expert disagreement regarding their effectiveness and applicability to a broad range of methods.\n\n**Detection:** This weakness may be detectable using manual code analysis. Unless authentication is decentralized and applied throughout the product, there can be sufficient time for the analyst to find incoming authentication routines and examine the program logic looking for usage of hard-coded credentials. Configuration files could also be analyzed.\n\n**Detection:** \n\nFor hard-coded credentials in incoming authentication: use monitoring tools that examine the product's process as it interacts with the operating system and the network. This technique is useful in cases when source code is unavailable, if the product was not developed by you, or if you want to verify that the build phase did not introduce any new weaknesses. Examples include debuggers that directly attach to the running process; system-call tracing utilities such as truss (Solaris) and strace (Linux); system activity monitors such as FileMon, RegMon, Process Monitor, and other Sysinternals utilities (Windows); and sniffers and protocol analyzers that monitor network traffic.\n\n\nAttach the monitor to the process and perform a login. Using call trees or similar artifacts from the output, examine the associated behaviors and see if any of them appear to be comparing the input to a fixed string or value.\n\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tNetwork Sniffer\n\t\tForced Path Execution\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tConfiguration Checker\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t\tFormal Methods / Correct-By-Construction\n\n**Mitigation:** \n\nFor outbound authentication: store passwords, keys, and other credentials outside of the code in a strongly-protected, encrypted configuration file or database that is protected from access by all outsiders, including other local users on the same system. Properly protect the key (CWE-320). If you cannot use encryption to protect the file, then make sure that the permissions are as restrictive as possible [REF-7].\n\n\nIn Windows environments, the Encrypted File System (EFS) may provide some protection.\n\n\n**Mitigation:** For inbound authentication: Rather than hard-code a default username and password, key, or other authentication credentials for first time logins, utilize a \"first login\" mode that requires the user to enter a unique strong password or key.\n\n**Mitigation:** If the product must contain hard-coded credentials or they cannot be removed, perform access control checks and limit which entities can access the feature that requires the hard-coded credentials. For example, a feature might only be enabled through the system console instead of through a network connection.\n\n**Mitigation:** \n\nFor inbound authentication using passwords: apply strong one-way hashes to passwords and store those hashes in a configuration file or database with appropriate access control. That way, theft of the file/database still requires the attacker to try to crack the password. When handling an incoming password during authentication, take the hash of the password and compare it to the saved hash.\n\n\nUse randomly assigned salts for each separate hash that is generated. This increases the amount of computation that an attacker needs to conduct a brute-force attack, possibly limiting the effectiveness of the rainbow table method.\n\n\n**Mitigation:** \n\nFor front-end to back-end connections: Three solutions are possible, although none are complete.\n\n\n  - The first suggestion involves the use of generated passwords or keys that are changed automatically and must be entered at given time intervals by a system administrator. These passwords will be held in memory and only be valid for the time intervals.\n\n  - Next, the passwords or keys should be limited at the back end to only performing actions valid for the front end, as opposed to having full access.\n\n  - Finally, the messages sent should be tagged and checksummed with time sensitive values so as to prevent replay-style attacks.\n\n\n",
        "languages": []
    },
    {
        "cwe": "799",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "307"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "8",
        "name": "J2EE Misconfiguration: Entity Bean Declared Remote",
        "description": "When an application exposes a remote interface for an entity bean, it might also expose methods that get or set the bean's data. These methods could be leveraged to read sensitive information, or to change data in ways that violate the application's expectations, potentially leading to other vulnerabilities.",
        "detail": null,
        "parent": [
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Declare Java beans \"local\" when possible. When a bean must be remotely accessible, make sure that sensitive information is not exposed, and ensure that the application logic performs appropriate validation of any data that might be modified by an attacker.\n",
        "languages": []
    },
    {
        "cwe": "80",
        "name": "Improper Neutralization of Script-Related HTML Tags in a Web Page (Basic XSS)",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special characters such as \"<\", \">\", and \"&\" that could be interpreted as web-scripting elements when they are sent to a downstream component that processes web pages.",
        "detail": "**Extended Description:**\nThis may allow such characters to be treated as control characters, which are executed client-side in the context of the user's session. Although this can be classified as an injection problem, the more pertinent issue is the improper conversion of such special characters to respective context-appropriate entities before displaying them to the user.\n",
        "parent": [
            "79"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.\n\n**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** With Struts, write all data from form beans with the bean's filter attribute set to true.\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n",
        "languages": []
    },
    {
        "cwe": "804",
        "name": "Guessable CAPTCHA",
        "description": "The product uses a CAPTCHA challenge, but the challenge can be guessed or automatically recognized by a non-human actor.",
        "detail": "**Extended Description:**\n\n\nAn automated attacker could bypass the intended protection of the CAPTCHA challenge and perform actions at a higher frequency than humanly possible, such as launching spam attacks.\n\n\nThere can be several different causes of a guessable CAPTCHA:\n\n\n  - An audio or visual image that does not have sufficient distortion from the unobfuscated source image.\n\n  - A question is generated with a format that can be automatically recognized, such as a math question.\n\n  - A question for which the number of possible answers is limited, such as birth years or favorite sports teams.\n\n  - A general-knowledge or trivia question for which the answer can be accessed using a data base, such as country capitals or popular entertainers.\n\n  - Other data associated with the CAPTCHA may provide hints about its contents, such as an image whose filename contains the word that is used in the CAPTCHA.\n\n\n\n**Consequence Note:** When authorization, authentication, or another protection mechanism relies on CAPTCHA entities to ensure that only human actors can access certain functionality, then an automated attacker such as a bot may access the restricted functionality by guessing the CAPTCHA.\n",
        "parent": [
            "1390",
            "863"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "805",
        "name": "Buffer Access with Incorrect Length Value",
        "description": "The product uses a sequential operation to read or write a buffer, but it uses an incorrect length value that causes it to access memory that is outside of the bounds of the buffer.",
        "detail": "**Extended Description:**\nWhen the length value exceeds the size of the destination, a buffer overflow could occur.\n\n**Consequence Note:** Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy. This can often be used to subvert any other security service.\n\n**Consequence Note:** Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.\n",
        "parent": [
            "119"
        ],
        "children": [],
        "related": [
            "130"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.\n\n\nAutomated static analysis generally does not account for environmental considerations when reporting out-of-bounds memory operations. This can make it difficult for users to determine which warnings should be investigated first. For example, an analysis tool might report buffer overflows that originate from command line arguments in a program that is not expected to run with setuid or other special privileges.\n\n\n**Detection:** This weakness can be detected using dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Detection:** Manual analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. This becomes difficult for weaknesses that must be considered for all inputs, since the attack surface can be too large.\n\n**Mitigation:** \n\nUse a language that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, many languages that perform their own memory management, such as Java and Perl, are not subject to buffer overflows. Other languages, such as Ada and C#, typically provide overflow protection, but the protection can be disabled by the programmer.\n\n\nBe wary that a language's interface to native code may still be subject to overflows, even if the language itself is theoretically safe.\n\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nExamples include the Safe C String Library (SafeStr) by Messier and Viega [REF-57], and the Strsafe.h library from Microsoft [REF-56]. These libraries provide safer versions of overflow-prone string-handling functions.\n\n\n**Effectiveness:** This is not a complete solution, since many buffer overflows are not related to strings.\n\n**Mitigation:** \n\nUse automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking. \n\n\n D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail. \n\n\n**Effectiveness:** \n\n This is not necessarily a complete solution, since these mechanisms only detect certain types of overflows. In addition, the result is still a denial of service, since the typical response is to exit the application. \n\n\n**Mitigation:** \n\nConsider adhering to the following rules when allocating and managing an application's memory:\n\n\n  - Double check that the buffer is as large as specified.\n\n  - When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string.\n\n  - Check buffer boundaries if accessing the buffer in a loop and make sure there is no danger of writing past the allocated space.\n\n  - If necessary, truncate all input strings to a reasonable length before passing them to the copy and concatenation functions.\n\n\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nRun or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code. \n\n\n Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking. \n\n\n For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335]. \n\n\n**Effectiveness:** These techniques do not provide a complete solution. For instance, exploits frequently use a bug that discloses memory addresses in order to maximize reliability of code execution [REF-1337]. It has also been shown that a side-channel attack can bypass ASLR [REF-1333].\n\n**Mitigation:** \n\n Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment. \n\n\n For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336]. \n\n\n**Effectiveness:** This is not a complete solution, since buffer overflows could be used to overwrite nearby variables to modify the software's state in dangerous ways. In addition, it cannot be used in cases in which self-modifying code is required. Finally, an attack could still cause a denial of service, since the typical response is to exit the application.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the product or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** \n\nRun the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n\n\nOS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Effectiveness:** The effectiveness of this mitigation depends on the prevention capabilities of the specific sandbox or jail being used and might only help to reduce the scope of an attack, such as restricting the attacker to certain system calls or limiting the portion of the file system that can be accessed.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "806",
        "name": "Buffer Access Using Size of Source Buffer",
        "description": "The product uses the size of a source buffer when reading from or writing to a destination buffer, which may cause it to access memory that is outside of the bounds of the buffer.",
        "detail": "**Extended Description:**\nWhen the size of the destination is smaller than the size of the source, a buffer overflow could occur.\n\n**Consequence Note:** Buffer overflows generally lead to crashes. Other attacks leading to lack of availability are possible, including putting the program into an infinite loop.\n\n**Consequence Note:** Buffer overflows often can be used to execute arbitrary code, which is usually outside the scope of a program's implicit security policy.\n\n**Consequence Note:** When the consequence is arbitrary code execution, this can often be used to subvert any other security service.\n",
        "parent": [
            "805"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Use an abstraction library to abstract away risky APIs. Examples include the Safe C String Library (SafeStr) by Viega, and the Strsafe.h library from Microsoft. This is not a complete solution, since many buffer overflows are not related to strings.\n\n**Mitigation:** \n\nUse automatic buffer overflow detection mechanisms that are offered by certain compilers or compiler extensions. Examples include: the Microsoft Visual Studio /GS flag, Fedora/Red Hat FORTIFY_SOURCE GCC flag, StackGuard, and ProPolice, which provide various mechanisms including canary-based detection and range/index checking. \n\n\n D3-SFCV (Stack Frame Canary Validation) from D3FEND [REF-1334] discusses canary-based detection in detail. \n\n\n**Effectiveness:** \n\n This is not necessarily a complete solution, since these mechanisms only detect certain types of overflows. In addition, the result is still a denial of service, since the typical response is to exit the application. \n\n\n**Mitigation:** Programmers should adhere to the following rules when allocating and managing their applications memory: Double check that your buffer is as large as you specify. When using functions that accept a number of bytes to copy, such as strncpy(), be aware that if the destination buffer size is equal to the source buffer size, it may not NULL-terminate the string. Check buffer boundaries if calling this function in a loop and make sure there is no danger of writing past the allocated space. Truncate all input strings to a reasonable length before passing them to the copy and concatenation functions.\n\n**Mitigation:** \n\nRun or compile the software using features or extensions that randomly arrange the positions of a program's executable and libraries in memory. Because this makes the addresses unpredictable, it can prevent an attacker from reliably jumping to exploitable code. \n\n\n Examples include Address Space Layout Randomization (ASLR) [REF-58] [REF-60] and Position-Independent Executables (PIE) [REF-64]. Imported modules may be similarly realigned if their default memory addresses conflict with other modules, in a process known as \"rebasing\" (for Windows) and \"prelinking\" (for Linux) [REF-1332] using randomly generated addresses. ASLR for libraries cannot be used in conjunction with prelink since it would require relocating the libraries at run-time, defeating the whole purpose of prelinking. \n\n\n For more information on these techniques see D3-SAOR (Segment Address Offset Randomization) from D3FEND [REF-1335]. \n\n\n**Effectiveness:** These techniques do not provide a complete solution. For instance, exploits frequently use a bug that discloses memory addresses in order to maximize reliability of code execution [REF-1337]. It has also been shown that a side-channel attack can bypass ASLR [REF-1333].\n\n**Mitigation:** \n\n Use a CPU and operating system that offers Data Execution Protection (using hardware NX or XD bits) or the equivalent techniques that simulate this feature in software, such as PaX [REF-60] [REF-61]. These techniques ensure that any instruction executed is exclusively at a memory address that is part of the code segment. \n\n\n For more information on these techniques see D3-PSEP (Process Segment Execution Prevention) from D3FEND [REF-1336]. \n\n\n**Effectiveness:** This is not a complete solution, since buffer overflows could be used to overwrite nearby variables to modify the software's state in dangerous ways. In addition, it cannot be used in cases in which self-modifying code is required. Finally, an attack could still cause a denial of service, since the typical response is to exit the application.\n\n**Mitigation:** Most mitigating technologies at the compiler or OS level to date address only a subset of buffer overflow problems and rarely provide complete protection against even that subset. It is good practice to implement strategies to increase the workload of an attacker, such as leaving the attacker to guess an unknown value that changes every program execution.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "807",
        "name": "Reliance on Untrusted Inputs in a Security Decision",
        "description": "The product uses a protection mechanism that relies on the existence or values of an input, but the input can be modified by an untrusted actor in a way that bypasses the protection mechanism.",
        "detail": "**Extended Description:**\n\n\nDevelopers may assume that inputs such as cookies, environment variables, and hidden form fields cannot be modified. However, an attacker could change these inputs using customized clients or other attacks. This change might not be detected. When security decisions such as authentication and authorization are made based on the values of these inputs, attackers can bypass the security of the software.\n\n\nWithout sufficient encryption, integrity checking, or other mechanism, any input that originates from an outsider cannot be trusted.\n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** Attackers can bypass the security decision to access whatever is being protected. The consequences will depend on the associated functionality, but they can range from granting additional privileges to untrusted users to bypassing important security checks. Ultimately, this weakness may lead to exposure or modification of sensitive data, system crash, or execution of arbitrary code.\n",
        "parent": [
            "693"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Detection:** Since this weakness does not typically appear frequently within a single software package, manual white box techniques may be able to provide sufficient code coverage and reduction of false positives if all potentially-vulnerable operations can be assessed within limited time constraints.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\t\tDatabase Scanners\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\t\tMonitored Virtual Environment - run potentially malicious code in sandbox / wrapper / virtual machine, see if it does anything suspicious\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAttack Modeling\n\n**Mitigation:** \n\nStore state information and sensitive data on the server side only.\n\n\nEnsure that the system definitively and unambiguously keeps track of its own state and user state and has rules defined for legitimate state transitions. Do not allow any application user to affect state directly in any way other than through legitimate actions leading to state transitions.\n\n\nIf information must be stored on the client, do not do so without encryption and integrity checking, or otherwise having a mechanism on the server side to catch tampering. Use a message authentication code (MAC) algorithm, such as Hash Message Authentication Code (HMAC) [REF-529]. Apply this against the state or sensitive data that has to be exposed, which can guarantee the integrity of the data - i.e., that the data has not been modified. Ensure that a strong hash function is used (CWE-328).\n\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nWith a stateless protocol such as HTTP, use a framework that maintains the state for you.\n\n\nExamples include ASP.NET View State [REF-756] and the OWASP ESAPI Session Management feature [REF-45].\n\n\nBe careful of language features that provide state support, since these might be provided as a convenience to the programmer and may not be considering security.\n\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n\n**Mitigation:** \n\nUnderstand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n\n\nIdentify all inputs that are used for security decisions and determine if you can modify the design so that you do not have to rely on submitted inputs at all. For example, you may be able to keep critical information about the user's session on the server side instead of recording it within external data.\n\n",
        "languages": []
    },
    {
        "cwe": "81",
        "name": "Improper Neutralization of Script in an Error Message Web Page",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes special characters that could be interpreted as web-scripting elements when they are sent to an error page.",
        "detail": "**Extended Description:**\n\n\nError pages may include customized 403 Forbidden or 404 Not Found pages.\n\n\nWhen an attacker can trigger an error that contains script syntax within the attacker's input, then cross-site scripting attacks may be possible.\n\n",
        "parent": [
            "79"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Do not write user-controlled input to error pages.\n\n**Mitigation:** Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.\n\n**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** With Struts, write all data from form beans with the bean's filter attribute set to true.\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n",
        "languages": []
    },
    {
        "cwe": "82",
        "name": "Improper Neutralization of Script in Attributes of IMG Tags in a Web Page",
        "description": "The web application does not neutralize or incorrectly neutralizes scripting elements within attributes of HTML IMG tags, such as the src attribute.",
        "detail": "**Extended Description:**\nAttackers can embed XSS exploits into the values for IMG attributes (e.g. SRC) that is streamed and then executed in a victim's browser. Note that when the page is loaded into a user's browsers, the exploit will automatically execute.\n",
        "parent": [
            "83"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n",
        "languages": []
    },
    {
        "cwe": "820",
        "name": "Missing Synchronization",
        "description": "The product utilizes a shared resource in a concurrent manner but does not attempt to synchronize access to the resource.",
        "detail": "**Extended Description:**\nIf access to a shared resource is not synchronized, then the resource may not be in a state that is expected by the product. This might lead to unexpected or insecure behaviors, especially if an attacker can influence the shared resource.\n",
        "parent": [
            "662"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "821",
        "name": "Incorrect Synchronization",
        "description": "The product utilizes a shared resource in a concurrent manner, but it does not correctly synchronize access to the resource.",
        "detail": "**Extended Description:**\nIf access to a shared resource is not correctly synchronized, then the resource may not be in a state that is expected by the product. This might lead to unexpected or insecure behaviors, especially if an attacker can influence the shared resource.\n",
        "parent": [
            "662"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "822",
        "name": "Untrusted Pointer Dereference",
        "description": "The product obtains a value from an untrusted source, converts this value to a pointer, and dereferences the resulting pointer.",
        "detail": "**Extended Description:**\n\n\nAn attacker can supply a pointer for memory locations that the product is not expecting. If the pointer is dereferenced for a write operation, the attack might allow modification of critical state variables, cause a crash, or execute code. If the dereferencing operation is for a read, then the attack might allow reading of sensitive data, cause a crash, or set a variable to an unexpected value (since the value will be read from an unexpected memory location).\n\n\nThere are several variants of this weakness, including but not necessarily limited to:\n\n\n  - The untrusted value is directly invoked as a function call.\n\n  - In OS kernels or drivers where there is a boundary between \"userland\" and privileged memory spaces, an untrusted pointer might enter through an API or system call (see CWE-781 for one such example).\n\n  - Inadvertently accepting the value from an untrusted control sphere when it did not have to be accepted as input at all. This might occur when the code was originally developed to be run by a single user in a non-networked environment, and the code is then ported to or otherwise exposed to a networked environment.\n\n\n\n**Consequence Note:** If the untrusted pointer is used in a read operation, an attacker might be able to read sensitive portions of memory.\n\n**Consequence Note:** If the untrusted pointer references a memory location that is not accessible to the product, or points to a location that is \"malformed\" or larger than expected by a read or write operation, the application may terminate unexpectedly.\n\n**Consequence Note:** If the untrusted pointer is used in a function call, or points to unexpected data in a write operation, then code execution may be possible.\n",
        "parent": [
            "119"
        ],
        "children": [],
        "related": [
            "125",
            "787"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "823",
        "name": "Use of Out-of-range Pointer Offset",
        "description": "The product performs pointer arithmetic on a valid pointer, but it uses an offset that can point outside of the intended range of valid memory locations for the resulting pointer.",
        "detail": "**Extended Description:**\n\n\nWhile a pointer can contain a reference to any arbitrary memory location, a program typically only intends to use the pointer to access limited portions of memory, such as contiguous memory used to access an individual array.\n\n\nPrograms may use offsets in order to access fields or sub-elements stored within structured data. The offset might be out-of-range if it comes from an untrusted source, is the result of an incorrect calculation, or occurs because of another error.\n\n\nIf an attacker can control or influence the offset so that it points outside of the intended boundaries of the structure, then the attacker may be able to read or write to memory locations that are used elsewhere in the product. As a result, the attack might change the state of the product as accessed through program variables, cause a crash or instable behavior, and possibly lead to code execution.\n\n\n**Alternate Terms:** Untrusted pointer offset\n\n**Consequence Note:** If the untrusted pointer is used in a read operation, an attacker might be able to read sensitive portions of memory.\n\n**Consequence Note:** If the untrusted pointer references a memory location that is not accessible to the program, or points to a location that is \"malformed\" or larger than expected by a read or write operation, the application may terminate unexpectedly.\n\n**Consequence Note:** If the untrusted pointer is used in a function call, or points to unexpected data in a write operation, then code execution may be possible.\n",
        "parent": [
            "119"
        ],
        "children": [],
        "related": [
            "125",
            "787"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "824",
        "name": "Access of Uninitialized Pointer",
        "description": "The product accesses or uses a pointer that has not been initialized.",
        "detail": "**Extended Description:**\n\n\nIf the pointer contains an uninitialized value, then the value might not point to a valid memory location. This could cause the product to read from or write to unexpected memory locations, leading to a denial of service. If the uninitialized pointer is used as a function call, then arbitrary functions could be invoked. If an attacker can influence the portion of uninitialized memory that is contained in the pointer, this weakness could be leveraged to execute code or perform other attacks.\n\n\nDepending on memory layout, associated memory management behaviors, and product operation, the attacker might be able to influence the contents of the uninitialized pointer, thus gaining more fine-grained control of the memory location to be accessed.\n\n\n**Consequence Note:** If the uninitialized pointer is used in a read operation, an attacker might be able to read sensitive portions of memory.\n\n**Consequence Note:** If the uninitialized pointer references a memory location that is not accessible to the product, or points to a location that is \"malformed\" (such as NULL) or larger than expected by a read or write operation, then a crash may occur.\n\n**Consequence Note:** If the uninitialized pointer is used in a function call, or points to unexpected data in a write operation, then code execution may be possible.\n",
        "parent": [
            "119"
        ],
        "children": [],
        "related": [
            "125",
            "787"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "825",
        "name": "Expired Pointer Dereference",
        "description": "The product dereferences a pointer that contains a location for memory that was previously valid, but is no longer valid.",
        "detail": "**Extended Description:**\nWhen a product releases memory, but it maintains a pointer to that memory, then the memory might be re-allocated at a later time. If the original pointer is accessed to read or write data, then this could cause the product to read or modify data that is in use by a different function or process. Depending on how the newly-allocated memory is used, this could lead to a denial of service, information exposure, or code execution.\n\n**Alternate Terms:** Dangling pointer\n\n**Consequence Note:** If the expired pointer is used in a read operation, an attacker might be able to control data read in by the application.\n\n**Consequence Note:** If the expired pointer references a memory location that is not accessible to the product, or points to a location that is \"malformed\" (such as NULL) or larger than expected by a read or write operation, then a crash may occur.\n\n**Consequence Note:** If the expired pointer is used in a function call, or points to unexpected data in a write operation, then code execution may be possible.\n",
        "parent": [
            "119",
            "672"
        ],
        "children": [],
        "related": [
            "125",
            "787"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Choose a language that provides automatic memory management.\n\n**Mitigation:** When freeing pointers, be sure to set them to NULL once they are freed. However, the utilization of multiple or complex data structures may lower the usefulness of this strategy.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "826",
        "name": "Premature Release of Resource During Expected Lifetime",
        "description": "The product releases a resource that is still intended to be used by itself or another actor.",
        "detail": "**Extended Description:**\n\n\nThis weakness focuses on errors in which the product should not release a resource, but performs the release anyway. This is different than a weakness in which the product releases a resource at the appropriate time, but it maintains a reference to the resource, which it later accesses. For this weakness, the resource should still be valid upon the subsequent access.\n\n\nWhen a product releases a resource that is still being used, it is possible that operations will still be taken on this resource, which may have been repurposed in the meantime, leading to issues similar to CWE-825. Consequences may include denial of service, information exposure, or code execution.\n\n\n**Consequence Note:** If the released resource is subsequently reused or reallocated, then a read operation on the original resource might access sensitive data that is associated with a different user or entity.\n\n**Consequence Note:** When the resource is released, the software might modify some of its structure, or close associated channels (such as a file descriptor). When the software later accesses the resource as if it is valid, the resource might not be in an expected state, leading to resultant errors that may lead to a crash.\n\n**Consequence Note:** When the resource is released, the software might modify some of its structure. This might affect logic in the sections of code that still assume the resource is active. If the released resource is related to memory and is used in a function call, or points to unexpected data in a write operation, then code execution may be possible upon subsequent accesses.\n",
        "parent": [
            "666"
        ],
        "children": [],
        "related": [
            "672"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "827",
        "name": "Improper Control of Document Type Definition",
        "description": "The product does not restrict a reference to a Document Type Definition (DTD) to the intended control sphere. This might allow attackers to reference arbitrary DTDs, possibly causing the product to expose files, consume excessive system resources, or execute arbitrary http requests on behalf of the attacker.",
        "detail": "**Extended Description:**\n\n\nAs DTDs are processed, they might try to read or include files on the machine performing the parsing. If an attacker is able to control the DTD, then the attacker might be able to specify sensitive resources or requests or provide malicious content.\n\n\nFor example, the SOAP specification prohibits SOAP messages from containing DTDs.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** If the attacker is able to include a crafted DTD and a default entity resolver is enabled, the attacker may be able to access arbitrary files on the system.\n\n**Consequence Note:** The DTD may cause the parser to consume excessive CPU cycles or memory using techniques such as nested or recursive entity references (CWE-776).\n\n**Consequence Note:** The DTD may include arbitrary HTTP requests that the server may execute. This could lead to other attacks leveraging the server's trust relationship with other entities.\n",
        "parent": [
            "706",
            "829"
        ],
        "children": [],
        "related": [
            "776"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": [
            "XML"
        ]
    },
    {
        "cwe": "828",
        "name": "Signal Handler with Functionality that is not Asynchronous-Safe",
        "description": "The product defines a signal handler that contains code sequences that are not asynchronous-safe, i.e., the functionality is not reentrant, or it can be interrupted.",
        "detail": "**Extended Description:**\n\n\nThis can lead to an unexpected system state with a variety of potential consequences depending on context, including denial of service and code execution.\n\n\nSignal handlers are typically intended to interrupt normal functionality of a program, or even other signals, in order to notify the process of an event. When a signal handler uses global or static variables, or invokes functions that ultimately depend on such state or its associated metadata, then it could corrupt system state that is being used by normal functionality. This could subject the program to race conditions or other weaknesses that allow an attacker to cause the program state to be corrupted. While denial of service is frequently the consequence, in some cases this weakness could be leveraged for code execution.\n\n\nThere are several different scenarios that introduce this issue:\n\n\n  - Invocation of non-reentrant functions from within the handler. One example is malloc(), which modifies internal global variables as it manages memory. Very few functions are actually reentrant.\n\n  - Code sequences (not necessarily function calls) contain non-atomic use of global variables, or associated metadata or structures, that can be accessed by other functionality of the program, including other signal handlers. Frequently, the same function is registered to handle multiple signals.\n\n  - The signal handler function is intended to run at most one time, but instead it can be invoked multiple times. This could happen by repeated delivery of the same signal, or by delivery of different signals that have the same handler function (CWE-831).\n\nNote that in some environments or contexts, it might be possible for the signal handler to be interrupted itself.\n\nIf both a signal handler and the normal behavior of the product have to operate on the same set of state variables, and a signal is received in the middle of the normal execution's modifications of those variables, the variables may be in an incorrect or corrupt state during signal handler execution, and possibly still incorrect or corrupt upon return.\n\n\n**Consequence Note:** The most common consequence will be a corruption of the state of the product, possibly leading to a crash or exit. However, if the signal handler is operating on state variables for security relevant libraries or protection mechanisms, the consequences can be far more severe, including protection mechanism bypass, privilege escalation, or information exposure.\n",
        "parent": [
            "364"
        ],
        "children": [
            "479"
        ],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** \n\nEliminate the usage of non-reentrant functionality inside of signal handlers. This includes replacing all non-reentrant library calls with reentrant calls.\n\n\nNote: This will not always be possible and may require large portions of the product to be rewritten or even redesigned. Sometimes reentrant-safe library alternatives will not be available. Sometimes non-reentrant interaction between the state of the system and the signal handler will be required by design.\n\n\n**Mitigation:** Where non-reentrant functionality must be leveraged within a signal handler, be sure to block or mask signals appropriately. This includes blocking other signals within the signal handler itself that may also leverage the functionality. It also includes blocking all signals reliant upon the functionality when it is being accessed or modified by the normal behaviors of the product.\n",
        "languages": []
    },
    {
        "cwe": "829",
        "name": "Inclusion of Functionality from Untrusted Control Sphere",
        "description": "The product imports, requires, or includes executable functionality (such as a library) from a source that is outside of the intended control sphere.",
        "detail": "**Extended Description:**\n\n\nWhen including third-party functionality, such as a web widget, library, or other source of functionality, the product must effectively trust that functionality. Without sufficient protection mechanisms, the functionality could be malicious in nature (either by coming from an untrusted source, being spoofed, or being modified in transit from a trusted source). The functionality might also contain its own weaknesses, or grant access to additional functionality and state information that should be kept private to the base system, such as system state information, sensitive application data, or the DOM of a web application.\n\n\nThis might lead to many different consequences depending on the included functionality, but some examples include injection of malware, information exposure by granting excessive privileges or permissions to the untrusted functionality, DOM-based XSS vulnerabilities, stealing user's cookies, or open redirect to malware (CWE-601).\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could insert malicious functionality into the program by causing the program to download code that the attacker has placed into the untrusted control sphere, such as a malicious web site.\n",
        "parent": [
            "669"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tForced Path Execution\n\t\tMonitored Virtual Environment - run potentially malicious code in sandbox / wrapper / virtual machine, see if it does anything suspicious\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tAttack Modeling\n\n**Mitigation:** Use a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n**Mitigation:** \n\nWhen the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n\nFor example, ID 1 could map to \"inbox.txt\" and ID 2 could map to \"profile.txt\". Features such as the ESAPI AccessReferenceMap [REF-45] provide this capability.\n\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nRun the code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which files can be accessed in a particular directory or which commands can be executed by the software.\n\n\nOS-level examples include the Unix chroot jail, AppArmor, and SELinux. In general, managed code may provide some protection. For example, java.io.FilePermission in the Java SecurityManager allows the software to specify restrictions on file operations.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of the application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Effectiveness:** The effectiveness of this mitigation depends on the prevention capabilities of the specific sandbox or jail being used and might only help to reduce the scope of an attack, such as restricting the attacker to certain system calls or limiting the portion of the file system that can be accessed.\n\n**Mitigation:** Run your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen validating filenames, use stringent allowlists that limit the character set to be used. If feasible, only allow a single \".\" character in the filename to avoid weaknesses such as CWE-23, and exclude directory separators such as \"/\" to avoid CWE-36. Use a list of allowable file extensions, which will help to avoid CWE-434.\n\n\nDo not rely exclusively on a filtering mechanism that removes potentially dangerous characters. This is equivalent to a denylist, which may be incomplete (CWE-184). For example, filtering \"/\" is insufficient protection if the filesystem also supports the use of \"\\\" as a directory separator. Another possible error could occur when the filtering is applied in a way that still produces dangerous data (CWE-182). For example, if \"../\" sequences are removed from the \".../...//\" string in a sequential fashion, two instances of \"../\" would be removed from the original string, but the remaining characters would still form the \"../\" string.\n\n\n**Mitigation:** \n\nStore library, include, and utility files outside of the web document root, if possible. Otherwise, store them in a separate directory and use the web server's access control capabilities to prevent attackers from directly requesting them. One common practice is to define a fixed constant in each calling program, then check for the existence of the constant in the library/include file; if the constant does not exist, then the file was directly requested, and it can exit immediately.\n\n\nThis significantly reduces the chance of an attacker being able to bypass any protection mechanisms that are in the base program but not in the include files. It will also reduce the attack surface.\n\n\n**Mitigation:** \n\nUnderstand all the potential areas where untrusted inputs can enter your software: parameters or arguments, cookies, anything read from the network, environment variables, reverse DNS lookups, query results, request headers, URL components, e-mail, files, filenames, databases, and any external systems that provide data to the application. Remember that such inputs may be obtained indirectly through API calls.\n\n\nMany file inclusion problems occur because the programmer assumed that certain inputs could not be modified, especially for cookies and URL components.\n\n\n**Mitigation:** Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.\n\n**Effectiveness:** An application firewall might not cover all possible input vectors. In addition, attack techniques might be available to bypass the protection mechanism, such as using malformed inputs that can still be processed by the component that receives those inputs. Depending on functionality, an application firewall might inadvertently reject or modify legitimate requests. Finally, some manual effort may be required for customization.\n",
        "languages": []
    },
    {
        "cwe": "83",
        "name": "Improper Neutralization of Script in Attributes in a Web Page",
        "description": "The product does not neutralize or incorrectly neutralizes \"javascript:\" or other URIs from dangerous attributes within tags, such as onmouseover, onload, onerror, or style.",
        "detail": null,
        "parent": [
            "79"
        ],
        "children": [
            "82"
        ],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including tag attributes, hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.\n\n**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** With Struts, write all data from form beans with the bean's filter attribute set to true.\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n",
        "languages": []
    },
    {
        "cwe": "830",
        "name": "Inclusion of Web Functionality from an Untrusted Source",
        "description": "The product includes web functionality (such as a web widget) from another domain, which causes it to operate within the domain of the product, potentially granting total access and control of the product to the untrusted source.",
        "detail": "**Extended Description:**\n\n\nIncluding third party functionality in a web-based environment is risky, especially if the source of the functionality is untrusted.\n\n\nEven if the third party is a trusted source, the product may still be exposed to attacks and malicious behavior if that trusted source is compromised, or if the code is modified in transmission from the third party to the product.\n\n\nThis weakness is common in \"mashup\" development on the web, which may include source functionality from other domains. For example, Javascript-based web widgets may be inserted by using '<SCRIPT SRC=\"http://other.domain.here\">' tags, which causes the code to run in the domain of the product, not the remote site from which the widget was loaded. As a result, the included code has access to the local DOM, including cookies and other data that the developer might not want the remote site to be able to access.\n\n\nSuch dependencies may be desirable, or even required, but sometimes programmers are not aware that a dependency exists.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "829"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "831",
        "name": "Signal Handler Function Associated with Multiple Signals",
        "description": "The product defines a function that is used as a handler for more than one signal.",
        "detail": "**Extended Description:**\n\n\nWhile sometimes intentional and safe, when the same function is used to handle multiple signals, a race condition could occur if the function uses any state outside of its local declaration, such as global variables or non-reentrant functions, or has any side effects.\n\n\nAn attacker could send one signal that invokes the handler function; in many OSes, this will typically prevent the same signal from invoking the handler again, at least until the handler function has completed execution. However, the attacker could then send a different signal that is associated with the same handler function. This could interrupt the original handler function while it is still executing. If there is shared state, then the state could be corrupted. This can lead to a variety of potential consequences depending on context, including denial of service and code execution.\n\n\nAnother rarely-explored possibility arises when the signal handler is only designed to be executed once (if at all). By sending multiple signals, an attacker could invoke the function more than once. This may generate extra, unintended side effects. A race condition might not even be necessary; the attacker could send one signal, wait until it is handled, then send the other signal.\n\n\n**Consequence Note:** The most common consequence will be a corruption of the state of the product, possibly leading to a crash or exit. However, if the signal handler is operating on state variables for security relevant libraries or protection mechanisms, the consequences can be far more severe, including protection mechanism bypass, privilege escalation, or information exposure.\n",
        "parent": [
            "364"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "832",
        "name": "Unlock of a Resource that is not Locked",
        "description": "The product attempts to unlock a resource that is not locked.",
        "detail": "**Extended Description:**\nDepending on the locking functionality, an unlock of a non-locked resource might cause memory corruption or other modification to the resource (or its associated metadata that is used for tracking locks).\n\n**Consequence Note:** Depending on the locking being used, an unlock operation might not have any adverse effects. When effects exist, the most common consequence will be a corruption of the state of the product, possibly leading to a crash or exit; depending on the implementation of the unlocking, memory corruption or code execution could occur.\n",
        "parent": [
            "667"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "833",
        "name": "Deadlock",
        "description": "The product contains multiple threads or executable segments that are waiting for each other to release a necessary lock, resulting in deadlock.",
        "detail": "**Consequence Note:** Each thread of execution will \"hang\" and prevent tasks from completing. In some cases, CPU consumption may occur if a lock check occurs in a tight loop.\n",
        "parent": [
            "662",
            "667"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "834",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "1322",
            "835"
        ],
        "related": [
            "606"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "835",
        "name": "Loop with Unreachable Exit Condition ('Infinite Loop')",
        "description": "The product contains an iteration or loop with an exit condition that cannot be reached, i.e., an infinite loop.",
        "detail": "**Consequence Note:** An infinite loop will cause unexpected consumption of resources, such as CPU cycles or memory. The software's operation may slow down, or cause a long time to respond.\n",
        "parent": [
            "834"
        ],
        "children": [],
        "related": [
            "1322"
        ],
        "scopes": [
            "Availability"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "836",
        "name": "Use of Password Hash Instead of Password for Authentication",
        "description": "The product records password hashes in a data store, receives a hash of a password from a client, and compares the supplied hash to the hash obtained from the data store.",
        "detail": "**Extended Description:**\n\n\nSome authentication mechanisms rely on the client to generate the hash for a password, possibly to reduce load on the server or avoid sending the password across the network. However, when the client is used to generate the hash, an attacker can bypass the authentication by obtaining a copy of the hash, e.g. by using SQL injection to compromise a database of authentication credentials, or by exploiting an information exposure. The attacker could then use a modified client to replay the stolen hash without having knowledge of the original password.\n\n\nAs a result, the server-side comparison against a client-side hash does not provide any more security than the use of passwords without hashing.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could bypass the authentication routine without knowing the original password.\n",
        "parent": [
            "1390"
        ],
        "children": [],
        "related": [
            "602"
        ],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "837",
        "name": "Improper Enforcement of a Single, Unique Action",
        "description": "The product requires that an actor should only be able to perform an action once, or to have only one unique action, but the product does not enforce or improperly enforces this restriction.",
        "detail": "**Extended Description:**\nIn various applications, a user is only expected to perform a certain action once, such as voting, requesting a refund, or making a purchase. When this restriction is not enforced, sometimes this can have security implications. For example, in a voting application, an attacker could attempt to \"stuff the ballot box\" by voting multiple times. If these votes are counted separately, then the attacker could directly affect who wins the vote. This could have significant business impact depending on the purpose of the product.\n\n**Consequence Note:** An attacker might be able to gain advantage over other users by performing the action multiple times, or affect the correctness of the product.\n",
        "parent": [
            "799"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "838",
        "name": "Inappropriate Encoding for Output Context",
        "description": "The product uses or specifies an encoding when generating output to a downstream component, but the specified encoding is not the same as the encoding that is expected by the downstream component.",
        "detail": "**Extended Description:**\n\n\nThis weakness can cause the downstream component to use a decoding method that produces different data than what the product intended to send. When the wrong encoding is used - even if closely related - the downstream component could decode the data incorrectly. This can have security consequences when the provided boundaries between control and data are inadvertently broken, because the resulting data could introduce control characters or special elements that were not sent by the product. The resulting data could then be used to bypass protection mechanisms such as input validation, and enable injection attacks.\n\n\nWhile using output encoding is essential for ensuring that communications between components are accurate, the use of the wrong encoding - even if closely related - could cause the downstream component to misinterpret the output.\n\n\nFor example, HTML entity encoding is used for elements in the HTML body of a web page. However, a programmer might use entity encoding when generating output for that is used within an attribute of an HTML tag, which could contain functional Javascript that is not affected by the HTML encoding.\n\n\nWhile web applications have received the most attention for this problem, this weakness could potentially apply to any type of product that uses a communications stream that could support multiple encodings.\n\n\n**Consequence Note:** An attacker could modify the structure of the message or data being sent to the downstream component, possibly injecting commands.\n",
        "parent": [
            "116"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Use context-aware encoding. That is, understand which encoding is being used by the downstream component, and ensure that this encoding is used. If an encoding can be specified, do so, instead of assuming that the default encoding is the same as the default being assumed by the downstream component.\n\n**Mitigation:** Where possible, use communications protocols or data formats that provide strict boundaries between control and data. If this is not feasible, ensure that the protocols or formats allow the communicating components to explicitly state which encoding/decoding method is being used. Some template frameworks provide built-in support.\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, consider using the ESAPI Encoding control [REF-45] or a similar tool, library, or framework. These will help the programmer encode outputs in a manner less prone to error.\n\n\nNote that some template mechanisms provide built-in support for the appropriate encoding.\n\n",
        "languages": []
    },
    {
        "cwe": "839",
        "name": "Numeric Range Comparison Without Minimum Check",
        "description": "The product checks a value to ensure that it is less than or equal to a maximum, but it does not also verify that the value is greater than or equal to the minimum.",
        "detail": "**Extended Description:**\n\n\nSome products use signed integers or floats even when their values are only expected to be positive or 0. An input validation check might assume that the value is positive, and only check for the maximum value. If the value is negative, but the code assumes that the value is positive, this can produce an error. The error may have security consequences if the negative value is used for memory allocation, array access, buffer access, etc. Ultimately, the error could lead to a buffer overflow or other type of memory corruption.\n\n\nThe use of a negative number in a positive-only context could have security implications for other types of resources. For example, a shopping cart might check that the user is not requesting more than 10 items, but a request for -3 items could cause the application to calculate a negative price and credit the attacker's account.\n\n\n**Alternate Terms:** Signed comparison\n\n**Consequence Note:** An attacker could modify the structure of the message or data being sent to the downstream component, possibly injecting commands.\n\n**Consequence Note:** in some contexts, a negative value could lead to resource consumption.\n\n**Consequence Note:** If a negative value is used to access memory, buffers, or other indexable structures, it could access memory outside the bounds of the buffer.\n",
        "parent": [
            "1023"
        ],
        "children": [],
        "related": [
            "119",
            "124",
            "195",
            "682"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** If the number to be used is always expected to be positive, change the variable type from signed to unsigned or size_t.\n\n**Mitigation:** If the number to be used could have a negative value based on the specification (thus requiring a signed value), but the number should only be positive to preserve code correctness, then include a check to ensure that the value is positive.\n",
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "84",
        "name": "Improper Neutralization of Encoded URI Schemes in a Web Page",
        "description": "The web application improperly neutralizes user-controlled input for executable script disguised with URI encodings.",
        "detail": null,
        "parent": [
            "79"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Resolve all URIs to absolute or canonical representations before processing.\n\n**Mitigation:** Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including tag attributes, hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.\n\n**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** With Struts, write all data from form beans with the bean's filter attribute set to true.\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n",
        "languages": []
    },
    {
        "cwe": "841",
        "name": "Improper Enforcement of Behavioral Workflow",
        "description": "The product supports a session in which more than one behavior must be performed by an actor, but it does not properly ensure that the actor performs the behaviors in the required sequence.",
        "detail": "**Extended Description:**\n\n\nBy performing actions in an unexpected order, or by omitting steps, an attacker could manipulate the business logic of the product or cause it to enter an invalid state. In some cases, this can also expose resultant weaknesses.\n\n\nFor example, a file-sharing protocol might require that an actor perform separate steps to provide a username, then a password, before being able to transfer files. If the file-sharing server accepts a password command followed by a transfer command, without any username being provided, the product might still perform the transfer.\n\n\nNote that this is different than CWE-696, which focuses on when the product performs actions in the wrong sequence; this entry is closely related, but it is focused on ensuring that the actor performs actions in the correct sequence.\n\n\nWorkflow-related behaviors include:\n\n\n  - Steps are performed in the expected order.\n\n  - Required steps are not omitted.\n\n  - Steps are not interrupted.\n\n  - Steps are performed in a timely fashion.\n\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could cause the product to skip critical steps or perform them in the wrong order, bypassing its intended business logic. This can sometimes have security implications.\n",
        "parent": [
            "691"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "842",
        "name": "Placement of User into Incorrect Group",
        "description": "The product or the administrator places a user into an incorrect group.",
        "detail": "**Extended Description:**\nIf the incorrect group has more access or privileges than the intended group, the user might be able to bypass intended security policy to access unexpected resources or perform unexpected actions. The access-control system might not be able to detect malicious usage of this group membership.\n",
        "parent": [
            "286"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "843",
        "name": "Access of Resource Using Incompatible Type ('Type Confusion')",
        "description": "The product allocates or initializes a resource such as a pointer, object, or variable using one type, but it later accesses that resource using a type that is incompatible with the original type.",
        "detail": "**Extended Description:**\n\n\nWhen the product accesses the resource using an incompatible type, this could trigger logical errors because the resource does not have expected properties. In languages without memory safety, such as C and C++, type confusion can lead to out-of-bounds memory access.\n\n\nWhile this weakness is frequently associated with unions when parsing data with many different embedded object types in C, it can be present in any application that can interpret the same variable or memory location in multiple ways.\n\n\nThis weakness is not unique to C and C++. For example, errors in PHP applications can be triggered by providing array parameters when scalars are expected, or vice versa. Languages such as Perl, which perform automatic conversion of a variable of one type when it is accessed as if it were another type, can also contain these issues.\n\n\n**Alternate Terms:** Object Type Confusion\n\n**Consequence Note:** When a memory buffer is accessed using the wrong type, it could read or write memory out of the bounds of the buffer, if the allocated buffer is smaller than the type that the code is attempting to access, leading to a crash and possibly code execution.\n",
        "parent": [
            "704"
        ],
        "children": [],
        "related": [
            "119",
            "1287"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "85",
        "name": "Doubled Character XSS Manipulations",
        "description": "The web application does not filter user-controlled input for executable script disguised using doubling of the involved characters.",
        "detail": null,
        "parent": [
            "79"
        ],
        "children": [],
        "related": [
            "675"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Resolve all filtered input to absolute or canonical representations before processing.\n\n**Mitigation:** Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including tag attributes, hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.\n\n**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** With Struts, write all data from form beans with the bean's filter attribute set to true.\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n",
        "languages": []
    },
    {
        "cwe": "86",
        "name": "Improper Neutralization of Invalid Characters in Identifiers in Web Pages",
        "description": "The product does not neutralize or incorrectly neutralizes invalid characters or byte sequences in the middle of tag names, URI schemes, and other identifiers.",
        "detail": "**Extended Description:**\nSome web browsers may remove these sequences, resulting in output that may have unintended control implications. For example, the product may attempt to remove a \"javascript:\" URI scheme, but a \"java%00script:\" URI may bypass this check and still be rendered as active javascript by some browsers, allowing XSS or other attacks.\n",
        "parent": [
            "436",
            "79"
        ],
        "children": [],
        "related": [
            "184"
        ],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n",
        "languages": []
    },
    {
        "cwe": "862",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "939"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "863",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "639",
            "804"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "87",
        "name": "Improper Neutralization of Alternate XSS Syntax",
        "description": "The product does not neutralize or incorrectly neutralizes user-controlled input for alternate script syntax.",
        "detail": null,
        "parent": [
            "79"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Resolve all input to absolute or canonical representations before processing.\n\n**Mitigation:** Carefully check each input parameter against a rigorous positive specification (allowlist) defining the specific characters and format allowed. All input should be neutralized, not just parameters that the user is supposed to specify, but all data in the request, including tag attributes, hidden fields, cookies, headers, the URL itself, and so forth. A common mistake that leads to continuing XSS vulnerabilities is to validate only fields that are expected to be redisplayed by the site. We often encounter data from the request that is reflected by the application server or the application that the development team did not anticipate. Also, a field that is not currently reflected may be used by a future developer. Therefore, validating ALL parts of the HTTP request is recommended.\n\n**Mitigation:** \n\nUse and specify an output encoding that can be handled by the downstream component that is reading the output. Common encodings include ISO-8859-1, UTF-7, and UTF-8. When an encoding is not specified, a downstream component may choose a different encoding, either by assuming a default encoding or automatically inferring which encoding is being used, which can be erroneous. When the encodings are inconsistent, the downstream component might treat some character or byte sequences as special, even if they are not special in the original encoding. Attackers might then be able to exploit this discrepancy and conduct injection attacks; they even might be able to bypass protection mechanisms that assume the original encoding is also being used by the downstream component.\n\n\nThe problem of inconsistent output encodings often arises in web pages. If an encoding is not specified in an HTTP header, web browsers often guess about which encoding is being used. This can open up the browser to subtle XSS attacks.\n\n\n**Mitigation:** With Struts, write all data from form beans with the bean's filter attribute set to true.\n\n**Mitigation:** To help mitigate XSS attacks against the user's session cookie, set the session cookie to be HttpOnly. In browsers that support the HttpOnly feature (such as more recent versions of Internet Explorer and Firefox), this attribute can prevent the user's session cookie from being accessible to malicious client-side scripts that use document.cookie. This is not a complete solution, since HttpOnly is not supported by all browsers. More importantly, XMLHTTPRequest and other powerful browser technologies provide read access to HTTP headers, including the Set-Cookie header in which the HttpOnly flag is set.\n",
        "languages": []
    },
    {
        "cwe": "88",
        "name": "Improper Neutralization of Argument Delimiters in a Command ('Argument Injection')",
        "description": "The product constructs a string for a command to be executed by a separate component\nin another control sphere, but it does not properly delimit the\nintended arguments, options, or switches within that command string.",
        "detail": "**Extended Description:**\n\n\nWhen creating commands using interpolation into a string, developers may assume that only the arguments/options that they specify will be processed. This assumption may be even stronger when the programmer has encoded the command in a way that prevents separate commands from being provided maliciously, e.g. in the case of shell metacharacters. When constructing the command, the developer may use whitespace or other delimiters that are required to separate arguments when the command. However, if an attacker can provide an untrusted input that contains argument-separating delimiters, then the resulting command will have more arguments than intended by the developer. The attacker may then be able to change the behavior of the command. Depending on the functionality supported by the extraneous arguments, this may have security-relevant consequences.\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could include arguments that allow unintended commands or code to be executed, allow sensitive data to be read or modified or could cause other unintended behavior.\n",
        "parent": [
            "74",
            "77"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Where possible, avoid building a single string that contains the command and its arguments. Some languages or frameworks have functions that support specifying independent arguments, e.g. as an array, which is used to automatically perform the appropriate quoting or escaping while building the command. For example, in PHP, escapeshellarg() can be used to escape a single argument to system(), or exec() can be called with an array of arguments. In C, code can often be refactored from using system() - which accepts a single string - to using exec(), which requires separate function arguments for each parameter.\n\n**Mitigation:** Understand all the potential areas where untrusted inputs can enter your product: parameters or arguments, cookies, anything read from the network, environment variables, request headers as well as content, URL components, e-mail, files, databases, and any external systems that provide data to the application. Perform input validation at well-defined interfaces.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Directly convert your input type into the expected data type, such as using a conversion function that translates a string into a number. After converting to the expected data type, ensure that the input's values fall within the expected range of allowable values and that multi-field consistencies are maintained.\n\n**Mitigation:** \n\nInputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180, CWE-181). Make sure that your application does not inadvertently decode the same input twice (CWE-174). Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization control.\n\n\nConsider performing repeated canonicalization until your input does not change any more. This will avoid double-decoding and similar scenarios, but it might inadvertently modify inputs that are allowed to contain properly-encoded dangerous content.\n\n\n**Mitigation:** When exchanging data between components, ensure that both components are using the same character encoding. Ensure that the proper encoding is applied at each interface. Explicitly set the encoding you are using whenever the protocol allows you to do so.\n\n**Mitigation:** When your application combines data from multiple sources, perform the validation after the sources have been combined. The individual data elements may pass the validation step but violate the intended restrictions after they have been combined.\n\n**Mitigation:** Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n**Mitigation:** Use dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n",
        "languages": [
            "PHP"
        ]
    },
    {
        "cwe": "89",
        "name": "Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection')",
        "description": "The product constructs all or part of an SQL command using externally-influenced input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could modify the intended SQL command when it is sent to a downstream component. Without sufficient removal or quoting of SQL syntax in user-controllable inputs, the generated SQL query can cause those inputs to be interpreted as SQL instead of ordinary user data.",
        "detail": "**Alternate Terms:** SQL injection, SQLi\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Mode of Introduction:** This weakness typically appears in data-rich applications that save user inputs in a database.\n\n**Consequence Note:** Adversaries could execute system commands, typically by changing the SQL statement to redirect output to a file that can then be executed.\n\n**Consequence Note:** Since SQL databases generally hold sensitive data, loss of confidentiality is a frequent problem with SQL injection vulnerabilities.\n\n**Consequence Note:** If poor SQL commands are used to check user names and passwords or perform other kinds of authentication, it may be possible to connect to the product as another user with no previous knowledge of the password.\n\n**Consequence Note:** If authorization information is held in a SQL database, it may be possible to change this information through the successful exploitation of a SQL injection vulnerability.\n\n**Consequence Note:** Just as it may be possible to read sensitive information, it is also possible to modify or even delete this information with a SQL injection attack.\n",
        "parent": [
            "74",
            "943"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Authentication",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** \n\nThis weakness can often be detected using automated static analysis tools. Many modern tools use data flow analysis or constraint-based techniques to minimize the number of false positives.\n\n\nAutomated static analysis might not be able to recognize when proper input validation is being performed, leading to false positives - i.e., warnings that do not have any security consequences or do not require any code changes.\n\n\nAutomated static analysis might not be able to detect the usage of custom API functions or third-party libraries that indirectly invoke SQL commands, leading to false negatives - especially if the API/library code is not available for analysis.\n\n\n**Detection:** This weakness can be detected using dynamic tools and techniques that interact with the software using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The software's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Detection:** Manual analysis can be useful for finding this weakness, but it might not achieve desired code coverage within limited time constraints. This becomes difficult for weaknesses that must be considered for all inputs, since the attack surface can be too large.\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tDatabase Scanners\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tWeb Application Scanner\n\t\tWeb Services Scanner\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFuzz Tester\n\t\tFramework-based Fuzzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tManual Source Code Review (not inspections)\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** \n\nUse a vetted library or framework that does not allow this weakness to occur or provides constructs that make this weakness easier to avoid.\n\n\nFor example, consider using persistence layers such as Hibernate or Enterprise Java Beans, which can provide significant protection against SQL injection if used properly.\n\n\n**Mitigation:** \n\nIf available, use structured mechanisms that automatically enforce the separation between data and code. These mechanisms may be able to provide the relevant quoting, encoding, and validation automatically, instead of relying on the developer to provide this capability at every point where output is generated.\n\n\nProcess SQL queries using prepared statements, parameterized queries, or stored procedures. These features should accept parameters or variables and support strong typing. Do not dynamically construct and execute query strings within these features using \"exec\" or similar functionality, since this may re-introduce the possibility of SQL injection. [REF-867]\n\n\n**Mitigation:** \n\nRun your code using the lowest privileges that are required to accomplish the necessary tasks [REF-76]. If possible, create isolated accounts with limited privileges that are only used for a single task. That way, a successful attack will not immediately give the attacker access to the rest of the software or its environment. For example, database applications rarely need to run as the database administrator, especially in day-to-day operations.\n\n\nSpecifically, follow the principle of least privilege when creating user accounts to a SQL database. The database users should only have the minimum privileges necessary to use their account. If the requirements of the system indicate that a user can read and modify their own data, then limit their privileges so they cannot read/write others' data. Use the strictest permissions possible on all database objects, such as execute-only for stored procedures.\n\n\n**Mitigation:** For any security checks that are performed on the client side, ensure that these checks are duplicated on the server side, in order to avoid CWE-602. Attackers can bypass the client-side checks by modifying values after the checks have been performed, or by changing the client to remove the client-side checks entirely. Then, these modified values would be submitted to the server.\n\n**Mitigation:** \n\nWhile it is risky to use dynamically-generated query strings, code, or commands that mix control and data together, sometimes it may be unavoidable. Properly quote arguments and escape any special characters within those arguments. The most conservative approach is to escape or filter all characters that do not pass an extremely strict allowlist (such as everything that is not alphanumeric or white space). If some special characters are still needed, such as white space, wrap each argument in quotes after the escaping/filtering step. Be careful of argument injection (CWE-88).\n\n\nInstead of building a new implementation, such features may be available in the database or programming language. For example, the Oracle DBMS_ASSERT package can check or enforce that parameters have certain properties that make them less vulnerable to SQL injection. For MySQL, the mysql_real_escape_string() API function is available in both C and PHP.\n\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nWhen constructing SQL query strings, use stringent allowlists that limit the character set based on the expected value of the parameter in the request. This will indirectly limit the scope of an attack, but this technique is less important than proper output encoding and escaping.\n\n\nNote that proper output encoding, escaping, and quoting is the most effective solution for preventing SQL injection, although input validation may provide some defense-in-depth. This is because it effectively limits what will appear in output. Input validation will not always prevent SQL injection, especially if you are required to support free-form text fields that could contain arbitrary characters. For example, the name \"O'Reilly\" would likely pass the validation step, since it is a common last name in the English language. However, it cannot be directly inserted into the database because it contains the \"'\" apostrophe character, which would need to be escaped or otherwise handled. In this case, stripping the apostrophe might reduce the risk of SQL injection, but it would produce incorrect behavior because the wrong name would be recorded.\n\n\nWhen feasible, it may be safest to disallow meta-characters entirely, instead of escaping them. This will provide some defense in depth. After the data is entered into the database, later processes may neglect to escape meta-characters before use, and you may not have control over those processes.\n\n\n**Mitigation:** When the set of acceptable objects, such as filenames or URLs, is limited or known, create a mapping from a set of fixed input values (such as numeric IDs) to the actual filenames or URLs, and reject all other inputs.\n\n**Mitigation:** \n\nEnsure that error messages only contain minimal details that are useful to the intended audience and no one else. The messages need to strike the balance between being too cryptic (which can confuse users) or being too detailed (which may reveal more than intended). The messages should not reveal the methods that were used to determine the error. Attackers can use detailed information to refine or optimize their original attack, thereby increasing their chances of success.\n\n\nIf errors must be captured in some detail, record them in log messages, but consider what could occur if the log messages can be viewed by attackers. Highly sensitive information such as passwords should never be saved to log files.\n\n\nAvoid inconsistent messaging that might accidentally tip off an attacker about internal state, such as whether a user account exists or not.\n\n\nIn the context of SQL Injection, error messages revealing the structure of a SQL query can help attackers tailor successful attack strings.\n\n\n**Mitigation:** Use an application firewall that can detect attacks against this weakness. It can be beneficial in cases in which the code cannot be fixed (because it is controlled by a third party), as an emergency prevention measure while more comprehensive software assurance measures are applied, or to provide defense in depth.\n\n**Effectiveness:** An application firewall might not cover all possible input vectors. In addition, attack techniques might be available to bypass the protection mechanism, such as using malformed inputs that can still be processed by the component that receives those inputs. Depending on functionality, an application firewall might inadvertently reject or modify legitimate requests. Finally, some manual effort may be required for customization.\n\n**Mitigation:** When using PHP, configure the application so that it does not use register_globals. During implementation, develop the application so that it does not rely on this feature, but be wary of implementing a register_globals emulation that is subject to weaknesses such as CWE-95, CWE-621, and similar issues.\n",
        "languages": [
            "SQL"
        ]
    },
    {
        "cwe": "9",
        "name": "J2EE Misconfiguration: Weak Access Permissions for EJB Methods",
        "description": "If elevated access rights are assigned to EJB methods, then an attacker can take advantage of the permissions to exploit the product.",
        "detail": "**Extended Description:**\nIf the EJB deployment descriptor contains one or more method permissions that grant access to the special ANYONE role, it indicates that access control for the application has not been fully thought through or that the application is structured in such a way that reasonable access control restrictions are impossible.\n",
        "parent": [
            "266"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** Follow the principle of least privilege when assigning access rights to EJB methods. Permission to invoke EJB methods should not be granted to the ANYONE role.\n",
        "languages": []
    },
    {
        "cwe": "90",
        "name": "Improper Neutralization of Special Elements used in an LDAP Query ('LDAP Injection')",
        "description": "The product constructs all or part of an LDAP query using externally-influenced input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could modify the intended LDAP query when it is sent to a downstream component.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker could include input that changes the LDAP query which allows unintended commands or code to be executed, allows sensitive data to be read or modified or causes other unintended behavior.\n",
        "parent": [
            "943"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n",
        "languages": []
    },
    {
        "cwe": "908",
        "name": "Use of Uninitialized Resource",
        "description": "The product uses or accesses a resource that has not been initialized.",
        "detail": "**Extended Description:**\nWhen a resource has not been properly initialized, the product may behave unexpectedly. This may lead to a crash or invalid memory access, but the consequences vary depending on the type of resource and how it is used within the product.\n\n**Consequence Note:** When reusing a resource such as memory or a program variable, the original contents of that resource may not be cleared before it is sent to an untrusted party.\n\n**Consequence Note:** The uninitialized resource may contain values that cause program flow to change in ways that the programmer did not intend.\n",
        "parent": [
            "665"
        ],
        "children": [],
        "related": [
            "909"
        ],
        "scopes": [
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Explicitly initialize the resource before use. If this is performed through an API function or standard procedure, follow all required steps.\n\n**Mitigation:** Pay close attention to complex conditionals that affect initialization, since some branches might not perform the initialization.\n\n**Mitigation:** Avoid race conditions (CWE-362) during initialization routines.\n\n**Mitigation:** Run or compile the product with settings that generate warnings about uninitialized variables or data.\n",
        "languages": []
    },
    {
        "cwe": "909",
        "name": "Missing Initialization of Resource",
        "description": "The product does not initialize a critical resource.",
        "detail": "**Extended Description:**\nMany resources require initialization before they can be properly used. If a resource is not initialized, it could contain unpredictable or expired data, or it could be initialized to defaults that are invalid. This can have security implications when the resource is expected to have certain properties or values.\n\n**Consequence Note:** When reusing a resource such as memory or a program variable, the original contents of that resource may not be cleared before it is sent to an untrusted party.\n\n**Consequence Note:** The uninitialized resource may contain values that cause program flow to change in ways that the programmer did not intend.\n",
        "parent": [
            "665"
        ],
        "children": [],
        "related": [
            "908"
        ],
        "scopes": [
            "Availability",
            "Confidentiality"
        ],
        "mitigation": "**Mitigation:** Explicitly initialize the resource before use. If this is performed through an API function or standard procedure, follow all specified steps.\n\n**Mitigation:** Pay close attention to complex conditionals that affect initialization, since some branches might not perform the initialization.\n\n**Mitigation:** Avoid race conditions (CWE-362) during initialization routines.\n\n**Mitigation:** Run or compile your product with settings that generate warnings about uninitialized variables or data.\n",
        "languages": []
    },
    {
        "cwe": "91",
        "name": "XML Injection (aka Blind XPath Injection)",
        "description": "The product does not properly neutralize special elements that are used in XML, allowing attackers to modify the syntax, content, or commands of the XML before it is processed by an end system.",
        "detail": "**Extended Description:**\nWithin XML, special elements could include reserved words or characters such as \"<\", \">\", \"\"\", and \"&\", which could then be used to add new data or modify XML syntax.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "74"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n",
        "languages": []
    },
    {
        "cwe": "910",
        "name": "Use of Expired File Descriptor",
        "description": "The product uses or accesses a file descriptor after it has been closed.",
        "detail": "**Extended Description:**\nAfter a file descriptor for a particular file or device has been released, it can be reused. The code might not write to the original file, since the reused file descriptor might reference a different file or device.\n\n**Alternate Terms:** Stale file descriptor\n\n**Consequence Note:** The program could read data from the wrong file.\n\n**Consequence Note:** Accessing a file descriptor that has been closed can cause a crash.\n",
        "parent": [
            "672"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality"
        ],
        "mitigation": null,
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "911",
        "name": "Improper Update of Reference Count",
        "description": "The product uses a reference count to manage a resource, but it does not update or incorrectly updates the reference count.",
        "detail": "**Extended Description:**\nReference counts can be used when tracking how many objects contain a reference to a particular resource, such as in memory management or garbage collection. When the reference count reaches zero, the resource can be de-allocated or reused because there are no more objects that use it. If the reference count accidentally reaches zero, then the resource might be released too soon, even though it is still in use. If all objects no longer use the resource, but the reference count is not zero, then the resource might not ever be released.\n\n**Consequence Note:** An adversary that can cause a resource counter to become inaccurate may be able to create situations where resources are not accounted for and not released, thus causing resources to become scarce for future needs.\n\n**Consequence Note:** An adversary that can cause a resource counter to become inaccurate may be able to force an error that causes the product to crash or exit out of its current operation.\n",
        "parent": [
            "664"
        ],
        "children": [],
        "related": [
            "672",
            "772"
        ],
        "scopes": [
            "Availability"
        ],
        "mitigation": null,
        "languages": [
            "C",
            "C++"
        ]
    },
    {
        "cwe": "912",
        "name": "Hidden Functionality",
        "description": "The product contains functionality that is not documented, not part of the specification, and not accessible through an interface or command sequence that is obvious to the product's users or administrators.",
        "detail": "**Extended Description:**\nHidden functionality can take many forms, such as intentionally malicious code, \"Easter Eggs\" that contain extraneous functionality such as games, developer-friendly shortcuts that reduce maintenance or support costs such as hard-coded accounts, etc. From a security perspective, even when the functionality is not intentionally malicious or damaging, it can increase the product's attack surface and expose additional weaknesses beyond what is already exposed by the intended functionality. Even if it is not easily accessible, the hidden functionality could be useful for attacks that modify the control flow of the application.\n",
        "parent": [
            "684"
        ],
        "children": [
            "1242",
            "506"
        ],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** Always verify the integrity of the product that is being installed.\n\n**Mitigation:** Conduct a code coverage analysis using live testing, then closely inspect any code that is not covered.\n",
        "languages": []
    },
    {
        "cwe": "913",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "470",
            "502",
            "914",
            "915",
            "94"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "914",
        "name": "Improper Control of Dynamically-Identified Variables",
        "description": "The product does not properly restrict reading from or writing to dynamically-identified variables.",
        "detail": "**Extended Description:**\nMany languages offer powerful features that allow the programmer to access arbitrary variables that are specified by an input string. While these features can offer significant flexibility and reduce development time, they can be extremely dangerous if attackers can modify unintended variables that have security implications.\n\n**Consequence Note:** An attacker could modify sensitive data or program variables.\n",
        "parent": [
            "913",
            "99"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Mitigation:** For any externally-influenced input, check the input against an allowlist of internal program variables that are allowed to be modified.\n\n**Mitigation:** Refactor the code so that internal program variables do not need to be dynamically identified.\n",
        "languages": []
    },
    {
        "cwe": "915",
        "name": "Improperly Controlled Modification of Dynamically-Determined Object Attributes",
        "description": "The product receives input from an upstream component that specifies multiple attributes, properties, or fields that are to be initialized or updated in an object, but it does not properly control which attributes can be modified.",
        "detail": "**Extended Description:**\n\n\nIf the object contains attributes that were only intended for internal use, then their unexpected modification could lead to a vulnerability.\n\n\nThis weakness is sometimes known by the language-specific mechanisms that make it possible, such as mass assignment, autobinding, or object injection.\n\n\n**Alternate Terms:** Mass Assignment, AutoBinding, PHP Object Injection\n\n**Consequence Note:** An attacker could modify sensitive data or program variables.\n",
        "parent": [
            "913"
        ],
        "children": [],
        "related": [
            "502"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** \n\nIf available, use features of the language or framework that allow specification of allowlists of attributes or fields that are allowed to be modified. If possible, prefer allowlists over denylists.\n\n\nFor applications written with Ruby on Rails, use the attr_accessible (allowlist) or attr_protected (denylist) macros in each class that may be used in mass assignment.\n\n\n**Mitigation:** If available, use the signing/sealing features of the programming language to assure that deserialized data has not been tainted. For example, a hash-based message authentication code (HMAC) could be used to ensure that data has not been modified.\n\n**Mitigation:** For any externally-influenced input, check the input against an allowlist of internal object attributes or fields that are allowed to be modified.\n\n**Mitigation:** Refactor the code so that object attributes or fields do not need to be dynamically identified, and only expose getter/setter functionality for the intended attributes.\n",
        "languages": [
            "ASP.NET",
            "PHP",
            "Python",
            "Ruby"
        ]
    },
    {
        "cwe": "916",
        "name": "Use of Password Hash With Insufficient Computational Effort",
        "description": "The product generates a hash for a password, but it uses a scheme that does not provide a sufficient level of computational effort that would make password cracking attacks infeasible or expensive.",
        "detail": "**Extended Description:**\n\n\nMany password storage mechanisms compute a hash and store the hash, instead of storing the original password in plaintext. In this design, authentication involves accepting an incoming password, computing its hash, and comparing it to the stored hash.\n\n\nMany hash algorithms are designed to execute quickly with minimal overhead, even cryptographic hashes. However, this efficiency is a problem for password storage, because it can reduce an attacker's workload for brute-force password cracking. If an attacker can obtain the hashes through some other method (such as SQL injection on a database that stores hashes), then the attacker can store the hashes offline and use various techniques to crack the passwords by computing hashes efficiently. Without a built-in workload, modern attacks can compute large numbers of hashes, or even exhaust the entire space of all possible passwords, within a very short amount of time, using massively-parallel computing (such as cloud computing) and GPU, ASIC, or FPGA hardware. In such a scenario, an efficient hash algorithm helps the attacker.\n\n\nThere are several properties of a hash scheme that are relevant to its strength against an offline, massively-parallel attack:\n\n\n  - The amount of CPU time required to compute the hash (\"stretching\")\n\n  - The amount of memory required to compute the hash (\"memory-hard\" operations)\n\n  - Including a random value, along with the password, as input to the hash computation (\"salting\")\n\n  - Given a hash, there is no known way of determining an input (e.g., a password) that produces this hash value, other than by guessing possible inputs (\"one-way\" hashing)\n\n  - Relative to the number of all possible hashes that can be generated by the scheme, there is a low likelihood of producing the same hash for multiple different inputs (\"collision resistance\")\n\nNote that the security requirements for the product may vary depending on the environment and the value of the passwords. Different schemes might not provide all of these properties, yet may still provide sufficient security for the environment. Conversely, a solution might be very strong in preserving one property, which still being very weak for an attack against another property, or it might not be able to significantly reduce the efficiency of a massively-parallel attack.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** If an attacker can gain access to the hashes, then the lack of sufficient computational effort will make it easier to conduct brute force attacks using techniques such as rainbow tables, or specialized hardware such as GPUs, which can be much faster than general-purpose CPUs for computing hashes.\n",
        "parent": [
            "327",
            "328"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBytecode Weakness Analysis - including disassembler + source code weakness analysis\n\t\tBinary Weakness Analysis - including disassembler + source code weakness analysis\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tBinary / Bytecode disassembler - then use manual analysis for vulnerabilities & anomalies\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFocused Manual Spotcheck - Focused manual analysis of source\n\t\tManual Source Code Review (not inspections)\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tSource code Weakness Analyzer\n\t\tContext-configured Source Code Weakness Analyzer\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tCost effective for partial coverage:\n```\n\n\t\tConfiguration Checker\n\n**Detection:** \n\nAccording to SOAR, the following detection techniques may be useful:\n\n```\n\t\tHighly cost effective:\n```\n\n\t\tFormal Methods / Correct-By-Construction\n\t```\n\t\tCost effective for partial coverage:\n```\n\n\t\tInspection (IEEE 1028 standard) (can apply to requirements, design, source code, etc.)\n\n**Mitigation:** \n\nUse an adaptive hash function that can be configured to change the amount of computational effort needed to compute the hash, such as the number of iterations (\"stretching\") or the amount of memory required. Some hash functions perform salting automatically. These functions can significantly increase the overhead for a brute force attack compared to intentionally-fast functions such as MD5. For example, rainbow table attacks can become infeasible due to the high computing overhead. Finally, since computing power gets faster and cheaper over time, the technique can be reconfigured to increase the workload without forcing an entire replacement of the algorithm in use.\n\n\nSome hash functions that have one or more of these desired properties include bcrypt [REF-291], scrypt [REF-292], and PBKDF2 [REF-293]. While there is active debate about which of these is the most effective, they are all stronger than using salts with hash functions with very little computing overhead.\n\n\nNote that using these functions can have an impact on performance, so they require special consideration to avoid denial-of-service attacks. However, their configurability provides finer control over how much CPU and memory is used, so it could be adjusted to suit the environment's needs.\n\n\n**Mitigation:** When using industry-approved techniques, use them correctly. Don't cut corners by skipping resource-intensive steps (CWE-325). These steps are often essential for preventing common attacks.\n",
        "languages": []
    },
    {
        "cwe": "917",
        "name": "Improper Neutralization of Special Elements used in an Expression Language Statement ('Expression Language Injection')",
        "description": "The product constructs all or part of an expression language (EL) statement in a framework such as a Java Server Page (JSP) using externally-influenced input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could modify the intended EL statement before it is executed.",
        "detail": "**Extended Description:**\nFrameworks such as Java Server Page (JSP) allow a developer to insert executable expressions within otherwise-static content. When the developer is not aware of the executable nature of these expressions and/or does not disable them, then if an attacker can inject expressions, this could lead to code execution or other unexpected behaviors.\n\n**Alternate Terms:** EL Injection\n",
        "parent": [
            "74",
            "77"
        ],
        "children": [],
        "related": [
            "1336"
        ],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid adding user-controlled data into an expression interpreter when possible.\n\n**Mitigation:** \n\nIf user-controlled data must be added to an expression interpreter, one or more of the following should be performed:\n\n\n  - Validate that the user input will not evaluate as an expression\n\n  - Encode the user input in a way that ensures it is not evaluated as an expression\n\n\n\n**Mitigation:** The framework or tooling might allow the developer to disable or deactivate the processing of EL expressions, such as setting the isELIgnored attribute for a JSP page to \"true\".\n",
        "languages": [
            "Java"
        ]
    },
    {
        "cwe": "918",
        "name": "Server-Side Request Forgery (SSRF)",
        "description": "The web server receives a URL or similar request from an upstream component and retrieves the contents of this URL, but it does not sufficiently ensure that the request is being sent to the expected destination.",
        "detail": "**Alternate Terms:** XSPA, SSRF\n\n**Consequence Note:** By providing URLs to unexpected hosts or ports, attackers can make it appear that the server is sending the request, possibly bypassing access controls such as firewalls that prevent the attackers from accessing the URLs directly. The server can be used as a proxy to conduct port scanning of hosts in internal networks, use other URLs such as that can access documents on the system (using file://), or use other protocols such as gopher:// or tftp://, which may provide greater control over the contents of requests.\n",
        "parent": [
            "441",
            "610"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n",
        "languages": []
    },
    {
        "cwe": "920",
        "name": "Improper Restriction of Power Consumption",
        "description": "The product operates in an environment in which power is a limited resource that cannot be automatically replenished, but the product does not properly restrict the amount of power that its operation consumes.",
        "detail": "**Extended Description:**\n\n\nIn environments such as embedded or mobile devices, power can be a limited resource such as a battery, which cannot be automatically replenished by the product itself, and the device might not always be directly attached to a reliable power source. If the product uses too much power too quickly, then this could cause the device (and subsequently, the product) to stop functioning until power is restored, or increase the financial burden on the device owner because of increased power costs.\n\n\nNormal operation of an application will consume power. However, in some cases, an attacker could cause the application to consume more power than intended, using components such as:\n\n\n  - Display\n\n  - CPU\n\n  - Disk I/O\n\n  - GPS\n\n  - Sound\n\n  - Microphone\n\n  - USB interface\n\n\n\n**Consequence Note:** The power source could be drained, causing the application - and the entire device - to cease functioning.\n",
        "parent": [
            "400"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "921",
        "name": "Storage of Sensitive Data in a Mechanism without Access Control",
        "description": "The product stores sensitive information in a file system or device that does not have built-in access control.",
        "detail": "**Extended Description:**\n\n\nWhile many modern file systems or devices utilize some form of access control in order to restrict access to data, not all storage mechanisms have this capability. For example, memory cards, floppy disks, CDs, and USB devices are typically made accessible to any user within the system. This can become a problem when sensitive data is stored in these mechanisms in a multi-user environment, because anybody on the system can read or write this data.\n\n\nOn Android devices, external storage is typically globally readable and writable by other applications on the device. External storage may also be easily accessible through the mobile device's USB connection or physically accessible through the device's memory card port.\n\n\n**Mode of Introduction:** OMISSION: This weakness is caused by missing a security tactic during the architecture and design phase.\n\n**Consequence Note:** Attackers can read sensitive information by accessing the unrestricted storage mechanism.\n\n**Consequence Note:** Attackers can modify or delete sensitive information by accessing the unrestricted storage mechanism.\n",
        "parent": [
            "922"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "922",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "921"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "923",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "940",
            "941"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "924",
        "name": "Improper Enforcement of Message Integrity During Transmission in a Communication Channel",
        "description": "The product establishes a communication channel with an endpoint and receives a message from that endpoint, but it does not sufficiently ensure that the message was not modified during transmission.",
        "detail": "**Extended Description:**\nAttackers might be able to modify the message and spoof the endpoint by interfering with the data as it crosses the network or by redirecting the connection to a system under their control.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** If an attackers can spoof the endpoint, the attacker gains all the privileges that were intended for the original endpoint.\n",
        "parent": [
            "345"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "925",
        "name": "Improper Verification of Intent by Broadcast Receiver",
        "description": "The Android application uses a Broadcast Receiver that receives an Intent but does not properly verify that the Intent came from an authorized source.",
        "detail": "**Extended Description:**\nCertain types of Intents, identified by action string, can only be broadcast by the operating system itself, not by third-party applications. However, when an application registers to receive these implicit system intents, it is also registered to receive any explicit intents. While a malicious application cannot send an implicit system intent, it can send an explicit intent to the target application, which may assume that any received intent is a valid implicit system intent and not an explicit intent from another application. This may lead to unintended behavior.\n\n**Alternate Terms:** Intent Spoofing\n\n**Consequence Note:** Another application can impersonate the operating system and cause the software to perform an unintended action.\n",
        "parent": [
            "940"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Before acting on the Intent, check the Intent Action to make sure it matches the expected System action.\n",
        "languages": []
    },
    {
        "cwe": "926",
        "name": "Improper Export of Android Application Components",
        "description": "The Android application exports a component for use by other applications, but does not properly restrict which applications can launch the component or access the data it contains.",
        "detail": "**Extended Description:**\n\n\nThe attacks and consequences of improperly exporting a component may depend on the exported component:\n\n\n  - If access to an exported Activity is not restricted, any application will be able to launch the activity. This may allow a malicious application to gain access to sensitive information, modify the internal state of the application, or trick a user into interacting with the victim application while believing they are still interacting with the malicious application.\n\n  - If access to an exported Service is not restricted, any application may start and bind to the Service. Depending on the exposed functionality, this may allow a malicious application to perform unauthorized actions, gain access to sensitive information, or corrupt the internal state of the application.\n\n  - If access to a Content Provider is not restricted to only the expected applications, then malicious applications might be able to access the sensitive data. Note that in Android before 4.2, the Content Provider is automatically exported unless it has been explicitly declared as NOT exported.\n\n\n\n**Background Details:**\n['\\n\\nThere are three types of components that can be exported in an Android application.\\n\\n\\n  - An Activity is an application component that provides a UI for users to interact with. A typical application will have multiple Activity screens that perform different functions, such as a main Activity screen and a separate settings Activity screen.\\n\\n  - A Service is an application component that is started by another component to execute an operation in the background, even after the invoking component is terminated. Services do not have a UI component visible to the user.\\n\\n  - The Content Provider mechanism can be used to share data with other applications or internally within the same application.\\n\\n']\n\n**Consequence Note:** Other applications, possibly untrusted, can launch the Activity.\n\n**Consequence Note:** Other applications, possibly untrusted, can bind to the Service.\n\n**Consequence Note:** Other applications, possibly untrusted, can read or modify the data that is offered by the Content Provider.\n",
        "parent": [
            "285"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If they do not need to be shared by other applications, explicitly mark components with android:exported=\"false\" in the application manifest.\n\n**Mitigation:** If you only intend to use exported components between related apps under your control, use android:protectionLevel=\"signature\" in the xml manifest to restrict access to applications signed by you.\n\n**Mitigation:** Limit Content Provider permissions (read/write) as appropriate.\n\n**Mitigation:** Limit Content Provider permissions (read/write) as appropriate.\n",
        "languages": []
    },
    {
        "cwe": "927",
        "name": "Use of Implicit Intent for Sensitive Communication",
        "description": "The Android application uses an implicit intent for transmitting sensitive data to other applications.",
        "detail": "**Extended Description:**\n\n\nSince an implicit intent does not specify a particular application to receive the data, any application can process the intent by using an Intent Filter for that intent. This can allow untrusted applications to obtain sensitive data. There are two variations on the standard broadcast intent, ordered and sticky.\n\n\nOrdered broadcast intents are delivered to a series of registered receivers in order of priority as declared by the Receivers. A malicious receiver can give itself a high priority and cause a denial of service by stopping the broadcast from propagating further down the chain. There is also the possibility of malicious data modification, as a receiver may also alter the data within the Intent before passing it on to the next receiver. The downstream components have no way of asserting that the data has not been altered earlier in the chain.\n\n\nSticky broadcast intents remain accessible after the initial broadcast. An old sticky intent will be broadcast again to any new receivers that register for it in the future, greatly increasing the chances of information exposure over time. Also, sticky broadcasts cannot be protected by permissions that may apply to other kinds of intents.\n\n\nIn addition, any broadcast intent may include a URI that references data that the receiving component does not normally have the privileges to access. The sender of the intent can include special privileges that grant the receiver read or write access to the specific URI included in the intent. A malicious receiver that intercepts this intent will also gain those privileges and be able to read or write the resource at the specified URI.\n\n\n**Consequence Note:** Other applications, possibly untrusted, can read the data that is offered through the Intent.\n\n**Consequence Note:** The application may handle responses from untrusted applications on the device, which could cause it to perform unexpected or unauthorized actions.\n",
        "parent": [
            "285",
            "668"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If the application only requires communication with its own components, then the destination is always known, and an explicit intent could be used.\n",
        "languages": []
    },
    {
        "cwe": "93",
        "name": "Improper Neutralization of CRLF Sequences ('CRLF Injection')",
        "description": "The product uses CRLF (carriage return line feeds) as a special element, e.g. to separate lines or records, but it does not neutralize or incorrectly neutralizes CRLF sequences from inputs.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "74"
        ],
        "children": [],
        "related": [
            "117"
        ],
        "scopes": [
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid using CRLF as a special sequence.\n\n**Mitigation:** Appropriately filter or quote CRLF sequences in user-controlled input.\n",
        "languages": []
    },
    {
        "cwe": "939",
        "name": "Improper Authorization in Handler for Custom URL Scheme",
        "description": "The product uses a handler for a custom URL scheme, but it does not properly restrict which actors can invoke the handler using the scheme.",
        "detail": "**Extended Description:**\nMobile platforms and other architectures allow the use of custom URL schemes to facilitate communication between applications. In the case of iOS, this is the only method to do inter-application communication. The implementation is at the developer's discretion which may open security flaws in the application. An example could be potentially dangerous functionality such as modifying files through a custom URL scheme.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "862"
        ],
        "children": [],
        "related": [],
        "scopes": [],
        "mitigation": "**Mitigation:** \n\nUtilize a user prompt pop-up to authorize potentially harmful actions such as those modifying data or dealing with sensitive information.\n\n\nWhen designing functionality of actions in the URL scheme, consider whether the action should be accessible to all mobile applications, or if an allowlist of applications to interface with is appropriate.\n\n",
        "languages": []
    },
    {
        "cwe": "94",
        "name": "Improper Control of Generation of Code ('Code Injection')",
        "description": "The product constructs all or part of a code segment using externally-influenced input from an upstream component, but it does not neutralize or incorrectly neutralizes special elements that could modify the syntax or behavior of the intended code segment.",
        "detail": "**Alternate Terms:** Code Injection\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** In some cases, injectable code controls authentication; this may lead to a remote vulnerability.\n\n**Consequence Note:** Injected code can access resources that the attacker is directly prevented from accessing.\n\n**Consequence Note:** When a product allows a user's input to contain code syntax, it might be possible for an attacker to craft the code in such a way that it will alter the intended control flow of the product. As a result, code injection can often result in the execution of arbitrary code. Code injection attacks can also lead to loss of data integrity in nearly all cases, since the control-plane data injected is always incidental to data recall or writing.\n\n**Consequence Note:** Often the actions performed by injected control code are unlogged.\n",
        "parent": [
            "74",
            "913"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Refactor your program so that you do not have to dynamically generate code.\n\n**Mitigation:** \n\nRun your code in a \"jail\" or similar sandbox environment that enforces strict boundaries between the process and the operating system. This may effectively restrict which code can be executed by your product.\n\n\nExamples include the Unix chroot jail and AppArmor. In general, managed code may provide some protection.\n\n\nThis may not be a feasible solution, and it only limits the impact to the operating system; the rest of your application may still be subject to compromise.\n\n\nBe careful to avoid CWE-243 and other weaknesses related to jails.\n\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\nTo reduce the likelihood of code injection, use stringent allowlists that limit which constructs are allowed. If you are dynamically constructing code that invokes a function, then verifying that the input is alphanumeric might be insufficient. An attacker might still be able to reference a dangerous function that you did not intend to allow, such as system(), exec(), or exit().\n\n\n**Mitigation:** Use automated static analysis tools that target this type of weakness. Many modern techniques use data flow analysis to minimize the number of false positives. This is not a perfect solution, since 100% accuracy and coverage are not feasible.\n\n**Mitigation:** Use dynamic tools and techniques that interact with the product using large test suites with many diverse inputs, such as fuzz testing (fuzzing), robustness testing, and fault injection. The product's operation may slow down, but it should not become unstable, crash, or generate incorrect results.\n\n**Mitigation:** Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).\n\n**Mitigation:** Run the code in an environment that performs automatic taint propagation and prevents any command execution that uses tainted variables, such as Perl's \"-T\" switch. This will force the program to perform validation steps that remove the taint, although you must be careful to correctly validate your inputs so that you do not accidentally mark dangerous inputs as untainted (see CWE-183 and CWE-184).\n\n**Mitigation:** \n\nFor Python programs, it is frequently encouraged to use the ast.literal_eval() function instead of eval, since it is intentionally designed to avoid executing code. However, an adversary could still cause excessive memory or stack consumption via deeply nested structures [REF-1372], so the python documentation discourages use of ast.literal_eval() on untrusted data [REF-1373].\n\n",
        "languages": []
    },
    {
        "cwe": "940",
        "name": "Improper Verification of Source of a Communication Channel",
        "description": "The product establishes a communication channel to handle an incoming request that has been initiated by an actor, but it does not properly verify that the request is coming from the expected origin.",
        "detail": "**Extended Description:**\nWhen an attacker can successfully establish a communication channel from an untrusted origin, the attacker may be able to gain privileges and access unexpected functionality.\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Consequence Note:** An attacker can access any functionality that is inadvertently accessible to the source.\n",
        "parent": [
            "346",
            "923"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control"
        ],
        "mitigation": "**Mitigation:** \n\nUse a mechanism that can validate the identity of the source, such as a certificate, and validate the integrity of data to ensure that it cannot be modified in transit using an Adversary-in-the-Middle (AITM) attack.\n\n\nWhen designing functionality of actions in the URL scheme, consider whether the action should be accessible to all mobile applications, or if an allowlist of applications to interface with is appropriate.\n\n",
        "languages": []
    },
    {
        "cwe": "941",
        "name": "Incorrectly Specified Destination in a Communication Channel",
        "description": "The product creates a communication channel to initiate an outgoing request to an actor, but it does not correctly specify the intended destination for that actor.",
        "detail": "**Extended Description:**\n\n\nAttackers at the destination may be able to spoof trusted servers to steal data or cause a denial of service.\n\n\nThere are at least two distinct weaknesses that can cause the product to communicate with an unintended destination:\n\n\n  - If the product allows an attacker to control which destination is specified, then the attacker can cause it to connect to an untrusted or malicious destination. For example, because UDP is a connectionless protocol, UDP packets can be spoofed by specifying a false source address in the packet; when the server receives the packet and sends a reply, it will specify a destination by using the source of the incoming packet - i.e., the false source. The server can then be tricked into sending traffic to the wrong host, which is effective for hiding the real source of an attack and for conducting a distributed denial of service (DDoS). As another example, server-side request forgery (SSRF) and XML External Entity (XXE) can be used to trick a server into making outgoing requests to hosts that cannot be directly accessed by the attacker due to firewall restrictions.\n\n  - If the product incorrectly specifies the destination, then an attacker who can control this destination might be able to spoof trusted servers. While the most common occurrence is likely due to misconfiguration by an administrator, this can be resultant from other weaknesses. For example, the product might incorrectly parse an e-mail or IP address and send sensitive data to an unintended destination. As another example, an Android application may use a \"sticky broadcast\" to communicate with a receiver for a particular application, but since sticky broadcasts can be processed by *any* receiver, this can allow a malicious application to access restricted data that was only intended for a different application.\n\n\n\n**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "923"
        ],
        "children": [],
        "related": [
            "406"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "942",
        "name": "Permissive Cross-domain Policy with Untrusted Domains",
        "description": "The product uses a cross-domain policy file that includes domains that should not be trusted.",
        "detail": "**Extended Description:**\n\n\nA cross-domain policy file (\"crossdomain.xml\" in Flash and \"clientaccesspolicy.xml\" in Silverlight) defines a list of domains from which a server is allowed to make cross-domain requests. When making a cross-domain request, the Flash or Silverlight client will first look for the policy file on the target server. If it is found, and the domain hosting the application is explicitly allowed to make requests, the request is made.\n\n\nTherefore, if a cross-domain policy file includes domains that should not be trusted, such as when using wildcards, then the application could be attacked by these untrusted domains.\n\n\nAn overly permissive policy file allows many of the same attacks seen in Cross-Site Scripting (CWE-79). Once the user has executed a malicious Flash or Silverlight application, they are vulnerable to a variety of attacks. The attacker could transfer private information, such as cookies that may include session information, from the victim's machine to the attacker. The attacker could send malicious requests to a web site on behalf of the victim, which could be especially dangerous to the site if the victim has administrator privileges to manage that site.\n\n\nIn many cases, the attack can be launched without the victim even being aware of it.\n\n\n**Mode of Introduction:** COMMISSION: This weakness refers to an incorrect design related to an architectural security tactic.\n\n**Consequence Note:** An attacker may be able to bypass the web browser's same-origin policy. An attacker can exploit the weakness to manipulate or steal cookies, create requests that can be mistaken for those of a valid user, compromise confidential information, or execute malicious code on the end user systems for a variety of nefarious purposes. Other damaging attacks include the disclosure of end user files, installation of Trojan horse programs, redirecting the user to some other page or site, running ActiveX controls (under Microsoft Internet Explorer) from sites that a user perceives as trustworthy, and modifying presentation of content.\n",
        "parent": [
            "183",
            "863",
            "923"
        ],
        "children": [],
        "related": [
            "668"
        ],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** Avoid using wildcards in the cross-domain policy file. Any domain matching the wildcard expression will be implicitly trusted, and can perform two-way interaction with the target server.\n\n**Mitigation:** For Flash, modify crossdomain.xml to use meta-policy options such as 'master-only' or 'none' to reduce the possibility of an attacker planting extraneous cross-domain policy files on a server.\n\n**Mitigation:** For Flash, modify crossdomain.xml to use meta-policy options such as 'master-only' or 'none' to reduce the possibility of an attacker planting extraneous cross-domain policy files on a server.\n",
        "languages": []
    },
    {
        "cwe": "943",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "89",
            "90"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "95",
        "name": "Improper Neutralization of Directives in Dynamically Evaluated Code ('Eval Injection')",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes code syntax before using the input in a dynamic evaluation call (e.g. \"eval\").",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Mode of Introduction:** This weakness is prevalent in handler/dispatch procedures that might want to invoke a large number of functions, or set a large number of variables.\n\n**Consequence Note:** The injected code could access restricted data / files.\n\n**Consequence Note:** In some cases, injectable code controls authentication; this may lead to a remote vulnerability.\n\n**Consequence Note:** Injected code can access resources that the attacker is directly prevented from accessing.\n\n**Consequence Note:** Code injection attacks can lead to loss of data integrity in nearly all cases as the control-plane data injected is always incidental to data recall or writing. Additionally, code injection can often result in the execution of arbitrary code or at least modify what code can be executed.\n\n**Consequence Note:** Often the actions performed by injected control code are unlogged.\n",
        "parent": [
            "94"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Detection:** Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically, this is done by building a model of data flow and control flow, then searching for potentially-vulnerable patterns that connect \"sources\" (origins of input) with \"sinks\" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)\n\n**Mitigation:** If possible, refactor your code so that it does not need to use eval() at all.\n\n**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** \n\nInputs should be decoded and canonicalized to the application's current internal representation before being validated (CWE-180, CWE-181). Make sure that your application does not inadvertently decode the same input twice (CWE-174). Such errors could be used to bypass allowlist schemes by introducing dangerous inputs after they have been checked. Use libraries such as the OWASP ESAPI Canonicalization control.\n\n\nConsider performing repeated canonicalization until your input does not change any more. This will avoid double-decoding and similar scenarios, but it might inadvertently modify inputs that are allowed to contain properly-encoded dangerous content.\n\n\n**Mitigation:** \n\nFor Python programs, it is frequently encouraged to use the ast.literal_eval() function instead of eval, since it is intentionally designed to avoid executing code. However, an adversary could still cause excessive memory or stack consumption via deeply nested structures [REF-1372], so the python documentation discourages use of ast.literal_eval() on untrusted data [REF-1373].\n\n",
        "languages": [
            "Java",
            "JavaScript",
            "PHP",
            "Perl",
            "Python",
            "Ruby"
        ]
    },
    {
        "cwe": "96",
        "name": "Improper Neutralization of Directives in Statically Saved Code ('Static Code Injection')",
        "description": "The product receives input from an upstream component, but it does not neutralize or incorrectly neutralizes code syntax before inserting the input into an executable resource, such as a library, configuration file, or template.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n\n**Mode of Introduction:** This issue is frequently found in PHP applications that allow users to set configuration variables that are stored within executable PHP files. Technically, this could also be performed in some compiled code (e.g., by byte-patching an executable), although it is highly unlikely.\n\n**Consequence Note:** The injected code could access restricted data / files.\n\n**Consequence Note:** In some cases, injectable code controls authentication; this may lead to a remote vulnerability.\n\n**Consequence Note:** Injected code can access resources that the attacker is directly prevented from accessing.\n\n**Consequence Note:** Code injection attacks can lead to loss of data integrity in nearly all cases as the control-plane data injected is always incidental to data recall or writing. Additionally, code injection can often result in the execution of arbitrary code.\n\n**Consequence Note:** Often the actions performed by injected control code are unlogged.\n",
        "parent": [
            "94"
        ],
        "children": [
            "97"
        ],
        "related": [],
        "scopes": [
            "Access Control",
            "Availability",
            "Confidentiality",
            "Integrity",
            "Non-Repudiation"
        ],
        "mitigation": "**Mitigation:** \n\nAssume all input is malicious. Use an \"accept known good\" input validation strategy, i.e., use a list of acceptable inputs that strictly conform to specifications. Reject any input that does not strictly conform to specifications, or transform it into something that does.\n\n\nWhen performing input validation, consider all potentially relevant properties, including length, type of input, the full range of acceptable values, missing or extra inputs, syntax, consistency across related fields, and conformance to business rules. As an example of business rule logic, \"boat\" may be syntactically valid because it only contains alphanumeric characters, but it is not valid if the input is only expected to contain colors such as \"red\" or \"blue.\"\n\n\nDo not rely exclusively on looking for malicious or malformed inputs. This is likely to miss at least one undesirable input, especially if the code's environment changes. This can give attackers enough room to bypass the intended validation. However, denylists can be useful for detecting potential attacks or determining which inputs are so malformed that they should be rejected outright.\n\n\n**Mitigation:** Perform proper output validation and escaping to neutralize all code syntax from data written to code files.\n",
        "languages": [
            "PHP",
            "Perl"
        ]
    },
    {
        "cwe": "97",
        "name": "Improper Neutralization of Server-Side Includes (SSI) Within a Web Page",
        "description": "The product generates a web page, but does not neutralize or incorrectly neutralizes user-controllable input that could be interpreted as a server-side include (SSI) directive.",
        "detail": "**Mode of Introduction:** REALIZATION: This weakness is caused during implementation of an architectural security tactic.\n",
        "parent": [
            "96"
        ],
        "children": [],
        "related": [],
        "scopes": [
            "Availability",
            "Confidentiality",
            "Integrity"
        ],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "98",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [],
        "related": [
            "73"
        ],
        "scopes": [],
        "mitigation": null,
        "languages": []
    },
    {
        "cwe": "99",
        "name": null,
        "description": null,
        "detail": null,
        "parent": [],
        "children": [
            "641",
            "694",
            "914"
        ],
        "related": [],
        "scopes": [],
        "mitigation": null,
        "languages": []
    }
]
